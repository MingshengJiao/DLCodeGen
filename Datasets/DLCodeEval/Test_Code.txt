import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns
import glob
import random
import os
import cv2
import tensorflow as tf
from tensorflow import keras   
from sklearn.utils import shuffle
from tensorflow.keras.utils import to_categorical
from keras.models import load_model
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Flatten, Dense,BatchNormalization,Dropout,Input,LSTM,Reshape
from keras.models import Sequential, Model
from keras.layers import Conv2D,GlobalMaxPooling2D
from tensorflow.keras.applications import  InceptionV3
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import datasets, layers, models
from keras.layers import Input, Conv2D, MaxPooling2D,BatchNormalization, Dropout
from sklearn.metrics import classification_report,confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from keras import regularizers

seed = 42
np.random.seed =seed

image_path = '/kaggle/input/violence-detection-2024'

MyDrive = '/kaggle/working'
dataset=r"/kaggle/input/violence-detection-2024/real-life-violence-dataset/dataset"
test_path=r"/kaggle/input/violence-detection-2024/real-life-violence-dataset/test"

from tensorflow.keras.preprocessing.image import ImageDataGenerator
IMG_SIZE = 224 
ColorChannels = 3
batch_size = 32

# Create data generators for training and validation
data_datagen = ImageDataGenerator(rescale=1./255 , validation_split=0.27)
test_datagen = ImageDataGenerator(rescale=1./255 )

train_generator = data_datagen.flow_from_directory(
    dataset,
    target_size=(IMG_SIZE, IMG_SIZE),
    color_mode='rgb',
    batch_size=batch_size,
    class_mode='categorical',
    subset='training',
)


validation_generator = data_datagen.flow_from_directory(
    dataset,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=batch_size,
    color_mode='rgb',
    class_mode='categorical',
    subset='validation',

)

test_generator = test_datagen.flow_from_directory(
    test_path,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=batch_size,
    color_mode='rgb',
)


plt.figure(figsize=(15,10))
plt.suptitle("Train Images", fontsize=20)
for i in range(30):
    img, label = train_generator.next()
    plt.subplot(5,6,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    if(label[0][0] == 1):
        plt.xlabel("non-violence")
    else:
        plt.xlabel("violence")
    plt.imshow(img[0])

# input_tensor= Input(shape=(IMG_SIZE, IMG_SIZE, ColorChannels))
# inception_model = InceptionV3(include_top=False, weights='imagenet', input_tensor=input_tensor)
# inception_model.summary()

# def freezing_layers(model_name):
#     for layer in model_name.layers:
#       layer.trainable = False   

# freezing_layers(inception_model)  

# inseption = Sequeinseptionntial()
# inseption.add(inception_model)
# inseption.add(layers.Flatten())
# inseption.add(layers.Dense(2048 ,activation='relu'))
# inseption.add(BatchNormalization())
# inseption.add(Dropout(0.5))
# inseption.add(layers.Dense(2, activation ='softmax'))


epochs=20

kernel_regularizer = regularizers.l2(0.0001)
def Inception_model():
    input_tensor = Input(shape=(IMG_SIZE, IMG_SIZE, ColorChannels))
    baseModel =  InceptionV3(include_top=False, weights='imagenet', input_tensor=input_tensor)
    
    headModel = baseModel.output
    headModel = Flatten()(headModel)
    headModel = Reshape((8, -1))(headModel)
    headModel = LSTM(64,return_sequences = True)(headModel)
    headModel = Dense(128, activation="relu")(headModel)
    headModel = Dense(2, activation="softmax")(headModel)
    model = Model(inputs=baseModel.input, outputs=headModel)

    for layer in baseModel.layers:
        layer.trainable = False

    return model
model = Inception_model()

model.summary()

from keras.callbacks import EarlyStopping,ModelCheckpoint

reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',
                                                  factor=0.6,
                                                  patience=20,
                                                  min_lr=0.00005,
                                                  verbose=1)

checkpoint =ModelCheckpoint("inception.h5", save_best_only=True)

early_stopping =EarlyStopping(patience=5, restore_best_weights=True)

model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

n_training_samples = len(train_generator)
n_validation_samples = len(validation_generator)

history = model.fit(train_generator,
                    epochs=epochs,
                    validation_data=validation_generator, 
                    callbacks = [early_stopping,checkpoint,reduce_lr])

score,acc=inseption.evaluate(test_generator)
print('Test Loss =', score)
print('Test Accuracy =', acc)

plt.figure(figsize=(16,25))
class_label = ['non-violence' , 'violence']
image, label = test_generator.next()
for i in range(18):
    model_pred = inseption.predict(image)
    plt.subplot(7,3,i+1)
    plt.imshow(image[i])
    plt.title(f"Prediction: {class_label[tf.argmax(model_pred[i])]}\nOriginal: {class_label[tf.argmax(label[i])]}")
    plt.axis("off")
plt.show()
-------------------------------------
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        pass
#         print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

import os
import zipfile
import io
import cv2
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, Dense, Flatten, InputLayer
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.preprocessing.image import ImageDataGenerator

IM_SIZE = 140

IM_SIZE = 224

def preprocess_image(image, label):
    # Image data augmentation (you can customize this part)
#     image = tf.image.random_flip_left_right(image)
#     image = tf.image.random_flip_up_down(image)

    # Rescaling pixel values to the range [0, 1]
    image = tf.cast(image, tf.float32) / 255.0

    return image, label

datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255,
#     preprocessing_function=preprocess_image
)

path='/kaggle/input/fresh-stale-dataset'

# fresh_stale_dataset = tf.keras.utils.image_dataset_from_directory(
# # fresh_stale_dataset = datagen.flow_from_directory(
#     path + '/dataset',
#     shuffle=True,  # will do the shuffling later
#     batch_size=1,
#     image_size=(IM_SIZE, IM_SIZE),
#     interpolation='bilinear',
# #     label_mode='categorical',  # Use 'binary' for binary classification
#     label_mode = 'binary',

# )
# fresh_stale_class_names = fresh_stale_dataset.class_names
# fresh_stale_class_names

# fresh_stale_dataset.map(preprocess_image)

dataset1 =  tf.keras.utils.image_dataset_from_directory(
# dataset1 = datage.flow_from_directory(
    path + '/dataset/Fresh',
    shuffle=True,  # will do the shuffling later
    batch_size=1,
    image_size=(IM_SIZE, IM_SIZE),
    interpolation='bilinear',
    label_mode='categorical',  # Use 'binary' for binary classification
    # label_mode = 'binary'
    
)

dataset2 =  tf.keras.utils.image_dataset_from_directory(
# dataset2 = datage.flow_from_directory(
    path + '/dataset/Stale',
    shuffle=True,  # will do the shuffling later
    batch_size=1,
    image_size=(IM_SIZE, IM_SIZE),
    interpolation='bilinear',
    label_mode='categorical',  # Use 'binary' for binary classification
    # label_mode = 'binary'
    
)


combined_class_names = dataset1.class_names + dataset2.class_names
combined_class_names

def update_labels1(x, y):
    zeros_tensor = tf.constant([0, 0, 0, 0, 0, 0], dtype=tf.float32)
    zeros_tensor = tf.expand_dims(zeros_tensor, axis=0)  # Add a batch dimension

    y_concatenated = tf.concat([y, zeros_tensor], axis=1)  # Assuming concatenation along axis=1

    return x, y_concatenated


dataset1 = dataset1.map(update_labels1)

def update_labels2(x, y):
    zeros_tensor = tf.constant([0, 0, 0, 0, 0, 0], dtype=tf.float32)
    zeros_tensor = tf.expand_dims(zeros_tensor, axis=0)  # Add a batch dimension

    y_concatenated = tf.concat([zeros_tensor, y], axis=1)  # Assuming concatenation along axis=1

    return x, y_concatenated


dataset2 = dataset2.map(update_labels2)

combined_dataset = dataset1.concatenate(dataset2)

# Shuffle the combined dataset
combined_dataset = combined_dataset.shuffle(buffer_size=len(combined_dataset))

# Inspect the first few elements
for image, label in combined_dataset.take(5):
    print(image.shape, label.numpy())


combined_dataset.map(preprocess_image)

def splits(dataset, TRAIN_RATIO, VAL_RATIO, TEST_RATIO):
    DATASET_SIZE = len(dataset)

    train_dataset = dataset.take(int(TRAIN_RATIO * DATASET_SIZE))
    val_dataset = dataset.skip(
        int(TRAIN_RATIO * DATASET_SIZE)).take(int(VAL_RATIO * DATASET_SIZE))
    test_dataset = dataset.skip(int(
        (TRAIN_RATIO + VAL_RATIO) * DATASET_SIZE)).take(int(TEST_RATIO * DATASET_SIZE))
    return train_dataset, val_dataset, test_dataset

TRAIN_RATIO = 0.8
VAL_RATIO = 0.1
TEST_RATIO = 0.1

train1_dataset, val1_dataset, test1_dataset = splits(
    combined_dataset, TRAIN_RATIO, VAL_RATIO, TEST_RATIO)

(len(combined_dataset), len(train1_dataset), len(val1_dataset))

for i, (image, label) in enumerate(train1_dataset.take(16)):
    image = np.squeeze(image, axis=0).astype("uint8")
    ax = plt.subplot(4, 4, i + 1)
    plt.imshow(image)
    class_idx = tf.argmax(tf.cast(label, dtype=tf.int32), axis=1).numpy()

    inferred_label = combined_class_names[class_idx[0]]
    plt.title(inferred_label)
    plt.axis('off')

plt.show()

train1_dataset.element_spec

def squeeze_function(x, y):
    return tf.squeeze(x, axis=0), tf.squeeze(y, axis=0)

train1_dataset = train1_dataset.map(squeeze_function).shuffle(
    buffer_size=8, reshuffle_each_iteration=True).batch(32).prefetch(tf.data.AUTOTUNE)
val1_dataset = val1_dataset.map(squeeze_function).shuffle(
    buffer_size=8, reshuffle_each_iteration=True).batch(32).prefetch(tf.data.AUTOTUNE)

train1_dataset.element_spec

import keras
from keras.layers import Dense,Dropout, Conv2D,MaxPooling2D , Activation, Flatten, BatchNormalization, SeparableConv2D
from keras.models import Sequential
from tensorflow.keras.applications import VGG16, ResNet50



resize_and_rescale = tf.keras.Sequential([
  tf.keras.layers.Resizing(IM_SIZE, IM_SIZE),
  tf.keras.layers.Rescaling(1./255)
])

model1 = Sequential()

# model1.add(resize_and_rescale)
model1.add(Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same', activation='relu', input_shape=(IM_SIZE,IM_SIZE,3)))
# model1.add(Conv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same', activation='relu'))
model1.add(BatchNormalization())
model1.add(SeparableConv2D(32, (3, 3), kernel_initializer='he_uniform', padding='same', activation='relu'))
model1.add(MaxPooling2D((2, 2)))
model1.add(BatchNormalization())
model1.add(Dropout(0.3))

model1.add(SeparableConv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same', activation='relu'))
model1.add(SeparableConv2D(64, (3, 3), kernel_initializer='he_uniform', padding='same', activation='relu'))
model1.add(BatchNormalization())
model1.add(MaxPooling2D((2, 2)))
model1.add(Dropout(0.4))

model1.add(Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same', activation='relu'))
# model1.add(BatchNormalization())
model1.add(Conv2D(128, (3, 3), kernel_initializer='he_uniform', padding='same', activation='relu'))
model1.add(BatchNormalization())
model1.add(MaxPooling2D((2, 2)))
model1.add(Dropout(0.5))

model1.add(Flatten())

#model1.add(Dense(512, activation='relu', kernel_initializer='he_uniform'))
#model1.add(Dropout(0.5))
model1.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
model1.add(Dropout(0.3))

model1.add(Dense(12, activation='softmax'))

# base_model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(IM_SIZE, IM_SIZE, 3))  

# model1 = Sequential()
# model1.add(base_model_vgg16)
# model1.add(Flatten())
# model1.add(Dense(256, activation='relu'))
# model1.add(Dropout(0.5))
# model1.add(Dense(12, activation='softmax'))  # num_classes is the number of classes in your dataset




# # Define the CNN model
# model = Sequential()

# # Convolutional and pooling layers
# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))
# model.add(MaxPooling2D((2, 2)))
# model.add(Conv2D(64, (3, 3), activation='relu'))
# model.add(MaxPooling2D((2, 2)))
# model.add(Conv2D(128, (3, 3), activation='relu'))
# model.add(MaxPooling2D((2, 2)))

# # Flatten layer to transition from convolutional to dense layers
# model.add(Flatten())

# # Dense layers
# model.add(Dense(128, activation='relu'))
# model.add(Dropout(0.5))  # Adding dropout for regularization
# model.add(Dense(64, activation='relu'))

# # Output layer with softmax activation for multi-class classification
# model.add(Dense(12, activation='softmax'))






model1.summary()

lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.001,
    decay_steps=1000,
    decay_rate=0.9,
    staircase=True)

optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)
model1.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
history = model1.fit(train1_dataset, validation_data=val1_dataset, epochs=20, verbose=1, batch_size=100, callbacks = [early_stopping])

-------------------------------------
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os


# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

import pandas as pd
import os
import cv2
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import LabelEncoder



import numpy as np
from tensorflow.keras.applications.mobilenet import preprocess_input

from wordcloud import WordCloud

from tensorflow.keras.preprocessing.image import ImageDataGenerator



from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D, Dropout, Dense
from tensorflow.keras.models import Model
import tensorflow as tf

df =  pd.read_csv('/kaggle/input/dog-breed-identification/labels.csv')
train = '/kaggle/input/dog-breed-identification/train'
test =  '/kaggle/input/dog-breed-identification/test'

df.info()

df.head()

plt.figure(figsize=(50,40))
sns.countplot(y="breed",data=df,palette="Set1")
plt.show()

print(10222/120)

print("Total number of unique Dog Breeds :",len(df.breed.unique()))

nrow=5
ncol=5
fig,ax=plt.subplots(nrow,ncol,figsize=(10,10))
for i,(img_id,breed) in enumerate(df[["id","breed"]].values[: nrow*ncol]):
    image_path=os.path.join(train,img_id+".jpg")
    image=cv2.imread(image_path)
    image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)
    row=i//ncol
    col=i%ncol
    ax[row,col].imshow(image)
    ax[row,col].set_title(breed)
    ax[row,col].axis("off")
    
plt.tight_layout()
plt.show()

num_breed = 120
image_size = 200
batch_size = 32
encoder = LabelEncoder()

breed=list(df["breed"].value_counts().keys())
new=sorted(breed,reverse=True)[: num_breed]
df=df.query("breed in @new")
df

df['image_file'] = df['id'].apply(lambda x: x + ".jpg")
df.head()

import numpy as np
from tensorflow.keras.applications.mobilenet import preprocess_input

import os
import cv2
import numpy as np
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

train_data=np.zeros((len(df),image_size,image_size,3),dtype="float32")

for i,img_id in enumerate(df["image_file"]):
    print(f"Reading image: {img_id}")
    
    img_path = os.path.join(train, img_id)
    
    if not os.path.exists(img_path):
        print(f"Image not found: {img_path}")
        continue
    
    img=cv2.resize(cv2.imread(img_path,cv2.IMREAD_UNCHANGED),((image_size,image_size)))
    
    if not np.any(img):
        print(f"Empty image: {img_path}")
        continue
    
    img_array=preprocess_input(np.expand_dims(np.array(img[...,: : -1].astype(np.float32)).copy(),axis=0))
    train_data[i]=img_array

train_data[i]

lab = df["breed"].unique().tolist()
print(lab)

from wordcloud import WordCloud
text = ' '.join(lab)
wordcloud = WordCloud(width=800, height=400, background_color='white',colormap="rainbow").generate(text)
plt.figure(figsize=(15, 10))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

label_data = encoder.fit_transform(df["breed"].values)
from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(train_data,label_data,test_size=0.2,random_state=42)

from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(rotation_range=45,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.25,
                                   horizontal_flip=True,
                                   fill_mode='nearest')

train_generator = train_datagen.flow(x_train, 
                                     y_train, 
                                     batch_size=batch_size)

test_datagen = ImageDataGenerator()
 
test_generator = test_datagen.flow(x_test, 
                                   y_test, 
                                   batch_size=batch_size)

resnet = ResNet50V2(input_shape = [image_size,image_size,3], weights='imagenet', include_top=False)
for layer in resnet.layers:
    layer.trainable = False
x = resnet.output
x = BatchNormalization()(x)
x = GlobalAveragePooling2D()(x)
# x = Dropout(0.2)(x)
x = Dense(1024, activation='relu')(x)
x = Dense(512, activation='relu')(x)
# x = Dropout(0.5)(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.2)(x)
prediction = Dense(num_breed, activation='softmax')(x)
model = Model(inputs=resnet.input, outputs=prediction)

learning_rate = 1e-3
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics=["accuracy"])
model.summary()

history = model.fit(train_generator,steps_per_epoch= x_train.shape[0] // batch_size,epochs=15,
                 validation_data= test_generator,
                 validation_steps= x_test.shape[0] // batch_size)n


learning_rate

plt.figure(figsize=(7,5))
plt.plot(history.history['accuracy'],label="Train_Accuracy",color="blue",marker="*")
plt.plot(history.history['val_accuracy'],label="Validation_Accuracy",color="red",marker="P")
plt.grid(True)
plt.legend()
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.show()

plt.figure(figsize=(7,5))
plt.plot(history.history['loss'],color="green",marker="D")
plt.plot(history.history['val_loss'],color="navy",marker="H")
plt.grid(True)
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['Train_Loss', 'Validation_Loss'], loc='upper left')
plt.show()

pre=model.predict(x_test)
predict=np.argmax(pre,axis=1)

from sklearn.metrics import confusion_matrix, classification_report
plt.figure(figsize=(50,30))
cf=confusion_matrix(y_test,predict)
sns.heatmap(cf,annot=True,fmt="d",cmap="jet",lw=4,linecolor="black",xticklabels=lab,yticklabels=lab)
plt.show()

print(classification_report(y_test,predict,target_names=lab))

import requests
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image, ImageDraw, ImageFont
from io import BytesIO
import tensorflow as tf


image_url = "https://images.ctfassets.net/sfnkq8lmu5d7/2gSHy100UdEdOiUne89849/0e93f7efd56a73fb773970dbe2c4f5c7/shutterstock_1793062390.jpg?w=1000&h=750&fl=progressive&q=70&fm=jpg"
# Load the image from the URL
response = requests.get(image_url)
image_path = Image.open(BytesIO(response.content))
image_resized_rgb = image_path.resize((224, 224)).convert('RGB')
image_array_rgb = np.array(image_resized_rgb)
image_scale_rgb = image_array_rgb.astype("float32") / 255.0
image_reshape_rgb = image_scale_rgb.reshape(1, 224, 224, 3)  
final_pred = model.predict(image_reshape_rgb)[0]
max_prob = np.argmax(final_pred)
results = lab  
my_predict = results[max_prob]
myFont = ImageFont.truetype('/kaggle/input/hack-font/Hack-Bold.ttf',8)
image_draw = ImageDraw.Draw(image_resized_rgb)
image_draw.text((10, 10), f"Predicted class: {my_predict}", font=myFont, fill=(255, 20, 30))
image_resized_rgb.save("my_image.png")
plt.figure(figsize=(8, 8))
plt.imshow(image_resized_rgb)
plt.axis("off")
plt.show()

import pickle

with open("modelidentifikasi.pkl", "wb") as save:
    pickle.dump(history, save)

with open("model.pkl", "rb") as save:
    model = pickle.load(save)
-------------------------------------
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D
from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import categorical_crossentropy
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications import imagenet_utils
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.applications.resnet50 import ResNet50
from sklearn.utils.class_weight import compute_class_weight
from keras.models import Model
from keras.layers import Dense
from sklearn.model_selection import StratifiedKFold
from keras.layers import Flatten
from sklearn.metrics import confusion_matrix
import itertools
import os
import pandas as pd
import shutil
import random
import glob
import matplotlib.pyplot as plt
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
%matplotlib inline

# Define the root directory
root_dir = '/kaggle/input/leaf-and-plant-cv/leaf'

# Initialize lists to store data
image_paths = []
subsets = []
targets = []

# Iterate through the train and test directories
for subset in ['train', 'test']:
    subset_path = os.path.join(root_dir, subset)

    # Iterate through each class folder
    for class_folder in os.listdir(subset_path):
        class_path = os.path.join(subset_path, class_folder)

        # Iterate through images in the class folder
        for image_filename in os.listdir(class_path):
            image_path = os.path.join(class_path, image_filename)

            # Append data to lists
            image_paths.append(image_path)
            subsets.append(subset)
            targets.append(class_folder)

# Create DataFrame
df = pd.DataFrame({
    'Image Path': image_paths,
    'Subset': subsets,
    'Target': targets
})

# Display the DataFrame
print(df.head())

# Specify the output CSV file path
output_csv_path = '/kaggle/working/leaf_classification.csv'

# Save the DataFrame to a CSV file
df.to_csv(output_csv_path, index=False)

# Print a message indicating the successful conversion
print(f"DataFrame has been successfully saved to {output_csv_path}")


# Filter the DataFrame to get only the "train" subset
train_df = df[df['Subset'] == 'train']
test_df = df[df['Subset'] == 'test']

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    #plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], '.2f'),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

def plotImages(images_arr):
    fig, axes = plt.subplots(1, 10, figsize=(20,20))
    axes = axes.flatten()
    for img, ax in zip( images_arr, axes):
        ax.imshow(img)
        ax.axis('off')
    plt.tight_layout()
    plt.show()

TRAIN_PATH = "/kaggle/input/leaf-and-plant-cv/leaf/train"
TEST_PATH = "/kaggle/input/leaf-and-plant-cv/leaf/test"

train_datagen = train_batches = ImageDataGenerator(
    rotation_range=20,  # Increased rotation range
    width_shift_range=0.2,  # Increased shift range
    height_shift_range=0.2,  # Increased shift range
    shear_range=0.2,  # Increased shear range
    zoom_range=0.2,  # Increased zoom range
    channel_shift_range=20.,  # Increased channel shift range
    horizontal_flip=True,
    preprocessing_function=tf.keras.applications.vgg16.preprocess_input)

valid_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input)

test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input)

classes=["Healthy", "Bunchy top", "Fusarium wilt", "Moko"]

from sklearn.model_selection import StratifiedKFold
data_kfold = pd.DataFrame()

accuracy_list = []
precision_list = []
recall_list = []

# k-fold
kfold = StratifiedKFold(n_splits=10,shuffle=True,random_state=42)
# Variable for keeping count of split we are executing
j = 0

for train_idx, val_idx in list(kfold.split(train_df['Image Path'],train_df['Target'])):
    x_train_df = df.iloc[train_idx]
    x_valid_df = df.iloc[val_idx]
    j+=1
    
    train_batches = train_datagen.flow_from_dataframe(dataframe=x_train_df,
                                                 x_col="Image Path", y_col="Target",
                                                 class_mode="categorical",
                                                classes=classes,
                                                 target_size=(224, 224), batch_size=32, shuffle=True)
    valid_batches = valid_datagen.flow_from_dataframe(dataframe=x_valid_df,
                                                 x_col="Image Path", y_col="Target",
                                                 class_mode="categorical", classes=classes,
                                                 target_size=(224, 224), batch_size=32, shuffle=False)
    test_batches = test_datagen.flow_from_dataframe(dataframe=test_df, classes=classes,
                                                 x_col="Image Path",y_col="Target",
                                                 class_mode=None,
                                                 target_size=(224,224), shuffle=False)
    assert test_batches.n == 170
    
    imgs, labels = next(train_batches)
    #test_imgs, test_labels = next(test_batches)
    plotImages(imgs)
    print(labels)
                
    # Load ResNet50 with pre-trained weights, including the top (fully connected) layer
    resnet50_model = ResNet50(weights='imagenet', include_top=True, input_shape=(224, 224, 3))

    # Remove the last dense layer (the output layer of the original ResNet50)
    resnet50_output = resnet50_model.layers[-2].output

    # Add your custom output layer
    custom_output_layer = Dense(4, activation='softmax')(resnet50_output)

    # Create a new model with ResNet50 as the input and your custom output layer
    leaf_classifier = Model(inputs=resnet50_model.input, outputs=custom_output_layer)
    
    class_weights = compute_class_weight('balanced', classes=np.unique(train_batches.classes), y=train_batches.classes)
    class_weight_dict = dict(enumerate(class_weights))
    
    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
    model_checkpoint = ModelCheckpoint(f'leaf_classifier{j}.h5', monitor='val_loss', save_best_only=True)
    
    leaf_classifier.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])
    
    history = leaf_classifier.fit(
    x=train_batches,
    validation_data=valid_batches,
    callbacks=[early_stopping, model_checkpoint],
    class_weight=class_weight_dict,
    verbose=1,
    epochs=2,
)
    
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('Model accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend(['Train', 'Validation'], loc='upper left')
    plt.show()
    
    # Evaluate the model on the validation set
    valid_batches.reset()  # Reset the validation generator
    valid_pred = leaf_classifier.predict(valid_batches)
    valid_predicted_class_indices = np.argmax(valid_pred, axis=1)
    
    # Calculate metrics for the current fold on the validation set
    val_true_labels = valid_batches.classes
    val_accuracy = accuracy_score(val_true_labels, valid_predicted_class_indices)
    val_precision = precision_score(val_true_labels, valid_predicted_class_indices, average='macro')
    val_recall = recall_score(val_true_labels, valid_predicted_class_indices, average='macro')

    # Store metrics for the current fold on the validation set
    accuracy_list.append(val_accuracy)
    precision_list.append(val_precision)
    recall_list.append(val_recall)
    
    print("Val acc: ", val_accuracy)
    print("Val prec: ", val_precision)
    print("Val rec: ", val_recall)
    
    # Generate classification report
    report = classification_report(val_true_labels, valid_predicted_class_indices, target_names=list(train_batches.class_indices.keys()), digits=4)

    # Print the classification report
    print(report)
    pred= leaf_classifier.predict(test_batches)

    predicted_class_indices=np.argmax(pred,axis=1)

    data_kfold[j] = predicted_class_indices
# After all folds, calculate average and standard deviation of metrics on the validation set

average_val_accuracy = np.mean(accuracy_list)
std_dev_val_accuracy = np.std(accuracy_list)

average_val_precision = np.mean(precision_list)
std_dev_val_precision = np.std(precision_list)

average_val_recall = np.mean(recall_list)
std_dev_val_recall = np.std(recall_list)

# Return the means and standard deviations
mean_and_std_dev = {
    'accuracy_mean': average_val_accuracy,
    'accuracy_std_dev': std_dev_val_accuracy,
    'precision_mean': average_val_precision,
    'precision_std_dev': std_dev_val_precision,
    'recall_mean': average_val_recall,
    'recall_std_dev': std_dev_val_recall
}

print(mean_and_std_dev)

ans = test_df.copy()
# Reset the indices of the 'ans' DataFrame
ans.reset_index(drop=True, inplace=True)

labels=(train_batches.class_indices)
labels2=dict((v,k) for k,v in labels.items())
import collections 
for i in range(len(data_kfold)):
    co = collections.Counter(data_kfold.loc[i])
    co = sorted(co.items(),key=lambda x: x[1],reverse=True)
    ans.Target.loc[i] = labels2[co[0][0]]



# Generate classification report
report = classification_report(test_df['Target'], ans['Target'], target_names=list(train_batches.class_indices.keys()), digits=4)

# Print the classification report
print(report)

plot_confusion_matrix(confusion_matrix(test_df['Target'], ans['Target']), list(train_batches.class_indices.keys()), normalize=True)
-------------------------------------
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split
import keras
# from keras.models import Model, load_model
# from keras.layers import Input ,BatchNormalization , Activation 
# from keras.layers.convolutional import Conv2D, UpSampling2D
# from keras.layers.pooling import MaxPooling2D
# from keras.layers.merge import concatenate
from tensorflow.keras.layers import concatenate
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D,BatchNormalization,Activation
from tensorflow.keras.models import Model, load_model
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras import optimizers 
from sklearn.model_selection import train_test_split
import os
import nibabel as nib
import cv2 as cv
import matplotlib.pyplot as plt
from keras import backend as K
import glob
import skimage.io as io
import skimage.color as color
import random as r
import math
from nilearn import plotting
# for dirname, _, filenames in os.walk('/kaggle/input'):
#     for filename in filenames:
#         print(os.path.join(dirname, filename))

Flair= nib.load('../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_003/BraTS20_Training_003_flair.nii')
Seg= nib.load('../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_003/BraTS20_Training_003_seg.nii')
T1= nib.load('../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_003/BraTS20_Training_003_t1.nii')
T1ce= nib.load('../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_003/BraTS20_Training_003_t1ce.nii')
T2= nib.load('../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_003/BraTS20_Training_003_t2.nii')

Path= '../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'
p=os.listdir(Path)
Input_Data= []
def Data_Preprocessing(modalities_dir):
    all_modalities = []    
    for modality in modalities_dir:      
        nifti_file   = nib.load(modality)
        brain_numpy  = np.asarray(nifti_file.dataobj)    
        all_modalities.append(brain_numpy)
    brain_affine   = nifti_file.affine
    all_modalities = np.array(all_modalities)
    all_modalities = np.rint(all_modalities).astype(np.int16)
    all_modalities = all_modalities[:, :, :, :]
    all_modalities = np.transpose(all_modalities)
    return all_modalities
for i in p[:20]:
    brain_dir = os.path.normpath(Path+'/'+i)
    flair     = glob.glob(os.path.join(brain_dir, '*_flair*.nii'))
    t1        = glob.glob(os.path.join(brain_dir, '*_t1*.nii'))
    t1ce      = glob.glob(os.path.join(brain_dir, '*_t1ce*.nii'))
    t2        = glob.glob(os.path.join(brain_dir, '*_t2*.nii'))
    gt        = glob.glob( os.path.join(brain_dir, '*_seg*.nii'))
    modalities_dir = [flair[0], t1[0], t1ce[0], t2[0], gt[0]]
    P_Data = Data_Preprocessing(modalities_dir)
    Input_Data.append(P_Data)


fig = plt.figure(figsize=(5,5))
immmg = Input_Data[10][100,:,:,0]
imgplot = plt.imshow(immmg)
plt.show()

def Data_Concatenate(Input_Data):
    counter=0
    Output= []
    for i in range(5):
        print('$')
        c=0
        counter=0
        for ii in range(len(Input_Data)):
            if (counter != len(Input_Data)):
                a= Input_Data[counter][:,:,:,i]
                #print('a={}'.format(a.shape))
                b= Input_Data[counter+1][:,:,:,i]
                #print('b={}'.format(b.shape))
                if(counter==0):
                    c= np.concatenate((a, b), axis=0)
                    print('c1={}'.format(c.shape))
                    counter= counter+2
                else:
                    c1= np.concatenate((a, b), axis=0)
                    c= np.concatenate((c, c1), axis=0)
                    print('c2={}'.format(c.shape))
                    counter= counter+2
        c= c[:,:,:,np.newaxis]
        Output.append(c)
    return Output

InData= Data_Concatenate(Input_Data)

AIO= concatenate(InData, axis=3)
AIO=np.array(AIO,dtype='float32')
TR=np.array(AIO[:,:,:,1],dtype='float32')
TRL=np.array(AIO[:,:,:,4],dtype='float32')

X_train , X_test, Y_train, Y_test = train_test_split(TR, TRL, test_size=0.15, random_state=32)
AIO=TRL=0

def Convolution(input_tensor,filters):
    
    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1))(input_tensor)
    x = BatchNormalization()(x)
    x = Activation('relu')(x) 
    return x



def model(input_shape):
    
    inputs = Input((input_shape))
    
    conv_1 = Convolution(inputs,32)
    maxp_1 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_1)
    
    conv_2 = Convolution(maxp_1,64)
    maxp_2 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_2)
    
    conv_3 = Convolution(maxp_2,128)
    maxp_3 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_3)
    
    # ASPP Module
    aspp1 = Conv2D(256, 1, activation='relu', padding='same', kernel_initializer='he_normal')(maxp_3)
    aspp2 = Conv2D(256, 3, activation='relu', padding='same', dilation_rate=1, kernel_initializer='he_normal')(maxp_3)
    aspp3 = Conv2D(256, 3, activation='relu', padding='same', dilation_rate=2, kernel_initializer='he_normal')(maxp_3)
    aspp4 = Conv2D(256, 3, activation='relu', padding='same', dilation_rate=4, kernel_initializer='he_normal')(maxp_3)
    concat_aspp = concatenate([aspp1, aspp2, aspp3, aspp4], axis=3)
    
    conv_4 = Convolution(concat_aspp,256)
    maxp_4 = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same') (conv_4)
    
    conv_5 = Convolution(maxp_4,512)
    upsample_6 = UpSampling2D((2, 2)) (conv_5)
    
    conv_6 = Convolution(upsample_6,256)
    upsample_7 = UpSampling2D((2, 2)) (conv_6)
    
    upsample_7 = concatenate([upsample_7, conv_3])
    
    conv_7 = Convolution(upsample_7,128)
    upsample_8 = UpSampling2D((2, 2)) (conv_7)
    
    conv_8 = Convolution(upsample_8,64)
    upsample_9 = UpSampling2D((2, 2)) (conv_8)
    
    upsample_9 = concatenate([upsample_9, conv_1])
    
    conv_9 = Convolution(upsample_9,32)
    outputs = Conv2D(1, (1, 1), activation='sigmoid') (conv_9)
    
    model = Model(inputs=[inputs], outputs=[outputs]) 
    
    return model




input_shape = (240,240,1)
model = model(input_shape)
model.summary()

def dice_coef(y_true, y_pred, smooth=1.0):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)

# Computing Precision 
def precision(y_true, y_pred):
        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
        precision = true_positives / (predicted_positives + K.epsilon())
        return precision

# Computing Sensitivity      
def sensitivity(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    return true_positives / (possible_positives + K.epsilon())

# Computing Specificity
def specificity(y_true, y_pred):
    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))
    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))
    return true_negatives / (possible_negatives + K.epsilon())

Adam=optimizers.Adam(lr=0.001)
model.compile(optimizer=Adam, loss='binary_crossentropy', metrics=['accuracy',dice_coef,precision,sensitivity,specificity])

history = model.fit(X_train,Y_train,batch_size=32,epochs=1,validation_split=0.20,verbose=1,initial_epoch=0)

model.evaluate(x=X_train, y=Y_train, batch_size=32 , verbose=1, sample_weight=None, steps=None)
model.evaluate(x=X_test, y=Y_test, batch_size=32, verbose=1, sample_weight=None, steps=None)

def load_and_preprocess_nifti(file_path, target_shape=(240, 240, 1)):
    img_nifti = nib.load(file_path)
    img_data = img_nifti.get_fdata()

    # Transpose to have the correct orientation
    img_data = np.transpose(img_data)

    # Resize each dimension separately
    resized_data = np.zeros(target_shape, dtype=img_data.dtype)
    for i in range(target_shape[2]):
        slice_resized = tf.image.resize(img_data[:, :, int(i * img_data.shape[2] / target_shape[2]), np.newaxis], target_shape[:2], method=tf.image.ResizeMethod.BICUBIC)[:, :, 0].numpy()
        resized_data[:, :, i] = slice_resized

    # Add any other preprocessing steps here (e.g., normalization)
    # ...

    return resized_data


import cv2
input_nifti_path ='/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_flair.nii'
# input_image = immmg

# target_mask = np.random.randint(0, 2, size=input_image.shape)

# # Train the model (replace input_image and target_mask with your actual data)
# model.fit(np.expand_dims(input_image, axis=0), np.expand_dims(target_mask, axis=0), epochs=10, batch_size=1)

# Make predictions
for i in range (0,10):
    input_image=Input_Data[i][100,:,:,0]
    predicted_mask = model.predict(np.expand_dims(input_image, axis=0))
    plt.subplot(1, 2, 1)
    plt.imshow(input_image, cmap='gray')
    plt.title('Original Brain Image')

    plt.subplot(1, 2, 2)
    plt.imshow(predicted_mask[0, :, :,0 ], cmap='gray')
    plt.title('Predicted Segmentation Mask')

    plt.show()

plt.subplot(1, 2, 1)
plt.imshow(input_image, cmap='gray')
plt.title('Original Brain Image')

plt.subplot(1, 2, 2)
plt.imshow(predicted_mask[0, :, :,0 ], cmap='gray')
plt.title('Predicted Segmentation Mask')

plt.show()

model.save('./BraTs2020.h5')

model.load_weights('./BraTs2020.h5')

fig = plt.figure(figsize=(5,5))
immmg = TR[90,:,:]
imgplot = plt.imshow(immmg)
plt.show()

pref_Tumor = model.predict(TR)

fig = plt.figure(figsize=(5,5))
immmg = pref_Tumor[90,:,:,0]
imgplot = plt.imshow(immmg)
plt.show() 

import random
import math  # cos() for Rastrigin
import copy  # array-copying convenience
import sys  # max float


# -------fitness functions---------

# rastrigin function
def fitness_rastrigin(position):
    fitness_value = 0.0
    for i in range(len(position)):
        xi = position[i]
        fitness_value += (xi * xi) - (10 * math.cos(2 * math.pi * xi)) + 10
    return fitness_value


# sphere function
def fitness_sphere(position):
    fitness_value = 0.0
    for i in range(len(position)):
        xi = position[i]
        fitness_value += (xi * xi);
    return fitness_value;


# -------------------------

# trade class
class trade:
    def __init__(self, fitness, dim, minx, maxx, seed):
        self.rnd = random.Random(seed)

        # a list of size dim
        # with 0.0 as value of all the elements
        self.position = [0.0 for i in range(dim)]

        # loop dim times and randomly select value of decision var
        # value should be in between minx and maxx
        for i in range(dim):
            self.position[i] = ((maxx - minx) *
                                self.rnd.random() + minx)

        # compute the fitness of trade
        self.fitness = fitness(self.position)


# Teaching learning based optimization
def seto(fitness, max_iter, n, dim, minx, maxx):
    rnd = random.Random(0)
    gh =255
    # create n random trades
    seller= [trade(fitness, dim, minx, maxx, i) for i in range(n)]

    # compute the value of best_position and best_fitness in the seller
    Xbest = [0.0 for i in range(dim)]
    Fbest = sys.float_info.max

    for i in range(n):  # check each trade
        if seller[i].fitness < Fbest:
            Fbest = seller[i].fitness
            Xbest = copy.copy(seller[i].position)

    # main loop of seto
    Iter = 0
    while Iter < max_iter:

        # after every 10 iterations
        # print iteration number and best fitness value so far
        # if Iter % 10 == 0 and Iter > 1:
        #     print("Iter = " + str(Iter) + " best fitness = %.3f" % Fbest)

        # for each trade of seller
        for i in range(n):
          ###            #
            Xmean = [0.0 for i in range(dim)]
            for k in range(n):
                for j in range(dim):
                    Xmean[j] += seller[k].position[j]

            for j in range(dim):
                Xmean[j] /= n;

            # initialize new solution
            Xnew = [0.0 for i in range(dim)]
            TF = random.randint(1, 3)

            # best trade
            Xteacher = Xbest

            # compute new solution
            for j in range(dim):
                Xnew[j] = seller[i].position[j] + rnd.random() * (Xteacher[j] - TF * Xmean[j])############

            for j in range(dim):
                Xnew[j] = max(Xnew[j], minx)
                Xnew[j] = min(Xnew[j], maxx)

            # compute fitness of new solution
            fnew = fitness(Xnew)

            if (fnew < seller[i].fitness):
                seller[i].position = Xnew
                seller[i].fitness = fnew

            # update best trade
            if (fnew < Fbest):
                Fbest = fnew
                Xbest = Xnew

            p = random.randint(0, n - 1)
            while (p == i):
                p = random.randint(0, n - 1)

            # partner solution
            Xpartner = seller[p]

            Xnew = [0.0 for i in range(dim)]
            if (seller[i].fitness < Xpartner.fitness):
                for j in range(dim):
                    Xnew[j] = seller[i].position[j] + rnd.random() * (
                                seller[i].position[j] - Xpartner.position[j])
            else:
                for j in range(dim):
                    Xnew[j] = seller[i].position[j] - rnd.random() * (
                                seller[i].position[j] - Xpartner.position[j])

            for j in range(dim):
                Xnew[j] = max(Xnew[j], minx)
                Xnew[j] = min(Xnew[j], maxx)

            # compute fitness of new solution
            fnew = fitness(Xnew)

            if (fnew < seller[i].fitness):
                seller[i].position = Xnew
                seller[i].fitness = fnew
            if (fnew < Fbest):
                Fbest = fnew
                Xbest = Xnew
            if Xbest[1] >= gh:
                Xbest = gh

        Iter += 1

    return Xbest
def main(num_particles ,max_iter):
    dim = 3
    fitness = fitness_rastrigin
    # for i in range(dim - 1):
    #     print("0, ", end="")
    # print("0)")
    import numpy as np
    # num_particles = 50
    # max_iter = 100
    best_position = seto(fitness, max_iter, num_particles, dim, -10.0, 10.0)
    best =np.round(best_position)
    return best

import cv2
import os
import pywt
import matplotlib.pyplot as plt
input_folder='../input'
fil_path = os.path.join(input_folder)
file_lst = os.listdir(fil_path)

Foldername = os.path.join(fil_path, file_lst[0])
Foldername1 = os.path.join(fil_path, file_lst[1])
Foldername2 = os.path.join(fil_path, file_lst[2])
Foldername3 = os.path.join(fil_path, file_lst[3])
################33
file_lst1 = os.listdir(Foldername)
for i in range(len(file_lst1)):
    print("...",i)
    Foldername_1 = os.path.join(Foldername, file_lst1[i+100])
    Foldername_2 = os.path.join(Foldername1, file_lst1[i+100])
    Foldername_3 = os.path.join(Foldername2, file_lst1[i+100])
    Foldername_4 = os.path.join(Foldername3, file_lst1[i+100])
    ff = os.listdir(Foldername_1)
    ff1 = os.listdir(Foldername_2)
    ff2 = os.listdir(Foldername_3)
    ff3 = os.listdir(Foldername_4)
    for j in range(len(ff)):
        filename =os.path.join(Foldername_1 ,ff[j])
        filename1 = os.path.join(Foldername_2, ff1[j])
        filename2 = os.path.join(Foldername_3, ff2[j])
        filename3 = os.path.join(Foldername_4, ff3[j])
        filter =cv2.imread(filename)
        filter_1 = cv2.imread(filename1)
        filter_2 = cv2.imread(filename2)
        filter_3 = cv2.imread(filename3)
        th = SETDO.main(2,10)
        ##############
        s_soft = pywt.threshold(filter, value=th, mode='soft')
        s_soft_1 = pywt.threshold(filter_1, value=th, mode='soft')
        s_soft_2 = pywt.threshold(filter_2, value=th, mode='soft')
        s_soft_3 = pywt.threshold(filter_3, value=th, mode='soft')
        plt.imshow(s_soft)
        ########
        graphpath4 = 'tht_images_2020\\flair\\' + str(i+100)
        full_gpath4 = os.path.realpath(graphpath4)
        if not os.path.exists(full_gpath4):
            os.makedirs(full_gpath4)
        plt.savefig(graphpath4 + '\\tht_img_' + str(j) + '.png')

        plt.imshow(s_soft_1)
        graphpath4_1 = 'tht_images_2020\\T1\\' + str(i+100)
        full_gpath4_1 = os.path.realpath(graphpath4_1)
        if not os.path.exists(full_gpath4_1):
            os.makedirs(full_gpath4_1)
        plt.savefig(graphpath4_1 + '\\tht_img_' + str(j) + '.png')
        ######
        plt.imshow(s_soft_2)

        graphpath4_2 = 'tht_images_2020\\T1C\\' + str(i+100)
        full_gpath4_2 = os.path.realpath(graphpath4_2)
        if not os.path.exists(full_gpath4_2):
            os.makedirs(full_gpath4_2)
        plt.savefig(graphpath4_2 + '\\tht_img_' + str(j) + '.png')
        ##########
        plt.imshow(s_soft_3)
        graphpath4_3 = 'tht_images_2020\\T2\\' + str(i+100)
        full_gpath4_3 = os.path.realpath(graphpath4_3)
        if not os.path.exists(full_gpath4_3):
            os.makedirs(full_gpath4_3)
        plt.savefig(graphpath4_3 + '\\wav_img_' + str(j) + '.png')

        res3 = 0.25*(s_soft+s_soft_2+s_soft_1+s_soft_3)
        res3[res3>0]=255
        plt.imshow(res3)
        graphpath5 = 'fused20\\' + str(i+100)
        full_gpath5 = os.path.realpath(graphpath5)
        if not os.path.exists(full_gpath5):
            os.makedirs(full_gpath5)
        plt.savefig(graphpath5 + '\\fu_img_' + str(j) + '.png')
-------------------------------------
from PIL import Image
from glob import glob
import numpy as np
import matplotlib.pyplot as plt
import os

class DataLoader():
    def __init__(self, dataset_name, img_res=(128, 128)):
        self.dataset_name = dataset_name
        self.img_res = img_res

    def load_data(self, batch_size=1, is_testing=False):
        data_type = "train" if not is_testing else "test"
        
        # Mendapatkan path dari gambar-gambar dalam folder dataset
        path = glob('/kaggle/input/research-gans-low-to-high/face_rgb/train/high_res/*')

        # Memilih secara acak sejumlah path gambar sejumlah batch_size
        batch_images = np.random.choice(path, size=batch_size)

        imgs_hr = []
        imgs_lr = []
        for img_path in batch_images:
            # Menggabungkan path gambar dengan folder 'original good images'
            img_path2 = os.path.join('/kaggle/input/research-gans-low-to-high/face_rgb/raw_data/high_res', os.path.basename(img_path))

            # Membaca dan mengubah ukuran gambar menggunakan PIL
            img = self.imread(img_path)
            img_good = self.imread(img_path2)

            h, w = self.img_res
            low_h, low_w = int(h / 4), int(w / 4)

            # Mengonversi tipe data gambar ke uint8
            img = img.astype(np.uint8)
            img_good = img_good.astype(np.uint8)

            # Mengubah ukuran gambar menjadi self.img_res
            img_hr = np.array(Image.fromarray(img).resize(self.img_res, Image.BICUBIC)).astype(float)
            img_good_hr = np.array(Image.fromarray(img_good).resize(self.img_res, Image.BICUBIC)).astype(float)
            
            # Mengubah ukuran gambar menjadi (low_h, low_w)
            img_lr = np.array(Image.fromarray(img).resize((low_h, low_w), Image.BICUBIC)).astype(float)

            # Jika sedang dalam tahap pelatihan dan random < 0.5, lakukan flipping
            if not is_testing and np.random.random() < 0.5:
                img_hr = np.fliplr(img_hr)
                img_lr = np.fliplr(img_lr)

            # Menambahkan gambar ke dalam list
            imgs_hr.append(img_hr)
            imgs_lr.append(img_lr)

        # Mengonversi list gambar menjadi numpy array dan normalisasi ke rentang [-1, 1]
        imgs_hr = np.array(imgs_hr) / 127.5 - 1.
        imgs_lr = np.array(imgs_lr) / 127.5 - 1.

        return imgs_hr, imgs_lr


    def imread(self, path):
        return np.array(Image.open(path).convert("RGB"))


# Contoh penggunaan
dataset_loader = DataLoader(dataset_name="dataset_name", img_res=(128, 128))
imgs_hr, imgs_lr = dataset_loader.load_data(batch_size=2, is_testing=False)
print(imgs_hr.shape)
print(imgs_lr.shape)


# Contoh penggunaan untuk menampilkan 10 gambar secara acak
dataset_loader = DataLoader(dataset_name="dataset_name", img_res=(128, 128))
imgs_hr, imgs_lr = dataset_loader.load_data(batch_size=10, is_testing=False)

# Menampilkan gambar-gambar
fig, axs = plt.subplots(2, 10, figsize=(15, 3))

for i in range(10):
    axs[0, i].imshow((imgs_lr[i] + 1) / 2.0)  # Kembalikan normalisasi ke rentang [0, 1]
    axs[0, i].axis('off')
    axs[0, i].set_title(f'Low-Res {i + 1}')

    axs[1, i].imshow((imgs_hr[i] + 1) / 2.0)  # Kembalikan normalisasi ke rentang [0, 1]
    axs[1, i].axis('off')
    axs[1, i].set_title(f'High-Res {i + 1}')

plt.show()


from tensorflow.keras.layers import Input, Dense, BatchNormalization, Activation, Flatten, Conv2D, UpSampling2D, Add
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import VGG19

def build_generator():
    # Model generator menggunakan blok residual
    def residual_block(x):
        filters = 64
        kernel_size = 3
        strides = 1
        padding = "same"

        res = Conv2D(filters, kernel_size, strides=strides, padding=padding)(x)
        res = BatchNormalization()(res)
        res = Activation("relu")(res)

        res = Conv2D(filters, kernel_size, strides=strides, padding=padding)(res)
        res = BatchNormalization()(res)

        # Menambahkan residual ke input
        res = Add()([res, x])
        return res

    # Input gambar dengan resolusi rendah
    input_lr = Input(shape=(None, None, 3))

    # Blok konvolusi pertama
    x = Conv2D(64, 9, padding="same")(input_lr)
    x = Activation("relu")(x)

    # Simpan residual untuk digunakan nanti
    residual = x

    # Tambahkan beberapa blok residual
    for _ in range(16):
        x = residual_block(x)

    # Tambahkan blok konvolusi lagi
    x = Conv2D(64, 3, padding="same")(x)
    x = BatchNormalization()(x)
    x = Add()([x, residual])

    # Blok penggandaan resolusi
    x = UpSampling2D(size=2)(x)
    x = Conv2D(256, 3, padding="same")(x)
    x = Activation("relu")(x)

    # Blok penggandaan resolusi lagi
    x = UpSampling2D(size=2)(x)
    x = Conv2D(256, 3, padding="same")(x)
    x = Activation("relu")(x)

    # Output gambar dengan resolusi tinggi
    output_hr = Conv2D(3, 9, activation="tanh", padding="same")(x)

    # Model generator
    generator = Model(inputs=input_lr, outputs=output_hr)
    return generator

def build_discriminator():
    # Model discriminator menggunakan arsitektur VGG19
    vgg19 = VGG19(include_top=False, weights="imagenet", input_shape=(None, None, 3))

    # Tidak menggunakan layer VGG19 terakhir
    vgg19.trainable = False
    for layer in vgg19.layers:
        layer.trainable = False

    # Ambil output dari layer sebelumnya
    vgg_output = vgg19.get_layer("block5_conv4").output

    # Input gambar dengan resolusi tinggi
    input_hr = Input(shape=(None, None, 3))

    # Masukkan gambar ke dalam model VGG19 hingga output yang diinginkan
    fake_hr = vgg19(input_hr)

    # Model discriminator
    discriminator = Model(inputs=input_hr, outputs=fake_hr)
    return discriminator

def build_srgan(generator, discriminator):
    # Tidak melatih bagian discriminator
    discriminator.trainable = False

    # Input gambar dengan resolusi rendah
    input_lr = Input(shape=(None, None, 3))

    # Gunakan generator untuk menghasilkan gambar dengan resolusi tinggi
    generated_hr = generator(input_lr)

    # Gunakan discriminator untuk menilai gambar dengan resolusi tinggi yang dihasilkan
    validity = discriminator(generated_hr)

    # Model SRGAN
    srgan = Model(inputs=input_lr, outputs=[generated_hr, validity])
    srgan.compile(optimizer=Adam(learning_rate=1e-4), loss=['mse', 'binary_crossentropy'], loss_weights=[1e-3, 1])
    return srgan

# Contoh penggunaan
generator = build_generator()
discriminator = build_discriminator()
srgan = build_srgan(generator, discriminator)

# Menampilkan arsitektur model
generator.summary()
discriminator.summary()
srgan.summary()


import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.optimizers import Adam

# Ambil data gambar menggunakan DataLoader
dataset_loader = DataLoader(dataset_name="dataset_name", img_res=(128, 128))
imgs_hr, imgs_lr = dataset_loader.load_data(batch_size=2, is_testing=False)

# Tentukan jumlah data untuk pelatihan dan validasi (80/20)
total_samples = imgs_hr.shape[0]
train_samples = int(0.8 * total_samples)

# Bagi data menjadi data pelatihan dan validasi
train_imgs_hr = imgs_hr[:train_samples]
train_imgs_lr = imgs_lr[:train_samples]

val_imgs_hr = imgs_hr[train_samples:]
val_imgs_lr = imgs_lr[train_samples:]

# Inisialisasi model SRGAN
generator = build_generator()
discriminator = build_discriminator()
srgan = build_srgan(generator, discriminator)

# Define an optimizer (you can adjust the learning rate if needed)
optimizer = Adam(learning_rate=0.0002, beta_1=0.9, beta_2=0.999)

# Compile model SRGAN with the optimizer and metrics
srgan.compile(optimizer=optimizer, loss=['mean_squared_error', 'binary_crossentropy'],
              metrics=['accuracy'])

# Melatih model SRGAN dan simpan history
history = srgan.fit(train_imgs_lr, [train_imgs_hr, np.ones((train_samples, 1))],
                    validation_data=(val_imgs_lr, [val_imgs_hr, np.ones((total_samples - train_samples, 1))]),
                    batch_size=2, epochs=50, verbose=1)


# Simpan model setelah pelatihan
srgan.save_weights("srgan_weights_final.h5")




# Plot the loss and accuracy
plt.figure(figsize=(12, 4))

# Plot total loss
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Total Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# Plot accuracy if available
if 'accuracy' in history.history:
    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

plt.tight_layout()
plt.show()

from PIL import Image
import os
import random
import matplotlib.pyplot as plt

# Path ke folder yang berisi gambar-gambar resolusi rendah
test_images_path = '/kaggle/input/research-gans-low-to-high/face_rgb/train/low_res/'

# Mendapatkan path dari gambar-gambar di folder tersebut
low_res_image_paths = [os.path.join(test_images_path, img) for img in os.listdir(test_images_path)]

# Memilih 5 gambar secara acak
selected_low_res_image_paths = random.sample(low_res_image_paths, 5)

# Memuat dan menampilkan gambar-gambar resolusi rendah tanpa perubahan
low_res_images = [Image.open(img_path).convert("RGB") for img_path in selected_low_res_image_paths]

plt.figure(figsize=(15, 5))
for i, img in enumerate(low_res_images):
    plt.subplot(1, 5, i+1)
    plt.imshow(img)
    plt.title('Original Low Res')
    plt.axis('off')
plt.show()


from PIL import Image

# Mendapatkan path dari gambar-gambar di folder tersebut
test_image_paths = glob(os.path.join(test_images_path, '*'))

# Memilih 5 gambar secara acak
selected_test_image_paths = np.random.choice(test_image_paths, size=5)

# Memuat dan menampilkan gambar-gambar resolusi rendah
test_lr_images = [np.array(Image.open(img_path).convert("RGB")) for img_path in selected_test_image_paths]

# Menampilkan gambar-gambar resolusi rendah
plt.figure(figsize=(15, 5))
for i, img in enumerate(test_lr_images):
    plt.subplot(1, 5, i+1)
    plt.imshow(img)
    plt.title('Low Res')
    plt.axis('off')
plt.show()

# Mengubah gambar-gambar resolusi rendah menjadi numpy array
test_lr_images = np.array(test_lr_images)

# Menggunakan model SRGAN untuk menghasilkan gambar-gambar dengan resolusi tinggi
generated_hr_images = generator.predict(test_lr_images)

# Menampilkan hasil gambar-gambar dengan resolusi tinggi yang dihasilkan oleh SRGAN
plt.figure(figsize=(15, 5))
for i, img in enumerate(generated_hr_images):
    plt.subplot(1, 5, i+1)
    plt.imshow((img + 1) / 2)
    plt.title('Generated HR')
    plt.axis('off')
plt.show()

# Mendapatkan path gambar-gambar asli dengan resolusi tinggi untuk perbandingan
test_hr_paths = [img_path.replace('low_res', 'high_res') for img_path in selected_test_image_paths]

# Memuat dan menampilkan gambar-gambar asli dengan resolusi tinggi
test_hr_images = [np.array(Image.open(img_path).convert("RGB")) for img_path in test_hr_paths]

plt.figure(figsize=(15, 5))
for i, img in enumerate(test_hr_images):
    plt.subplot(1, 5, i+1)
    plt.imshow(img)
    plt.title('Original HR')
    plt.axis('off')
plt.show()


# Menentukan path penyimpanan untuk gambar-gambar HR asli
original_hr_output_path = '/kaggle/working/original_hr_images/'

# Membuat direktori jika belum ada
os.makedirs(original_hr_output_path, exist_ok=True)

# Menyimpan gambar-gambar HR asli dalam format PNG
for i, img in enumerate(test_hr_images):
    Image.fromarray(img).save(os.path.join(original_hr_output_path, f'original_hr_{i+1}.png'))

# Menampilkan link untuk mengunduh gambar-gambar HR asli
original_hr_output_path

-------------------------------------
# Operating sisteme erişim
import os

# Görüntüyü okumak için;
import cv2

# Matris ve cebirsel işlemler için;
import numpy as np

# Grafik görselleştirme için;
import matplotlib.pyplot as plt

# U-Net modeli için gerekli modüller;
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout, Conv2DTranspose
from keras.models import load_model

# Wavelet Transformation için;
from skimage.restoration import denoise_wavelet
import pywt

# Gauss Filtresi için;
from scipy.ndimage import gaussian_filter

# Kullanılacak metrikler için;
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim

# Eğitim ve test verilerinin oluşturulması için;
from sklearn.model_selection import train_test_split

""" 
    Bu notebook çalışması kaggle üzerinde çalıştırılmıştır. Bu nedenle veri setinin bulunduğu klasörün yolu kaggle üzerindeki yol olarak verilmiştir.
    Bu notebook dosyasının doğru çalışabilmesi için veri setinin aşağıda
    verilen linkten input olarak kaggle notebook data kısmına eklenmesi gerekmektedir.

    Veri seti kaggle üzerinde bulunmaktadır. Veri seti kendi kaggle hesabımda public olarak paylaşılmıştır. Linkten veri setine ulaşabilirsiniz.
    
    İyi çalışmalar dilerim.
"""

# Veri setinin indirme linki;

# https://www.kaggle.com/datasets/hsyndmr/dnd-nam-noise-data

# Veri setinin bulunduğu klasörün yolu;

inputs = "/kaggle/input/dnd-nam-noise-data/Noisy_Dataset" 

def apply_gaussian_smoothing(image, kernel_size=(5, 5), sigma=0):
    
    # Görüntünün normalizasyonu
    image = image / 255.0

    # Gaussian smoothing işleminin uygulanması
    smoothed_image = cv2.GaussianBlur(image, kernel_size, sigma)

    return np.round(smoothed_image*255.0).astype(np.uint8) # Görüntünün 256 seviyeli hale getirmek için yapılmıştır.

def apply_wavelet_transform(image, wavelet='haar', level=2):

    # Wavelet Transform Denoising işleminin uygulanması;
    transformed_image = denoise_wavelet(image, channel_axis=-1, convert2ycbcr=True,
                           method='BayesShrink', mode='soft',
                           rescale_sigma=True)

    return transformed_image

def calculate_psnr_ssim(original, predicted):

    metricResults = []

    for orig, pred in zip(original, predicted):
        # İki görüntünün boyutlarının aynı olması gerekmektedir!!!
        if orig.shape != pred.shape:
            raise ValueError('Input images must have the same dimensions.')

        # Görüntüleri 0-255 aralığında olamalıdır!!!
        orig = cv2.convertScaleAbs(orig)
        pred = cv2.convertScaleAbs(pred)

        # PSNR hesapla ve listeye ekle
        psnr_value = psnr(orig, pred)
        metricResults.append(psnr_value)

        # SSIM hesapla ve listeye ekle
        ssim_value = ssim(orig, pred,channel_axis = -1)
        metricResults.append(ssim_value)

    return metricResults

# Veri setindeki tüm dosyalar
images = [f for f in os.listdir(inputs)]

metricDict ={"OriginalImages":[],
             "WaveletImages":[],
             "SmoothedImages":[],
             "WaveletPSNR": [],
             "WaveletSSIM": [],
             "SmoothingPSNR": [],
             "SmoothingSSIM": []}

# Temel yöntemlerin uygulanması ve sonuçlarının çıktı yerine aktarılması
for imageName in images:

    # Görüntü
    imagePath = os.path.join(inputs, imageName)
    image = cv2.imread(imagePath)

    metricDict["OriginalImages"].append(image)

    # Wavelet transform işlemi uygulanırsa;
    waveletTransformedImage = apply_wavelet_transform(image)

    # Gaussian smoothing işlemi uygulanırsa;
    smoothedImage = apply_gaussian_smoothing(image)

    # Her iki elde edilen görüntünün orjinal görüntü ile olan PSNR ve SSIM metrikleri hesaplanırsa;
    waveletTransformedMetric = calculate_psnr_ssim(image,waveletTransformedImage)
    smoothedMetric = calculate_psnr_ssim(image,smoothedImage)

    metricDict["WaveletPSNR"].append(np.mean(waveletTransformedMetric[0]))
    metricDict["WaveletSSIM"].append(np.mean(waveletTransformedMetric[1]))
    metricDict["WaveletImages"].append(waveletTransformedImage)

    metricDict["SmoothingPSNR"].append(np.mean(smoothedMetric[0]))
    metricDict["SmoothingSSIM"].append(np.mean(smoothedMetric[1]))
    metricDict["SmoothedImages"].append(smoothedImage)


maxWaveletSSIMIndex = np.array(metricDict["WaveletSSIM"]).argmax()

plt.figure(figsize=(15, 10))

plt.subplot(1, 3, 1)
original_image = metricDict["OriginalImages"][maxWaveletSSIMIndex]
plt.imshow(original_image)
plt.title('Original Görüntü')

plt.subplot(1, 3, 2)
waveletTransformedImage = metricDict["WaveletImages"][maxWaveletSSIMIndex]
plt.xlabel("SSIM: " + str(round(metricDict["WaveletSSIM"][maxWaveletSSIMIndex], 6)) + "\
            PSNR: " + str(round(metricDict["WaveletPSNR"][maxWaveletSSIMIndex], 6)))
plt.imshow(waveletTransformedImage)
plt.title(f'Wavelet Transform Uygulanmış Görüntü')

plt.subplot(1, 3, 3)
smoothedImage = metricDict["SmoothedImages"][maxWaveletSSIMIndex]
plt.xlabel("SSIM: " + str(round(metricDict["SmoothingSSIM"][maxWaveletSSIMIndex], 6)) +"\
            PSNR: " + str(round(metricDict["SmoothingPSNR"][maxWaveletSSIMIndex], 6)))
plt.imshow(smoothedImage)
plt.title(f'Gaussian Smoothing Uygulanmış Görüntü')

plt.show()

minWaveletSSIMIndex = np.array(metricDict["WaveletSSIM"]).argmin()

plt.figure(figsize=(15, 10))

plt.subplot(1, 3, 1)
original_image = metricDict["OriginalImages"][minWaveletSSIMIndex]
plt.imshow(original_image)
plt.title('Original Görüntü')

plt.subplot(1, 3, 2)
waveletTransformedImage = metricDict["WaveletImages"][minWaveletSSIMIndex]
plt.xlabel("SSIM: " + str(round(metricDict["WaveletSSIM"][minWaveletSSIMIndex], 6)) + "\
            PSNR: " + str(round(metricDict["WaveletPSNR"][minWaveletSSIMIndex], 6)))
plt.imshow(waveletTransformedImage)
plt.title(f'Wavelet Transform Uygulanmış Görüntü')

plt.subplot(1, 3, 3)
smoothedImage = metricDict["SmoothedImages"][minWaveletSSIMIndex]
plt.xlabel("SSIM: " + str(round(metricDict["SmoothingSSIM"][minWaveletSSIMIndex], 6)) + "\
            PSNR: " + str(round(metricDict["SmoothingPSNR"][minWaveletSSIMIndex], 6)))
plt.imshow(smoothedImage)
plt.title(f'Gaussian Smoothing Uygulanmış Görüntü')

plt.show()

def image_to_array(images, alteredImages):

    originalImagesResizedList = []
    alteredImagesResizedList = []

    for image, alteredImage in zip(images, alteredImages):

        image = image / 255.0
        alteredImage = alteredImage / 255.0

        originalImagesResizedList.append(image)
        alteredImagesResizedList.append(alteredImage)

    return np.array(originalImagesResizedList), np.array(alteredImagesResizedList)

def build_model(input_layer, start_neurons):

    # Daraltma Kısmı
    conv1 = Conv2D(start_neurons*1,(2,2), activation='relu', padding='same')(input_layer)
    conv1 = Conv2D(start_neurons*1,(2,2), activation='relu', padding='same')(conv1)
    pool1 = MaxPooling2D((2,2))(conv1)
    pool1 = Dropout(0.5)(pool1)

    conv2 = Conv2D(start_neurons*2,(2,2), activation='relu', padding='same')(pool1)
    conv2 = Conv2D(start_neurons*2,(2,2), activation='relu', padding='same')(conv2)
    pool2 = MaxPooling2D((2,2))(conv2)
    pool2 = Dropout(0.5)(pool2)

    # Orta Kısım
    convm = Conv2D(start_neurons * 4, (2,2), activation='relu', padding='same')(pool2)
    convm = Conv2D(start_neurons * 4, (2,2), activation='relu', padding='same')(convm)

    # Genişleme Kısmı
    deconv2 = Conv2DTranspose(start_neurons*4,(2,2), strides=(2,2), padding='same')(convm)
    uconv2 = concatenate([deconv2, conv2])
    uconv2 = Dropout(0.5)(uconv2)
    uconv2 = Conv2D(start_neurons*2, (2,2), activation='relu', padding='same')(uconv2)
    uconv2 = Conv2D(start_neurons*2, (2,2), activation='relu', padding='same')(uconv2)

    deconv1 = Conv2DTranspose(start_neurons*4,(2,2), strides=(2,2), padding='same')(uconv2)
    uconv1 = concatenate([deconv1, conv1])
    uconv1 = Dropout(0.5)(uconv1)
    uconv1 = Conv2D(start_neurons*1, (2,2), activation='relu', padding='same')(uconv1)
    uconv1 = Conv2D(start_neurons*1, (2,2), activation='relu', padding='same')(uconv1)

    output_layer = Conv2D(3, (1,1), padding='same', activation='sigmoid')(uconv1)
    return output_layer


X ,y = image_to_array(metricDict["OriginalImages"], metricDict["SmoothedImages"])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)

X_train.shape

# U-Net Modeli
img_size_target = 512
input_layer = Input((img_size_target, img_size_target,3))
output_layer = build_model(input_layer,16)

# Modelin compile edilmesi
model_unet = Model(input_layer, output_layer)
model_unet.compile(optimizer='adam', loss='MSE')


model_unet.summary()

model_unet.fit(X_train, y_train, epochs=20,
          batch_size = 16, shuffle=True, validation_data=(X_test, y_test))

# Oluşturulan modelin kaydedilmesi
model_unet.save("/kaggle/working/Trained_Model")

predictions = model_unet.predict(X_test)


testResults = {"PSNR Results":[],
               "SSIM Results":[]}

for originalImage, modelPrediction in zip(X_test,predictions):
    
    results = calculate_psnr_ssim(original_image, modelPrediction)
    
    testResults["PSNR Results"].append(np.mean(results[0]))
    testResults["SSIM Results"].append(np.mean(results[1]))
    

maxIndex = np.array(testResults["SSIM Results"]).argmax()

plt.figure(figsize=(15, 10))

plt.subplot(1, 3, 1)
original_image = X_test[maxIndex]
plt.imshow(original_image)
plt.title('Original Görüntü')

plt.subplot(1, 3, 2)
smoothedImage = y_test[maxIndex]
plt.imshow(smoothedImage)
plt.title(f'Gaussian Smoothing Uygulanmış Görüntü')

plt.subplot(1, 3, 3)
modelPrediction = predictions[maxIndex]
plt.xlabel("SSIM: " + str(round(testResults["SSIM Results"][maxIndex], 6)) + "\
            PSNR: " + str(round(testResults["PSNR Results"][maxIndex], 6)))
plt.imshow(modelPrediction)
plt.title(f'Modelden Elde Edilen Görüntü')

plt.show()

minIndex = np.array(testResults["SSIM Results"]).argmin()

plt.figure(figsize=(15, 10))

plt.subplot(1, 3, 1)
original_image = X_test[minIndex]
plt.imshow(original_image)
plt.title('Original Görüntü')

plt.subplot(1, 3, 2)
smoothedImage = y_test[minIndex]
plt.imshow(smoothedImage)
plt.title(f'Gaussian Smoothing Uygulanmış Görüntü')

plt.subplot(1, 3, 3)
modelPrediction = predictions[minIndex]
plt.xlabel("SSIM: " + str(round(testResults["SSIM Results"][minIndex], 6)) + "\
            PSNR: " + str(round(testResults["PSNR Results"][minIndex], 6)))
plt.imshow(modelPrediction)
plt.title(f'Modelden Elde Edilen Görüntü')

plt.show()
-------------------------------------
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

import os
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import glob
import random
from PIL import Image
import time
import datetime, zipfile

import tensorflow as tf
from tensorflow.keras.layers import *
from tensorflow.keras.models import Model
from tensorflow.keras.losses import mean_squared_error
from tensorflow.keras.optimizers import Adam

def load_image(img_path):
    img = tf.io.read_file(img_path) # returns string 
    img = tf.io.decode_jpeg(img, channels = 3)
    img = tf.image.resize(img, size = (384, 384), antialias = True)
    img = img / 255.0
    return img

def data_path(orig_img_path, hazy_img_path):

    train_img = []
    val_img = []

    orig_img = glob.glob(orig_img_path + '/*.png')
    n = len(orig_img)
    random.shuffle(orig_img)
    train_keys = orig_img[:int(0.9*n)]        
    val_keys = orig_img[int(0.9*n):]
    
    split_dict = {}
    for key in train_keys:
        split_dict[key] = 'train'
    for key in val_keys:
        split_dict[key] = 'val'

    hazy_img = glob.glob(hazy_img_path + '/*.png')
    for img in hazy_img:
        img_name = img.split('/')[-1]
        orig_path = orig_img_path + '/' + img_name.split('_')[0] + '.png'
        if (split_dict[orig_path] == 'train'):
            train_img.append([img, orig_path])  # img hazy image path
        else:
            val_img.append([img, orig_path])
            
    return train_img, val_img

data_path(orig_img_path = '/kaggle/input/clear-foggy/too_shorter/clear image', hazy_img_path = '/kaggle/input/clear-foggy/too_shorter/training_foggy_rainy_img')

# function to load tensor image data in batches.

def dataloader(train_data, val_data, batch_size):
    
    train_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in train_data]).map(lambda x: load_image(x))
    train_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in train_data]).map(lambda x: load_image(x))
    train = tf.data.Dataset.zip((train_data_haze, train_data_orig)).shuffle(buffer_size=100, reshuffle_each_iteration=True).batch(batch_size)
    
    val_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in val_data]).map(lambda x: load_image(x))
    val_data_haze = tf.data.Dataset.from_tensor_slices([img[0] for img in val_data]).map(lambda x: load_image(x))
    val = tf.data.Dataset.zip((val_data_haze, val_data_orig)).shuffle(buffer_size=100, reshuffle_each_iteration=True).batch(batch_size)
    
    return train, val

# function to display output.

def display_img(model, hazy_img, orig_img):
    
    dehazed_img = model(hazy_img, training = True)
    plt.figure(figsize = (15,12))
    
    display_list = [hazy_img[0], orig_img[0], dehazed_img[0]]
    title = ['Hazy Image', 'Ground Truth', 'Dehazed Image']
    
    for i in range(3):
        plt.subplot(1, 3, i+1)
        plt.title(title[i])
        plt.imshow(display_list[i])
        plt.axis('off')
        
    plt.show()

## network
def gman_net():
    
    inputs = tf.keras.Input(shape = [384, 384, 3])     
    
                                    #GMAN Network
        
    conv = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                  bias_initializer = b_init, kernel_regularizer = regularizer)(inputs)
    conv = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                  bias_initializer = b_init, kernel_regularizer = regularizer)(conv)
    
    
                                    #Encoding Layers
    conv_up = Conv2D(filters = 128, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv)
    conv_up = Conv2D(filters = 128, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv_up)
                                    
                                    #Residual Layers
    conv1_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                   bias_initializer = b_init, kernel_regularizer = regularizer)(conv_up)
    conv1_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv1_1)
    conv1_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),
                   bias_initializer = b_init, kernel_regularizer = regularizer)(conv1_2)
    conc1 = tf.add(conv1_3, conv1_1)
    conv1 = tf.keras.activations.relu(conc1)

    conv2_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv1)
    conv2_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv2_1)
    conv2_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv2_2)
    conc2 = tf.add(conv2_3, conv2_1)
    conv2 = tf.keras.activations.relu(conc2)

    conv3_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv2)
    conv3_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_1)
    conv3_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_2)
    conv3_4 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_3)
    conv3_5 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3_4)
    conc3 = tf.add(conv3_5, conv3_1)
    conv3 = tf.keras.activations.relu(conc3)

    conv4_1 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv3)
    conv4_2 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_1)
    conv4_3 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_2)
    conv4_4 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_3)
    conv4_5 = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),
                     bias_initializer = b_init, kernel_regularizer = regularizer)(conv4_4)
    conc4 = tf.add(conv4_5, conv4_1)
    conv4 = tf.keras.activations.relu(conc4)

                                            ##### Decoding Layers #####
    deconv = Conv2DTranspose(filters = 64, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),
                             kernel_regularizer = regularizer)(conv4)
    deconv = Conv2DTranspose(filters = 64, kernel_size = 3, strides = 2, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),
                             kernel_regularizer = regularizer)(deconv)

    conv = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                  bias_initializer = b_init, kernel_regularizer = regularizer)(deconv)
    conv = Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),
                  bias_initializer = b_init, kernel_regularizer = regularizer)(conv)
    conc = tf.add(conv, inputs)
    gman_output = tf.keras.activations.relu(conc)
    
                               ######################## Parallel Network ###########################
    
    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 4, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                 kernel_regularizer = regularizer)(inputs)
    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                 kernel_regularizer = regularizer)(conv)
    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 2, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                 kernel_regularizer = regularizer)(conv)
    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                 kernel_regularizer = regularizer)(conv)
    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                 kernel_regularizer = regularizer)(conv)
    conv = Conv2D(filters = 64, kernel_size = 3, dilation_rate = 1, padding = 'same', kernel_initializer = k_init, activation = 'relu',
                 kernel_regularizer = regularizer)(conv)
    deconv = Conv2DTranspose(filters = 64, kernel_size = 3, dilation_rate = 4, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),
                           activation = 'relu', kernel_regularizer = regularizer)(conv)
    conv = Conv2D(filters = 3, kernel_size = 3, strides = 1, padding = 'same', kernel_initializer = tf.keras.initializers.glorot_normal(seed = 101),
                 kernel_regularizer = regularizer)(deconv)
    conc = tf.add(conv, inputs)
    pn_output = tf.keras.activations.relu(conc)
    
    output = tf.add(gman_output, pn_output)
    
    return Model(inputs = inputs, outputs = output)

epochs = 8
batch_size = 16
k_init = tf.keras.initializers.random_normal(stddev=0.008, seed = 101)      
regularizer = tf.keras.regularizers.L2(1e-4)
b_init = tf.constant_initializer()

train_data, val_data = data_path(orig_img_path = '../input/dehaze/clear_images', hazy_img_path = '../input/dehaze/haze')
train, val = dataloader(train_data, val_data, batch_size)

optimizer = Adam(learning_rate = 1e-4)
net = gman_net()

train_loss_tracker = tf.keras.metrics.MeanSquaredError(name = "train loss")
val_loss_tracker = tf.keras.metrics.MeanSquaredError(name = "val loss")

#Training and validation function
def train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer):
    
    for epoch in range(epochs):
        
        print("\nStart of epoch %d" % (epoch,), end=' ')
        start_time_epoch = time.time()
        start_time_step = time.time()
        
        # training loop
        
        for step, (train_batch_haze, train_batch_orig) in enumerate(train):

            with tf.GradientTape() as tape:

                train_logits = net(train_batch_haze, training = True)
                loss = mean_squared_error(train_batch_orig, train_logits)

            grads = tape.gradient(loss, net.trainable_weights)
            optimizer.apply_gradients(zip(grads, net.trainable_weights))

            train_loss_tracker.update_state(train_batch_orig, train_logits)
            if step == 0:
                print('[', end='')
            if step % 64 == 0:
                print('=', end='')
        
        print(']', end='')
        print('  -  ', end='')
        print('Training Loss: %.4f' % (train_loss_tracker.result()), end='')
        
        # validation loop
        
        for step, (val_batch_haze, val_batch_orig) in enumerate(val):
            val_logits = net(val_batch_haze, training = False)
            val_loss_tracker.update_state(val_batch_orig, val_logits)
            
            if step % 32 ==0:
                display_img(net, val_batch_haze, val_batch_orig)
        
        print('  -  ', end='')
        print('Validation Loss: %.4f' % (val_loss_tracker.result()), end='')
        print('  -  ', end=' ')
        print("Time taken: %.2fs" % (time.time() - start_time_epoch))
        
        net.save('trained_model')           # save the model(variables, weights, etc)
        train_loss_tracker.reset_states()
        val_loss_tracker.reset_states()

%%time
train_model(epochs, train, val, net, train_loss_tracker, val_loss_tracker, optimizer)

#Evaluation
def evaluate(net, test_img_path):
    
    test_img = glob.glob(test_img_path + '/*.jpg')
    random.shuffle(test_img)
    
    for img in test_img:
        
        img = tf.io.read_file(img)
        img = tf.io.decode_jpeg(img, channels = 3)
        
        if img.shape[1] > img.shape[0]:
            img = tf.image.resize(img, size = (1080, 1920), antialias = True)
        if img.shape[1] < img.shape[0]:
            img = tf.image.resize(img, size = (1920, 1080), antialias = True)
        
        img = img / 255
        img = tf.expand_dims(img, axis = 0)      # transform input image from 3D to 4D
        
        dehaze = net(img, training = False)
        
        plt.figure(figsize = (80, 80))
        
        display_list = [img[0], dehaze[0]]       # make the first dimension zero
        title = ['Hazy Image', 'Dehazed Image']

        for i in range(2):
            plt.subplot(1, 2, i+1)
            plt.title(title[i], fontsize = 65, y = 1.045)
            plt.imshow(display_list[i])
            plt.axis('off')
        
        plt.show()

test_net = tf.keras.models.load_model('trained_model', compile = False)
evaluate(test_net, '../input/hazy-test-images')
-------------------------------------
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from kaggle_datasets import KaggleDatasets
%matplotlib inline

from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Dropout, LeakyReLU, ReLU, ZeroPadding2D, GroupNormalization, Concatenate, ZeroPadding2D
from tensorflow.keras.models import Model
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.optimizers import Adam

print(tf.__version__)

# try:
#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
#     print('Device:', tpu.master())
#     tf.config.experimental_connect_to_cluster(tpu)
#     tf.tpu.experimental.initialize_tpu_system(tpu)
#     strategy = tf.distribute.experimental.TPUStrategy(tpu)
# except:
#     strategy = tf.distribute.get_strategy()
# print('Number of replicas:', strategy.num_replicas_in_sync)

# AUTOTUNE = tf.data.experimental.AUTOTUNE

GCS_PATH = KaggleDatasets().get_gcs_path()

#monet_files= tf.io.gfile.glob('/kaggle/input/gan-getting-started/monet_tfrec/*.tfrec')
#photo_files= tf.io.gfile.glob('/kaggle/input/gan-getting-started/photo_tfrec/*.tfrec')
monet_files= tf.io.gfile.glob(str(GCS_PATH + '/monet_tfrec/*.tfrec'))
photo_files= tf.io.gfile.glob(str(GCS_PATH + '/photo_tfrec/*.tfrec'))

print('No. of Monet TFRecord files: ',len(monet_files))
print('No. of Photo TFRecord files: ',len(photo_files))

IMAGE_SIZE= [256,256]                                            # desired/required size of image

def decode_img(image):                                           # function for decoding the image present in jpeg format
    image= tf.image.decode_jpeg(image,channels= 3)               # 3 channels because of RGB
    image= (tf.cast(image, tf.float32)/255)*2 -1                 # converting the pixel values in range [-1,1]
    image= tf.reshape(image, shape= [*IMAGE_SIZE,3])             # reshaping the image to proper size
    return image

def read_tfrec(example):                                         # function for extracting image from TFRecord format
    tfrec_format= {
        'image_name': tf.io.FixedLenFeature([], tf.string),      # [] denotes fixed length feature where length= 1
        'image': tf.io.FixedLenFeature([], tf.string),
        'target': tf.io.FixedLenFeature([], tf.string)
    }
    example= tf.io.parse_single_example(example, tfrec_format)
    image= decode_img(example['image'])
    return image

def load_data(files):
    data= tf.data.TFRecordDataset(files)
    data= data.map(read_tfrec)                                   # (num_parallel_calls= AUTOTUNE) in  case of TPU
    return data

monet_data= load_data(monet_files).batch(1)                      # forming batches of size=1 (i.e. 1 image processed at a time)
photo_data= load_data(photo_files).batch(1)

monet_data

ex_monet= next(iter(monet_data))
ex_photo= next(iter(photo_data))


plt.subplot(1,2,1)                                       # creating a subplot with 1 row and 2 columns
plt.title('Photo')
plt.imshow(ex_photo[0]*0.5 +0.5)                         # rescaling the image to [0,1] for displaying

plt.subplot(1,2,2)
plt.title('Monet')
plt.imshow(ex_monet[0]*0.5 +0.5)                   

def downsample(filters, size, instance_norm= True):                                   # for extracting important features (size is reduced)
    initializer= tf.random_normal_initializer(0,0.02)                                 # mean=0 and standard deviation=0.02 for initializing kernel weights
    gamma_init= keras.initializers.RandomNormal(mean= 0, stddev= 0.02)
    
    model= keras.Sequential()                                          
    model.add(Conv2D(filters, size, strides=2, padding='same', kernel_initializer= initializer, use_bias= False))
    
    if instance_norm:
         model.add(GroupNormalization(groups= -1, gamma_initializer= gamma_init))     # groups= -1 to make it work like Instance Normalization
   
    model.add(LeakyReLU())
    
    return model

# def downsample(filters, size, instance_norm= True):                                   # for extracting important features (size is reduced)
#     initializer= tf.random_normal_initializer(0,0.02)                                 # mean=0 and standard deviation=0.02 for initializing kernel weights
#     gamma_init= keras.initializers.RandomNormal(mean= 0, stddev= 0.02)
    
#     i= Input(shape= (None,None,filters))                                    
#     x= Conv2D(filters, size, strides=2, padding='same', kernel_initializer= initializer, use_bias= False) (i)
    
#     if instance_norm:
#          x= GroupNormalization(groups= -1, gamma_initializer= gamma_init) (x)        # groups= -1 to make it work like Instance Normalization
   
#     x= LeakyReLU() (x)
    
#     model= Model(i,x)
    
#     return model

def upsample(filters, size, dropout= False):                                         # for locating features accurately using skip connections 
    initializer= tf.random_normal_initializer(0,0.02)
    gamma_init= keras.initializers.RandomNormal(mean= 0, stddev= 0.02)
    
    model= keras.Sequential()
    model.add(Conv2DTranspose(filters, size, strides= 2, padding= 'same', kernel_initializer= initializer, use_bias= False))
    model.add(GroupNormalization(groups= -1, gamma_initializer= gamma_init))
    
    if dropout:
        model.add(Dropout(0.5))
    
    model.add(ReLU())
    
    return model

# def upsample(filters, size, dropout= False):                                         # for locating features accurately using skip connections 
#     initializer= tf.random_normal_initializer(0,0.02)
#     gamma_init= keras.initializers.RandomNormal(mean= 0, stddev= 0.02)
    
#     i= Input(shape= (None,None,filters))
#     x= Conv2DTranspose(filters, size, strides= 2, padding='same', kernel_initializer= initializer, use_bias= False) (i)
#     x= GroupNormalization(groups= -1, gamma_initializer= gamma_init) (x)
    
#     if dropout:
#         x= Dropout(0.5) (x)
        
#     model= Model(i,x)
    
#     return model

def generator():
    down_stack= [
        downsample(64,4,False),                 # size= (128,128,64)  (size denotes the dimensions of image after the corresponding layer/operation)
        downsample(128,4),                      # size= (64,64,128)
        downsample(256,4),                      # size= (32,32,256)
        downsample(512,4),                      # size= (16,16,512)
        downsample(512,4),                      # size= (8,8,512)
        downsample(512,4),                      # size= (4,4,512)
        downsample(512,4),                      # size= (2,2,512)
        downsample(512,4),                      # size= (1,1,512)
    ]
    
    up_stack= [
        upsample(512,4,True),                   # size= (2,2,1024)  (no. of channels doubled because upsample block concats output of last downsample block)    
        upsample(512,4,True),                   # size= (4,4,1024)
        upsample(512,4,True),                   # size= (8,8,1024)
        upsample(512,4),                        # size= (16,16,1024)  (dropout= false so that information is maintained for generating detailed outputs)
        upsample(256,4),                        # size= (32,32,512)
        upsample(128,4),                        # size= (64,64,256)
        upsample(64,4)                          # size= (128,128,128)
    ]
    
    initializer= tf.random_normal_initializer(0,0.02)
    last_layer= Conv2DTranspose(3, 4, strides= 2, padding= 'same', kernel_initializer= initializer, activation= 'tanh')     # 3 output channels required
    
    i= Input(shape= [256,256,3])                # input layer
    x= i
    skips= []
    for down in down_stack:                     # downsampling
        x= down (x) 
        skips.append(x)                         # appending skip connections to the 'skips' list
        
    skips= reversed(skips[:-1])                 # last skip connection is not used because of alignment with upsampling path
    
    for up, skip in zip(up_stack,skips):        # upsampling and concatenating output with skip connection
        x= up (x)
        x= Concatenate() ([x,skip])
        
    x= last_layer(x)                            # last layer (Conv2DTranspose) for generating the final output 
    
    model= Model(i,x)
    
    return model

def discriminator():
    i= Input(shape= [256,256,3])
    x= downsample(64,4) (i)                                 # size= (128,128,64) 
    x= downsample(128,4) (x)                                # size= (64,64,128) 
    x= downsample(256,4) (x)                                # size= (32,32,256)
    
    x= ZeroPadding2D() (x)                                  # size= (34,34,256)    (1 pixel padding is added at top,bottom,left,right) 
    
    initializer= tf.random_normal_initializer(0,0.02)
    gamma_init= keras.initializers.RandomNormal(mean= 0, stddev= 0.02)
    x= Conv2D(512, 4, strides= 1, padding= 'same', kernel_initializer= initializer, use_bias= False) (x)      # size= (31,31,512) (size= orig - kernel + 1)
    x= GroupNormalization(groups= -1, gamma_initializer= gamma_init) (x)
    x= LeakyReLU() (x)
    
    x= ZeroPadding2D() (x)                                  # size= (33,33,512)    (zero padding applied to maintain spatial information)
    
    x= Conv2D(1, 4, strides= 1, padding= 'same', kernel_initializer= initializer) (x)       # size= (30,30,1) 
                                                                                            # sigmoid not used to output unbounded logits
    model= Model(i,x)                                                                       # (more numerically stable during training)
    
    return model

# with strategy.scope():
monet_generator= generator()                     # photo to monet-esque
monet_discriminator= discriminator()             # to differentiate between generated monet-esque images and real monet-esque images
photo_generator= generator()                     # monet-esque to photo
photo_discriminator= discriminator()             # to differentiate between generated 'normal' images and real 'normal' images

photo_to_monet= monet_generator(ex_photo)                # won't generate monet-esque photos as we have not fit the data into generator yet

plt.subplot(1,2,1)                                       # creating a subplot with 1 row and 2 columns
plt.title('Original Photo')
plt.imshow(ex_photo[0]*0.5 +0.5)                         # rescaling the image to [0,1] for displaying

plt.subplot(1,2,2)
plt.title('Generated Monet-esque photo')
plt.imshow(photo_to_monet[0]*0.5 +0.5)                   

class CycleGAN(keras.Model):                       # CycleGAN class inheriting from keras.Model class so that it can use its methods to train, compile etc.
    def __init__(                                  # arguments to be passed in a CycleGAN class object   
        self,
        monet_gen,
        monet_disc,
        photo_gen,
        photo_disc,
        lambda_cycle= 10                           # 'lambda_cycle' controls the importance of cycle consistency loss
    ):
        super(CycleGAN,self).__init__()            # calls the constructor of the parent class (keras.Model), initializing the base properties and methods
        self.m_gen= monet_gen                      # assigning argument values to attributes of a CycleGAN class object/instance
        self.m_disc= monet_disc
        self.p_gen= photo_gen
        self.p_disc= photo_disc
        self.lambda_cycle= lambda_cycle
        
    def compile(                                   
        self,
        m_gen_optimizer,
        m_disc_optimizer,
        p_gen_optimizer,
        p_disc_optimizer,
        gen_loss_function,
        disc_loss_function,
        cycle_loss_function,
        identity_loss_function
    ):
        super(CycleGAN,self).compile()             # calls the 'compile' fn of the parent class (keras.Model), initializing the base properties and methods
        self.m_gen_optimizer = m_gen_optimizer
        self.m_disc_optimizer = m_disc_optimizer
        self.p_gen_optimizer = p_gen_optimizer
        self.p_disc_optimizer = p_disc_optimizer
        self.gen_loss_function = gen_loss_function
        self.disc_loss_function = disc_loss_function
        self.cycle_loss_function = cycle_loss_function
        self.identity_loss_function = identity_loss_function
        
    def train_step(self,batch_data):                                # automatically invoked when fit() method is called 
        real_monet, real_photo= batch_data
        
        with tf.GradientTape(persistent= True) as tape:             # to keep a track of operations (persistent= True bcz of multiple calls to Gradient())
            
            fake_monet= self.m_gen(real_photo, training= True)      # photo to monet and then cycled back to photo
            cycled_photo= self.p_gen(fake_monet, training= True)
            
            fake_photo= self.p_gen(real_monet, training= True)      # monet to photo and then cycled back to monet
            cycled_monet= self.m_gen(fake_photo, training= True)
            
            same_photo= self.p_gen(real_photo, training= True)      # generating itself (useful in calculating identity loss)
            same_monet= self.m_gen(real_monet, training= True)      
            
            disc_real_photo= self.p_disc(real_photo, training= True)   # discriminator used to check by inputing real images
            disc_real_monet= self.m_disc(real_monet, training= True)   
            
            disc_fake_photo= self.p_disc(fake_photo, training= True)   # discriminator used to check by inputing fake images
            disc_fake_monet= self.m_disc(fake_monet, training= True)
            
            gen_monet_loss= self.gen_loss_function(disc_fake_monet)    # generator loss
            gen_photo_loss= self.gen_loss_function(disc_fake_photo)
            
            total_cycle_loss = (self.cycle_loss_function(real_monet, cycled_monet, self.lambda_cycle) +     # total cycle consistency loss
            self.cycle_loss_function(real_photo, cycled_photo, self.lambda_cycle))
            
            total_gen_monet_loss= (gen_monet_loss + total_cycle_loss   +                                    # total generator monet loss
            self.identity_loss_function(real_monet, same_monet, self.lambda_cycle) )  
            
            total_gen_photo_loss= (gen_photo_loss + total_cycle_loss   +                                    # total generator photo loss
            self.identity_loss_function(real_photo, same_photo, self.lambda_cycle) )
            
            disc_monet_loss= self.disc_loss_function(disc_real_monet, disc_fake_monet)                      # discriminator monet loss 
            disc_photo_loss= self.disc_loss_function(disc_real_photo, disc_fake_photo)                      # discriminator photo loss
            
            
        gen_monet_gradients= tape.gradient(total_gen_monet_loss, self.m_gen.trainable_variables)            # calculate gradients for generators
        gen_photo_gradients= tape.gradient(total_gen_photo_loss, self.p_gen.trainable_variables)            # diff loss fn wrt trainable variables of model
        
        disc_monet_gradients= tape.gradient(disc_monet_loss, self.m_disc.trainable_variables)               # calculate gradients for discriminators
        disc_photo_gradients= tape.gradient(disc_photo_loss, self.p_disc.trainable_variables)
        
        self.m_gen_optimizer.apply_gradients(zip(gen_monet_gradients, self.m_gen.trainable_variables))      # apply the gradients to optimizer
        self.p_gen_optimizer.apply_gradients(zip(gen_photo_gradients, self.p_gen.trainable_variables))      # basically performing gradient descent
        self.m_disc_optimizer.apply_gradients(zip(disc_monet_gradients, self.m_disc.trainable_variables))
        self.p_disc_optimizer.apply_gradients(zip(disc_photo_gradients, self.p_disc.trainable_variables))
        
        return {
            'gen_monet_loss': total_gen_monet_loss,
            'gen_photo_loss': total_gen_photo_loss,
            'disc_monet_loss': disc_monet_loss,
            'disc_photo_loss': disc_photo_loss
        }

# with strategy.scope():
def gen_loss_fn(generated):            # from_logits=True used bcz disc return unbounded values & NONE redn used to return tensor of indiv losses bcz those values are returned at each epoch
    return BinaryCrossentropy(from_logits= True, reduction= tf.keras.losses.Reduction.NONE)(tf.ones_like(generated),generated)

# with strategy.scope():
def disc_loss_fn(real, generated):
    loss_real= BinaryCrossentropy(from_logits= True, reduction= tf.keras.losses.Reduction.NONE)(tf.ones_like(real),real)
    loss_fake= BinaryCrossentropy(from_logits= True, reduction= tf.keras.losses.Reduction.NONE)(tf.zeros_like(generated),generated)
        
    total_loss= (loss_real + loss_fake)/2
        
    return total_loss

# with strategy.scope():
def cycle_loss_fn(real, cycled, lambda_cycle):
    loss= tf.reduce_mean(tf.abs(real - cycled))
        
    return lambda_cycle*loss                        # lambda controls the weight of cycle consistency loss in overall loss 

# with strategy.scope():
def identity_loss_fn(real, same, Lambda):           # LAMBDA has same use as in case of cycle consistency loss
    loss= tf.reduce_mean(tf.abs(real - same))
        
    return Lambda*loss*0.5                          # factor of '0.5' used for normalization purposes

# with strategy.scope():
m_gen_opt= Adam(learning_rate= 2e-4, beta_1= 0.5)
m_disc_opt= Adam(learning_rate= 2e-4, beta_1= 0.5)

p_gen_opt= Adam(learning_rate= 2e-4, beta_1= 0.5)
p_disc_opt= Adam(learning_rate= 2e-4, beta_1= 0.5)

# with strategy.scope():
cyclegan_model= CycleGAN(monet_generator, monet_discriminator, photo_generator, photo_discriminator, 10)
cyclegan_model.compile(m_gen_opt, m_disc_opt, p_gen_opt, p_disc_opt, gen_loss_fn, disc_loss_fn, 
                        cycle_loss_fn, identity_loss_fn)

cyclegan_model.fit(tf.data.Dataset.zip((monet_data, photo_data)), epochs= 50)

fig,ax= plt.subplots(6,2, figsize=(7,20))
for i,img in enumerate(photo_data.take(6)):
    pred= monet_generator(img, training= False)[0].numpy()   # training= False to make sure not to update model's weights
    pred= (pred*127.5 + 127.5).astype(np.uint8)              # making pixel range to [0,255]
    img= (img[0]*127.5 + 127.5).numpy().astype(np.uint8)
    
    ax[i,0].imshow(img)
    ax[i,1].imshow(pred)
    ax[i,0].set_title('Real Photo')
    ax[i,1].set_title('Generated Monet-esque')
    ax[i,0].axis('off')
    ax[i,1].axis('off')

import PIL
!mkdir ../images

i = 1
for image in photo_data:
    pred = monet_generator(image, training=False)[0].numpy()
    pred = (pred*127.5 + 127.5).astype(np.uint8)
    im = PIL.Image.fromarray(pred)
    im.save("../images/" + str(i) + ".jpg")
    i += 1

import shutil
shutil.make_archive("/kaggle/working/images", 'zip', "/kaggle/images")
-------------------------------------
### Deep learning model - FP-net
#Importing Relevant Libraries
import sys
sys.path.append('/kaggle/input/designproject')
import util_cgfft
import util_functions
import util_functions_1
import generate_shapes
import setup_functions

import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage import zoom

#Importing the tensorflow and keras libraries
from tensorflow.keras import layers
import tensorflow as tf
import tensorflow.keras as keras
from tensorflow.keras.models import Model
from keras.datasets import mnist
from tensorflow.keras.layers import Flatten,Dense,Reshape,Add,Input, Conv2D, Conv2DTranspose, MaxPooling2D,GlobalAveragePooling2D,Activation,BatchNormalization,Concatenate
from tensorflow.keras.optimizers import Adam

Es_Data_concat=np.load('/kaggle/input/dl-data-sripriya/Es_Data_concat_V_8.npy')
Stacked_img_concat=np.load('/kaggle/input/dl-data-sripriya/Stacked_img_concat_V_8.npy')

print(np.shape(Es_Data_concat))
print(np.shape(Stacked_img_concat))

if(np.shape(Stacked_img_concat)!=(25000,64,64,2)):
    Stacked_img_concat = np.reshape(Stacked_img_concat, (25000, 64, 64, 2))
print(np.shape(Es_Data_concat))
print(np.shape(Stacked_img_concat))

BATCH_SIZE=np.shape(Es_Data_concat)[0]
print(BATCH_SIZE)

class UNet:

    def __init__(self, input_shape=(20,8,1), num_classes=1):
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.model = None

    def build_model(self):
        # U-Net architecture
        # Encoder
        input_layer = Input(shape=self.input_shape)
        encoder_conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)
        encoder_conv1 = BatchNormalization()(encoder_conv1)
        encoder_conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(encoder_conv1)
        encoder_conv1 = BatchNormalization()(encoder_conv1)
        encoder_conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(encoder_conv1)
        encoder_pool1 = MaxPooling2D((2,2))(encoder_conv1)
        
#         print('1st level')
#         print(np.shape(encoder_conv1))
#         print(np.shape(encoder_pool1))
        
        encoder_conv2 = Conv2D(64,(3,3), activation='relu',padding='same')(encoder_pool1)
        encoder_conv2 = BatchNormalization()(encoder_conv2)
        encoder_conv2 = Conv2D(128,(3,3),activation='relu',padding='same')(encoder_conv2)
        encoder_conv2 = BatchNormalization()(encoder_conv2)
        encoder_conv2 = Conv2D(128,(3,3),activation='relu',padding='same')(encoder_conv2)
        encoder_pool2 = MaxPooling2D((2,2))(encoder_conv2)
        
#         print('2nd level')
#         print(np.shape(encoder_conv2))
#         print(np.shape(encoder_pool2))
        
        encoder_conv3 = Conv2D(128,(3,3),activation='relu',padding='same')(encoder_pool2)
        encoder_conv3 = BatchNormalization()(encoder_conv3)
        encoder_conv3 = Conv2D(256,(3,3),activation='relu',padding='same')(encoder_conv3)
        encoder_conv3 = BatchNormalization()(encoder_conv3)
        encoder_conv3 = Conv2D(256,(3,3),activation='relu',padding='same')(encoder_conv3)
        encoder_conv3 = BatchNormalization()(encoder_conv3)
        
#         print('3rd level')
#         print(np.shape(encoder_conv3))
       
        decoder_conv1 = Conv2DTranspose(256,(3,3),activation='relu',padding='same', strides=(2, 2))(encoder_conv3)
#         print('Decoder level 1')
#         print(np.shape(decoder_conv1))
#         print('Encoder conv2 :')
#         print(np.shape(encoder_conv2))
        decoder_conv1 = Concatenate()([decoder_conv1,encoder_conv2])
        decoder_conv1 = Conv2D(128,(3,3),activation='relu',padding='same')(decoder_conv1)
        decoder_conv1 = BatchNormalization()(decoder_conv1)
        decoder_conv1 = Conv2D(128,(3,3),activation='relu',padding='same')(decoder_conv1)
        decoder_conv1 = BatchNormalization()(decoder_conv1)
        
        decoder_conv2 = Conv2DTranspose(128,(3,3),activation='relu',padding='same', strides=(2, 2))(decoder_conv1)
#         print('Decoder level 2')
#         print(np.shape(decoder_conv2))
#         print('Encoder conv1 :')
#         print(np.shape(encoder_conv1))
        decoder_conv2 = Concatenate()([decoder_conv2,encoder_conv1])
        decoder_conv2 = Conv2D(64,(3,3),activation='relu',padding='same')(decoder_conv2)
        decoder_conv2 = BatchNormalization()(decoder_conv2)
        decoder_conv2 = Conv2D(64,(3,3),activation='relu',padding='same')(decoder_conv2)
        decoder_conv2 = BatchNormalization()(decoder_conv2)
        
        #print('Decoder level 3')
        #print(np.shape(decoder_conv2))
        decoder_conv3 = Conv2D(self.num_classes,(1,1),activation='relu')(decoder_conv2)
        decoder_conv3 = MaxPooling2D((2,2))(decoder_conv3)
        #print('After 1x1 convolution shape: ')
        #print(np.shape(decoder_conv3))
        decoder_conv3 = Concatenate()([decoder_conv3,encoder_conv2])
        decoder_conv3 = MaxPooling2D((2,2))(decoder_conv3)
        #print(np.shape(decoder_conv3))
        output = GlobalAveragePooling2D(data_format='channels_last')(decoder_conv3)    
        #print(np.shape(output))
        output = Dense((64*64*2),activation='relu')(output)
        output = Reshape((64,64,2))(output)
        #print(np.shape(output))
        model = Model(inputs=input_layer, outputs=output, name="UNet")
        return model

    def compile_and_summarize_model(self, model, optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['accuracy']):
        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)
        model.summary()
        self.model = model

modeldef = UNet()
Image_input = Input(shape=(20, 8, 1))
model = modeldef.build_model()
modeldef.compile_and_summarize_model(model)

from tensorflow.keras.utils import plot_model
plot_model(model, to_file='u_net.png', show_shapes=True, show_layer_names=True)

from tensorflow.keras.callbacks import EarlyStopping
early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)
unet=model.fit(Es_Data_concat, Stacked_img_concat, epochs=50, batch_size=16, validation_split=0.2 ,callbacks=[early_stopping])

unet.save('UNet.h5')
print('Model saved!')

print(unet.history.keys())

# Create subplots
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

# Set a common title for both subplots
fig.suptitle('CNN Performance', fontsize=14)
fig.subplots_adjust(top=0.85, wspace=0.3)

# Calculate the maximum number of epochs
max_epoch = len(fpnet.history['loss']) + 1
epoch_list = list(range(1, max_epoch))

# Plot loss in the first subplot
ax1.plot(epoch_list, unet.history['loss'], label='Train Loss', marker='o')
ax1.plot(epoch_list, unet.history['val_loss'], label='Validation Loss', marker='o')
ax1.set_xticks(np.arange(1, max_epoch, 5))
ax1.set_ylabel('Loss Value')
ax1.set_xlabel('Epoch')
ax1.set_title('Loss')
ax1.legend()

# Plot accuracy in the second subplot
ax2.plot(epoch_list, unet.history['accuracy'], label='Train Accuracy', marker='o')
ax2.plot(epoch_list, unet.history['val_accuracy'], label='Validation Accuracy', marker='o')
ax2.set_xticks(np.arange(1, max_epoch, 5))
ax2.set_ylabel('Accuracy')
ax2.set_xlabel('Epoch')
ax2.set_title('Accuracy')
ax2.legend()

# Display the plots
plt.show()


from sklearn.metrics import mean_squared_error
fpnetout=[]
indices=np.arange(0,10,1,dtype=int)
for i in indices:
    # Load Es Data
    pred=Es_Data_concat[i]
    Es_Data_split = util_functions_1.split_Es4(pred)
    magnitude = np.linalg.norm(Es_Data_split, axis=0)
    magnitude = magnitude.reshape(1,20, 8, 1)

    # Load Ground Truth Images
    stacked_groundtruth=Stacked_img_concat[i]

    # Predict using the model
    prediction = model.predict(magnitude)

    # Plot the results
    plt.figure()
    plt.subplot(121)
    plt.imshow(prediction[0, :, :, 0])
    plt.colorbar()
    plt.title('Predicted image')
    plt.subplot(122)
    plt.imshow(stacked_groundtruth[:, :, 0])
    plt.colorbar()
    plt.title('Ground truth')
    plt.show()

    # Calculate Mean Squared Error
    predicted_flat = prediction[0, :, :, 0].flatten()
    ground_truth_flat = stacked_groundtruth[:, :, 0].flatten()
    mse = mean_squared_error(ground_truth_flat, predicted_flat)
    print(f"Iteration {i+1}: Mean Squared Error: {mse}")

from sklearn.metrics import mean_squared_error
indices= []
for i in range(1,10):
    indices.append(i/2)
print('The austria generated are for these contrasts: ')
print(indices)

for i in range(len(indices)):
    # Load Es Data
    contrast=indices[i]
    pred = np.load(f'/kaggle/input/austria-v-6-es-data/austria_{contrast}.npy')
    Es_Data_split = util_functions_1.split_Es4(pred)
    magnitude = np.linalg.norm(Es_Data_split, axis=0)
    magnitude = magnitude.reshape(1,20, 6, 1)
    
    pred2=dx_Es(pred)
    fd_Es_split = util_functions_1.split_Es4(pred2)
    magnitude2 = np.linalg.norm(fd_Es_split, axis=0)
    magnitude2 = magnitude.reshape(1,20, 6, 1)
    
    magnitude = [magnitude,magnitude2]
  

    # Load Ground Truth Images
    ground_truth = np.load(f'/kaggle/input/austria-v-6-data/64image_{contrast}.npy')
    print(ground_truth.shape)
    ground_truth = ground_truth.reshape(64, 64)
    ground_truth_1 = np.load(f'/kaggle/input/austria-v-6-data/64image_{contrast}.npy')
    ground_truth_1 = ground_truth_1.reshape(64, 64)
    stacked_groundtruth = np.stack((ground_truth, ground_truth_1), axis=-1)

    # Predict using the model
    prediction = model.predict(magnitude)

    # Plot the results
    plt.figure()
    plt.subplot(121)
    plt.imshow(prediction[0, :, :, 0])
    plt.colorbar()
    plt.title('Predicted image')
    plt.subplot(122)
    # Display the magnitude of the complex image
    plt.imshow(np.abs(stacked_groundtruth[:, :, 0]))
    plt.colorbar()
    plt.title('Ground truth')
    plt.show()

    # Calculate Mean Squared Error
    predicted_flat = prediction[0, :, :, 0].flatten()
    ground_truth_flat = np.abs(stacked_groundtruth[:, :, 0]).flatten()
    mse = mean_squared_error(ground_truth_flat, predicted_flat)
    print(f"Iteration {i+1}: Mean Squared Error: {mse}")

from sklearn.metrics import mean_squared_error
indices= []
for i in range(1,10):
    indices.append(i/2)
print('The circle generated are for these contrasts: ')
print(indices)

for i in range(len(indices)):
    # Load Es Data
    contrast=indices[i]
    pred = np.load(f'/kaggle/input/circle-v-6-es-data/circle_{contrast}.npy')
    Es_Data_split = util_functions_1.split_Es4(pred)
    magnitude = np.linalg.norm(Es_Data_split, axis=0)
    magnitude = magnitude.reshape(1,20, 6, 1)
    
    pred2=dx_Es(pred)
    fd_Es_split = util_functions_1.split_Es4(pred2)
    magnitude2 = np.linalg.norm(fd_Es_split, axis=0)
    magnitude2 = magnitude.reshape(1,20, 6, 1)
    
    magnitude = [magnitude,magnitude2]
  

    # Load Ground Truth Images
    ground_truth = np.load(f'/kaggle/input/circle-data-v-6/64image_{contrast}.npy')
    print(ground_truth.shape)
    ground_truth = ground_truth.reshape(64, 64)
    ground_truth_1 = np.load(f'/kaggle/input/circle-data-v-6/64image_{contrast}.npy')
    ground_truth_1 = ground_truth_1.reshape(64, 64)
    stacked_groundtruth = np.stack((ground_truth, ground_truth_1), axis=-1)

    # Predict using the model
    prediction = model.predict(magnitude)

    # Plot the results
    plt.figure()
    plt.subplot(121)
    plt.imshow(prediction[0, :, :, 0])
    plt.colorbar()
    plt.title('Predicted image')
    plt.subplot(122)
    # Display the magnitude of the complex image
    plt.imshow(np.abs(stacked_groundtruth[:, :, 0]))
    plt.colorbar()
    plt.title('Ground truth')
    plt.show()

    # Calculate Mean Squared Error
    predicted_flat = prediction[0, :, :, 0].flatten()
    ground_truth_flat = np.abs(stacked_groundtruth[:, :, 0]).flatten()
    mse = mean_squared_error(ground_truth_flat, predicted_flat)
    print(f"Iteration {i+1}: Mean Squared Error: {mse}")

from sklearn.metrics import mean_squared_error
indices= []
for i in range(1,10):
    indices.append(i/2)
print('The square generated are for these contrasts: ')
print(indices)

for i in range(len(indices)):
    # Load Es Data
    contrast=indices[i]
    pred = np.load(f'/kaggle/input/square-v-6-es-data/square_{contrast}.npy')
    Es_Data_split = util_functions_1.split_Es4(pred)
    magnitude = np.linalg.norm(Es_Data_split, axis=0)
    magnitude = magnitude.reshape(1,20, 6, 1)
    
    pred2=dx_Es(pred)
    fd_Es_split = util_functions_1.split_Es4(pred2)
    magnitude2 = np.linalg.norm(fd_Es_split, axis=0)
    magnitude2 = magnitude.reshape(1,20, 6, 1)
    
    magnitude = [magnitude,magnitude2]
  

    # Load Ground Truth Images
    ground_truth = np.load(f'/kaggle/input/square-data-v-6/64image_{contrast}.npy')
    print(ground_truth.shape)
    ground_truth = ground_truth.reshape(64, 64)
    ground_truth_1 = np.load(f'/kaggle/input/square-data-v-6/64image_{contrast}.npy')
    ground_truth_1 = ground_truth_1.reshape(64, 64)
    stacked_groundtruth = np.stack((ground_truth, ground_truth_1), axis=-1)

    # Predict using the model
    prediction = model.predict(magnitude)

    # Plot the results
    plt.figure()
    plt.subplot(121)
    plt.imshow(prediction[0, :, :, 0])
    plt.colorbar()
    plt.title('Predicted image')
    plt.subplot(122)
    # Display the magnitude of the complex image
    plt.imshow(np.abs(stacked_groundtruth[:, :, 0]))
    plt.colorbar()
    plt.title('Ground truth')
    plt.show()

    # Calculate Mean Squared Error
    predicted_flat = prediction[0, :, :, 0].flatten()
    ground_truth_flat = np.abs(stacked_groundtruth[:, :, 0]).flatten()
    mse = mean_squared_error(ground_truth_flat, predicted_flat)
    print(f"Iteration {i+1}: Mean Squared Error: {mse}")
-------------------------------------
import os
import pickle
import numpy as np
from tqdm.notebook import tqdm
from tensorflow.keras.layers import add
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.utils import to_categorical, plot_model
from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add
from tensorflow.keras.optimizers import Adam
import re
from PIL import Image
import matplotlib.pyplot as plt
from keras.models import load_model
from tensorflow.keras.callbacks import ModelCheckpoint

BASE_DIR = '/kaggle/input/flickr8k'
WORKING_DIR = '/kaggle/working'


# load vgg16 model
model = VGG16()
# restructure the model
model = Model(inputs=model.inputs, outputs=model.layers[-2].output)
# summarize
print(model.summary())

# extract features from image
features = {}
directory = os.path.join(BASE_DIR, 'Images')

for img_name in tqdm(os.listdir(directory)):
    # load the image from file
    img_path = directory + '/' + img_name
    image = load_img(img_path, target_size=(224, 224))
    # convert image pixels to numpy array
    image = img_to_array(image)
    # reshape data for model
    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))
    # preprocess image for vgg
    image = preprocess_input(image)
    # extract features
    feature = model.predict(image, verbose=0)
    # get image ID
    image_id = img_name.split('.')[0]
    # store feature
    features[image_id] = feature

# store features in pickle
pickle.dump(features, open(os.path.join(WORKING_DIR, 'features.pkl'), 'wb'))


# load features from pickle
with open(os.path.join(WORKING_DIR, 'features.pkl'), 'rb') as f:
    features = pickle.load(f)

with open(os.path.join(BASE_DIR, 'captions.txt'), 'r') as f:
    next(f)
    captions_doc = f.read()


# create mapping of image to captions
mapping = {}
# process lines
for line in tqdm(captions_doc.split('\n')):
    # split the line by comma(,)
    tokens = line.split(',')
    if len(line) < 2:
        continue
    image_id, caption = tokens[0], tokens[1:]
    # remove extension from image ID
    image_id = image_id.split('.')[0]
    # convert caption list to string
    caption = " ".join(caption)
    # create list if needed
    if image_id not in mapping:
        mapping[image_id] = []
    # store the caption
    mapping[image_id].append(caption)

len(mapping)

# Clean and preprocess text
def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^a-zA-Z]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    text = 'startseq ' + text + ' endseq'
    return text


def clean(mapping):
    for key, captions in mapping.items():
        for i in range(len(captions)):
            # take one caption at a time
            caption = captions[i]
            # preprocessing steps
            captions[i] = clean_text(caption)


# before preprocess of text
mapping['1000268201_693b08cb0e']


# preprocess the text
clean(mapping)

# after preprocess of text
mapping['1000268201_693b08cb0e']

all_captions = []
for key in mapping:
    for caption in mapping[key]:
        all_captions.append(caption)

len(all_captions)

all_captions[:10]

# tokenize the text
tokenizer = Tokenizer()
tokenizer.fit_on_texts(all_captions)
vocab_size = len(tokenizer.word_index) + 1


vocab_size

# get maximum length of the caption available
max_length = max(len(caption.split()) for caption in all_captions)
max_length

image_ids = list(mapping.keys())
split = int(len(image_ids) * 0.80)
train = image_ids[:split]
test = image_ids[split:]

# create data generator to get data in batch (avoids session crash)
def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size):
    # loop over images
    X1, X2, y = list(), list(), list()
    n = 0
    while 1:
        for key in data_keys:
            n += 1
            captions = mapping[key]
            # process each caption
            for caption in captions:
                # encode the sequence
                seq = tokenizer.texts_to_sequences([caption])[0]
                # split the sequence into X, y pairs
                for i in range(1, len(seq)):
                    # split into input and output pairs
                    in_seq, out_seq = seq[:i], seq[i]
                    # pad input sequence
                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]
                    # encode output sequence
                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]
                    
                    # store the sequences
                    X1.append(features[key][0])
                    X2.append(in_seq)
                    y.append(out_seq)
            if n == batch_size:
                X1, X2, y = np.array(X1), np.array(X2), np.array(y)
                yield [X1, X2], y
                X1, X2, y = list(), list(), list()
                n = 0


# encoder model
# image feature layers
inputs1 = Input(shape=(4096,))
fe1 = Dropout(0.4)(inputs1)
fe2 = Dense(256, activation='relu')(fe1)
# sequence feature layers
inputs2 = Input(shape=(max_length,))
se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)
se2 = Dropout(0.4)(se1)
se3 = LSTM(256)(se2)

# decoder model
decoder1 = add([fe2, se3])
decoder2 = Dense(256, activation='relu')(decoder1)
outputs = Dense(vocab_size, activation='softmax')(decoder2)

model = Model(inputs=[inputs1, inputs2], outputs=outputs)
model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])

# plot the model
plot_model(model, show_shapes=True)

# Train the model with fine-tuning
epochs = 30
batch_size = 64
steps = len(train) // batch_size
checkpoint_filepath = WORKING_DIR + '/Image_model.h5'
model_checkpoint = ModelCheckpoint(checkpoint_filepath, save_best_only=True, save_weights_only=True)

history = model.fit(
    data_generator(train, mapping, features, tokenizer, max_length, vocab_size, batch_size),
    epochs=epochs,
    steps_per_epoch=steps,
    verbose=1,
    callbacks=[model_checkpoint]
)


# save the model
model.save(WORKING_DIR+'/Image_model.h5')

# Load the best weights
model.load_weights(checkpoint_filepath)

def idx_to_word(integer, tokenizer):
    for word, index in tokenizer.word_index.items():
        if index == integer:
            return word
    return None

# generate caption for an image
def predict_caption(model, image, tokenizer, max_length):
    # add start tag for generation process
    in_text = 'startseq'
    # iterate over the max length of sequence
    for i in range(max_length):
        # encode input sequence
        sequence = tokenizer.texts_to_sequences([in_text])[0]
        # pad the sequence
        sequence = pad_sequences([sequence], max_length)
        # predict next word
        yhat = model.predict([image, sequence], verbose=0)
        # get index with high probability
        yhat = np.argmax(yhat)
        # convert index to word
        word = idx_to_word(yhat, tokenizer)
        # stop if word not found
        if word is None:
            break
        # append word as input for generating next word
        in_text += " " + word
        # stop if we reach end tag
        if word == 'endseq':
            break
      
    return in_text


from nltk.translate.bleu_score import corpus_bleu
# validate with test data
actual, predicted = list(), list()

for key in tqdm(test):
    # get actual caption
    captions = mapping[key]
    # predict the caption for image
    y_pred = predict_caption(model, features[key], tokenizer, max_length) 
    # split into words
    actual_captions = [caption.split() for caption in captions]
    y_pred = y_pred.split()
    # append to the list
    actual.append(actual_captions)
    predicted.append(y_pred)
    
# calcuate BLEU score
print("BLEU-1: %f" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))
print("BLEU-2: %f" % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))

from PIL import Image
import matplotlib.pyplot as plt
def generate_caption(image_name):
    # load the image
    # image_name = "1001773457_577c3a7d70.jpg"
    image_id = image_name.split('.')[0]
    img_path = os.path.join(BASE_DIR, "Images", image_name)
    image = Image.open(img_path)
    captions = mapping[image_id]
    print('---------------------Actual---------------------')
    for caption in captions:
        print(caption)
    # predict the caption
    y_pred = predict_caption(model, features[image_id], tokenizer, max_length)
    print('--------------------Predicted--------------------')
    print(y_pred)
    plt.imshow(image)

generate_caption("1001773457_577c3a7d70.jpg")

generate_caption("1002674143_1b742ab4b8.jpg")

generate_caption("101669240_b2d3e7f17b.jpg")

vgg_model = VGG16()
# restructure the model
vgg_model = Model(inputs=vgg_model.inputs, outputs=vgg_model.layers[-2].output)

def generate_caption(image_path):
    # Load the image
    image = load_img(image_path, target_size=(224, 224))
    # Convert image pixels to a numpy array
    image = img_to_array(image)
    # Reshape data for the VGG model
    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))
    # Preprocess image for VGG
    image = preprocess_input(image)
    # Extract features using the VGG model
    feature = vgg_model.predict(image, verbose=0)
    
    # Predict the caption
    predicted_caption = predict_caption(model, feature, tokenizer, max_length)
    
    # Display the image and captions
    img = Image.open(image_path)
    plt.imshow(img)
    plt.title('Predicted Caption: ' + predicted_caption)
    plt.show()
    
    
    

# Example usage:
generate_caption("/kaggle/input/pictst/download (1).jpg")

generate_caption("/kaggle/input/picturetest/download.jpg")

generate_caption("/kaggle/input/imagtest/download (1).jpg")

generate_caption("/kaggle/input/imagtest/download.jpg")

generate_caption("/kaggle/input/imagtest/fMMAXWUvT8O1ALHdw3GY_Capitalism.jpg")

generate_caption("/kaggle/input/imagtest/images (1).jpg")

generate_caption("/kaggle/input/imagtest/images.jpg")

generate_caption("/kaggle/input/testing/download.jpg")

generate_caption("/kaggle/input/testingimage/OIF (1).jpg")

generate_caption("/kaggle/input/testingimage/OIF (2).jpg")

generate_caption("/kaggle/input/testingimage/OIF.jpg")

generate_caption("/kaggle/input/testingimage/OIP (1).jpg")

generate_caption("/kaggle/input/testingimage/OIP (2).jpg")

generate_caption("/kaggle/input/testingimage/OIP (3).jpg")

generate_caption("/kaggle/input/testingimage/OIP (4).jpg")

generate_caption("/kaggle/input/testingimage/OIP (5).jpg")

generate_caption("/kaggle/input/testingimage/OIP.jpg")

generate_caption("/kaggle/input/testingimage/th (1).jpg")

generate_caption("/kaggle/input/testingimage/th (2).jpg")

generate_caption("/kaggle/input/testingimage/th (3).jpg")

generate_caption("/kaggle/input/testingimage/th.jpg")

generate_caption("/kaggle/input/testingimagee/download (1).jpg")

generate_caption("/kaggle/input/testingimagee/download.jpg")

generate_caption("/kaggle/input/testingimagee/images (1).jpg")

generate_caption("/kaggle/input/testingimagee/images (2).jpg")

generate_caption("/kaggle/input/testingimagee/images (3).jpg")

generate_caption("/kaggle/input/testingimagee/images.jpg")

generate_caption("/kaggle/input/imtest/WhatsApp Image 2023-12-30 at 18.48.05_129f4192.jpg")

generate_caption("/kaggle/input/imtesss/WhatsApp Image 2023-12-30 at 18.48.43_dabc6501.jpg")

generate_caption("/kaggle/input/immmmmm/WhatsApp Image 2023-12-30 at 18.52.27_0cb64ce1.jpg")

generate_caption("/kaggle/input/immmmmm/WhatsApp Image 2023-12-30 at 18.52.27_0cb64ce1.jpg")

<p style='font-size: 18px'><strong>Conclusion: </strong>This may not be the best performing model, but the objective of this kernel is to give a gist of how Image Captioning problems can be approached. In the future work of this kernel <strong>Attention model</strong> training and <strong>BLEU Score</strong> assessment will be performed.</p>
-------------------------------------
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
pd.set_option('display.max_columns',300)
import json
import tensorflow as tf
from tensorflow.keras.layers import LSTM, Bidirectional, Dropout, Embedding, Dense, Input, Lambda, Conv1D, MaxPool1D
from tensorflow.keras.models import Model
from tqdm.notebook import tqdm
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv("/kaggle/input/asl-fingerspelling/train.csv")
df

# ! pip install fastparquet pyarrow

landm = pd.read_parquet("/kaggle/input/asl-fingerspelling/train_landmarks/1019715464.parquet")
landm

handcolumns = [c for c in landm.columns if "hand" in c]

del landm

with open("/kaggle/input/asl-fingerspelling/character_to_prediction_index.json", "r") as f:
    charmap = json.load(f)

charmap = {k:v+4 for k,v in charmap.items()}
charmap["[START]"]=1
charmap['[PAD]']=0
charmap['[UNK]']=2
charmap['[END]']=3

train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

train_df.shape, test_df.shape

del df

import re

def is_numeric_and_punctuation_string(input_string):
    # Define a regular expression pattern for numbers and punctuation marks
    pattern = r'^[0-9.,;:"\'?!()\[\]{}\-+*/%&@#<>=]*$'

    # Use re.match to check if the entire string matches the pattern
    match = re.match(pattern, input_string)

    # If there is a match, the string contains only numbers and punctuation marks
    return bool(match)

# Example usage:
input_str = "123,456.789!"
result = is_numeric_and_punctuation_string(input_str)
print(result)

file_manager = dict()

def generator(train, handcolumns, charmaps, max_frame, max_char):
    train = train.sort_values(by='file_id')
    while True:
        for fileid in train["file_id"].unique():
            if not fileid in file_manager.keys():
                path = f"/kaggle/input/asl-fingerspelling/train_landmarks/{fileid}.parquet"
                land_marks = pd.read_parquet(path)[handcolumns]
                for col in handcolumns: 
                    land_marks[col] = land_marks[col].astype('float16', errors='ignore')
                file_manager[fileid]=land_marks
            else:
                land_marks = file_manager[fileid]
            land_marks.dropna(how='all', axis=0, inplace=True)
            land_marks.fillna(0.0, inplace=True)
            frameCount = pd.DataFrame(land_marks.index.value_counts())
            frameCount["id"] = frameCount.index
            frameCount.columns = ["frameCount", "id"]
            this_file_seqs = train[train["file_id"]==fileid]
            
            d = pd.merge(this_file_seqs[["sequence_id", "phrase"]], frameCount, how='inner', left_on="sequence_id", right_on="id")
            d["len"] = d["phrase"].apply(len)
            d["avgF/Char"] = d["frameCount"]/d["len"]
            f = d[(d["avgF/Char"]>5) & (d["avgF/Char"]<=15)]
            for seqId, phrase in f[["sequence_id", "phrase"]].values:
                if is_numeric_and_punctuation_string(phrase) or phrase.startswith("http") or phrase.startswith("www"):
                    continue
                allframes = land_marks.loc[seqId].values[:max_frame] # limit to max number of frames
                pads =np.zeros(shape=(max_frame-len(allframes), len(handcolumns)))
                if pads.shape[0]!=0:
                    padded_frames = np.row_stack((pads, allframes))
                else:
                    padded_frames = allframes
                phrase = phrase[:min((max_char-1), len(phrase))] # limit max number of characters
                target_in = [1] + [charmaps[c] for c in phrase]  + [0.0]*(max_char - len(phrase)-1) # [START] + [index of chars] + post pad with 0
                target_out = [charmaps[c] for c in phrase] + [3] + [0.0]*(max_char - len(phrase)-1) # [index of chars] + [END] + post pad with 0
                yield (tf.cast(np.array(padded_frames), dtype=tf.float32), np.array(target_in, dtype='int8')), np.array(target_out, dtype='int8')

# "http".startswith

max_frame = 300
max_char = 75

# gen = generator(train_df, handcolumns, charmap, max_frame,max_char)

# for (x,i1), i2 in gen:
#     break

# i1.dtype, x.shape, i1.shape, i2.shape

# del gen
# del x
# del i1
# del i2

signature = (
                (
                    tf.TensorSpec(shape=(max_frame, len(handcolumns)), dtype=tf.float32),
                    tf.TensorSpec(shape=(max_char, 1), dtype=tf.int8)
                ),
                tf.TensorSpec(shape=(max_char, 1), dtype=tf.int8)
            )

batch_size=32
train_gen = generator(train_df, handcolumns, charmap, max_frame,max_char)
train_dataset = tf.data.Dataset.from_generator(lambda : train_gen, output_types=((tf.float32, tf.int8), tf.int8))
train_dataset = train_dataset.batch(batch_size)

test_gen = generator(test_df, handcolumns, charmap, max_frame,max_char)
test_dataset = tf.data.Dataset.from_generator(lambda : test_gen, output_types=((tf.float32, tf.int8), tf.int8))
test_dataset = test_dataset.batch(batch_size)

# it = test_dataset.as_numpy_iterator()
# x,y = it.next()
# x[0].shape, x[1].shape, y.shape

# del it
# del x
# del y

units = 512



# Encoder
enc_inp = Input(shape=(max_frame, len(handcolumns)))

conv1d = Conv1D(units, 8, padding='same')
conv1out = conv1d(enc_inp)
maxpool1d = MaxPool1D()
poolout = maxpool1d(conv1out)

conv1d2 = Conv1D(units, 5, padding='same')
conv1out2 = conv1d2(poolout)
maxpool1d2 = MaxPool1D()
poolout2 = maxpool1d2(conv1out2)

bilstm = Bidirectional(LSTM(units, return_sequences=True),  merge_mode='ave')
bilstm_out = bilstm(poolout2)
dropout_enc = Dropout(0.3)(bilstm_out)
bilstm2 = Bidirectional(LSTM(units, return_sequences=True),  merge_mode='ave')
bilstm2_out = bilstm2(dropout_enc)
bilstm3 = Bidirectional(LSTM(units, return_state=True),  merge_mode='ave')

skip_layer = tf.keras.layers.Add()
added = skip_layer([poolout2,bilstm2_out, dropout_enc])

enc_x, f_h, f_c, b_h, b_c = bilstm3(added)

# Transform States
dense1 = Dense(units, activation='linear')
b_hT = dense1(b_h)
dense2 = Dense(units, activation='linear')
b_cT = dense2(b_c)

# Decoder
dec_inp = Input(shape=(max_char,))
emb_layer = Embedding(max(charmap.values())+1, units)
embeddings = emb_layer(dec_inp)

lstm_before = LSTM(units, return_sequences=True, return_state=True)
dec_lstm_before_out, f_h1, f_c1 = lstm_before(embeddings,initial_state=[b_hT, b_cT])

lstm_dec = LSTM(units, return_sequences=True, return_state=True)
dec_lstm_out1, f_h2, f_c2 = lstm_dec(dec_lstm_before_out, initial_state=[f_h1, f_c1])
dropout_dec = Dropout(0.3)(dec_lstm_out1)
lstm_dec2 = LSTM(units, return_sequences=True, return_state=True)
dec_lstm_out2, dec_f_h, dec_f_c = lstm_dec2(dropout_dec, initial_state=[f_h2, f_c2])


dec_skip_layer = tf.keras.layers.Add()
dec_added = dec_skip_layer([dec_lstm_out1, dec_lstm_out2])

dense = Dense(units, activation='relu')
dense_out = dense(dec_added)
dense2 = Dense(len(charmap), activation='linear')
dense_out2 = dense2(dense_out)

m = Model(inputs=[enc_inp, dec_inp], outputs=dense_out2)
m.summary()

# # Encoder Separator
# sep_enc_inp = 

tf.keras.utils.plot_model(m, show_shapes=True, show_layer_activations=True, show_trainable=True)

def masked_accuracy(y_true, y_pred):
    """
    Calculate accuracy while masking out padded tokens in zero-padded sequences using TensorFlow.

    Parameters:
    - y_true: True labels, a 2D tensor of shape (batch_size, sequence_length) where padding is represented as 0.
    - y_pred: Predicted labels, a 2D tensor of the same shape as y_true.

    Returns:
    - accuracy: A scalar tensor representing the accuracy.
    """

    # Create a mask for non-padded tokens by checking where y_true is not equal to 0.
    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=tf.float32)

    # Calculate the number of correctly classified non-padded tokens.
    correct_tokens = tf.reduce_sum(tf.cast(tf.math.equal(y_true, y_pred), dtype=tf.float32) * mask)

    # Calculate the total number of non-padded tokens in the batch.
    total_tokens = tf.reduce_sum(mask)

    # Calculate the accuracy by dividing the correct non-padded tokens by the total non-padded tokens.
    accuracy = correct_tokens / total_tokens

    return accuracy

optmizer = tf.keras.optimizers.Adam(learning_rate=1e-3)
lossfn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
# metrics = tf.keras.metrics.Accuracy()
metrics = masked_accuracy

# m.compile(optimizer=optmizer, loss=lossfn, metrics=[metrics])

epochs = 1000
train_step_per_epoch = train_df.shape[0]//batch_size
validation_step_per_epoch = test_df.shape[0]//batch_size

# ! pip install ipywidgets

tr_it = train_dataset.as_numpy_iterator()
ts_it = test_dataset.as_numpy_iterator()

for epoch in range(epochs):
    print(f"Training for Epoch: {epoch+1}/{epochs}")
    cum_loss = 0
    cum_acc = 0
    for i in (pbar:=tqdm(range(train_step_per_epoch))):
        x_batch, y_batch = tr_it.next()
        with tf.GradientTape() as tape:
            logits = m(x_batch, training=True)
            loss_value = lossfn(y_batch, logits)
        grads = tape.gradient(loss_value, m.trainable_weights)
        optmizer.apply_gradients(zip(grads, m.trainable_weights))
        acc = metrics(y_batch, tf.argmax(logits, axis=-1))

        cum_loss += loss_value.numpy()
        cum_acc += acc.numpy()
        
        lossstr = str(np.round(cum_loss/(i+1), 4))
        accstr = str(np.round(cum_acc/(i+1)*100,3))+"%"
        pbar.set_description(f"Loss: {lossstr}, Accuracy: {accstr}")
    print(f"Avg. Loss{cum_loss/train_step_per_epoch}, Avg. Accuracy {cum_acc*100/train_step_per_epoch}%")
    print(f"Validating...")
    cum_loss = 0
    cum_acc = 0
    for i in (pbar:=tqdm(range(validation_step_per_epoch))):
        x_batch, y_batch = ts_it.next()
        logits = m(x_batch, training=False)        
        loss_value = lossfn(y_batch, logits)
        acc = metrics(y_batch, tf.argmax(logits, axis=-1))

        cum_loss += loss_value.numpy()
        cum_acc += acc.numpy()
        
        lossstr = str(np.round(cum_loss/(i+1), 4))
        accstr = str(np.round(cum_acc/(i+1)*100,3))+"%"
        pbar.set_description(f"Loss: {lossstr}, Accuracy: {accstr}")
    print(f"Avg. Loss{cum_loss/validation_step_per_epoch}, Avg. Accuracy {cum_acc*100/validation_step_per_epoch}%")
    print("=="*70)

file_manager.keys()

inverse_charmap = {v:k for k,v in charmap.items()}

texts = ["".join([inverse_charmap.get(i,"['UNK']") for i in seq if i not in [2,0]]) for seq in y_batch]
texts

logits = m.predict(x_batch)
texts_pred = ["".join([inverse_charmap.get(i,"['UNK']") for i in seq if i not in [2,0]]) for seq in tf.argmax(logits, axis=-1).numpy()]

texts_pred
-------------------------------------
import numpy as np 
import pandas as pd 
import os
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing import image 
from tensorflow.keras.preprocessing.sequence import pad_sequences
import string
from tqdm import tqdm
import re
import tensorflow as tf 
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Layer, Input, Dropout, Flatten, Dense, Embedding, LSTM, add, Concatenate, Reshape, concatenate, Bidirectional,MaxPool2D
from tensorflow.keras.callbacks import EarlyStopping

train_df = pd.read_csv("/kaggle/input/satellite-image-caption-generation/train.csv")
test_df = pd.read_csv("/kaggle/input/satellite-image-caption-generation/test.csv")

root= "/kaggle/input/satellite-image-caption-generation/"

def remove_text_noise(string_input):  
    string_input = str(string_input)
    string_input = string_input.replace("\n"," ")
    string_input = string_input.lower()
    translator = str.maketrans("", "", string.punctuation+"[]()")
    no_punctuations = string_input.translate(translator)
    no_punctuations = re.sub(r'\s+', ' ', no_punctuations).strip()
    return "sos"+" "+no_punctuations+" "+"eos"

def read_preprocess_image(path,vgg16):
    img = image.load_img(path,target_size=(224,224,3))
    img = image.img_to_array(img)
    img = np.expand_dims(img,axis = 0)
    preprocessed_img = preprocess_input(img)
    features = vgg16.predict(preprocessed_img,verbose=0)
    return features 
    

train_df['captions'] = train_df["captions"].apply(remove_text_noise)
test_df["captions"] = test_df['captions'].apply(remove_text_noise)
train_df['filepath'] = root+train_df['filepath']
test_df['filepath'] = root+test_df['filepath']

tokenizer = Tokenizer(filters="")
tokenizer.fit_on_texts(train_df["captions"].values)
voc_size = len(tokenizer.word_index)+1
seq_max = 512
batch_size = 64 

class CustomDataGenerator(tf.keras.utils.Sequence):

    def __init__(self, df, batch_size, tokenizer, vocab_size, max_length,  shuffle=True, **kwargs):
        super(CustomDataGenerator, self).__init__(**kwargs)
        self.df = df.copy()
        self.batch_size = batch_size
        self.tokenizer = tokenizer
        self.vocab_size = vocab_size
        self.max_length = max_length
        self.feature_extractor_model=VGG16(include_top=False,weights="imagenet")
        self.shuffle = shuffle
        self.n = len(self.df)

    
    
    def read_preprocess_image(self,path):
        img = image.load_img(path,target_size=(224,224,3))
        img = image.img_to_array(img)
        img = np.expand_dims(img,axis = 0)
        preprocessed_img = preprocess_input(img)
        features = self.feature_extractor_model.predict(preprocessed_img,verbose=0)
        return features 
    
    def on_epoch_end(self):
        if self.shuffle:
            self.df = self.df.sample(frac=1).reset_index(drop=True)

    def __len__(self):
        return self.n // self.batch_size

    def __getitem__(self,index):

        batch = self.df.iloc[index * self.batch_size:(index + 1) * self.batch_size,:]
        X1, X2, y = self.__get_data(batch)
        return (X1, X2), y

    def __get_data(self,batch):

        X1, X2, y = list(), list(), list()

        images = batch['filepath'].tolist()

        for image in images:
            feature = self.read_preprocess_image(image)[0]

            captions = batch.loc[batch['filepath']== image, 'captions'].tolist()
            for caption in captions:
                seq = self.tokenizer.texts_to_sequences([caption])

                for i in range(1,len(seq[0])):
                    in_seq, out_seq = seq[0][:i], seq[0][i]
                    
                    in_seq = pad_sequences([in_seq], maxlen=self.max_length)[0]
                    out_seq = to_categorical([out_seq], num_classes=self.vocab_size)[0]
                    X1.append(feature)
                    X2.append(in_seq)
                    y.append(out_seq)

        X1, X2, y = np.array(X1), np.array(X2), np.array(y)
        return X1, X2, y


train_generator = CustomDataGenerator(df = train_df, batch_size =32
                                      , tokenizer = tokenizer,vocab_size = voc_size,
                                      max_length =123)

test_generator = CustomDataGenerator(df = test_df, batch_size =32
                                      , tokenizer = tokenizer,vocab_size = voc_size,
                                      max_length =123)

input1 = Input(shape=(7,7,512))
input2 = Input(shape=(123,))
max_pool = MaxPool2D()(input1)
flatten = Flatten()(max_pool)
img_features = Dense(512)(flatten)
img_features_reshaped = Reshape((1, 512), input_shape=(512,))(img_features)
sentence_features = Embedding(voc_size, 512, mask_zero=False)(input2)
merged = concatenate([img_features_reshaped,sentence_features],axis=1)
sentence_features = Bidirectional(LSTM(256, dropout=0.1))(merged)

X = Dropout(0.5)(sentence_features)
X = Dense(100, activation='relu')(X)
X = Dropout(0.5)(X)
output = Dense(voc_size, activation='softmax')(X)

caption_model = Model(inputs=[input1,input2], outputs=output)
caption_model.compile(loss='categorical_crossentropy',
                          optimizer=tf.optimizers.AdamW(learning_rate=0.001, weight_decay=0.004),metrics=['accuracy'])

caption_model.summary()

caption_model.fit(train_generator,epochs = 5, validation_data = test_generator, 
                         callbacks = [EarlyStopping(monitor='val_loss', min_delta = 0, patience = 2, restore_best_weights = True)])

caption_model.save("caption.h5")

vgg16 = VGG16(include_top=False,weights="imagenet")

def read_preprocess_image(path):
        img = image.load_img(path,target_size=(224,224,3))
        img = image.img_to_array(img)
        img = np.expand_dims(img,axis = 0)
        preprocessed_img = preprocess_input(img)
        features = vgg16.predict(preprocessed_img,verbose=0)
        return features

def predict_caption(model, image, tokenizer, max_length):
    features = read_preprocess_image(image)
  
    in_text = 'sos'
    for i in range(max_length):
        sequence = tokenizer.texts_to_sequences([in_text])[0]
        sequence = pad_sequences([sequence],123)
        print(features.shape,sequence.shape)
        y_pred_ = caption_model.predict([features,sequence])
        y_pred = np.argmax(y_pred_)

        word = tokenizer.index_word[y_pred]
        if word is None:
            break

        in_text+= " " + word
        if word == 'eos':
            break

    return in_text

predict_caption(None, "/kaggle/input/satellite-image-caption-generation/valid/00721.jpg", tokenizer, 123)

import pickle

# saving
with open('tokenizer.pickle', 'wb') as handle:
    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)

# loading
with open('tokenizer.pickle', 'rb') as handle:
    tokenizer = pickle.load(handle)

-------------------------------------
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Dense, Lambda, Bidirectional, LSTM
import tensorflow.keras.backend as K
from tensorflow.keras.models import load_model

char_list = ' شه045لذس2ط71قك83رجت6بثا9دضزوعظغىفنمخصح'

# Load the model architecture
inputs = Input(shape=(32, 128, 1))
conv_1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
batch_norm_1 = BatchNormalization()(conv_1)
pool_1 = MaxPooling2D(pool_size=(2, 2), strides=2)(batch_norm_1)
conv_2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool_1)
batch_norm_2 = BatchNormalization()(conv_2)
pool_2 = MaxPooling2D(pool_size=(2, 2), strides=2)(batch_norm_2)
conv_3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool_2)
conv_4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv_3)
pool_4 = MaxPooling2D(pool_size=(2, 1))(conv_4)
conv_5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool_4)
batch_norm_5 = BatchNormalization()(conv_5)
conv_6 = Conv2D(512, (3, 3), activation='relu', padding='same')(batch_norm_5)
batch_norm_6 = BatchNormalization()(conv_6)
pool_6 = MaxPooling2D(pool_size=(2, 1))(batch_norm_6)
conv_7 = Conv2D(512, (2, 2), activation='relu')(pool_6)
squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)
blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(squeezed)
blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(blstm_1)
outputs = Dense(len(char_list) + 1, activation='softmax')(blstm_2)
act_model = Model(inputs, outputs)

# Load the weights into the model
act_model.load_weights('/kaggle/input/license-plate-recogntion-last/final_model_last.hdf5')

# Now, your model 'act_model' is loaded with the weights from 'final_model_last.hdf5'.
# You can use this model for testing.


import cv2
import numpy as np
import matplotlib.pyplot as plt



# Path to the image you want to test
image_path = "/kaggle/input/license-plate-recogntion-last/train_images/00000.jpg"

# Read and preprocess the image
img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
img = cv2.resize(img, (128, 32))
img = np.expand_dims(img, axis=2)
img = np.expand_dims(img, axis=0)

# Predict characters from the image
prediction = act_model.predict(img)

# Use CTC decoder to decode the predictions
out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0]) * prediction.shape[1], greedy=True)[0][0])

# Decode the predictions into text
predicted_text = ''
for p in out:
    for p_idx in p:
        if int(p_idx) != -1:
            predicted_text += char_list[int(p_idx)]

# Display the image
plt.imshow(cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.show()

# Display the predicted text
print("Predicted Text:", predicted_text)

from tensorflow.keras.models import load_model

# Save the model
act_model.save('full_model.h5')

# Load the model
loaded_model = load_model('full_model.h5')

# Now, you can use the loaded model for testing
# Path to the image you want to test
image_path = "/kaggle/input/license-plate-recogntion-last/train_images/00001.jpg"

# Read and preprocess the image
img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
img = cv2.resize(img, (128, 32))
img = np.expand_dims(img, axis=2)
img = np.expand_dims(img, axis=0)

# Predict characters from the image
prediction = loaded_model.predict(img)

# Use CTC decoder to decode the predictions
out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0]) * prediction.shape[1], greedy=True)[0][0])

# Decode the predictions into text
predicted_text = ''
for p in out:
    for p_idx in p:
        if int(p_idx) != -1:
            predicted_text += char_list[int(p_idx)]
            
# Display the image
plt.imshow(cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.show()

# Display the predicted text
print("Predicted Text:", predicted_text)


!pip install tf2onnx
!pip install onnxruntime
!pip install keras2onnx==1.7.0



import tf2onnx

# Convert the TensorFlow model to ONNX format
onnx_model_path = 'full_model.onnx'
tf2onnx.convert.from_keras(loaded_model, output_path=onnx_model_path)


import onnxruntime

# Load the ONNX model
onnx_session = onnxruntime.InferenceSession(onnx_model_path)

# Get the input name dynamically
input_name = onnx_session.get_inputs()[0].name

# Preprocess the input image (if needed)
# img = preprocess_image(img)

# Predict characters from the image
prediction = onnx_session.run(None, {input_name: img})

# Convert the output to a numpy array
output = np.array(prediction[0])

# Reshape the output if needed
# output = output.reshape(...)

# Decode the predictions into text
predicted_text = ''
for p in output:
    for p_idx in p:
        if int(p_idx) != -1:
            predicted_text += char_list[int(p_idx)]

# Display the predicted text
print("Predicted Text:", predicted_text)

-------------------------------------
import os
import pickle
import numpy as np
from tqdm.notebook import tqdm

from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.utils import to_categorical, plot_model
from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add

BASE_DIR = '/kaggle/input/tamilimages4k'
WORKING_DIR = '/kaggle/working'

# load vgg16 model
model = VGG16()
# restructure the model
model = Model(inputs=model.inputs, outputs=model.layers[-2].output)
# summarize
print(model.summary())

# extract features from image
features = {}
directory = os.path.join(BASE_DIR, 'Images4k')

for img_name in tqdm(os.listdir(directory)):
    # load the image from file
    img_path = directory + '/' + img_name
    image = load_img(img_path, target_size=(224, 224))
    # convert image pixels to numpy array
    image = img_to_array(image)
    # reshape data for model
    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))
    # preprocess image for vgg
    image = preprocess_input(image)
    # extract features
    feature = model.predict(image, verbose=0)
    # get image ID
    image_id = img_name.split('.')[0]
    # store feature
    features[image_id] = feature

# store features in pickle
pickle.dump(features, open(os.path.join(WORKING_DIR, 'features.pkl'), 'wb'))

# load features from pickle
with open(os.path.join(WORKING_DIR, 'features.pkl'), 'rb') as f:
    features = pickle.load(f)

with open(os.path.join(BASE_DIR,'1st4kimgcaptions.txt'), 'r') as f:
    next(f)
    captions_doc = f.read()

# create mapping of image to captions
mapping = {}
# process lines
for line in tqdm(captions_doc.split('\n')):
    # split the line by comma(,)
    tokens = line.split(',')
    if len(line) < 2:
        continue
    image_id, caption = tokens[0], tokens[1:]
    # remove extension from image ID
    image_id = image_id.split('.')[0]
    # convert caption list to string
    caption = " ".join(caption)
    # create list if needed
    if image_id not in mapping:
        mapping[image_id] = []
    # store the caption
    mapping[image_id].append(caption)

len(mapping)

def clean(mapping):
    for key, captions in mapping.items():
        for i in range(len(captions)):
            # take one caption at a time
            caption = captions[i]
            # preprocessing steps
            # convert to lowercase
            caption = caption.lower()
            # delete digits, special chars, etc., 
            caption = caption.replace('[^A-Za-z]', '')
            # delete additional spaces
            caption = caption.replace('\s+', ' ')
            # add start and end tags to the caption
            caption = 'startseq ' + " ".join([word for word in caption.split() if len(word)>1]) + ' endseq'
            captions[i] = caption

# before preprocess of text
mapping['1001773457_577c3a7d70']

# preprocess the text
clean(mapping)

# after preprocess of text
mapping['1001773457_577c3a7d70']

all_captions = []
for key in mapping:
    for caption in mapping[key]:
        all_captions.append(caption)

len(all_captions)

all_captions[:5]

# tokenize the text
tokenizer = Tokenizer()
tokenizer.fit_on_texts(all_captions)
vocab_size = len(tokenizer.word_index) + 1
tokenizer

vocab_size


# get maximum length of the caption available
max_length = max(len(caption.split()) for caption in all_captions)
max_length

image_ids = list(mapping.keys())
split = int(len(image_ids) * 0.80)
train = image_ids[:split]
test = image_ids[split:]
test


# startseq girl going into wooden building endseq
#        X                   y
# startseq                   girl
# startseq girl              going
# startseq girl going        into
# ...........
# startseq girl going into wooden building      endseq

# create data generator to get data in batch (avoids session crash)
def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size):
    # loop over images
    X1, X2, y = list(), list(), list()
    n = 0
    while 1:
        for key in data_keys:
            n += 1
            captions = mapping[key]
            # process each caption
            for caption in captions:
                # encode the sequence
                seq = tokenizer.texts_to_sequences([caption])[0]
                # split the sequence into X, y pairs
                for i in range(1, len(seq)):
                    # split into input and output pairs
                    in_seq, out_seq = seq[:i], seq[i]
                    # pad input sequence
                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]
                    in_seq
                    # encode output sequence
                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]
                    out_seq
                    
                    # store the sequences
                    X1.append(features[key][0])
                    X2.append(in_seq)
                    y.append(out_seq)
                    
            if n == batch_size:
                X1, X2, y = np.array(X1), np.array(X2), np.array(y)
                yield [X1, X2], y
                X1, X2, y = list(), list(), list()
                n = 0

# encoder model
# image feature layers
inputs1 = Input(shape=(4096,))
fe1 = Dropout(0.4)(inputs1)
fe2 = Dense(256, activation='relu')(fe1)
# sequence feature layers
inputs2 = Input(shape=(max_length,))
se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)
se2 = Dropout(0.4)(se1)
se3 = LSTM(256)(se2)

# decoder model
decoder1 = add([fe2, se3])
decoder2 = Dense(256, activation='relu')(decoder1)
outputs = Dense(vocab_size, activation='softmax')(decoder2)

model = Model(inputs=[inputs1, inputs2], outputs=outputs)
model.compile(loss='categorical_crossentropy', optimizer='adam')

# plot the model
plot_model(model, show_shapes=True)

# train the model
epochs = 50
batch_size = 32
steps = len(train) // batch_size

for i in range(epochs):
    # create data generator
    generator = data_generator(train, mapping, features, tokenizer, max_length, vocab_size, batch_size)
    # fit for one epoch
    model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)

# save the model
model.save(WORKING_DIR+'/best_model.h5')

def idx_to_word(integer, tokenizer):
    for word, index in tokenizer.word_index.items():
        if index == integer:
            return word
    return None

# generate caption for an image
def predict_caption(model, image, tokenizer, max_length):
    # add start tag for generation process
    in_text = 'startseq'
    # iterate over the max length of sequence
    for i in range(max_length):
        # encode input sequence
        sequence = tokenizer.texts_to_sequences([in_text])[0]
        # pad the sequence
        sequence = pad_sequences([sequence], max_length)
        # predict next word
        yhat = model.predict([image, sequence], verbose=0)
        # get index with high probability
        yhat = np.argmax(yhat)
        # convert index to word
        word = idx_to_word(yhat, tokenizer)
        # stop if word not found
        if word is None:
            break
        # append word as input for generating next word
        in_text += " " + word
        # stop if we reach end tag
        if word == 'endseq':
            break
      
    return in_text

from nltk.translate.bleu_score import corpus_bleu
# validate with test data
actual, predicted = list(), list()

for key in tqdm(test):
    # get actual caption
    captions = mapping[key]
    # predict the caption for image
    y_pred = predict_caption(model, features[key], tokenizer, max_length) 
    # split into words
    actual_captions = [caption.split() for caption in captions]
    y_pred = y_pred.split()
    # append to the list
    actual.append(actual_captions)
    predicted.append(y_pred)
    
# calcuate BLEU score
print("BLEU-1: %f" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))
print("BLEU-2: %f" % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))

from PIL import Image
import matplotlib.pyplot as plt
def generate_caption(image_name):
    # load the image
    # image_name = "1089059626.jpg"
    image_id = image_name.split('.')[0]
    img_path = os.path.join(BASE_DIR, "Images4k", image_name)
    image = Image.open(img_path)
    captions = mapping[image_id]
    print('---------------------Actual---------------------')
    for caption in captions:
        print(caption)
    # predict the caption
    y_pred = predict_caption(model, features[image_id], tokenizer, max_length)
    print('--------------------Predicted--------------------')
    print(y_pred)
    plt.imshow(image)

generate_caption("1007320043_627395c3d8.jpg")

generate_caption("1030985833_b0902ea560.jpg")

generate_caption("103195344_5d2dc613a3.jpg")

vgg_model = VGG16()
# restructure the model
vgg_model = Model(inputs=vgg_model.inputs, outputs=vgg_model.layers[-2].output)

#image_path = '/kaggle/input/tamilimages4k/Images4k/2873070704_2141a7a86a.jpg'
image_path = '/kaggle/input/tamilimages4k/Images4k/3064716525_b8418d4946.jpg'

# load image
image = load_img(image_path, target_size=(224, 224))
plt.imshow(image)
# convert image pixels to numpy array
image = img_to_array(image)
# reshape data for model
image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))
# preprocess image for vgg
image = preprocess_input(image)

# extract features
feature = vgg_model.predict(image, verbose=0)
# predict from the trained model
predict_caption(model, feature, tokenizer, max_length)


-------------------------------------
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

import os
import cv2
import glob 
# used to find all the pathnames matching a specified pattern
import PIL
import shutil
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from skimage import data
from skimage.util import montage 
import skimage.transform as skTrans
from skimage.transform import rotate
from skimage.transform import resize
from PIL import Image, ImageOps  

# neural imaging
import nilearn as nl
import nibabel as nib
import nilearn.plotting as nlplt


# ml libs
import keras
import keras.backend as K
from keras.callbacks import CSVLogger
import tensorflow as tf
from tensorflow.keras.utils import plot_model
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from tensorflow.keras.models import *
from tensorflow.keras.layers import *
from tensorflow.keras.optimizers import *
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard
from tensorflow.keras.layers.experimental import preprocessing


# Make numpy printouts easier to read.
np.set_printoptions(precision=3, suppress=True)

# DEFINE seg-areas  
SEGMENT_CLASSES = {
    0 : 'NOT tumor',   
    1 : 'NECROTIC/CORE', # or NON-ENHANCING tumor CORE - RED
    2 : 'EDEMA',  # Green
    3 : 'ENHANCING' # original 4 -> converted into 3 later, Yellow
}

# there are 155 slices per volume
# to start at 5 and use 145 slices means we will skip the first 5 and last 5 
VOLUME_SLICES = 100 
VOLUME_START_AT = 22 # first slice of volume that we will include

IMG_SIZE=128

import tarfile
file = tarfile.open('../input/brats-2021-task1/BraTS2021_Training_Data.tar')

file.extractall('./BraTS2021_Training_Data')
file.close()

TRAIN_DATASET_PATH = './BraTS2021_Training_Data/'

def check_nifti(file_path):
    try:
        img = nib.load(file_path)
        # Additional checks if needed
        return True
    except Exception as e:
        print(f"Error loading {file_path}: {str(e)}")
        return False

data_folder = 'path_to_extracted_data'
damaged_files = []

for root, dirs, files in os.walk(data_folder):
    for file in files:
        file_path = os.path.join(root, file)
        if file_path.endswith('.nii') or file_path.endswith('.nii.gz'):
            if not check_nifti(file_path):
                damaged_files.append(file_path)

if damaged_files:
    print("Damaged files:")
    for damaged_file in damaged_files:
        print(damaged_file)
else:
    print("No damaged files found.")

#anatomical image ..  echo planar imaging ...region of interest  
niimg = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS2021_01261/BraTS2021_01261_flair.nii.gz')
nimask = nl.image.load_img(TRAIN_DATASET_PATH + 'BraTS2021_01261/BraTS2021_01261_seg.nii.gz')

fig, axes = plt.subplots(nrows=4, figsize=(30, 40))

nlplt.plot_anat(niimg,
                title='BraTS18_Training_001_flair.nii plot_anat',
                axes=axes[0])

nlplt.plot_epi(niimg,
               title='BraTS18_Training_001_flair.nii plot_epi',
               axes=axes[1])

nlplt.plot_img(niimg,
               title='BraTS18_Training_001_flair.nii plot_img',
               axes=axes[2])

nlplt.plot_roi(nimask, 
               title='BraTS18_Training_001_flair.nii with mask plot_roi',
               bg_img=niimg, 
               axes=axes[3], cmap='Paired')

plt.show()

# dice loss as defined above for 4 classes
def dice_coef(y_true, y_pred, smooth=1.0):
    class_num = 4
    for i in range(class_num):
        y_true_f = K.flatten(y_true[:,:,:,i])
        y_pred_f = K.flatten(y_pred[:,:,:,i])
        intersection = K.sum(y_true_f * y_pred_f)
        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))
   #     K.print_tensor(loss, message='loss value for class {} : '.format(SEGMENT_CLASSES[i]))
        if i == 0:
            total_loss = loss
        else:
            total_loss = total_loss + loss
            
    total_loss = total_loss / class_num
#    K.print_tensor(total_loss, message=' total dice coef: ')
    return total_loss


 
# These functions are used for evaluating the performance of a segmentation model on three different classes
# in medical imaging (presumably related to brain tumor segmentation).
# Input Parameters:
# y_true: The ground truth segmentation mask for the edema class.
# y_pred: The predicted segmentation mask for the edema class.
# epsilon: A small constant to avoid division by zero.

def dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):
    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))
    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)

def dice_coef_edema(y_true, y_pred, epsilon=1e-6):
    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))
    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)

def dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):
    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))
    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)



# Computing Precision 
def precision(y_true, y_pred):
        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
        precision = true_positives / (predicted_positives + K.epsilon())
        return precision

    
# Computing Sensitivity      
def sensitivity(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    return true_positives / (possible_positives + K.epsilon())


# Computing Specificity
def specificity(y_true, y_pred):
    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))
    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))
    return true_negatives / (possible_negatives + K.epsilon())

def build_unet(inputs, ker_init, dropout):
    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)
    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)
    
    pool = MaxPooling2D(pool_size=(2, 2))(conv1)
    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)
    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)
    
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)
    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)
    
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)
    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)
    
    
    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)
    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)
    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)
    drop5 = Dropout(dropout)(conv5)

    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))
    merge7 = concatenate([conv3,up7], axis = 3)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)
    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)

    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))
    merge8 = concatenate([conv2,up8], axis = 3)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)
    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)

    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))
    merge9 = concatenate([conv,up9], axis = 3)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)
    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)
    
    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv9))
    merge = concatenate([conv1,up], axis = 3)
    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)
    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)
    
    conv10 = Conv2D(4, (1,1), activation = 'softmax')(conv)
    
    return Model(inputs = inputs, outputs = conv10)

input_layer = Input((IMG_SIZE, IMG_SIZE, 2))

model = build_unet(input_layer, 'he_normal', 0.2)
model.compile(loss="categorical_crossentropy", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing] )


plot_model(model, 
           show_shapes = True,
           show_dtype=False,
           show_layer_names = True, 
           rankdir = 'TB', 
           expand_nested = False, 
           dpi = 70)

# lists of directories with studies
train_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]

# file BraTS20_Training_355 has ill formatted name for for seg.nii file
#train_and_val_directories.remove(TRAIN_DATASET_PATH+'BraTS20_Training_355')

#extracts the last part of each path to become ID 
def pathListIntoIds(dirList):
    x = []
    for i in range(0,len(dirList)):
        x.append(dirList[i][dirList[i].rfind('/')+1:])
    return x

train_and_test_ids = pathListIntoIds(train_and_val_directories); 

    
train_test_ids, val_ids = train_test_split(train_and_test_ids,test_size=0.2) 
train_ids, test_ids = train_test_split(train_test_ids,test_size=0.15) 

case_index = 0
case_name = test_ids[case_index]

test_image_flair = nib.load(os.path.join(TRAIN_DATASET_PATH, case_name, f'{case_name}_flair.nii.gz')).get_fdata()
test_image_t1 = nib.load(os.path.join(TRAIN_DATASET_PATH, case_name, f'{case_name}_t1.nii.gz')).get_fdata()
test_image_t1ce = nib.load(os.path.join(TRAIN_DATASET_PATH, case_name, f'{case_name}_t1ce.nii.gz')).get_fdata()
test_image_t2 = nib.load(os.path.join(TRAIN_DATASET_PATH, case_name, f'{case_name}_t2.nii.gz')).get_fdata()
test_mask = nib.load(os.path.join(TRAIN_DATASET_PATH, case_name, f'{case_name}_seg.nii.gz')).get_fdata()

fig, axes = plt.subplots(1, 5, figsize=(20, 5))
slice_w = test_image_flair.shape[2] // 2

axes[0].imshow(test_image_flair[:, :, slice_w], cmap='gray')
axes[0].set_title('Image flair')

axes[1].imshow(test_image_t1[:, :, slice_w], cmap='gray')
axes[1].set_title('Image t1')

axes[2].imshow(test_image_t1ce[:, :, slice_w], cmap='gray')
axes[2].set_title('Image t1ce')

axes[3].imshow(test_image_t2[:, :, slice_w], cmap='gray')
axes[3].set_title('Image t2')

axes[4].imshow(test_mask[:, :, slice_w])
axes[4].set_title('Mask')

plt.show()


class DataGenerator(tf.keras.utils.Sequence):
    'Generates data for Keras'
    def __init__(self, list_IDs, dim=(IMG_SIZE,IMG_SIZE), batch_size = 1, n_channels = 2, shuffle=True):
        'Initialization'
        self.dim = dim
        self.batch_size = batch_size
        self.list_IDs = list_IDs
        self.n_channels = n_channels
        self.shuffle = shuffle
        self.on_epoch_end()

    def __len__(self):
        'Denotes the number of batches per epoch'
        return int(np.floor(len(self.list_IDs) / self.batch_size))

    def __getitem__(self, index):
        'Generate one batch of data'
        # Generate indexes of the batch
        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]

        # Find list of IDs
        Batch_ids = [self.list_IDs[k] for k in indexes]

        # Generate data
        X, y = self.__data_generation(Batch_ids)

        return X, y

    def on_epoch_end(self):
        'Updates indexes after each epoch'
        self.indexes = np.arange(len(self.list_IDs))
        if self.shuffle == True:
            np.random.shuffle(self.indexes)

    def __data_generation(self, Batch_ids):
        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)
        # Initialization
        X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))
        y = np.zeros((self.batch_size*VOLUME_SLICES, 240, 240))
        Y = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, 4))

        
        # Generate data
        for c, i in enumerate(Batch_ids):
            case_path = os.path.join(TRAIN_DATASET_PATH, i)

            data_path = os.path.join(case_path, f'{i}_flair.nii.gz');
            flair = nib.load(data_path).get_fdata()    

            data_path = os.path.join(case_path, f'{i}_t1ce.nii.gz');
            ce = nib.load(data_path).get_fdata()
            
            data_path = os.path.join(case_path, f'{i}_seg.nii.gz');
            seg = nib.load(data_path).get_fdata()
        
            for j in range(VOLUME_SLICES):
                X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));
                X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));

                y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];
                    
        # Generate masks
        y[y==4] = 3;
        mask = tf.one_hot(y, 4);
        Y = tf.image.resize(mask, (IMG_SIZE, IMG_SIZE));
        return X/np.max(X), Y
        
training_generator = DataGenerator(train_ids)
valid_generator = DataGenerator(val_ids)
test_generator = DataGenerator(test_ids)

print(len(train_ids))
print(len(val_ids))
print(len(test_ids))

# show number of data for each dir 
def showDataLayout():
    plt.bar(["Train","Valid","Test"],
    [len(train_ids), len(val_ids), len(test_ids)], align='center',color=[ 'green','red', 'blue'])
    plt.legend()

    plt.ylabel('Number of images')
    plt.title('Data distribution')
    plt.savefig('data2018.png')
    plt.show()
    
showDataLayout()

from keras.callbacks import ModelCheckpoint, EarlyStopping

filepath="3D-UNet-2018-weights-improvement-{epoch:02d}-{val_accuracy:.3f}.hdf5" 

checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')

#It helps prevent overfitting. The patience parameter is set to 3, meaning training will stop after 3 epochs without improvement.
early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)

csv_logger = CSVLogger('training_2021_2D_UNet.log')

model.fit(training_generator,
                    epochs=1,
                    steps_per_epoch=len(train_ids),
                    callbacks= [checkpoint, csv_logger, early_stop],
                    validation_data = valid_generator
                    )  

# Metrics: Various metrics are reported during training and validation to assess the model's performance. These include:

# Loss: A measure of how well the model is performing. It represents an error value that the model is trying to minimize during training.
# Accuracy: The proportion of correctly classified samples.
# Mean Intersection over Union (mean_io_u): A metric used for image segmentation tasks, measuring the overlap between predicted and true segmentation masks.
# Dice Coefficient (dice_coef): Another metric for segmentation tasks, measuring the similarity between predicted and true masks.
# Precision, Sensitivity, Specificity: These are commonly used metrics in binary classification tasks. Precision is the ratio of true positives to the sum of true positives and false positives. Sensitivity (recall) is the ratio of true positives to the sum of true positives and false negatives. Specificity is the ratio of true negatives to the sum of true negatives and false positives.
# Dice Coefficients for Necrotic, Edema, Enhancing: Specific dice coefficients for different classes in the segmentation task.
# This is common in medical image segmentation where different regions of interest are segmented separately.
# Validation Metrics: These are metrics evaluated on a separate dataset not used for training. 
# They give an indication of how well the model generalizes to new, unseen data.

model.save("model_2021_2D_UNet.h5")

# "model_2021_2D_UNet.h5": This is the filename for the saved model. 
#     [[[[[[The ".h5" extension indicates that the Hierarchical Data Format version 5 (HDF5)]]]]]]
# file format is used for saving the model. HDF5 is a file format and a set of tools for managing complex data,
#     commonly used in the scientific and engineering fields.

############ load trained model ################
model = tf.keras.models.load_model('model_2021_2D_UNet.h5', 
                                   custom_objects={ 'accuracy' : tf.keras.metrics.MeanIoU(num_classes=4),
                                                   "dice_coef": dice_coef,
                                                   "precision": precision,
                                                   "sensitivity":sensitivity,
                                                   "specificity":specificity,
                                                   "dice_coef_necrotic": dice_coef_necrotic,
                                                   "dice_coef_edema": dice_coef_edema,
                                                   "dice_coef_enhancing": dice_coef_enhancing
                                                  }, compile=False)

history = pd.read_csv('training_2021_2D_UNet.log', sep=',', engine='python')

# hist=history.history

############### ########## ####### #######

# hist=history.history

acc = history['accuracy']
val_acc = history['val_accuracy']

epoch = range(len(acc))

loss = history['loss']
val_loss = history['val_loss']

train_dice = history['dice_coef']
val_dice = history['val_dice_coef']

f, ax = plt.subplots(1, 3, figsize=(16, 8))

ax[0].plot(epoch, acc, 'b', label='Training Accuracy')
ax[0].plot(epoch, val_acc, 'r', label='Validation Accuracy')
ax[0].legend()

ax[1].plot(epoch, loss, 'b', label='Training Loss')
ax[1].plot(epoch, val_loss, 'r', label='Validation Loss')
ax[1].legend()

ax[2].plot(epoch, train_dice, 'b', label='Training dice coef')
ax[2].plot(epoch, val_dice, 'r', label='Validation dice coef')
ax[2].legend()

plt.savefig('training_result_2018.png')
plt.show()


# mri type must one of 1) flair 2) t1 3) t1ce 4) t2 ------- or even 5) seg
# returns volume of specified study at `path`
def imageLoader(path):
    image = nib.load(path).get_fdata()
    X = np.zeros((self.batch_size*VOLUME_SLICES, *self.dim, self.n_channels))
    for j in range(VOLUME_SLICES):
        X[j +VOLUME_SLICES*c,:,:,0] = cv2.resize(image[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));
        X[j +VOLUME_SLICES*c,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE));

        y[j +VOLUME_SLICES*c] = seg[:,:,j+VOLUME_START_AT];
    return np.array(image)


# load nifti file at `path`
# and load each slice with mask from volume
# choose the mri type & resize to `IMG_SIZE`
def loadDataFromDir(path, list_of_files, mriType, n_images):
    scans = []
    masks = []
    for i in list_of_files[:n_images]:
        fullPath = glob.glob( i + '/*'+ mriType +'*')[0]
        currentScanVolume = imageLoader(fullPath)
        currentMaskVolume = imageLoader( glob.glob( i + '/*seg*')[0] ) 
        # for each slice in 3D volume, find also it's mask
        for j in range(0, currentScanVolume.shape[2]):
            scan_img = cv2.resize(currentScanVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')
            mask_img = cv2.resize(currentMaskVolume[:,:,j], dsize=(IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_AREA).astype('uint8')
            scans.append(scan_img[..., np.newaxis])
            masks.append(mask_img[..., np.newaxis])
    return np.array(scans, dtype='float32'), np.array(masks, dtype='float32')
        
#brains_list_test, masks_list_test = loadDataFromDir(VALIDATION_DATASET_PATH, test_directories, "flair", 5)

def predictByPath(case_path,case):
    files = next(os.walk(case_path))[2]
    X = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))
  #  y = np.empty((VOLUME_SLICES, IMG_SIZE, IMG_SIZE))

   # /content/MICCAI_BraTS_2018_Data_Training/HGG/Brats18_2013_10_1/Brats18_2013_10_1_flair.nii

    #vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_flair.nii');
    vol_path = case_path + case + '_flair.nii';
    flair=nib.load(vol_path).get_fdata()
    
    #vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_t1ce.nii');
    vol_path = case_path + case + '_t1ce.nii';
    ce=nib.load(vol_path).get_fdata() 
    
 #   vol_path = os.path.join(case_path, f'BraTS20_Training_{case}_seg.nii');
 #   seg=nib.load(vol_path).get_fdata()  

    
    for j in range(VOLUME_SLICES):
        X[j,:,:,0] = cv2.resize(flair[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))
        X[j,:,:,1] = cv2.resize(ce[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))
 #       y[j,:,:] = cv2.resize(seg[:,:,j+VOLUME_START_AT], (IMG_SIZE,IMG_SIZE))
        
  #  model.evaluate(x=X,y=y[:,:,:,0], callbacks= callbacks)
    return model.predict(X/np.max(X), verbose=1)

def showPredictsById(case, start_slice = 60):
    path = TRAIN_DATASET_PATH + case + '/'

    # TRAIN_DATASET_PATH + test_ids[0] + "/" + test_ids[0] + '_flair.nii'

    gt = nib.load(path + case +'_seg.nii').get_fdata()
    origImage = nib.load(path + case +'_flair.nii').get_fdata()
    p = predictByPath(path,case)

    core = p[:,:,:,1]
    edema= p[:,:,:,2]
    enhancing = p[:,:,:,3]

    plt.figure(figsize=(18, 50))
    f, axarr = plt.subplots(1,6, figsize = (18, 50)) 

    for i in range(6): # for each image, add brain background
        axarr[i].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap="gray", interpolation='none')
    
    axarr[0].imshow(cv2.resize(origImage[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE)), cmap="gray")
    axarr[0].title.set_text('Original image flair')
    curr_gt=cv2.resize(gt[:,:,start_slice+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation = cv2.INTER_NEAREST)
    axarr[1].imshow(curr_gt, cmap="Reds", interpolation='none', alpha=0.3) # ,alpha=0.3,cmap='Reds'
    axarr[1].title.set_text('Ground truth')
    axarr[2].imshow(p[start_slice,:,:,1:4], cmap="Reds", interpolation='none', alpha=0.3)
    axarr[2].title.set_text('all classes')
    axarr[3].imshow(edema[start_slice,:,:], cmap="OrRd", interpolation='none', alpha=0.3)
    axarr[3].title.set_text(f'{SEGMENT_CLASSES[1]} predicted')
    axarr[4].imshow(core[start_slice,:,], cmap="OrRd", interpolation='none', alpha=0.3)
    axarr[4].title.set_text(f'{SEGMENT_CLASSES[2]} predicted')
    axarr[5].imshow(enhancing[start_slice,:,], cmap="OrRd", interpolation='none', alpha=0.3)
    axarr[5].title.set_text(f'{SEGMENT_CLASSES[3]} predicted')
    plt.savefig('Test_01.png')
    plt.show()
    
    

showPredictsById(case=test_ids[3])
showPredictsById(case=test_ids[4])
showPredictsById(case=test_ids[5])
showPredictsById(case=test_ids[6])

test_ids[3]

case = test_ids[4]
# path = f"../input/brats2018-dataset/MICCAI_BraTS_2018_Data_Training/Brats18_{case}"
path = TRAIN_DATASET_PATH + test_ids[4] + "/" 
gt = nib.load(path + test_ids[4] +'_seg.nii').get_fdata()
p = predictByPath(path,case)


core = p[:,:,:,1]
edema= p[:,:,:,2]
enhancing = p[:,:,:,3]


i=40 # slice at
eval_class =3 #     0 : 'NOT tumor',  1 : 'ENHANCING',    2 : 'CORE',    3 : 'WHOLE'



gt[gt != eval_class] = 1 # use only one class for per class evaluation 

resized_gt = cv2.resize(gt[:,:,i+VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))

plt.figure()
f, axarr = plt.subplots(1,2) 
axarr[0].imshow(resized_gt, cmap="gray")
axarr[0].title.set_text('ground truth')
axarr[1].imshow(p[i,:,:,eval_class], cmap="gray")
axarr[1].title.set_text(f'predicted class: {SEGMENT_CLASSES[eval_class]}')
plt.show()

csv_logger = CSVLogger('./evaluation_50.log')
model.compile(loss="categorical_crossentropy", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing] )
# Evaluate the model on the test data using `evaluate`
print("Evaluate on test data")
results = model.evaluate(test_generator, batch_size=100, callbacks= [csv_logger])
print("test loss, test acc:", results)
-------------------------------------
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
from PIL import Image
import matplotlib.pyplot as plt
import os
import glob as gb
import os

import tensorflow as tf
from keras import backend as K
from keras.losses import binary_crossentropy
from keras.layers import Layer
from tensorflow.keras.layers import Activation, Reshape
from tensorflow.keras.models import Model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, UpSampling2D, Concatenate
from sklearn.model_selection import train_test_split
from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, TensorBoard
# for dirname, _, filenames in os.walk('/kaggle/input'):
#     for filename in filenames:
#         print(os.path.join(dirname, filename))

# Check if a GPU is available
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))

# Check TensorFlow version and GPU availability
print("TensorFlow Version: ", tf.__version__)
print("GPU Available: ", tf.config.list_physical_devices('GPU'))

base_path = '/kaggle/input/blood-vessel-segmentation/'
dataset = 'train/kidney_1_dense/'
image_files = gb.glob(base_path+dataset+'images/*')
label_files = gb.glob(base_path+dataset+'labels/*')

def plot_image_path(path, idx=0):
    all_path = gb.glob(path)
    image = get_image(all_path[idx])
    print(image.shape)
    tmp = plt.imshow(image, cmap='gray')
    plt.colorbar(tmp)
    
def plot_image(image):
    tmp = plt.imshow(image, cmap='gray')
    plt.colorbar(tmp)
    
def light_intensity(path, idx=0):
    fig = plt.figure('Light')
    ax = fig.add_subplot(111)
    all_path = gb.glob(path)
    image = np.array(Image.open(all_path[idx]))[:100]
    w, h = image.shape
    thresh = image.max() / 2.5
    ax.imshow(image, cmap='gray')
    for x in range(w):
        for y in range(h):
            ax.annotate(str(round(image[x][y], 2)), xy=(x, y), horizontalalignment='center', verticalalignment='center', color='white')
            
def get_image(path):
    return np.array(Image.open(path))

def preprocess_image(path):
    image = get_image(path)
    
    if image.ndim > 2 and image.shape[2] > 1:
        image = image[...,0]
        
    image = image / 255.0
    
    image = tf.convert_to_tensor(image, dtype=tf.float32)
    
    if image.ndim == 2:
        image = image[..., tf.newaxis]
        
    if image.ndim != 3:
        raise ValueError('Image tensor must be 3 dimensions [height, width, channels]')
        
    return tf.image.resize(image, [256, 256])

def preprocess_label(path):
    label = get_image(path)
    
    if label.ndim > 2 and label.shape[2] > 1:
        label = label[..., 0]
        
    label = label / 255.0 if label.max() > 1 else label
    
    label = tf.convert_to_tensor(label, dtype=tf.float32)
    
    if label.ndim == 2:
        label = label[..., tf.newaxis]
    
    # Ensure mask tensor is 3D at this point
    if label.ndim != 3:
        raise ValueError('Label tensor must be 3 dimensions [height, width, channels]')
        
    label = tf.image.resize(label, [256, 256], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
    
    label = tf.where(label > 0.5, 1., 0.)
    
    return label

subset_size = int(0.9 * len(image_files))

image_subset = image_files[:subset_size]
label_subset = label_files[:subset_size]

images = np.array([preprocess_image(i) for i in image_subset])

labels = np.array([preprocess_label(i) for i in label_subset])

print(images.shape)
print(images.dtype)

print(labels.shape)
print(labels.dtype)

class MaxPoolingWithArgmax2D(Layer):

    def __init__(
            self,
            pool_size=(2, 2),
            strides=(2, 2),
            padding='same',
            **kwargs):
        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)
        self.padding = padding
        self.pool_size = pool_size
        self.strides = strides

    def call(self, inputs, **kwargs):
        padding = self.padding
        pool_size = self.pool_size
        strides = self.strides
        ksize = [1, pool_size[0], pool_size[1], 1]
        padding = padding.upper()
        strides = [1, strides[0], strides[1], 1]
        output, argmax = tf.nn.max_pool_with_argmax(
            inputs,
            ksize=ksize,
            strides=strides,
            padding=padding)

        argmax = K.cast(argmax, K.floatx())
        return [output, argmax]

    def compute_output_shape(self, input_shape):
        ratio = (1, 2, 2, 1)
        output_shape = [
            dim // ratio[idx]
            if dim is not None else None
            for idx, dim in enumerate(input_shape)]
        output_shape = tuple(output_shape)
        return [output_shape, output_shape]

    def compute_mask(self, inputs, mask=None):
        return 2 * [None]

class MaxUnpooling2D(Layer):
    def __init__(self, size=(2, 2), **kwargs):
        super(MaxUnpooling2D, self).__init__(**kwargs)
        self.size = size

    def call(self, inputs, output_shape=None):
        updates, mask = inputs[0], inputs[1]
        with tf.compat.v1.variable_scope(self.name):
            mask = K.cast(mask, 'int32')
            input_shape = tf.shape(updates, out_type='int32')

            if output_shape is None:
                output_shape = (
                    input_shape[0],
                    input_shape[1] * self.size[0],
                    input_shape[2] * self.size[1],
                    input_shape[3])

            ret = tf.scatter_nd(K.expand_dims(K.flatten(mask)),
                                K.flatten(updates),
                                [K.prod(output_shape)])

            input_shape = updates.shape
            out_shape = [-1,
                         input_shape[1] * self.size[0],
                         input_shape[2] * self.size[1],
                         input_shape[3]]
        return K.reshape(ret, out_shape)

class SentimentSegmentation():

    def __init__(self, x, y,input_shape=(256,256,1), encoders=None, decoders=None):
        self.seed = 2024
        self.encoders = encoders
        self.decoders = decoders
        self.x = x
        self.y = y
        self.x_train, self.x_test, self.y_train, self.y_test= train_test_split(self.x, self.y, test_size=0.3)
        self.input_shape = input_shape
        self.early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)
        self.generate()
        self.gpus = tf.config.experimental.list_physical_devices('GPU')

    def seed_everything(seed=2024):
        import random
        random.seed(seed)
        np.random.seed(seed)

    def create_encoder(self, x, conv_num=2, filters_num=64, kernel_size=3, stride=1, padding='same', pool_size=(2, 2)):
        for _ in range(conv_num):
            x = Conv2D(filters=filters_num, kernel_size=(kernel_size, kernel_size), strides=stride, padding=padding)(x)
            x = BatchNormalization()(x)
            x = Activation('relu')(x)

#         pool, mask = MaxPoolingWithArgmax2D(pool_size)(x)
        pool, mask = (0, 0)
        x = MaxPooling2D(pool_size)(x)
        return x, pool, mask

    def create_decoder(self,x, pool, mask, conv_num=2, filters_num=64, kernel_size=3, stride=1, padding='same', pool_size=(2, 2), is_output=False):
#         x = MaxUnpooling2D(pool_size)([x, mask])
#         print(x.shape)
        x = UpSampling2D(pool_size)(x)
#         x = Concatenate()([x, pool])
        print('decoder:')
        layers_num = conv_num - 1 if is_output else conv_num
        for i in range(layers_num):
            x = Conv2D(filters=filters_num, kernel_size=(kernel_size, kernel_size), strides=stride, padding=padding)(x)
            x = BatchNormalization()(x)
            x = Activation('relu')(x)
            print(x.shape)
            
        if is_output:
            x = Conv2D(1, (1, 1), 1, padding="valid")(x)
            x = BatchNormalization()(x)
            print('last_layer:', x.shape)
            x = Reshape((self.input_shape[0]*self.input_shape[1], 1), input_shape=self.input_shape,)(x)
            x = Activation('sigmoid')(x)
            x = Reshape((self.input_shape[0], self.input_shape[1], 1), input_shape=x.shape,)(x)
            
        return x

    def generate(self):
        inputs = Input(shape=self.input_shape)
        base_filter_number = 64
        
        # Encoders    
        print(inputs.shape)
        x, pool_1, mask_1 = self.create_encoder(inputs, filters_num=base_filter_number * 1)
        print(x.shape)
        x, pool_2, mask_2 = self.create_encoder(x, filters_num=base_filter_number * 2)
        print(x.shape)
        x, pool_3, mask_3 = self.create_encoder(x, conv_num=3, filters_num=base_filter_number * 3)
        print(x.shape)
        x, pool_4, mask_4 = self.create_encoder(x, conv_num=3, filters_num=base_filter_number * 4)
        print(x.shape)
        x, pool_5, mask_5 = self.create_encoder(x, conv_num=3, filters_num=base_filter_number * 5)
        print('ta-da',x.shape,'\n\n')
        
        # Decoders
        dec5 = self.create_decoder(x, pool_5, mask_5, filters_num=base_filter_number * 5)
        print('after:',dec5.shape)
        dec4 = self.create_decoder(dec5, pool_4, mask_4, filters_num=base_filter_number * 4)
        print('after:',dec4.shape)
        dec3 = self.create_decoder(dec4, pool_3, mask_3, filters_num=base_filter_number * 3)
        print('after:',dec3.shape)
        dec2 = self.create_decoder(dec3, pool_2, mask_2, filters_num=base_filter_number * 2)
        print('after:',dec2.shape)
        dec1 = self.create_decoder(dec2, pool_1, mask_1, filters_num=base_filter_number * 1, is_output=True)
        print('after:',dec1.shape)
#         outputs = tf.reshape(dec1, [256,256])
#         print('reshaped:',outputs)
        self.model = Model(inputs=inputs, outputs=dec1, name="SegNet")
        return self.model

    def lr_scheduler(self, epoch, lr):
        decay_rate = 0.1
        decay_step = 30
        
        if epoch % decay_step == 0 and epoch:
            return lr * decay_rate
        return lr

    def dice_coef(self, y_true, y_pred):
        epsilon = 1e-6
#         print(y_true.shape)
#         print(y_pred.shape)
        axes = tuple(range(1, len(y_pred.shape) - 1))
        numerator = 2. * K.sum(y_pred * y_true, axes)
        denominator = K.sum(K.square(y_pred) + K.square(y_true), axes)

        return K.mean((numerator + epsilon) / (denominator + epsilon))

    def dice_coef_loss(self, y_true, y_pred):
        return 1 - self.dice_coef(y_true, y_pred)

    def summary(self):
        return self.model.summary()

    def compile(self):
        self.model.compile(loss=self.dice_coef_loss, optimizer='adam', metrics=["accuracy", self.dice_coef])

    def fit(self):
        scheduler = LearningRateScheduler(self.lr_scheduler, verbose=1)
        self.model.fit(self.x_train,
                       self.y_train,
                       batch_size=8,
                       epochs=2,
                       validation_data=(self.x_test, self.y_test),
                       callbacks=[self.early_stopping, scheduler])

    def fit_gpu(self):
        if self.gpus:
            with tf.device('/GPU:0'):
                results = self.fit()
                print("GPU is available and used.")
        else:
            print("No GPU available.")
            
    def get_model(self):
        return self.model

SS = SentimentSegmentation(images, labels)
SS.compile()
# SS.summary()
SS.fit_gpu()
model = SS.get_model()

test_set_path = '/kaggle/input/blood-vessel-segmentation/test'
test_images_path = []

for dirs in gb.glob(test_set_path + '/*'):
     test_images_path += gb.glob(dirs+'/images/*')
        
test_images = np.array([preprocess_image(i) for i in sorted(test_images_path)])
test_images_raw = np.array([i for i in sorted(test_images_path)])

# make predictions
predicted_labels = model.predict(test_images)

predicted_labels = predicted_labels*10

predicted_labels[0].flatten()

int_labels = (predicted_labels > 0.98).astype(np.uint8)

plot_image(int_labels[0])

print(int_labels[0].shape)
print(np.mean(int_labels[0]))
print(np.max(int_labels[0]))

plot_image(test_images[0])
np.mean(test_images[0])
np.max(test_images[0])

def rle_encode(img):
    '''
    img: numpy array, 1 - mask, 0 - background
    Returns run length as string formated
    '''
    pixels = img.flatten()
    print(pixels.shape)
    pixels = np.concatenate([[0], pixels, [0]])
    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1
    runs[1::2] -= runs[::2]
    rle = ' '.join(str(x) for x in runs)
    if rle=='':
        rle = '1 0'
    return rle

all_rle = [rle_encode(label) for label in int_labels]
ids = [f'{p.split("/")[-3]}_{os.path.basename(p).split(".")[0]}' for p in test_images_path]

submission = pd.DataFrame({
    "id": ids,
    "rle": all_rle
})

submission.head()

submission.to_csv("submission.csv", index=False)
-------------------------------------
!pip install keras==2.10
import tensorflow as tf
from tensorflow import keras

keras.__version__

!pip install segmentation-models==1.0.1

import os
import glob
import cv2  
import numpy as np  
import matplotlib.pyplot as plt
import pandas as pd
import tifffile
from PIL import Image
import albumentations as A
from tqdm import tqdm
from sklearn.model_selection import train_test_split

import segmentation_models as sm
from segmentation_models import Unet
from segmentation_models import get_preprocessing
from segmentation_models import metrics
from segmentation_models.metrics import iou_score
from segmentation_models import set_framework
from tensorflow.keras.layers import Conv2DTranspose, Dropout, Conv2D
from tensorflow.keras import regularizers
from keras.models import Model
from segmentation_models.utils import set_trainable
from segmentation_models import losses

sm.set_framework('tf.keras')

def load_dataset(root_dir):
    data_list = []
    label_mapping = {
        'Cercospora': 0,
        'Coffee Rust': 1,
        'Phoma': 2
    }

    for folder in ["Images", "Leaf Masks", "Biotic Stress Masks"]:
        image_folder = os.path.join(root_dir, folder)
        leaf_folder = os.path.join(root_dir, "Leaf Masks")
        stress_folder = os.path.join(root_dir, "Biotic Stress Masks")

        for image_class in os.listdir(image_folder):
            class_images = glob.glob(os.path.join(image_folder, image_class, "*.jpg"))
            for img_path in class_images:
                img_name = os.path.basename(img_path).split(".")[0]

                leaf_mask_name = img_name.replace(" ", "_") + "_leaf.ome.tiff"
                leaf_mask_path = os.path.join(leaf_folder, image_class, leaf_mask_name)

                if image_class == 'Coffee Rust':
                    stress_mask_name = img_name.replace(" ", "_") + "_rust.ome.tiff"
                else:
                    stress_mask_name = img_name.replace(" ", "_") + "_" + image_class.lower() + ".ome.tiff"
                stress_mask_path = os.path.join(stress_folder, image_class, stress_mask_name)

                data_list.append((img_path, leaf_mask_path, stress_mask_path, image_class, label_mapping[image_class]))

    return data_list, label_mapping

train_data, train_label_mapping = load_dataset("/kaggle/input/segmentation-v6/Segmentation Coffee Dataset/Train")
test_data, test_label_mapping = load_dataset("/kaggle/input/segmentation-v6/Segmentation Coffee Dataset/Test")


train_df = pd.DataFrame(train_data, columns=['ImagePath', 'LeafMaskPath', 'BioticStressMaskPath', 'ClassName', 'Label'])
test_df = pd.DataFrame(test_data, columns=['ImagePath', 'LeafMaskPath', 'BioticStressMaskPath', 'ClassName', 'Label'])

def augment_image_and_mask(image, mask):
    augmentations = A.Compose([
        A.Resize(height=256, width=512, p=1.0),
        A.HorizontalFlip(p=0.5),
        A.Rotate(limit=30, p=0.3),
        A.VerticalFlip(p=0.3),
    ])

    # Convert mask to a format compatible with albumentations (e.g., uint8)
    mask = mask.astype(np.uint8)

    augmented = augmentations(image=image, mask=mask)
    augmented_image = augmented['image']
    augmented_mask = augmented['mask']
    return augmented_image, augmented_mask


def read_tiff_mask(mask_path):
    return tifffile.imread(mask_path)

train_images = []
train_leaf_masks = []
train_label = []

for index, row in tqdm(train_df.iterrows(), total=len(train_df)):
    img_path = row['ImagePath']
    leaf_mask_path = row['LeafMaskPath']

    # Read JPG image and convert from RGB to BGR
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Read TIFF masks
    leaf_mask = read_tiff_mask(leaf_mask_path)

    # Augment images and masks together
    for _ in range(3):
        augmented_image, augmented_leaf_mask = augment_image_and_mask(img, leaf_mask)

        train_images.append(augmented_image)
        train_leaf_masks.append(np.where(augmented_leaf_mask==0, 0, 1))
        train_label.append(row['Label'])

norm_train_images = np.array(train_images)
norm_train_leaf_masks = np.array(train_leaf_masks)
norm_train_label = np.array(train_label)

test_images = []
test_leaf_masks = []
test_label = []

for index, row in tqdm(test_df.iterrows(), total=len(test_df)):
    img_path = row['ImagePath']
    leaf_mask_path = row['LeafMaskPath']

    # Read JPG image and convert from RGB to BGR
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Read TIFF masks
    leaf_mask = read_tiff_mask(leaf_mask_path)

    # Augment images and masks together
    for _ in range(3):
        augmented_image, augmented_leaf_mask = augment_image_and_mask(img, leaf_mask)

        test_images.append(augmented_image)
        test_leaf_masks.append(np.where(augmented_leaf_mask==0, 0, 1))
        test_label.append(row['Label'])

norm_test_images = np.array(test_images)
norm_test_leaf_masks = np.array(test_leaf_masks)
norm_test_label = np.array(test_label)

def scale_image(data):
    return (data - np.min(data)) / (np.max(data) - np.min(data))

norm_train_images = np.array([scale_image(i) for i in norm_train_images])
norm_test_images = np.array([scale_image(i) for i in norm_test_images])


num_samples_to_visualize = 3  

for i in range(num_samples_to_visualize):
   
    img = norm_train_images[i]
    leaf_mask = norm_train_leaf_masks[i]


    fig, axs = plt.subplots(1, 2, figsize=(8, 5))

    axs[0].imshow(img)
    axs[0].set_title('Image')

    axs[1].imshow(leaf_mask)
    axs[1].set_title('Leaf Mask')

    plt.show()

x_train, x_val, y_train, y_val = norm_train_images, norm_test_images, norm_train_leaf_masks, norm_test_leaf_masks

input_shape = (256, 512, 3)
y_train = y_train.astype(np.float32)
y_val = y_val.astype(np.float32)

BACKBONE = 'resnet34'
preprocess_input = sm.get_preprocessing(BACKBONE)
x_train_preprocessed = preprocess_input(x_train)
x_val_preprocessed = preprocess_input(x_val)

model = sm.Unet(BACKBONE, input_shape=input_shape, encoder_weights='imagenet')


for layer in model.layers:
    if isinstance(layer, Conv2D):
        layer.kernel_regularizer = regularizers.l2(1e-4)
    if isinstance(layer, Dropout):
        layer.rate = 0.5  

num_classes = 1
output = Conv2DTranspose(num_classes, (1, 1), activation='sigmoid')(model.output)

DiceLoss = losses.DiceLoss()

model = Model(inputs=model.input, outputs=output)
model.compile(optimizer='adam', loss=DiceLoss, metrics=['binary_accuracy', metrics.FScore(), iou_score])


history = model.fit(
    x=x_train_preprocessed,
    y=y_train,
    batch_size=16,
    epochs=40,
    validation_data=(x_val_preprocessed, y_val),
)

results_df = pd.DataFrame(history.history)
results_df.to_csv('resnet50.csv', index=False)
results_df

# Fetch the metrics from history
loss = history.history['loss']
val_loss = history.history['val_loss']
binary_accuracy = history.history['binary_accuracy']
val_binary_accuracy = history.history['val_binary_accuracy']
fscore = history.history['f1-score']  # Assuming 'f1-score' is stored
val_fscore = history.history['val_f1-score']  # Assuming 'val_f1-score' is stored
iou_score = history.history['iou_score']
val_iou_score = history.history['val_iou_score']

epochs = range(1, len(loss) + 1)

# Plotting Loss
plt.figure(figsize=(8, 5))
plt.plot(epochs, loss, 'r', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Plotting Accuracy
plt.figure(figsize=(8, 5))
plt.plot(epochs, binary_accuracy, 'r', label='Binary Accuracy')
plt.plot(epochs, val_binary_accuracy, 'b', label='Validation Binary Accuracy')
plt.title('Binary Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Plotting F1-score
plt.figure(figsize=(8, 5))
plt.plot(epochs, fscore, 'r', label='F1-score')
plt.plot(epochs, val_fscore, 'b', label='Validation F1-score')
plt.title('F1-score')
plt.xlabel('Epochs')
plt.ylabel('F1-score')
plt.legend()

# Plotting IoU-score
plt.figure(figsize=(8, 5))
plt.plot(epochs, iou_score, 'r', label='IoU-score')
plt.plot(epochs, val_iou_score, 'b', label='Validation IoU-score')
plt.title('IoU-score')
plt.xlabel('Epochs')
plt.ylabel('IoU-score')
plt.legend()

plt.tight_layout()
plt.show()



model.save('resnet50.h5')

saved_model = keras.models.load_model('/kaggle/working/resnet50.h5', compile=False)

def preprocess(image_array):
    image = cv2.resize(image_array, (512, 256))
    normalized_image = image / 255.0
    return np.expand_dims(normalized_image, axis=0)

def predict(image, threshold=0.7):
    preprocessed_image = preprocess(image)
    prediction = saved_model.predict(preprocessed_image)
    pred_image = np.squeeze(prediction > threshold)
    return pred_image


image_path = '/kaggle/input/sample/Try/Rust(516).jpg'
image = cv2.imread(image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

predicted_image = predict(image)

plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(image)
plt.title('Original Image')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.imshow(predicted_image)
plt.title('Predicted Mask')
plt.axis('off')

plt.tight_layout()
plt.show()
-------------------------------------
import os
import numpy as np
import json
import zipfile
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import tensorflow as tf
import tensorflow.keras.layers as tfl
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from PIL import Image, ImageDraw
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
tf.random.set_seed(221) # for reproducible results

INPUT_SIZE = (1920, 1080)
IMG_SIZE = 512 # image size for the network
N = 512
path = ''
image_path = os.path.join(path, '/kaggle/input/football-player-segmentation/images/')
mask_path = os.path.join(path, '/kaggle/input/football-player-segmentation/annotations/')
with open('/kaggle/input/football-player-segmentation/annotations/instances_default.json') as f:
    annotations = json.load(f)

image_id_dict = {image['id']: image['file_name'] for image in annotations['images']}

images = np.zeros((N, IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
for img_id, img_filename in image_id_dict.items():
    img = Image.open(os.path.join(image_path, img_filename))
    img = img.resize((IMG_SIZE, IMG_SIZE))
    images[img_id - 1] = img

# show first 9 images
fig = plt.figure(figsize=(12, 6))

for i in range(9):
    plt.subplot(3, 3, i+1)
    plt.imshow(images[i]/255)
    plt.axis('off')

fig.tight_layout()

# Example of one annotation mask
annote = annotations['annotations'][0]
print(annote['image_id'])
mask = Image.new('1', INPUT_SIZE) # create new image in INPUT_SIZE filled with black (default)
mask_draw = ImageDraw.Draw(mask, '1') # so we can draw on the mask image
mask_draw.polygon(annote['segmentation'][0], fill=1) # draw a player in white
mask = mask.resize((IMG_SIZE, IMG_SIZE))
plt.imshow(mask)

masks = np.zeros((N, IMG_SIZE, IMG_SIZE), dtype=bool)

# iterate through all annotations
for annotation in annotations['annotations']:
    # get image id of the annotation
    img_id = annotation['image_id']
    mask = Image.new('1', INPUT_SIZE)
    mask_draw = ImageDraw.ImageDraw(mask, '1')
    segmentation = annotation['segmentation'][0]
    mask_draw.polygon(segmentation, fill=1)
    bool_array = np.array(mask.resize((IMG_SIZE, IMG_SIZE))) > 0
    masks[img_id - 1] = masks[img_id - 1] | bool_array

masks = masks.reshape(N, IMG_SIZE, IMG_SIZE, 1) # add channel dimension

plt.imshow(masks[0])

# masks applied on top of the images
fig = plt.figure(figsize=(12, 6))

for i in range(9):
    plt.subplot(3, 3, i+1)
    plt.imshow(images[i]/255)
    plt.imshow(masks[i], alpha=0.5)
    plt.axis('off')

fig.tight_layout()

images_train, images_test, masks_train, masks_test = train_test_split(images, masks, test_size=0.1, random_state=42)
print(f"Train images shape: {images_train.shape}, Train masks shape: {masks_train.shape}")
print(f"Test images shape: {images_test.shape}, Test masks shape: {masks_test.shape}")

def jaccard_index(y_true, y_pred):
    y_true = tf.keras.backend.flatten(y_true)
    y_pred = tf.keras.backend.flatten(y_pred)
    intersection = tf.keras.backend.sum(y_true * y_pred)
    union = tf.keras.backend.sum(y_true) + tf.keras.backend.sum(y_pred) - intersection
    return (intersection + 1e-7) / (union + 1e-7)

def conv_block(inputs, n_filters, maxpooling=True):
    """
    Convolution block of U-Net. Two convolutional layers, followed by Batch Norm
    and ReLU activation.

    Inputs:
        inputs - input tensor to the block
        n_filters - number of filter for the conv layers
    Returns:
        out - output from the block
        skip - input to the decoder network
    """
    x = tfl.Conv2D(filters=n_filters, kernel_size=3, padding='same')(inputs)
    x = tfl.BatchNormalization()(x)
    x = tfl.Activation('relu')(x)
    x = tfl.Conv2D(filters=n_filters, kernel_size=3, padding='same')(x)
    x = tfl.BatchNormalization()(x)
    skip = tfl.Activation('relu')(x)
    if maxpooling == True:
        out = tfl.MaxPool2D(pool_size=(2, 2), strides=(2, 2))(skip)
    else:
        out = skip

    return out, skip

def upsampling_block(expansive_input, contractive_input, n_filters):
    """
    Upsampling block

    Inputs:
        expansive_input - input from the previous layer of the expansive path
        contractive_input - input from the corresponding encoder block
    """
    # upsample and perform convolution
    up = tfl.Conv2DTranspose(n_filters, kernel_size=2, strides=2, padding='same')(expansive_input)
    # concatenate the inputs on the channel axis
    input = tfl.concatenate([up, contractive_input], axis=3)
    out, _ = conv_block(input, n_filters, False)

    return out

def unet_model(input_size=(512, 512, 3), n_filters=64):
    """
    U-Net model

    Inputs:
        input_size - size of the input image
        n_filters - base number of filters

    Returns:
        model - U-Net model
    """
    # Contracting path
    inputs = tfl.Input(input_size)
    cblock1 = conv_block(inputs, n_filters)
    cblock2 = conv_block(cblock1[0], n_filters*2)
    cblock3 = conv_block(cblock2[0], n_filters*4)
    cblock4 = conv_block(cblock3[0], n_filters*8)
    # Bridge
    cblock5 = conv_block(cblock4[0], n_filters*16, maxpooling=False)

    # Expansive path
    ublock6 = upsampling_block(cblock5[0], cblock4[1],  n_filters*8)
    ublock7 = upsampling_block(ublock6, cblock3[1],  n_filters*4)
    ublock8 = upsampling_block(ublock7, cblock2[1],  n_filters*2)
    ublock9 = upsampling_block(ublock8, cblock1[1],  n_filters)

    out = tfl.Conv2D(1, 1, padding='same', activation='sigmoid')(ublock9)

    model = tf.keras.Model(inputs=inputs, outputs=out)

    return model

unet = unet_model()

unet.summary()

unet.compile(optimizer=tf.keras.optimizers.Adam(),
             loss=tf.keras.losses.BinaryCrossentropy(),
             metrics=[jaccard_index, 'accuracy'])
unet.fit(images_train, masks_train, epochs=10, batch_size=4, validation_split=0.2)

unet.evaluate(images_test, masks_test, batch_size=4)

predicted_mask = unet.predict(images_test, batch_size=4)
predicted_mask2 = (predicted_mask > 0.5).astype(np.uint8)

# predicted masks
fig, ax = plt.subplots(5, 3, figsize=(12, 10))

for i in range(5):
    ax[i, 0].imshow(images_test[i])
    ax[i, 0].axis('off')
    ax[i, 1].imshow(masks_test[i])
    ax[i, 1].axis('off')
    ax[i, 2].imshow(predicted_mask2[i])
    ax[i, 2].axis('off')

ax[0, 0].set_title('Original image')
ax[0, 1].set_title('True mask')
ax[0, 2].set_title('Predicted mask')

fig.tight_layout()

cr = classification_report(masks_test.flatten(), predicted_mask2.flatten())
print(cr)
-------------------------------------
import tensorflow as tf
from tensorflow import keras

from tensorflow.keras.layers import Input, Embedding, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import gc

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import EarlyStopping
from keras.layers import Conv1D, Reshape, Masking
from keras.metrics import Accuracy
from tensorflow.keras import layers, regularizers
from tensorflow.keras.layers.experimental import preprocessing
from tensorflow.keras.losses import categorical_crossentropy

class TransformerEncoder(layers.Layer):
    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):
        super().__init__(**kwargs)
        self.embed_dim = embed_dim
        self.dense_dim = dense_dim
        self.num_heads = num_heads
        self.attention = layers.MultiHeadAttention(
            num_heads=num_heads, key_dim=embed_dim)
        self.dense_proj = keras.Sequential(
            [layers.Dense(dense_dim, activation="relu"),
             layers.Dense(embed_dim),]
        )
        self.layernorm_1 = layers.LayerNormalization()
        self.layernorm_2 = layers.LayerNormalization()

    def call(self, inputs, mask=None):
        if mask is not None:
            mask = mask[:, tf.newaxis, :]
        
        attention_output = self.attention(
            inputs, inputs, attention_mask=mask)
        proj_input = self.layernorm_1(inputs + attention_output)
        proj_output = self.dense_proj(proj_input)
        return self.layernorm_2(proj_input + proj_output)

    def get_config(self):
        config = super().get_config()
        config.update({
            "embed_dim": self.embed_dim,
            "num_heads": self.num_heads,
            "dense_dim": self.dense_dim,
        })
        return config

"""class TransformerDecoder(layers.Layer):
    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):
        super().__init__(**kwargs)
        
        self.embed_dim = embed_dim
        self.dense_dim = dense_dim
        self.num_heads = num_heads
        
        self.attention_1 = layers.MultiHeadAttention(
            num_heads=num_heads, key_dim=embed_dim
        )
        self.attention_2 = layers.MultiHeadAttention(
            num_heads=num_heads, key_dim=embed_dim
        )
        self.dense_proj = keras.Sequential([
            layers.Dense(dense_dim, activation="relu"),
            layers.Dense(embed_dim),
        ])
        
        self.layernorm_1 = layers.LayerNormalization()
        self.layernorm_2 = layers.LayerNormalization()
        self.layernorm_3 = layers.LayerNormalization()
        self.supports_masking = True
        
    def get_config(self):
        config = super().get_config()
        config.update({
            "embed_dim": self.embed_dim,
            "num_heads": self.num_heads,
            "dense_dim": self.dense_dim,
        })
        return config


def get_causal_attention_mask(self, inputs):
    input_shape = tf.shape(inputs)
    batch_size, sequence_length = input_shape[0], input_shape[1]
    
    i = tf.range(sequence_length)[:, tf.newaxis]
    j = tf.range(sequence_length)
    mask = tf.cast(i >= j, dtype="int32")
    mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))
    
    mult = tf.concat(
        [
            tf.expand_dims(batch_size, -1),
            tf.constant([1, 1], dtype=tf.int32)
        ],
        axis=0
    )
    
    return tf.tile(mask, mult)   
    
      
    
    
def call(self, inputs, encoder_outputs, mask=None):
    causal_mask = self.get_causal_attention_mask(inputs)
    
    if mask is not None:
        padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype="int32")
        padding_mask = tf.minimum(padding_mask, causal_mask)
        
        attention_output_1 = self.attention_1(
            query=inputs,
            value=inputs,
            key=inputs,
            attention_mask=causal_mask
        )
        attention_output_1 = self.layernorm_1(inputs + attention_output_1)
        
        attention_output_2 = self.attention_2(
            query=attention_output_1,
            value=encoder_outputs,
            key=encoder_outputs,
            attention_mask=padding_mask
        )
        attention_output_2 = self.layernorm_2(attention_output_1 + attention_output_2)
        
        proj_output = self.dense_proj(attention_output_2)
        
    return self.layernorm_3(attention_output_2 + proj_output)

"""

"""def one_hot_to_word(encoded_word):
    max_word_length = 10
    alphabet_size = 27

    # Reshape the encoded word back to the matrix form
    encoded_matrix = encoded_word.reshape((max_word_length, alphabet_size))

    # Initialize an empty string to store the reconstructed word
    reconstructed_word = ""

    # Iterate through each position in the matrix
    for row in encoded_matrix:
        # Find the index where value is 1 in each row
        if sum(row) == 0:
            break
        char_index = np.argmax(row)

        # Convert the index to the corresponding character
        if 0 <= char_index < alphabet_size:
            char = chr(char_index + ord('a'))
            reconstructed_word += char

    return reconstructed_word"""

import numpy as np

# Function to convert a word to a one-hot encoded matrix
def word_to_one_hot(word):
    max_word_length = 10
    alphabet_size = 27

    # Convert the word to lowercase
    word = word.lower()

    # Truncate the word if it's longer than 10 characters
    word = word[:max_word_length]

    # Create a matrix of zeros with dimensions 10x26
    one_hot_matrix = np.zeros((max_word_length, alphabet_size))

    # Iterate through each character in the word
    for i, char in enumerate(word):
       
        if char == "*":
            one_hot_matrix[i, -1] = 1
                
        
        if 'a' <= char <= 'z':
            
            char_index = ord(char) - ord('a')
            one_hot_matrix[i, char_index] = 1 
            
    return one_hot_matrix.flatten()        

import re
import numpy as np

def remove_punctuation_except_asterisk(input_string):
    # Define a regular expression pattern to match all punctuation except *
    punctuation_pattern = r'[^\w\s*]'

    # Remove punctuation except *
    processed_string = re.sub(punctuation_pattern, '', input_string)
    return processed_string

class CustomAccuracy2(tf.keras.metrics.Metric):
    def __init__(self, name='word_acc', **kwargs):
        super().__init__(name=name, **kwargs)
        self.total_count = self.add_weight(name='total_count', initializer='zeros')
        self.correct_count = self.add_weight(name='correct_count', initializer='zeros')

    def update_state(self, y_true, y_pred, sample_weight=None):
        total = tf.cast(tf.shape(y_true)[0], tf.float32)
        self.total_count.assign_add(total)
        
        all_correct = tf.ones_like(y_true[:, 0], dtype=tf.float32)
        
        for i in tf.range(10):
            y_pred_slice = y_pred[:, i * 27:(i + 1) * 27]
            y_true_slice = y_true[:, i * 27:(i + 1) * 27]
            all_correct *= tf.cast(tf.argmax(y_pred_slice, axis=1) == tf.argmax(y_true_slice, axis=1), tf.float32)
        
        correct_numbers = tf.reduce_sum(all_correct)  
        self.correct_count.assign_add(correct_numbers)

    def result(self):
        epsilon = tf.constant(0.1, dtype=tf.float32)
        accuracy = self.correct_count / (self.total_count + epsilon)
        
        return accuracy


import tensorflow as tf

class CustomAccuracy1(tf.keras.metrics.Metric):
    def __init__(self, name='letter_acc', **kwargs):
        super().__init__(name=name, **kwargs)
        self.total_count = self.add_weight(name='total_count', initializer='zeros')
        self.correct_count = self.add_weight(name='correct_count', initializer='zeros')

    def update_state(self, y_true, y_pred, sample_weight=None):
        count = tf.constant(0, dtype=tf.float32)
        total = tf.constant(0, dtype=tf.float32)

        for i in tf.range(10):
            masked_slice = y_pred[:, i * 27:(i + 1) * 27]
            count += tf.reduce_sum(tf.cast(tf.argmax(masked_slice, axis=1) == tf.argmax(y_true[:, i * 27:(i + 1) * 27], axis=1), tf.float32))
            total += tf.cast(tf.shape(y_true)[0], tf.float32)  
        
        self.total_count.assign_add(total)
        self.correct_count.assign_add(count)
        

    def result(self):
        epsilon = tf.constant(0.1, dtype=tf.float32)
        accuracy1 = self.correct_count / (self.total_count + epsilon)
        
        return accuracy1

import tensorflow as tf

class CustomOutputLayer(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super(CustomOutputLayer, self).__init__(**kwargs)
        self.reshape_layer = tf.keras.layers.Reshape((10, 27))
        self.softmax_layers = [tf.keras.layers.Softmax() for _ in range(10)]

    def call(self, inputs):
        reshaped_output = self.reshape_layer(inputs)
        softmax_outputs = [softmax(reshaped_output[:, i, :]) for i, softmax in enumerate(self.softmax_layers)]
        return tf.concat(softmax_outputs, axis=1)

file_train = np.load('/kaggle/input/books-image-data/book_250000.npz')
#file_test = np.load('/kaggle/input/brave-new-world-book-words/book_test.npz')

file_t_train = np.load('/kaggle/input/books-image-data/book_250000_target.npy')
#file_t_test = np.load('/kaggle/input/brave-new-world-book-words/book_test_target.npz')

file_train.files

X_train=file_train['words_as_image'].astype(np.float32)

"""X_test=file_test['words_list'].astype(np.float32)

y_train=file_t_train['words']
y_test=file_t_test['words']
"""

file_train.close()
file_test.close()
file_t_train.close()
file_t_test.close()

y_train =y_train.astype(str)
y_test =y_test.astype(str)

y_train = [remove_punctuation_except_asterisk(element) for element in y_train]
y_test = [remove_punctuation_except_asterisk(element) for element in y_test]


y_train = np.array([word_to_one_hot(word) for word in y_train])
y_test = np.array([word_to_one_hot(word) for word in y_test])

def segment(dizi):
    section_size = 32
    total_sections = 8
    new_dizi = []
    for sample in dizi:
        sample_sections = []

        for time_step in sample:
            row = []

            # Iterate through the total sections
            for i in range(total_sections):
                start_index = i * section_size
                end_index = start_index + section_size

                # Create a section
                section = time_step[start_index:end_index]

                # Convert section to NumPy array
                section_array = np.array(section)

                # Append the section_array to the row
                row.append(section_array)
            # Convert the row to a NumPy array
            row_array = np.array(row)

            # Append the row_array to the sample_sections
            sample_sections.append(row_array)

        # Convert the sample_sections to a NumPy array
        sample_sections_array = np.array(sample_sections)

        # Append the sample_sections_array to the result_sections
        new_dizi.append(sample_sections_array)

    # Convert the result_sections to a NumPy array
    new_dizi = np.array(new_dizi)
    return new_dizi

new_X_train_160=segment(X_train)
new_X_test_160=segment(X_test)

new_X_train_160=new_X_train_160.reshape((300000,80,32))

new_X_test_160=new_X_test_160.reshape((141268,80,32))

gc.collect()

sequence_size = 10*8
embed_dim = 32
num_heads = 2
dense_dim = 2
stack_number = 3

inputs = keras.Input(shape=(sequence_size, embed_dim)) 
x = inputs

all_positions = [[i]*8 for i in range(10)]
flattened_positions = np.array(all_positions).flatten()
positions = tf.constant(flattened_positions)

position_encode = layers.Embedding(input_dim=sequence_size, output_dim=embed_dim)(positions)

x = x + position_encode

for _ in range(stack_number):
    x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)


regularization = keras.regularizers.l2(0.01)

x = layers.Conv1D(filters=64, kernel_size=3, activation='relu', kernel_regularizer=regularization, padding="same")(x)
x = layers.Dropout(0.0)(x)
x = layers.Conv1D(filters=16, kernel_size=3, activation='relu', kernel_regularizer=regularization, padding="same")(x)

x = layers.Flatten()(x)
x = layers.Dropout(0.2)(x)
x = layers.Dense(1024, activation="relu")(x)
x = layers.Dropout(0.6)(x)
x = layers.Dense(512, activation="relu")(x)
x = layers.Dense(270, activation="linear")(x)

outputs = CustomOutputLayer()(x)
model = keras.Model(inputs, outputs)

model.summary()

my_loss_1="mean_squared_error"
my_loss_2="categorical_crossentropy"

from tensorflow.keras.callbacks import ReduceLROnPlateau

reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7)

model.compile(optimizer='adam', loss=my_loss_1, metrics=[CustomAccuracy1(), CustomAccuracy2()])
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, verbose=1, restore_best_weights=True)
history = model.fit(new_X_train_160, y_train, epochs=1000, batch_size=32, verbose=1, validation_data=(new_X_test_160, y_test), callbacks=[early_stopping, reduce_lr])

del model

gc.collect()
-------------------------------------
import pandas as pd
from sklearn.model_selection import train_test_split
import cv2
from keras.models import Sequential
from keras.layers import Dense
from tensorflow.keras.layers import Dense, Dropout, Flatten
import keras
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.applications.resnet_v2 import ResNet50V2

train = pd.read_csv('/kaggle/input/facial-keypoints-detection/training.zip', compression='zip')

train.fillna(method = 'ffill', inplace=True)

class Config:
    size = 96
    img_size = (size, size, 3)
    test_size = .15
    random_state = 42
    batch_size=32
config = Config()

img = []
n = len(train)
for i in range(n):
    face_pixel = np.array(train['Image'][i].split(' '), dtype='float')
    face_pixel = np.reshape(face_pixel, (config.size,config.size))
    face_pixel = np.float32(face_pixel)
    face_pixel = cv2.cvtColor(face_pixel, cv2.COLOR_GRAY2RGB) /255
    img.append(face_pixel)
X_train = np.array(img)

y_train = train.drop('Image',axis=1).values
y_train.shape

def image_with_keypoints(X, y, index):
    image = plt.imshow(X[index],cmap='gray')
    l = []
    for i in range(1,31,2):
        l.append(plt.plot( y[index][i-1], y_train[index][i], 'r*'))
        
    return image, l



fig = plt.figure(figsize=(3, 3))

image_with_keypoints(X_train, y_train, 0)

plt.show()

X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = config.test_size, random_state = config.random_state)
X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = config.test_size, random_state = config.random_state)

X_train.shape, X_val.shape, X_test.shape

def train_model(model_api, config, classes, folder_name):
  model_base = model_api(include_top = False, input_shape = config.img_size, weights = 'imagenet')

  model_base.trainable = False

  model = Sequential()
  model.add(model_base)
  model.add(Flatten())
#   model.add(Dense(256, activation='relu'))
  model.add(Dense(128, activation='relu'))
  model.add(Dense(64, activation='relu'))
  model.add(Dense(classes))
    
    
  model.compile(optimizer=keras.optimizers.Adam(5e-5), loss='mse', metrics=['accuracy'])

#   early = EarlyStopping(monitor="val_accuracy", mode="max", patience=2, verbose = 1)
#   checkpoint = ModelCheckpoint(f'./{folder_name}.ckpt', monitor='val_accuracy', save_best_only=True, mode='max')

  model.fit(
      X_train, 
      y_train, 
      batch_size=config.batch_size,
      epochs = 10, 
      validation_data=(X_val, y_val),
      verbose=1)#,
#       callbacks=[checkpoint, early])
  

  return model

resnet_model = train_model(ResNet50V2, config, y_train.shape[1], 'ResNet50V2')

test_loss, test_accuracy = resnet_model.evaluate(X_test, y_test)
print("Test results \n Loss:",test_loss,'\n Accuracy',test_accuracy)

test_acc = np.expand_dims(X_train[0], axis=0)
%timeit resnet_model.predict(test_acc, verbose = 0)

from keras.applications import MobileNet, MobileNetV2, DenseNet121
mobile_model = train_model(MobileNet, config, y_train.shape[1], 'MobileNet')

test_loss, test_accuracy = mobile_model.evaluate(X_test, y_test)
print("Test results \n Loss:",test_loss,'\n Accuracy',test_accuracy)

test_acc = np.expand_dims(X_train[0], axis=0)
%timeit mobile_model.predict(test_acc, verbose = 0)

mobilev2_model = train_model(MobileNetV2, config, y_train.shape[1], 'MobileNetV2')

test_loss, test_accuracy = mobilev2_model.evaluate(X_test, y_test)
print("Test results \n Loss:",test_loss,'\n Accuracy',test_accuracy)

test_acc = np.expand_dims(X_train[0], axis=0)
%timeit mobilev2_model.predict(test_acc, verbose = 0)

from keras.applications import EfficientNetV2B0
eff_model = train_model(EfficientNetV2B0, config, y_train.shape[1], 'EfficientNetV2B0')

test_loss, test_accuracy = eff_model.evaluate(X_test, y_test)
print("Test results \n Loss:",test_loss,'\n Accuracy',test_accuracy)

test_acc = np.expand_dims(X_train[0], axis=0)
%timeit eff_model.predict(test_acc, verbose = 0)

alex_model=keras.models.Sequential([
    keras.layers.Conv2D(filters=128, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=config.img_size),
    keras.layers.BatchNormalization(),
    keras.layers.MaxPool2D(pool_size=(2,2)),
    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.MaxPool2D(pool_size=(3,3)),
    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding="same"),
    keras.layers.BatchNormalization(),
    keras.layers.MaxPool2D(pool_size=(2,2)),
    keras.layers.Flatten(),
    keras.layers.Dense(256,activation='relu'),
    keras.layers.Dense(128,activation='relu'),
    keras.layers.Dense(y_test.shape[1])  
    
    
])

    
alex_model.compile(optimizer=keras.optimizers.Adam(5e-5), loss='mse', metrics=['accuracy'])

#   early = EarlyStopping(monitor="val_accuracy", mode="max", patience=2, verbose = 1)
#   checkpoint = ModelCheckpoint(f'./{folder_name}.ckpt', monitor='val_accuracy', save_best_only=True, mode='max')

alex_model.fit(
  X_train, 
  y_train, 
  batch_size=config.batch_size,
  epochs = 10, 
  validation_data=(X_val, y_val),
  verbose=1)#,

test_loss, test_accuracy = alex_model.evaluate(X_test, y_test)
print("Test results \n Loss:",test_loss,'\n Accuracy',test_accuracy)

test_acc = np.expand_dims(X_train[0], axis=0)
%timeit alex_model.predict(test_acc, verbose = 0)

fig = plt.figure(figsize=(3, 3))
image_with_keypoints(X_test, y_test, 0)
plt.title('True Label') 
plt.show()

y_pred = resnet_model.predict(X_test, verbose = 0)
fig = plt.figure(figsize=(3, 3))

image_with_keypoints(X_test, y_pred, 0)
plt.title('Predict') 
plt.show()
-------------------------------------

import tensorflow as tf
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

pip install imutils

from tensorflow.keras.layers import Input, concatenate, LeakyReLU, BatchNormalization, Conv2D, MaxPooling2D, Dropout, UpSampling2D
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.callbacks import LearningRateScheduler
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
from skimage.transform import resize
import os
import csv
import PIL
import numpy as np
import random
import cv2
import imutils
import tensorflow.keras.backend as K
import tensorflow as tf
from tensorflow.keras.applications import ResNet50

HEIGHT = 240
WIDTH = 320
INIT_LR = 0.0001
EPOCHS = 15
TRAIN_PATH = "./data/nyu2_train.csv"
TEST_PATH = "./data/nyu2_test.csv"

def downsampling_block(input_tensor, n_filters):
  x = Conv2D(filters=n_filters, kernel_size=(3,3), padding='same')(input_tensor)
  x = LeakyReLU(alpha=0.2)(x)
  x = BatchNormalization()(x)

  x = Conv2D(filters=n_filters, kernel_size=(3,3), padding='same')(x)
  x = LeakyReLU(alpha=0.2)(x)
  x = BatchNormalization()(x)
  return x

def upsampling_block(input_tensor, n_filters, name, concat_with):
  x = UpSampling2D((2, 2), interpolation='bilinear', name=name)(input_tensor)
  x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same', name=name+"_convA")(x)
  x = LeakyReLU(alpha=0.2)(x)

  x = concatenate([x, concat_with], axis=3)

  x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same', name=name+"_convB")(x)
  x = LeakyReLU(alpha=0.2)(x)
  x = BatchNormalization()(x)

  x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same', name=name+"_convC")(x)
  x = LeakyReLU(alpha=0.2)(x)
  x = BatchNormalization()(x)
  return x

def build(height, width, depth):
  # input
  i = Input(shape=(height, width, depth))

  resnet50 = ResNet50(include_top = False, weights = "imagenet", input_tensor = i)
  resnet50.summary()

  # encoder
#   conv1 = downsampling_block(i, 32)
#   pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
#   conv2 = downsampling_block(pool1, 64)
#   pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
#   conv3 = downsampling_block(pool2, 128)
#   pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
#   conv4 = downsampling_block(pool3, 256)
#   pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)

  conv1 = resnet50.get_layer("input_1").output
  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
  conv2 = resnet50.get_layer("conv1_relu").output
  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
  conv3 = resnet50.get_layer("conv2_block3_out").output
  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
  conv4 = resnet50.get_layer("conv3_block4_out").output
  pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)
  

  # bottleneck
  conv5 = resnet50.get_layer("conv4_block6_out").output
  conv5 = LeakyReLU(alpha=0.2)(conv5)
  conv5 = resnet50.get_layer("conv4_block6_out").output
  conv5 = LeakyReLU(alpha=0.2)(conv5)

  # decoder
  conv6 = upsampling_block(conv5, 256, "up1", concat_with=conv4)
  conv7 = upsampling_block(conv6, 128, "up2", concat_with=conv3)
  conv8 = upsampling_block(conv7, 64, "up3", concat_with=conv2)
  conv9 = upsampling_block(conv8, 32, "up4", concat_with=conv1)

  # output
  o = Conv2D(filters=1, kernel_size=3, strides=(1,1), activation='sigmoid', padding='same', name='conv10')(conv9)

  model = Model(inputs=i, outputs=o)
  return model

model = build(HEIGHT, WIDTH, 3)

model.summary()
# from tensorflow.keras.utils import plot_model
# plot_model(model, to_file='./model.png')

!git clone https://gitlab.com/siddinc/new_depth.git ./data

# loading the dataset

def read_csv(csv_file_path):
  with open(csv_file_path, 'r') as f:
    csv_reader = csv.reader(f, delimiter=',')
    return [('./' + row[0], './' + row[1]) for row in csv_reader if len(row) > 0]

def train_val_split(train_paths, val_size):
  random.shuffle(train_paths)
  len_train_paths = len(train_paths)
  i = int(len_train_paths*(1.0 - val_size))
  train = train_paths[0:i]
  val = train_paths[i:len(train_paths)]
  return train, val

def load_train_paths(train_path):
  train_paths = read_csv(train_path)
  labels = {img_path: dm_path for img_path, dm_path in train_paths}
  x_paths = [img_path for img_path, dm in train_paths]
  x_train_paths, x_val_paths = train_val_split(x_paths, 0.3)

  partition = {
    'train': x_train_paths,
    'validation': x_val_paths
  }
  return partition, labels

# preprocessing the dataset

def normalize_img(img):
    norm_img = (img - img.min()) / (img.max() - img.min())
    return norm_img

def preprocess_image(img_path, horizontal_flip=False):
  image = cv2.imread(img_path)
  image = imutils.resize(image, height=HEIGHT)
  # image = image[:, 21:149].astype("float")
  image = image.astype("float")
  image = normalize_img(image)

  if horizontal_flip:
    image = cv2.flip(image, 1)
  return image

def preprocess_depth_map(depth_map_path, horizontal_flip=False):
  depth_map = cv2.imread(depth_map_path)
  depth_map = cv2.cvtColor(depth_map, cv2.COLOR_BGR2GRAY)
  depth_map = imutils.resize(depth_map, height=HEIGHT)
  # depth_map = depth_map[:, 21:149].astype("float")
  depth_map = depth_map.astype("float")
  depth_map = normalize_img(depth_map)

  if horizontal_flip:
    depth_map = cv2.flip(depth_map, 1)

  depth_map = np.reshape(depth_map, (depth_map.shape[0], depth_map.shape[1], 1))
  return depth_map

# data generator

from tensorflow.keras.utils import Sequence

class DataGenerator(Sequence):
  def __init__(self, list_IDs, labels, batch_size=16, dim=(128,128), n_channels=3, shuffle=True, pred=False):
    self.dim = dim
    self.batch_size = batch_size
    self.labels = labels
    self.list_IDs = list_IDs
    self.n_channels = n_channels
    self.shuffle = shuffle
    self.pred = pred
    self.on_epoch_end()

  def __len__(self):
    return int(np.floor(len(self.list_IDs) / self.batch_size))

  def __getitem__(self, index):
    indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]
    list_IDs_temp = [self.list_IDs[k] for k in indexes]
    if self.pred:
      X = self.__data_generation(list_IDs_temp)
      return X
    X, y = self.__data_generation(list_IDs_temp)
    return X, y

  def on_epoch_end(self):
    self.indexes = np.arange(len(self.list_IDs))
    if self.shuffle == True:
      np.random.shuffle(self.indexes)

  def __data_generation(self, list_IDs_temp):
    X = np.empty((self.batch_size, self.dim[0], self.dim[1],self.n_channels))

    if not self.pred:
      y = np.empty((self.batch_size, self.dim[0], self.dim[1], 1))

      for i, ID in enumerate(list_IDs_temp):
        res = random.choice([True, False])
        X[i,] = preprocess_image(ID, res)
        y[i,] = preprocess_depth_map(self.labels[ID], res)
      return X, y
    else:
      for i, ID in enumerate(list_IDs_temp):
        res = random.choice([True, False])
        X[i,] = preprocess_image(ID, res)
      return X

partition, labels = load_train_paths(TRAIN_PATH)

print(len(partition['train']), len(partition['validation']))

training_generator = DataGenerator(list_IDs=partition['train'], labels=labels, batch_size=16, dim=(HEIGHT, WIDTH), n_channels=3, shuffle=True, pred=False)
validation_generator = DataGenerator(list_IDs=partition['validation'], labels=labels, batch_size=16, dim=(HEIGHT, WIDTH), n_channels=3, shuffle=True, pred=False)

def poly_decay(epoch):
  maxEpochs = EPOCHS
  baseLR = INIT_LR
  power = 1.0
  alpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power
  return alpha

opt = Adam(lr=INIT_LR, amsgrad=True)
callbacks = [LearningRateScheduler(poly_decay)]

# custom loss
def depth_loss(y_true, y_pred):
  w1, w2, w3 = 1.0, 1.0, 0.1

  l_depth = K.mean(K.abs(y_pred - y_true), axis=-1)

  dy_true, dx_true = tf.image.image_gradients(y_true)
  dy_pred, dx_pred = tf.image.image_gradients(y_pred)
  l_edges = K.mean(K.abs(dy_pred - dy_true) + K.abs(dx_pred - dx_true), axis=-1)

  l_ssim = K.clip((1 - tf.image.ssim(y_true, y_pred, 1.0)) * 0.5, 0, 1)

  return (w1 * l_ssim) + (w2 * K.mean(l_edges)) + (w3 * K.mean(l_depth))

#custom soft accuracy
def depth_acc(y_true, y_pred):
  return K.mean(K.equal(K.round(y_true), K.round(y_pred)))

model.compile(optimizer=opt, loss=depth_loss, metrics=[depth_acc])

r = model.fit(training_generator, validation_data=validation_generator, epochs=15, callbacks=callbacks)

model.save("resnet_unet_15.keras")

# model.load_weights("/kaggle/input/unet-resnet-nyu-model-5/unet_resnet_nyu_model.keras")

import matplotlib.pyplot as plt
plt.style.use('ggplot')
# e = np.linspace(1, EPOCHS, num=EPOCHS)

plt.plot(r.history['loss'], label='loss')
plt.plot(r.history['val_loss'], label='val_loss')

plt.plot(r.history['depth_acc'], label='acc')
plt.plot(r.history['val_depth_acc'], label='val_acc')

plt.legend()
plt.show()

img_dm_pairs = read_csv('./data/nyu2_test.csv')
labels = {i: j for i,j in img_dm_pairs}
test_paths = [i for i,j in img_dm_pairs]
print(len(test_paths))
partition = {'test': test_paths}

x_test = np.empty((len(test_paths), HEIGHT, WIDTH, 3))
y_test = np.empty((len(test_paths), HEIGHT, WIDTH, 1))

for i, ID in enumerate(partition['test'][:]):
  x_test[i, ] = preprocess_image(ID, horizontal_flip=False)
  y_test[i, ] = preprocess_depth_map(labels[ID], horizontal_flip=False)

print(model.evaluate(x_test, y_test))

import matplotlib.pyplot as plt
import numpy as np

preds = model.predict(x_test)

for i in range(len(test_paths)-600):
  path = partition['test'][i]
  label_path = labels[path]
  pred = preds[i]
  pred = np.squeeze(pred, axis=-1)

  plt.subplot(1,3,1)
  plt.axis("off")
  plt.title("Prediction")
  plt.imshow(pred, cmap=plt.get_cmap('inferno_r'))

  plt.subplot(1,3,2)
  plt.axis("off")
  plt.title("GT")
  img = preprocess_depth_map(label_path, horizontal_flip=False)
  img = np.squeeze(img, axis=-1)
  plt.imshow(img, cmap=plt.get_cmap('inferno_r'))

  plt.subplot(1,3,3)
  plt.axis("off")
  plt.title("Original RGB image")
  img1 = preprocess_image(path, horizontal_flip=False)
  plt.imshow(img1)

  plt.show()
-------------------------------------
!python --version
!pip --version

import tensorflow as tf
import tensorflow_addons as tfa
from tensorflow.keras.preprocessing.image import load_img,img_to_array
from tensorflow.keras.initializers import RandomNormal
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.optimizers import *
from tensorflow.keras.models import Model,Sequential
from tensorflow.keras.layers import *
from tensorflow.keras.callbacks import *
from tensorflow.keras import backend as K
from tensorflow.keras.losses import *
from tensorflow.keras.mixed_precision import experimental as mixed_precision
from tensorflow.keras.regularizers import l1_l2
from tensorflow.python.client import device_lib
import numpy as np

from matplotlib import cm as CM
import matplotlib.pyplot as plt
import tensorflow as tf
from tqdm import tqdm
import scipy.io as io
from PIL import Image
import PIL
import h5py
import os
import glob
import cv2
import random
import math
import sys
import itertools 

print(tf.__version__)

policy = mixed_precision.Policy('mixed_float16')
mixed_precision.set_policy(policy)

print('Compute dtype: %s' % policy.compute_dtype)
print('Variable dtype: %s\n\n' % policy.variable_dtype)

for info in device_lib.list_local_devices():
    if (info.name.find('GPU') != -1):
        print(info)

def getPath(data_type):
    root = r'../input/shanghaitech-with-people-density-map/ShanghaiTech'
    print(root)
    if data_type.find('part_A')!=-1:
        target_train = os.path.join(root,r'part_A/train_data','images')
        target_test = os.path.join(root,r'part_A/test_data','images')

    elif data_type.find('part_B')!=-1:
        target_train = os.path.join(root,r'part_B/train_data','images')
        target_test = os.path.join(root,r'part_B/test_data','images')

    train_path = []
    for img_path in glob.glob(os.path.join(target_train, '*.jpg')):
        train_path.append(str(img_path))
        
    test_path = []
    for img_path in glob.glob(os.path.join(target_test, '*.jpg')):
        test_path.append(str(img_path))
        
    return train_path, test_path

def load_density(file_path):
    gt_file = h5py.File(file_path, 'r')
    groundtruth = np.asarray(gt_file['density'])
    groundtruth = np.expand_dims(groundtruth, axis=-1)
    return groundtruth

# Get input image path
train_paths, test_paths = getPath('part_B')
# Get ground truth path
gth_train = [path.replace('jpg', 'h5').replace('images', 'ground-truth-h5') for path in train_paths]
gth_test = [path.replace('jpg', 'h5').replace('images', 'ground-truth-h5') for path in test_paths]

print('train len:', len(train_paths))
print('test len:', len(test_paths))

print(train_paths[0])
print(gth_train[0])

train_labels=np.array([load_density(path) for path in gth_train]).astype('float16')
print(train_labels.shape)
test_labels=np.array([load_density(path) for path in gth_test]).astype('float16')
print(test_labels.shape)

target_type=tf.dtypes.float16
def load_img(path):
    image_string=tf.io.read_file(path)
    image=tf.image.decode_jpeg(image_string,channels=3)
    image=tf.image.convert_image_dtype(image, target_type)
    return image

def gen_translate_func(translate_range):
    def translate_function(img, gth):
        ratio=tf.random.uniform((2,), minval=translate_range[1], maxval=translate_range[0], dtype=tf.dtypes.int32)
        ratio=tf.cast(ratio, target_type)

        out_gth=tfa.image.translate(gth, ratio, 'BILINEAR')
        out_img=tfa.image.translate(img, ratio, 'BILINEAR')

        return out_img, out_gth
    return translate_function

def gen_downsampling_func(downsampling, method='nearest', batch=True):
    batchadd=1
    if batch==False:
        batchadd=0
    @tf.function
    def _downsampling_function_(img, gth):
        down_ratio=downsampling
        before_resize=tf.reduce_sum(gth)
        gth_shape=tf.shape(gth)
        out_gth=tf.image.resize(gth, (gth_shape[0+batchadd]//down_ratio, gth_shape[1+batchadd]//down_ratio), method=method,antialias=False)
        out_gth=tf.cast(out_gth, dtype=target_type)
        after_resize=tf.reduce_sum(out_gth)
        if (before_resize >= 0.3) and (after_resize > 0.01):
            out_gth=out_gth * before_resize / after_resize
        return img, out_gth
    return _downsampling_function_

def gen_randomcrop_func(crop_size, batch=True):
    batchadd=1
    if batch==False:
        batchadd=0
    @tf.function
    def _random_crop_(img, gth):
        
        output_shape=tf.constant(crop_size)
        img_shape=tf.shape(img)

        ratio_x=tf.random.uniform((1,), minval=0, maxval=img_shape[1+batchadd]-output_shape[1], dtype=tf.dtypes.int32)[0]
        ratio_y=tf.random.uniform((1,), minval=0, maxval=img_shape[0+batchadd]-output_shape[0], dtype=tf.dtypes.int32)[0]

        out_img=tf.image.crop_to_bounding_box(img, ratio_y, ratio_x, output_shape[0], output_shape[1])
        out_gth=tf.image.crop_to_bounding_box(gth, ratio_y, ratio_x, output_shape[0], output_shape[1])

        return out_img, out_gth
    return _random_crop_

def gen_coarsedrop_func(hole_count, hole_size, hole_prob=0.75):
    def _dropout_(image, gth):
        shape = tf.shape(image)
        BATCH = shape[0]
        IMG_WIDTH = shape[2]
        IMG_HEIGHT = shape[1]
        IMG_WIDTH_F = tf.cast(IMG_WIDTH, tf.float32)
        IMG_HEIGHT_F = tf.cast(IMG_HEIGHT, tf.float32)
        PROBABILITY = hole_prob
        CT = hole_count
        CROP_SIZE = tf.cast(hole_size,tf.int32)
        # DO DROPOUT WITH PROBABILITY DEFINED ABOVE
        P = tf.cast( tf.random.uniform([], 0.0, 1.0) < PROBABILITY, tf.int32)
        if (P==0): return image, gth
        
        mask = tf.ones((IMG_HEIGHT,IMG_WIDTH,1))
        for k in range(CT):
            # CHOOSE RANDOM LOCATION
            x = tf.cast( tf.random.uniform([],0.0,IMG_WIDTH_F),tf.int32)
            y = tf.cast( tf.random.uniform([],0.0,IMG_HEIGHT_F),tf.int32)
            # COMPUTE SQUARE
            ya = tf.math.maximum(0,y-CROP_SIZE//2)
            yb = tf.math.minimum(IMG_HEIGHT,y+CROP_SIZE//2)
            xa = tf.math.maximum(0,x-CROP_SIZE//2)
            xb = tf.math.minimum(IMG_WIDTH,x+CROP_SIZE//2)
            # DROPOUT IMAGE
            one = mask[ya:yb,0:xa,:]
            two = tf.zeros([yb-ya,xb-xa,1]) 
            three = mask[ya:yb,xb:IMG_WIDTH,:]
            middle = tf.concat([one,two,three],axis=1)
            mask = tf.concat([mask[0:ya,:,:],middle,mask[yb:IMG_HEIGHT,:,:]],axis=0)
        
        # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR 
        mask = tf.cast(mask, dtype='float16')
        return image*mask, gth*mask
    return _dropout_

def basic_dataset(img_data, label_data, batch_size=1, flip=False, downsampling=1, buffer_size=32, shuffle=False):
    input_data=tf.data.Dataset.from_tensor_slices(img_data)
    input_data = input_data.map(load_img)
    output_data=tf.data.Dataset.from_tensor_slices(label_data)

    if flip:
        input_data=input_data.concatenate(input_data.map(tf.image.flip_left_right))
        output_data=output_data.concatenate(output_data.map(tf.image.flip_left_right))

    dataset=tf.data.Dataset.zip((input_data, output_data))
    if shuffle:
        dataset = dataset.batch(batch_size).repeat().shuffle(buffer_size=buffer_size, reshuffle_each_iteration=True)
    else:
        dataset = dataset.batch(batch_size).repeat()

    if downsampling!=1:
        dataset=dataset.map(gen_downsampling_func(downsampling=downsampling))
    return dataset

def crop_dataset(img_data, label_data, crop_size, flip, downsampling, batch_size=1, sample_method='bicubic', buffer_size=16, 
hole_count=0, hole_size=100, hole_prob=0.75):
    dataset = basic_dataset(img_data, label_data, flip=flip, batch_size=batch_size, downsampling=1, shuffle=True, buffer_size=buffer_size)
    dataset=dataset.map(gen_randomcrop_func(crop_size))
    if hole_count!=0:
        dataset=dataset.map(gen_coarsedrop_func(hole_count=hole_count, hole_size=hole_size, hole_prob=hole_prob))
    if downsampling!=1:
        dataset=dataset.map(gen_downsampling_func(downsampling=downsampling, method=sample_method))
    return dataset

def translate_dataset(img_data, label_data, translate_range, flip, downsampling, batch_size=1, sample_method='bicubic', buffer_size=16, 
hole_count=0, hole_size=100, hole_prob=0.75):
    dataset = basic_dataset(img_data, label_data, flip=flip, batch_size=batch_size, downsampling=1, shuffle=True, buffer_size=buffer_size)
    dataset=dataset.map(gen_translate_func(translate_range))
    if hole_count!=0:
        dataset=dataset.map(gen_coarsedrop_func(hole_count=hole_count, hole_size=hole_size, hole_prob=hole_prob))
    if downsampling!=1:
        dataset=dataset.map(gen_downsampling_func(downsampling=downsampling, method=sample_method))
    return dataset
            
def show_images(images, cols = 2, titles = None, padding=1, axis="off", channel1=CM.jet):
    assert((titles is None)or (len(images) == len(titles)))
    n_images = len(images)
    # if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]
    if titles is None: titles = [None for i in range(1,n_images + 1)]
    fig = plt.figure()
    
    for n, (image, title) in enumerate(zip(images, titles)):
        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)

        plt.axis(axis)
        plt.subplots_adjust(wspace=padding, hspace=padding)

        if (image.shape[2] == 1):
            image = image[:,:,0]
            plt.imshow(image, cmap=channel1)
        elif np.any(image > 1.0):
            plt.imshow(image / 255.0)
        else:
            plt.imshow(image)
        a.set_title(title, fontsize=20)
    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)
    plt.show()
def density_mae(y_truth, y_pred):
    return tf.reduce_mean(tf.abs(tf.reduce_sum(y_truth, axis=(1,2,3))-tf.reduce_sum(y_pred, axis=(1,2,3))))

def CSRNet(batch_norm=False, middle_activation='relu', final_activation='sigmoid', reg=(0.0,0.0), normal_input=True, dilations=[2,2,2,2,2,2], dtype=tf.dtypes.float16):
    init=RandomNormal(stddev=0.01)
    
    activationDict = {
        'sigmoid': tf.math.sigmoid,
        'relu': tf.nn.relu,
        'tanh': tf.math.tanh,
        'leakyrelu': tf.nn.leaky_relu,
        'elu': tf.nn.elu,
        'softsign':tf.nn.softsign
    }
    vgg16 = VGG16(weights='imagenet', include_top=False)
    vgg16.trainable=False
    
    input_layer = Input(shape=(None, None, 3))
    x = input_layer
    if (normal_input):
        x = Lambda(lambda batch: (batch - tf.constant([0.485,0.456,0.406], dtype=dtype)) / tf.constant([0.229,0.224,0.225],dtype=dtype))(x)

    count = 0
    for layer in vgg16.layers:
        layer.trainable = False
        x = layer(x)
        if 'conv' in layer.name:
            count+=1
        if count == 10:
            break;
            
    
    if batch_norm:
        x = BatchNormalization()(x)
    
    if batch_norm:
        x = Conv2D(filters=512, kernel_size=(3, 3), dilation_rate=dilations[0], padding='same', use_bias=False, kernel_initializer=init, kernel_regularizer=l1_l2(l1=reg[0], l2=reg[1]))(x)
        x = BatchNormalization()(x)
    else:
        x = Conv2D(filters=512, kernel_size=(3, 3), dilation_rate=dilations[0], padding='same', use_bias=True, kernel_initializer=init, kernel_regularizer=l1_l2(l1=reg[0], l2=reg[1]))(x)
    x = Activation(activationDict[middle_activation])(x)
    
    if batch_norm:
        x = Conv2D(filters=512, kernel_size=(3, 3), dilation_rate=dilations[1], padding='same', use_bias=False, kernel_initializer=init, kernel_regularizer=l1_l2(l1=reg[0], l2=reg[1]))(x)
        x = BatchNormalization()(x)
    else:
        x = Conv2D(filters=512, kernel_size=(3, 3), dilation_rate=dilations[1], padding='same', use_bias=True, kernel_initializer=init, kernel_regularizer=l1_l2(l1=reg[0], l2=reg[1]))(x)
    x = Activation(activationDict[middle_activation])(x)
    
    if batch_norm:
        x = Conv2D(filters=512, kernel_size=(3, 3), dilation_rate=dilations[2], padding='same', use_bias=False, kernel_initializer=init, kernel_regularizer=l1_l2(l1=reg[0], l2=reg[1]))(x)
        x = BatchNormalization()(x)
    else:
        x = Conv2D(filters=512, kernel_size=(3, 3), dilation_rate=dilations[2], padding='same', use_bias=True, kernel_initializer=init, kernel_regularizer=l1_l2(l1=reg[0], l2=reg[1]))(x)
    x = Activation(activationDict[middle_activation])(x)
    
    
    if batch_norm:
        x = Conv2D(filters=256, kernel_size=(3, 3), dilation_rate=dilations[3], padding='same', use_bias=False, kernel_initializer=init, kernel_regularizer=l1_l2(l1=reg[0], l2=reg[1]))(x)
        x = BatchNormalization()(x)
    else:
        x = Conv2D(filters=256, kernel_size=(3, 3), dilation_rate=dilations[3], padding='same', use_bias=True, kernel_initializer=init, kernel_regularizer=l1_l2(l1=reg[0], l2=reg[1]))(x)
    x = Activation(activationDict[middle_activation])(x)
    
    
    if batch_norm:
        x = Conv2D(filters=128, kernel_size=(3, 3), dilation_rate=dilations[4], padding='same', use_bias=False, kernel_initializer=init, kernel_regularizer=l1_l2(l1=reg[0], l2=reg[1]))(x)
        x = BatchNormalization()(x)
    else:
        x = Conv2D(filters=128, kernel_size=(3, 3), dilation_rate=dilations[4], padding='same', use_bias=True, kernel_initializer=init, kernel_regularizer=l1_l2(l1=reg[0], l2=reg[1]))(x)
    x = Activation(activationDict[middle_activation])(x)
    
    
    if batch_norm:
        x = Conv2D(filters=64, kernel_size=(3, 3), dilation_rate=dilations[5], padding='same', use_bias=False, kernel_initializer=init, kernel_regularizer=l1_l2(l1=reg[0], l2=reg[1]))(x)
        x = BatchNormalization()(x)
    else:
        x = Conv2D(filters=64, kernel_size=(3, 3), dilation_rate=dilations[5], padding='same', use_bias=True, kernel_initializer=init, kernel_regularizer=l1_l2(l1=reg[0], l2=reg[1]))(x)
    x = Activation(activationDict[middle_activation])(x)
        
    ###############################    
    x = Conv2D(filters=1, kernel_size=(1, 1), dilation_rate=1, padding='same', use_bias=True, kernel_initializer=init)(x)
    x = Activation(activationDict[final_activation])(x)
    
    model = Model(input_layer, x)
    return model

sgd = SGD(lr = 1e-4, momentum = 0.7, nesterov=True)
rms = RMSprop(lr=1e-4, momentum=0.7, decay=0.0001)
nadam = Nadam(lr=1e-2)

optimizer = rms
loss = 'binary_crossentropy'

batch_size=8
train_size=320

val_gen = basic_dataset(train_paths[train_size:], train_labels[train_size:], batch_size=1, flip=False, downsampling=8, buffer_size=16, shuffle=False)
test_gen = basic_dataset(test_paths, test_labels, batch_size=1, flip=False, downsampling=8, buffer_size=16, shuffle=False)
train_gen  = crop_dataset(train_paths[:train_size], train_labels[:train_size], crop_size=(760,1000), flip=True, downsampling=8, batch_size=batch_size, sample_method='bicubic', buffer_size=8)

filepath = r'/kaggle/working/CSRNet_1'
reduceLR=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_density_mae', factor=0.5, patience=5, verbose=1, min_delta=1e-8)
earlyStop=tf.keras.callbacks.EarlyStopping(monitor='val_density_mae', patience=25, verbose=1, restore_best_weights=True)
monitor=tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_density_mae', verbose=0, save_best_only=True, save_weights_only=True)


model = CSRNet(middle_activation='relu', final_activation='sigmoid', dtype=tf.dtypes.float16)
model.compile(optimizer=optimizer, loss=loss, metrics=[density_mae])
model.build(input_shape=(None, None, None, 3))

print('train baseline: ', np.mean( np.sum(train_labels[:train_size], axis=(1,2,3))))
print('val baseline: ', np.mean( np.sum(train_labels[320:], axis=(1,2,3))))

model.fit(train_gen, steps_per_epoch=int(train_size*2/batch_size), epochs=80, verbose=1, use_multiprocessing=True,
              max_queue_size=32, workers=6, validation_data=val_gen, validation_steps=80, callbacks=[earlyStop, monitor, reduceLR])

model.load_weights(filepath)
model.evaluate(val_gen, steps=80, verbose=1, workers=4)
model.evaluate(test_gen, steps=316, verbose=1, workers=4)

for a,b in test_gen.take(4):
    c = model.predict(a)
    a = tf.cast(a, dtype=tf.dtypes.float32)
    b = tf.cast(b, dtype=tf.dtypes.float32)
    c = c.astype('float32')
    show_images([a[0], b[0], c[0]], 1, ['', np.sum(b[0]), np.sum(c[0])])

sgd = SGD(lr = 1e-4, momentum = 0.7, nesterov=True)
rms = RMSprop(lr=1e-4, momentum=0.7, decay=0.0001)
nadam = Nadam(lr=1e-2)

optimizer = rms
loss = 'binary_crossentropy'

batch_size=8
train_size=320

val_gen = basic_dataset(train_paths[train_size:], train_labels[train_size:], batch_size=1, flip=False, downsampling=8, buffer_size=16, shuffle=False)
test_gen = basic_dataset(test_paths, test_labels, batch_size=1, flip=False, downsampling=8, buffer_size=16, shuffle=False)
train_gen = crop_dataset(train_paths[:train_size], train_labels[:train_size], crop_size=(760,1000), flip=True, downsampling=8, batch_size=batch_size, sample_method='bicubic', buffer_size=8,
                             hole_prob=1.0, hole_size=30, hole_count=20)

filepath = r'/kaggle/working/CSRNet_2'
reduceLR=tf.keras.callbacks.ReduceLROnPlateau(monitor='val_density_mae', factor=0.5, patience=5, verbose=1, min_delta=1e-8)
earlyStop=tf.keras.callbacks.EarlyStopping(monitor='val_density_mae', patience=25, verbose=1, restore_best_weights=True)
monitor=tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_density_mae', verbose=0, save_best_only=True, save_weights_only=True)


model = CSRNet(middle_activation='relu', final_activation='sigmoid', dtype=tf.dtypes.float16)
model.compile(optimizer=optimizer, loss=loss, metrics=[density_mae])
model.build(input_shape=(None, None, None, 3))

print('train baseline: ', np.mean( np.sum(train_labels[:train_size], axis=(1,2,3))))
print('val baseline: ', np.mean( np.sum(train_labels[320:], axis=(1,2,3))))

model.fit(train_gen, steps_per_epoch=int(train_size*2/batch_size), epochs=80, verbose=1, use_multiprocessing=True,
              max_queue_size=32, workers=6, validation_data=val_gen, validation_steps=80, callbacks=[earlyStop, monitor, reduceLR])

model.load_weights(filepath)
model.evaluate(val_gen, steps=80, verbose=1, workers=4)
model.evaluate(test_gen, steps=316, verbose=1, workers=4)

for a,b in test_gen.take(4):
    c = model.predict(a)
    a = tf.cast(a, dtype=tf.dtypes.float32)
    b = tf.cast(b, dtype=tf.dtypes.float32)
    c = c.astype('float32')
    show_images([a[0], b[0], c[0]], 1, ['', np.sum(b[0]), np.sum(c[0])])

for a,b in test_gen.take(10):
    c = model.predict(a)
    a = tf.cast(a, dtype=tf.dtypes.float32)
    b = tf.cast(b, dtype=tf.dtypes.float32)
    c = c.astype('float32')
    show_images([a[0], b[0], c[0]], 1, ['', np.sum(b[0]), np.sum(c[0])])

for a,b in test_gen.take(100):
    c = model.predict(a)
    a = tf.cast(a, dtype=tf.dtypes.float32)
    b = tf.cast(b, dtype=tf.dtypes.float32)
    c = c.astype('float32')
    show_images([a[0], b[0], c[0]], 1, ['', np.sum(b[0]), np.sum(c[0])])
-------------------------------------
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

import tensorflow as tf
from tensorflow.keras.layers import Input, Concatenate, Conv2D, Flatten, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
import numpy as np

# Assuming you have your data loaded and preprocessed, and stored in variables X, y

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define model architecture
stopnet_encoder_input = Input(shape=(image_height, image_width, num_channels))
efficientnet_input = Input(shape=(efficientnet_input_shape))

# EfficientNet encoder
efficientnet_output = efficientnet_model(efficientnet_input)  # Placeholder function for EfficientNet

# StopNet encoder layers (placeholders)
stopnet_encoder_output = stopnet_encoder(stopnet_encoder_input)  # Placeholder function for StopNet

# Concatenate features
concatenated_features = Concatenate()([stopnet_encoder_output, efficientnet_output])

# Convolutional layers for occupancy grid decoder
occupancy_decoder_output = Conv2D(...)(concatenated_features)  # Placeholder convolutional layers

# Define model
model = Model(inputs=[stopnet_encoder_input, efficientnet_input], outputs=occupancy_decoder_output)

# Compile the model
model.compile(optimizer=Adam(), loss='mse', metrics=['accuracy'])

# Train the model
model.fit([X_train_stopnet, X_train_efficientnet], y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)

# Evaluate the model
loss, accuracy = model.evaluate([X_test_stopnet, X_test_efficientnet], y_test)

print(f'Test Loss: {loss}')
print(f'Test Accuracy: {accuracy}')

# Predict occupancy flow for 8 seconds using 2 seconds of video
predictions = model.predict([X_test_stopnet, X_test_efficientnet])

# Calculate accuracy metrics for every second of predicted occupancy flow
# You need to define your accuracy metrics based on your specific requirements


import tensorflow as tf

def parse_tfrecord_fn(example):
    feature_description = {
        'image': tf.io.FixedLenFeature([], tf.string),  # Assuming image is stored as a string
        'label': tf.io.FixedLenFeature([], tf.int64)
    }
    example = tf.io.parse_single_example(example, feature_description)
    image = tf.image.decode_jpeg(example['image'], channels=3)  # Decode image from string
    label = example['label']
    return image, label



# Define path to TFRecord file
tfrecord_path = '/kaggle/input/waymo-motion-2/training_tfexample.tfrecord-00210-of-01000'

# Create TFRecordDataset
dataset = tf.data.TFRecordDataset(tfrecord_path)

# Map parsing function to dataset
dataset = dataset.map(parse_tfrecord_fn)

# Example: Print first image and label
for image, label in dataset.take(1):
    print('Label:', label.numpy())
    # Display image
    import matplotlib.pyplot as plt
    plt.imshow(image.numpy())
    plt.axis('off')
    plt.show()


pip install waymo-open-dataset-tf-2-11-0==1.6.1
-------------------------------------
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from scipy.stats import entropy
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Bidirectional
from tensorflow.keras.callbacks import EarlyStopping

# Load the dataset
df = pd.read_csv('/kaggle/input/dos-attack-http-dataset/DoS_Attack_HTTP_Dataset.csv')

#Create a copy of the dataset
# df = dataset.copy()

# Display the first few rows of the copied dataset
print("First few rows of the copied dataset:")
df.head()

# Display the dimensions of the copied dataset
print("\nDimensions of the copied dataset:")
df.shape

# Display basic statistics for numerical columns in the copied dataset
print("\nSummary statistics for numerical columns in the copied dataset:")
df.describe()

print('\nInformation about the dataset')
df.info()

print('\n Checking for null values.....')
null_values = df.isnull().sum()

print('Display columns with null values')
null_columns = null_values[null_values > 0]
if not null_columns.empty:
    print('Columns with null values:')
    print(null_columns)
else:
    print('No null values found in the dataset.')

#Impute null values with the mean of the column
mean_flow_bytes_per_second = df['Flow_Byts/s'].mean()
df['Flow_Byts/s'].fillna(mean_flow_bytes_per_second)

# Check for null values in the "Flow_Byts/s" column
null_values_flow_bytes_per_second = df['Flow_Byts/s'].isnull().sum()
print("Null values in 'Flow_Byts/s' column after replacement:", null_values_flow_bytes_per_second)


import matplotlib.pyplot as plt

# Histogram of a numerical feature
plt.hist(df['Flow_Duration'], bins=20, color='blue', alpha=0.7)
plt.xlabel('Flow Duration')
plt.ylabel('Frequency')
plt.title('Histogram of Flow Duration')
plt.show()

# Box plot of a numerical feature
plt.boxplot(df['Tot_Fwd_Pkts'])
plt.xlabel('Forward Packets')
plt.title('Box plot of Forward Packets')
plt.show()


# Summary statistics of a numerical feature
print("Summary statistics of Flow Duration:")
print(df['Flow_Duration'].describe())

# Scatter plot between two numerical features
plt.scatter(df['Flow_Duration'], df['Flow_Byts/s'], alpha=0.5)
plt.xlabel('Flow Duration')
plt.ylabel('Flow Bytes/s')
plt.title('Scatter Plot between Flow Duration and Flow Bytes/s')
plt.show()

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA


# Replace infinity values with NaN
df.replace([np.inf, -np.inf], np.nan, inplace=True)

# Select only numerical columns for standardization
numerical_columns = df.select_dtypes(include=['number'])

# Impute NaN values with the mean of each column
numerical_columns_filled = numerical_columns.fillna(numerical_columns.mean())

# Standardize the numerical data
scaler = StandardScaler()
numerical_columns_scaled = scaler.fit_transform(numerical_columns_filled)

# Perform PCA on the scaled data
pca = PCA(n_components=2)
pca_result = pca.fit_transform(numerical_columns_scaled)

# Create DataFrame for PCA results
pca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'])

# Concatenate PCA results with labels
pca_df['Label'] = df['Label']
print(pca_df)

# Plot PCA results with labels
plt.figure(figsize=(10, 6))
sns.scatterplot(data=pca_df, x='PC1', y='PC2', hue='Label', palette='Set1', alpha=0.7)
plt.title('PCA Scatter Plot with Label')
plt.show()


pca_df.head(10)

from sklearn.preprocessing import LabelEncoder

# Initialize LabelEncoder
label_encoder = LabelEncoder()

# Apply label encoding to each categorical column
for col in ['Label', 'Cat', 'Sub_Cat']:
    df[col + '_Encoded'] = label_encoder.fit_transform(df[col])

# Flip the labels
for col in ['Label_Encoded', 'Cat_Encoded', 'Sub_Cat_Encoded']:
    df[col] = 1 - df[col]

# Drop original categorical columns after encoding
df.drop(['Label', 'Cat', 'Sub_Cat'], axis=1, inplace=True)


from sklearn.preprocessing import LabelEncoder

# Exclude non-numeric columns from the correlation calculation
numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns
correlation_with_label = df[numeric_columns].corrwith(df['Label_Encoded']).drop('Label_Encoded') 

# Sort the correlations in descending order
correlation_with_label_sorted = correlation_with_label.abs().sort_values(ascending=False)

# Display the sorted correlation values
correlation_with_label_sorted.head(20)

df.head()

categorical_columns = df.select_dtypes(include=['object']).columns.tolist()
print("Categorical Columns:", categorical_columns)

# for column in categorical_columns:
#     unique_categories = df[column].unique()
#     print(f"Unique categories in {column}: {unique_categories}")


from sklearn.impute import SimpleImputer
from sklearn.feature_selection import mutual_info_classif


# Selecting the numerical features
numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns
X_numerical = df[numerical_cols]
X_numerical = X_numerical.drop('Label_Encoded', axis=1)

# Impute missing values in numerical columns with the mean
imputer = SimpleImputer(strategy='mean')
X_numerical_imputed = imputer.fit_transform(X_numerical)

# Calculate mutual information for numerical features after imputation
mutual_info_numerical = mutual_info_classif(X_numerical_imputed, df['Label_Encoded'], discrete_features='auto')

# Create a DataFrame to display the results
mutual_info_numerical_df = pd.DataFrame(mutual_info_numerical, index=X_numerical.columns, columns=['Mutual Information'])
mutual_info_numerical_df.sort_values(by='Mutual Information', ascending=False, inplace=True)
mutual_info_numerical_df.head(10)


# Create new feature: Packet rate (packets per second)
df['Packet_Rate'] = df['Tot_Fwd_Pkts'] / df['Flow_Duration']

# Create new feature: Packet size distribution (ratio of forward packets to total packets)
df['Packet_Size_Distribution'] = df['Tot_Fwd_Pkts'] / (df['Tot_Fwd_Pkts'] + df['Tot_Bwd_Pkts'])

# Create new feature: Frequency of specific protocol types
# Assuming Protocol column contains protocol types
protocol_counts = df['Protocol'].value_counts(normalize=True)  # Get relative frequency of each protocol
df['Protocol_Frequency'] = df['Protocol'].map(protocol_counts)

# Display the updated DataFrame with new features
df.head()


from sklearn.impute import SimpleImputer

# Impute missing values in numerical columns with the mean
imputer = SimpleImputer(strategy='mean')
X_numerical_imputed = imputer.fit_transform(X_numerical)

# Calculate mutual information for numerical features after imputation
mutual_info_numerical = mutual_info_classif(X_numerical_imputed, df['Label_Encoded'], discrete_features='auto')

# Create a DataFrame to display the results
mutual_info_numerical_df = pd.DataFrame(mutual_info_numerical, index=X_numerical.columns, columns=['Mutual Information'])
mutual_info_numerical_df.sort_values(by='Mutual Information', ascending=False, inplace=True)
mutual_info_numerical_df.head(20)


# List of features related to network traffic patterns, packet characteristics, and communication behavior
relevant_features = [
    'Flow_Duration', 'Tot_Fwd_Pkts', 'Tot_Bwd_Pkts', 'TotLen_Fwd_Pkts', 'TotLen_Bwd_Pkts',
    'Fwd_Pkt_Len_Max', 'Fwd_Pkt_Len_Min', 'Fwd_Pkt_Len_Mean', 'Fwd_Pkt_Len_Std',
    'Bwd_Pkt_Len_Max', 'Bwd_Pkt_Len_Min', 'Bwd_Pkt_Len_Mean', 'Bwd_Pkt_Len_Std',
    'Flow_Byts/s', 'Flow_Pkts/s', 'Flow_IAT_Mean', 'Flow_IAT_Std', 'Flow_IAT_Max', 'Flow_IAT_Min',
    'Fwd_IAT_Tot', 'Fwd_IAT_Mean', 'Bwd_IAT_Mean', 'Fwd_IAT_Max', 'Fwd_IAT_Min',
    'Bwd_IAT_Tot', 'Fwd_IAT_Std', 'Bwd_IAT_Std', 'Bwd_IAT_Max', 'Bwd_IAT_Min',
    'Fwd_PSH_Flags', 'Bwd_PSH_Flags', 'Fwd_URG_Flags', 'Bwd_URG_Flags',
    'Fwd_Header_Len', 'Bwd_Header_Len', 'Fwd_Pkts/s', 'Bwd_Pkts/s',
    'Pkt_Len_Min', 'Pkt_Len_Max', 'Pkt_Len_Mean', 'Pkt_Len_Std', 'Pkt_Len_Var',
    'FIN_Flag_Cnt', 'SYN_Flag_Cnt', 'RST_Flag_Cnt', 'PSH_Flag_Cnt', 'ACK_Flag_Cnt',
    'URG_Flag_Cnt', 'CWE_Flag_Count', 'ECE_Flag_Cnt', 'Down/Up_Ratio',
    'Pkt_Size_Avg', 'Fwd_Seg_Size_Avg', 'Bwd_Seg_Size_Avg', 'Fwd_Byts/b_Avg',
    'Fwd_Pkts/b_Avg', 'Fwd_Blk_Rate_Avg', 'Bwd_Byts/b_Avg', 'Bwd_Pkts/b_Avg',
    'Bwd_Blk_Rate_Avg', 'Subflow_Fwd_Pkts', 'Subflow_Fwd_Byts', 'Subflow_Bwd_Pkts',
    'Subflow_Bwd_Byts', 'Init_Fwd_Win_Byts', 'Init_Bwd_Win_Byts', 'Fwd_Act_Data_Pkts',
    'Fwd_Seg_Size_Min', 'Active_Mean', 'Active_Std', 'Active_Max', 'Active_Min',
    'Idle_Mean', 'Idle_Std', 'Idle_Max', 'Idle_Min',
    'Packet_Rate', 'Packet_Size_Distribution', 'Protocol_Frequency'
]

# Remove irrelevant or redundant features
df_selected_features = df[relevant_features]

# Display the selected features
print("Updated Selected Features:")
df_selected_features.columns


from sklearn.impute import SimpleImputer

# Impute missing values in numerical columns with the mean
imputer = SimpleImputer(strategy='mean')
X_numerical_imputed = imputer.fit_transform(X_numerical)

# Calculate mutual information for numerical features after imputation
mutual_info_numerical = mutual_info_classif(X_numerical_imputed, df['Label_Encoded'], discrete_features='auto')

# Create a DataFrame to display the results
mutual_info_numerical_df = pd.DataFrame(mutual_info_numerical, index=X_numerical.columns, columns=['Mutual Information'])
mutual_info_numerical_df.sort_values(by='Mutual Information', ascending=False, inplace=True)
mutual_info_numerical_df.head(20)

from sklearn.preprocessing import StandardScaler
import pandas as pd

# Select only numerical features for scaling
numerical_features = df_selected_features.select_dtypes(include=['float64', 'int64'])

# Clip extreme values to a specified range
lower_bound = -1e6  # Specify the lower bound
upper_bound = 1e6   # Specify the upper bound
numerical_features = numerical_features.clip(lower=lower_bound, upper=upper_bound)

# Standardize numerical features since we are using bi-LSTM
scaler = StandardScaler()
scaled_features = scaler.fit_transform(numerical_features)
df_scaled = pd.DataFrame(scaled_features, columns=numerical_features.columns)

# Concatenate scaled numerical features with categorical features
df_concatenated = pd.concat([df_scaled, df[['Cat_Encoded', 'Sub_Cat_Encoded']]], axis=1)

# Display the concatenated dataset
print("Concatenated Dataset:")
print(df_concatenated.head())

# Split the concatenated dataset into features (X) and target (y)
X = df_concatenated
y = df['Label_Encoded']

# Further split the dataset into training and validation sets
from sklearn.model_selection import train_test_split
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
X_train['Flow_Pkts/s'] = X_train['Flow_Pkts/s'].fillna(0)



# Display the shapes of the training and validation sets
print("Training set shape:", X_train.shape, y_train.shape)
print("Validation set shape:", X_val.shape, y_val.shape)


# Check for null values in X_train by column
null_columns = X_train.columns[X_train.isnull().any()]
print("Columns with null values in X_train:")
print(null_columns)


X_train['Flow_Pkts/s'] = X_train['Flow_Pkts/s'].fillna(0)

# Check for null values in X_train by column
null_columns = X_train.columns[X_train.isnull().any()]
print("Columns with null values in X_train:")
print(null_columns)

X_train['Flow_Byts/s'] = X_train['Flow_Byts/s'].fillna(0)
null_columns = X_train.columns[X_train.isnull().any()]
print("Columns with null values in X_train after filling NaN:")
print(null_columns)


import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Bidirectional, Dense
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Dropout
import numpy as np

# Reshape the input data to include a time step dimension
X_train_reshaped = X_train.values.reshape(-1, 1, num_features)
X_val_reshaped = X_val.values.reshape(-1, 1, num_features)


# Create and train the bi-LSTM model with adjustments
model = Sequential()
model.add(Input(shape=input_shape)) # Specify the input shape using Input layer
model.add(Bidirectional(LSTM(units=64, activation='tanh'))) # Changed activation to 'tanh'
model.add(Dropout(0.2)) # Added dropout layer
model.add(Dense(units=1, activation='sigmoid'))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
early_stopping = EarlyStopping(patience=3, monitor='val_loss')

import time

start_time = time.time()
model.fit(X_train_reshaped, y_train, validation_data=(X_val_reshaped, y_val), epochs=10, batch_size=32, callbacks=[early_stopping])
end_time = time.time()
training_time = end_time - start_time

print("Training Time: {:.5f} seconds".format(training_time))

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Predict probabilities
y_pred_probs = model.predict(X_val_reshaped)

# Calculate ROC curve
fpr, tpr, thresholds = roc_curve(y_val, y_pred_probs)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()


from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import seaborn as sns

# Convert probabilities to class predictions
y_pred = (y_pred_probs > 0.5).astype(int)

# Generate confusion matrix
conf_matrix = confusion_matrix(y_val, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=True)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.xticks([0.5, 1.5], ['Normal', 'Bot'])
plt.yticks([0.5, 1.5], ['Normal', 'Bot'])
plt.show()


# Calculate metrics
accuracy = accuracy_score(y_val, y_pred)
precision = precision_score(y_val, y_pred)
recall = recall_score(y_val, y_pred)
f1 = f1_score(y_val, y_pred)

# Print metrics
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)


# Prediction time
start_time = time.time()
y_pred = model.predict(X_val_reshaped)
end_time = time.time()
overhead = end_time - start_time
overhead_percentage = (overhead / training_time) * 100
delay = overhead / len(X_val_reshaped)

print("Overhead (Time taken by the model to make predictions): {:.5f} seconds".format(overhead))
print("Overhead Percentage: {}%".format(overhead_percentage))
print("Delay (Average time taken per data point for prediction):{:.5f} seconds".format(delay))

-------------------------------------
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, regularizers
from sklearn.model_selection import train_test_split,StratifiedKFold

from tensorflow.keras.models import Sequential,load_model
from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout
from tensorflow.keras.utils import to_categorical
from keras.layers import LeakyReLU, SpatialDropout2D, Activation, BatchNormalization, GlobalAveragePooling2D
from keras.optimizers import Adam
from keras.regularizers import l2
from keras import backend as keras_backend

import warnings
warnings.filterwarnings("ignore")

!cd ..

!ls

melX = np.load('/kaggle/input/npaudio/last_X.npy')
mely = np.load('/kaggle/input/npaudio/last_label.npy')

num_classes = 10
mely = tf.keras.utils.to_categorical(mely, num_classes)


num_rows = 40
num_columns = 249
num_channels = 1
num_classes = 10  # Assuming you have 10 classes, change accordingly

def create_model():
    # Assuming your input shape is (num_rows, num_columns, num_channels)
    input_shape = (num_rows, num_columns, num_channels)

    model = models.Sequential()

    # Horizontal Shifting (1x5 kernel)
    model.add(layers.Conv2D(32, (1, 5), padding='same', input_shape=input_shape, kernel_regularizer=regularizers.l2(0.01)))
    model.add(layers.LeakyReLU(alpha=0.1))
    model.add(layers.BatchNormalization())

    # Vertical Shifting (5x1 kernel)
    model.add(layers.Conv2D(32, (5, 1), padding='same', kernel_regularizer=regularizers.l2(0.01)))
    model.add(layers.LeakyReLU(alpha=0.1))
    model.add(layers.BatchNormalization())

    # Concatenate the results along the last axis (channel axis)
    concatenated = layers.Concatenate(axis=-1)([model.layers[-2].output, model.layers[-1].output])

    # Layer 2
    model.add(layers.Conv2D(32, (6, 6), padding='same', kernel_regularizer=regularizers.l2(0.01)))
    model.add(layers.MaxPooling2D(pool_size=(4, 2), strides=(4, 2)))
    model.add(layers.LeakyReLU(alpha=0.1))
    model.add(layers.BatchNormalization())

    # Layer 3
    model.add(layers.Conv2D(48, (5, 5), padding='same', kernel_regularizer=regularizers.l2(0.01)))
    model.add(layers.LeakyReLU(alpha=0.1))
    model.add(layers.BatchNormalization())

    # Layer 4
    model.add(layers.Conv2D(64, (4, 4), padding='same', kernel_regularizer=regularizers.l2(0.01)))
    model.add(layers.MaxPooling2D(pool_size=(4, 2), strides=(4, 2)))
    model.add(layers.LeakyReLU(alpha=0.1))
    model.add(layers.BatchNormalization())

    # Layer 5
    model.add(layers.Conv2D(74, (4, 4), padding='same', kernel_regularizer=regularizers.l2(0.01)))
    model.add(layers.LeakyReLU(alpha=0.1))
    model.add(layers.BatchNormalization())

    # Layer 6
    model.add(layers.Flatten())
    model.add(layers.Dense(64, activation='relu'))
    model.add(layers.Dropout(0.5))
    model.add(layers.BatchNormalization())

    # Output Layer
    model.add(layers.Dense(num_classes, activation='softmax'))

    return model


# Set the number of folds
num_folds = 5
skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)

# Initialize lists to store training and validation accuracies
train_accuracies = []
val_accuracies = []

# Iterate through folds
for fold_index, (train_index, val_index) in enumerate(skf.split(melX, np.argmax(mely, axis=1))):
    print(f"Training fold {fold_index + 1}/{num_folds}")

    # Split the data into training and validation sets
    X_train, X_val = melX[train_index], melX[val_index]
    y_train, y_val = mely[train_index], mely[val_index]
    adam = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.99, beta_2=0.999)

    # Create the model
    model = create_model()

    # Compile the model
    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)

    # Train the model
    history = model.fit(X_train,
                        y_train,
                        batch_size=64,
                        epochs=60,
                        validation_data=(X_val, y_val),
                        verbose=1)

    # Evaluate and store training accuracy
    train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)
    train_accuracies.append(train_acc)

    # Evaluate and store validation accuracy
    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)
    val_accuracies.append(val_acc)
    
    model.save(f"model{fold_index+1}.h5")

# Print average training and validation accuracies
print(f"\nAverage Training Accuracy: {np.mean(train_accuracies):.4f}")
print(f"Average Validation Accuracy: {np.mean(val_accuracies):.4f}")

# Print average training and validation accuracies
print(f"\nAverage Training Accuracy: {np.mean(train_accuracies) * 100:.4f}")
print(f"Average Validation Accuracy: {np.mean(val_accuracies) * 100:.4f}")

model.summary()

# 758/758 ━━━━━━━━━━━━━━━━━━━━ 46s 40ms/step - accuracy: 0.4158 - loss: 14.0070 - val_accuracy: 0.6678 - val_loss: 5.8673
# Epoch 2/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.7351 - loss: 4.6527 - val_accuracy: 0.8355 - val_loss: 2.4823
# Epoch 3/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.8296 - loss: 2.1950 - val_accuracy: 0.8424 - val_loss: 1.4919
# Epoch 4/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.8670 - loss: 1.3492 - val_accuracy: 0.9034 - val_loss: 0.9400
# Epoch 5/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.8904 - loss: 0.9530 - val_accuracy: 0.9152 - val_loss: 0.7183
# Epoch 6/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 20s 27ms/step - accuracy: 0.9039 - loss: 0.7446 - val_accuracy: 0.9134 - val_loss: 0.6080
# Epoch 7/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 20s 27ms/step - accuracy: 0.9170 - loss: 0.6111 - val_accuracy: 0.9356 - val_loss: 0.4752
# Epoch 8/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9236 - loss: 0.5203 - val_accuracy: 0.9275 - val_loss: 0.4792
# Epoch 9/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9336 - loss: 0.4662 - val_accuracy: 0.9386 - val_loss: 0.4004
# Epoch 10/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 20s 27ms/step - accuracy: 0.9375 - loss: 0.4237 - val_accuracy: 0.9443 - val_loss: 0.3728
# Epoch 11/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9409 - loss: 0.3979 - val_accuracy: 0.9328 - val_loss: 0.3902
# Epoch 12/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9471 - loss: 0.3693 - val_accuracy: 0.9455 - val_loss: 0.3490
# Epoch 13/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 20s 27ms/step - accuracy: 0.9443 - loss: 0.3656 - val_accuracy: 0.9546 - val_loss: 0.3145
# Epoch 14/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 20s 27ms/step - accuracy: 0.9499 - loss: 0.3418 - val_accuracy: 0.9456 - val_loss: 0.3406
# Epoch 15/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9482 - loss: 0.3449 - val_accuracy: 0.9451 - val_loss: 0.3417
# Epoch 16/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9560 - loss: 0.3156 - val_accuracy: 0.9450 - val_loss: 0.3264
# Epoch 17/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9510 - loss: 0.3243 - val_accuracy: 0.9538 - val_loss: 0.3056
# Epoch 18/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9498 - loss: 0.3339 - val_accuracy: 0.9476 - val_loss: 0.3410
# Epoch 19/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9613 - loss: 0.3003 - val_accuracy: 0.9482 - val_loss: 0.3188
# Epoch 20/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 28ms/step - accuracy: 0.9580 - loss: 0.2983 - val_accuracy: 0.9547 - val_loss: 0.3049
# Epoch 21/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9537 - loss: 0.3188 - val_accuracy: 0.9573 - val_loss: 0.2986
# Epoch 22/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9640 - loss: 0.2872 - val_accuracy: 0.9633 - val_loss: 0.2728
# Epoch 23/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9653 - loss: 0.2769 - val_accuracy: 0.9515 - val_loss: 0.3046
# Epoch 24/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9593 - loss: 0.2967 - val_accuracy: 0.9460 - val_loss: 0.3345
# Epoch 25/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9629 - loss: 0.2878 - val_accuracy: 0.9579 - val_loss: 0.2866
# Epoch 26/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9609 - loss: 0.2883 - val_accuracy: 0.9556 - val_loss: 0.3004
# Epoch 27/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9617 - loss: 0.2938 - val_accuracy: 0.9618 - val_loss: 0.2791
# Epoch 28/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9659 - loss: 0.2743 - val_accuracy: 0.9625 - val_loss: 0.2744
# Epoch 29/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 20s 27ms/step - accuracy: 0.9624 - loss: 0.2822 - val_accuracy: 0.9522 - val_loss: 0.3080
# Epoch 30/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9620 - loss: 0.2920 - val_accuracy: 0.9581 - val_loss: 0.2862
# Epoch 31/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9641 - loss: 0.2860 - val_accuracy: 0.9680 - val_loss: 0.2722
# Epoch 32/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9685 - loss: 0.2745 - val_accuracy: 0.9620 - val_loss: 0.2789
# Epoch 33/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 20s 27ms/step - accuracy: 0.9625 - loss: 0.2851 - val_accuracy: 0.9645 - val_loss: 0.2780
# Epoch 34/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9699 - loss: 0.2657 - val_accuracy: 0.9573 - val_loss: 0.2928
# Epoch 35/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 41s 27ms/step - accuracy: 0.9628 - loss: 0.2827 - val_accuracy: 0.9570 - val_loss: 0.2982
# Epoch 36/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9652 - loss: 0.2819 - val_accuracy: 0.9511 - val_loss: 0.3234
# Epoch 37/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9662 - loss: 0.2773 - val_accuracy: 0.9607 - val_loss: 0.2987
# Epoch 38/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9683 - loss: 0.2678 - val_accuracy: 0.9532 - val_loss: 0.3134
# Epoch 39/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9683 - loss: 0.2685 - val_accuracy: 0.9632 - val_loss: 0.2767
# Epoch 40/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9678 - loss: 0.2689 - val_accuracy: 0.9600 - val_loss: 0.2942
# Epoch 41/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9673 - loss: 0.2735 - val_accuracy: 0.9595 - val_loss: 0.2875
# Epoch 42/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9709 - loss: 0.2576 - val_accuracy: 0.9672 - val_loss: 0.2591
# Epoch 43/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9680 - loss: 0.2620 - val_accuracy: 0.9467 - val_loss: 0.3400
# Epoch 44/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9647 - loss: 0.2876 - val_accuracy: 0.9389 - val_loss: 0.3795
# Epoch 45/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9654 - loss: 0.2871 - val_accuracy: 0.9474 - val_loss: 0.3322
# Epoch 46/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9704 - loss: 0.2599 - val_accuracy: 0.9594 - val_loss: 0.2905
# Epoch 47/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9637 - loss: 0.2843 - val_accuracy: 0.9647 - val_loss: 0.2728
# Epoch 48/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9696 - loss: 0.2572 - val_accuracy: 0.9483 - val_loss: 0.3300
# Epoch 49/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9651 - loss: 0.2805 - val_accuracy: 0.9622 - val_loss: 0.2944
# Epoch 50/50
# 758/758 ━━━━━━━━━━━━━━━━━━━━ 21s 27ms/step - accuracy: 0.9703 - loss: 0.2621 - val_accuracy: 0.9626 - val_loss: 0.2814

model.saev
-------------------------------------
!pip install -U scikit-learn
!pip install category_encoders
!pip install iterative-stratification
# !pip install -U numpy
# !pip install --force-reinstall --no-deps numpy==1.26.4
!pip install keras_tuner
from sklearn.impute import KNNImputer
import tensorflow_datasets as tfds
from sklearn.ensemble import IsolationForest
import os
from tensorflow.keras.layers import GaussianDropout
import tensorflow.experimental.numpy as tnp
tnp.experimental_enable_numpy_behavior()
import numpy as np
import random as rn
import pandas as pd
import pickle
import gc
import tensorflow.keras.backend as K
from matplotlib import pyplot as plt
import datetime
from keras import backend as K
import math
from sklearn.model_selection import StratifiedKFold
import gc
# from sklearn.metrics import roc_curve, roc_auc_score
# from tf.keras.optimizers import Adam

import keras_tuner
from tensorflow.keras.metrics import Metric
import tensorflow
# import numpy as np
# import pandas as pds
# from keras.models import Sequential
# from keras.layers import Input, Dense, Dropout, BatchNormalization,Activation

INFERENCE = True
os.environ['PYTHONHASHSEED'] = '0'
tensorflow.keras.utils.set_random_seed(1)
tensorflow.config.experimental.enable_op_determinism()
np.random.seed(1)
rn.seed(1)
tensorflow.keras.utils.set_random_seed(1)
tensorflow.config.experimental.enable_op_determinism()
from sklearn.preprocessing import StandardScaler,LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error
from tensorflow.keras.optimizers  import Nadam,Adam
from tensorflow.keras.layers import Activation
from tensorflow.keras.models import Model,Sequential
from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping
from tensorflow.keras.layers import Dense, Input, InputLayer, Add, Concatenate, Dropout, BatchNormalization
from tensorflow.keras.utils import plot_model
from tensorflow.keras.optimizers  import Nadam
from tensorflow.keras.layers import concatenate
from keras.layers import Dense, BatchNormalization, Activation

INFERENCE = True
os.environ['PYTHONHASHSEED'] = '0'
np.random.seed(1)
rn.seed(1)
tensorflow.keras.utils.set_random_seed(1)
tensorflow.config.experimental.enable_op_determinism()
import math
import os
import lightgbm as lgb
from catboost import Pool
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
from sklearn.ensemble import RandomForestClassifier
from tqdm import tqdm
import os
import gc
import warnings
import pickle
from sklearn.decomposition import LatentDirichletAllocation as LDA
from sklearn.decomposition import TruncatedSVD,NMF,FactorAnalysis,KernelPCA,FastICA
from scipy.stats import rankdata
warnings.filterwarnings('ignore')
import random
import scipy as sp
import numpy as np
import pandas as pd
import joblib
import itertools
from sklearn.metrics import mean_squared_error
pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)
from tqdm.auto import tqdm
from sklearn.model_selection import StratifiedKFold, train_test_split,GroupKFold,StratifiedGroupKFold
from sklearn.preprocessing import LabelEncoder,StandardScaler,MinMaxScaler
from catboost import CatBoostClassifier as cat
from itertools import combinations
import lightgbm as lgb
import random as rn
import pandas as pd #基本ライブラリー
import numpy as np #基本ライブラリー
from sklearn.model_selection import KFold
from sklearn.preprocessing import LabelEncoder
import random as rn
import os
import gc
from sklearn.ensemble import IsolationForest
from lightgbm import LGBMClassifier
import seaborn as sns
tensorflow.config.run_functions_eagerly(True)
random.seed(1)
os.environ['PYTHONHASHSEED'] = str(1)
np.random.seed(1)
# import tensorflow as tf
import warnings
warnings.filterwarnings("ignore")
tensorflow.keras.utils.set_random_seed(1)
tensorflow.config.experimental.enable_op_determinism()
INFERENCE = True

from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler, EarlyStopping
from tensorflow.keras.layers import Dense, Input, InputLayer, Add, Concatenate, Dropout, BatchNormalization
from tensorflow.keras.utils import plot_model

os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
from sklearn.preprocessing import LabelEncoder,StandardScaler,MinMaxScaler
from lightgbm import LGBMClassifier
import seaborn as sns
random.seed(1)
os.environ['PYTHONHASHSEED'] = str(1)
np.random.seed(1)
import xgboost as xgb
import warnings
warnings.filterwarnings("ignore")
from tensorflow.keras import backend as K
INFERENCE = True

np.__version__

class CFG:
    folds=5
    seed=1
    ver='pyboost_ver1'
    model='py'
def fix_seed(seed=CFG.seed):
    os.environ['PYTHONHASHSEED'] = str(seed)
    # Python random
    random.seed(seed)
    # Numpy
    np.random.seed(seed)
    # Pytorch
    os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
    os.environ["CUDA_VISIBLE_DEVICES"] = "0"
fix_seed()

train=pd.read_csv('/kaggle/input/playground-series-s4e3/train.csv')
test=pd.read_csv('/kaggle/input/playground-series-s4e3/test.csv')

for c in train.select_dtypes(include=object):
    train[c]=train[c].astype(str)
    test[c]=test[c].astype(str)
    train[c]=train[c].str.normalize("NFKC")
    test[c]=test[c].str.normalize("NFKC")
    train[c]=train[c].str.normalize("NFKD")
    test[c]=test[c].str.normalize("NFKD")
    train[c]=train[c].str.normalize("NFD")
    test[c]=test[c].str.normalize("NFD")
    train[c]=train[c].str.normalize("NFC")
    test[c]=test[c].str.normalize("NFC")
#     train[c]=train[c].str.lower()
#     test[c]=test[c].str.lower()

train.columns

train['sum']=train[['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']].sum(axis=1)

train['sum'].value_counts()

train[train['sum']==0]

train[train['sum']==2]

train=train[train['sum']==1]
train.reset_index(inplace=True,drop=True)

train

train.drop('sum',inplace=True,axis=1)

df=pd.concat([train,test])
df.reset_index(inplace=True,drop=True)
def decomposition_PCA(col_x,col_y,df1,df2,df3):
    pca=KernelPCA(n_components=1,random_state=1)
    ss=StandardScaler()
    df3[[col_x,col_y]]=ss.fit_transform(df3[[col_x,col_y]])
    df1[[col_x,col_y]]=ss.transform(df1[[col_x,col_y]])
    df2[[col_x,col_y]]=ss.transform(df2[[col_x,col_y]])
    pca.fit(df3[[col_x,col_y]])
    df1[f'{col_x}_{col_y}_merge']=pca.transform(df1[[col_x,col_y]])
    df2[f'{col_x}_{col_y}_merge']=pca.transform(df2[[col_x,col_y]])
#     df1.drop([col_x,col_y],axis=1,inplace=True)
#     df2.drop([col_x,col_y],axis=1,inplace=True)
    return df1,df2
    
    

x_list=['X_Minimum', 'X_Maximum', 'X_Perimeter', 'Edges_X_Index', 'Log_X_Index']
y_list=['Y_Minimum', 'Y_Maximum','Y_Perimeter', 'Edges_Y_Index', 'Log_Y_Index']
for x,y in zip(x_list,y_list):
    print(x)
    print(y)
    train,test=decomposition_PCA(x,y,train,test,df)
    

pca=KernelPCA(n_components=1,random_state=1)
pca.fit(df[['Sum_of_Luminosity', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity']])
train['Luminosity']=pca.transform(train[['Sum_of_Luminosity', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity']])
test['Luminosity']=pca.transform(test[['Sum_of_Luminosity', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity']])
# train.drop(['Sum_of_Luminosity', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity'],axis=1,inplace=True)
# test.drop(['Sum_of_Luminosity', 'Minimum_of_Luminosity', 'Maximum_of_Luminosity'],axis=1,inplace=True)

train

train[['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']].describe()

test.columns

df=pd.concat([train,test])
df.reset_index(inplace=True,drop=True)
features=[c for c in test.columns if c not in['id']]
model = IsolationForest(
                            n_estimators=1000,
                            max_samples='auto', 
                            contamination=0.05,
                            max_features=16,#4 
                            bootstrap=False,
                            n_jobs=-1,
                            random_state=1)
model.fit(df[features])
train['if_scores'] = model.decision_function(train[features])
test['if_scores'] = model.decision_function(test[features])

train.columns

import os
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "0"



# train["class"]=np.where((train['K_Scatch']==1)&(train['Bumps']==1),7,train["class"])
# train["class"]=np.where((train['K_Scatch']==1)&(train['Other_Faults']==1),8,train["class"])


def reg_model(hp,n_inputs=len(features),n_outputs=7):
    input1=Input(shape=(n_inputs,))
#     input2=Input(shape=(n_inputs2,))

    # x=Dense(14863/9)(input1)
#     x2=Dense(hp.Choice('unit1_2',[32,64,128]))(input2)
#     x2=BatchNormalization()(x2)
#     x2 = Activation(hp.Choice("activation1_2", ["relu", "tanh",'swish']))(x2)
#     x2=GaussianDropout(rate=hp.Choice('unit_drop1_2',[0.7,0.3,0.1,0.0]),seed=1)(x2)

#     x2=Dense(hp.Choice('unit2_2',[16,32,64,128]))(x2)
#     x2=BatchNormalization()(x2)
#     x2 = Activation(hp.Choice("activation2_2", ["relu", "tanh",'swish']))(x2)
#     x2=GaussianDropout(rate=hp.Choice('unit_drop2_2',[0.3,0.1,0.0]),seed=1)(x2)

#     x2=Dense(hp.Choice('unit3_2',[8,16,32,64]))(x2)
#     x2=BatchNormalization()(x2)
#     x2 = Activation(hp.Choice("activation3_2", ["relu", "tanh",'swish']))(x2)
#     x2=GaussianDropout(rate=hp.Choice('unit_drop3_2',[0.3,0.1,0.0]),seed=1)(x2)


# #     # x=Dense(14863/32)(x)
# #     x2=Dense(hp.Choice('unit3_2',[32,64,128]))(x2)
# #     x2=BatchNormalization()(x2)
# #     x2 = Activation(hp.Choice("activation3_2", ["relu", "tanh",'swish']))(x2)
# #     # x=Dropout(rate=0.05)(x)
# #     x2=Dropout(rate=hp.Choice('unit_drop3_2',[0.3,0.1,0.0]))(x2)
# #     # x=Dense(600)(x)
# #################################################
#     x2=Dense(hp.Choice('unit4_2',[16,32,64,128]))(x2)
#     x2=BatchNormalization()(x2)
#     x2 = Activation(hp.Choice("activation4_2", ["relu", "tanh",'swish']))(x2)
#     # x=Dropout(rate=0.05)(x)
#     x2=Dropout(rate=hp.Choice('unit_drop4_2',[0.05,0.3,0.2,0.1,0.0]))(x2)





    x=Dense(hp.Choice('unit1',[8,16,len(features)]))(input1)
    x=BatchNormalization()(x)
    x = Activation(hp.Choice("activation1", ["relu", "tanh",'swish']))(x)
    x=GaussianDropout(rate=hp.Choice('unit_drop1_1',[0.7,0.5,0.3,0.0]),seed=1)(x)

    x=Dense(hp.Choice('unit2',[4,8,16]))(x)
    x=BatchNormalization()(x)
    x = Activation(hp.Choice("activation2", ["relu", "tanh",'swish']))(x)
    x=GaussianDropout(rate=hp.Choice('unit_drop2',[0.3,0.1,0.0]),seed=1)(x)

    ###################################3
    x=Dense(hp.Choice('unit3',[4,8,16]))(x)
    x=BatchNormalization()(x)
    x = Activation(hp.Choice("activation3", ["relu", "tanh",'swish']))(x)
    x=GaussianDropout(rate=hp.Choice('unit_drop3',[0.3,0.1,0.0]),seed=1)(x)
    
    x=Dense(hp.Choice('unit4',[4,8,16]))(x)
    x=BatchNormalization()(x)
    x = Activation(hp.Choice("activation4", ["relu", "tanh",'swish']))(x)
    x=GaussianDropout(rate=hp.Choice('unit_drop4',[0.3,0.1,0.0]),seed=1)(x)


#     x=Dense(hp.Choice('unit4',[4,8,16,32,64]))(x)
#     x=BatchNormalization()(x)
#     x = Activation(hp.Choice("activation4", ["relu", "tanh",'swish']))(x)
#     x=Dropout(rate=hp.Choice('unit_drop4',[0.3,0.2,0.0]))(x)


#     x=Dense(hp.Choice('unit5',[4,8,16,32,64]))(x)
#     x=BatchNormalization()(x)
#     x = Activation(hp.Choice("activation5", ["relu", "tanh",'swish']))(x)
#     x=Dropout(rate=hp.Choice('unit_drop5',[0.3,0.2,0.0]))(x)
    

#     # x=Dense(14863/32)(x)
#     x=Dense(hp.Choice('unit3',[6,12,24,48]))(x)
#     x=BatchNormalization()(x)
#     x = Activation('relu')(x)
#     # x=Dropout(rate=0.05)(x)
#     x=Dropout(rate=hp.Choice('unit_drop3',[0.05,0.3,0.2,0.1,0.0]))(x)
#     # x=Dense(600)(x)
##################################################
    x=Dense(hp.Choice('unit5',[8,16]))(x)
    x=BatchNormalization()(x)
    x = Activation(hp.Choice("activation5", ["relu", "tanh",'sigmoid']))(x)
#     x=Dropout(rate=0.05)(x)
    x=GaussianDropout(rate=hp.Choice('unit_drop_last',[0.3,0.1,0.0]),seed=1)(x)
    output=Dense(7)(x)
    output = Activation('sigmoid')(output)
#     model=Model([input1],x)
    learning_rate=0.003
#     concatted = tensorflow.keras.layers.Concatenate()([x, x2])
#     concatted=BatchNormalization()(concatted)
#     concatted = Activation(hp.Choice("activation_con", ["relu", "tanh",'swish']))(concatted)
#     concatted = GaussianDropout(rate=hp.Choice('unit_con1',[0.3,0.1,0.0]),seed=1)(concatted)
#     concatted=Dense(hp.Choice('unitcon2',[2,4,8,16,32]))(concatted)
#     concatted=BatchNormalization()(concatted)
#     concatted = Activation(hp.Choice("activation_con2", ["relu", "tanh",'swish']))(concatted)
#     concatted=Dropout(rate=hp.Choice('unit_drop_con2',[0.5,0.3,0.2,0.0]))(concatted)
#     concatted=Dense(1)(concatted)
#     concatted = Activation(hp.Choice("activation_con3", ["relu", "tanh",'swish']))(concatted)
#     model=Model([input1,input2],concatted)

    # compile model
    model = Model(inputs=input1, outputs=output)
    model.compile(loss=tensorflow.keras.losses.BinaryCrossentropy(),metrics=[tensorflow.keras.metrics.BinaryCrossentropy()],optimizer=Adam(learning_rate=learning_rate))
    return model
plot_model(reg_model(keras_tuner.HyperParameters()), show_layer_names=False, show_shapes=True)

ss=StandardScaler()
ss.fit(df[features])
train[features] = ss.transform(train[features]) 
test[features] = ss.transform(test[features])

from iterstrat.ml_stratifiers import MultilabelStratifiedKFold
folds=5
sfk=MultilabelStratifiedKFold(n_splits=CFG.folds, shuffle=True, random_state=2)
train['predict']=0

TUNE=True
oof=pd.DataFrame()
test_predict=pd.DataFrame()
tuner = keras_tuner.BayesianOptimization(
        reg_model,
        overwrite=True,
        objective=keras_tuner.Objective("val_binary_crossentropy", direction="min"),
        max_trials=50,
        seed=1)
lr = ReduceLROnPlateau(monitor="val_binary_crossentropy", factor=0.5, 
                      patience=4, verbose=-1)
es = EarlyStopping(monitor="val_binary_crossentropy",
                  patience=8, 
                  verbose=-1,
                  mode="min", 
                  restore_best_weights=True)
callbacks = [lr, es, tensorflow.keras.callbacks.TerminateOnNaN()]
from iterstrat.ml_stratifiers import MultilabelStratifiedKFold
skf=MultilabelStratifiedKFold(n_splits=5,random_state=1,shuffle=True)
# del test
# gc.collect()
test_predictions = np.zeros((test.shape[0],7), dtype=np.float64)
oof = np.zeros((train.shape[0],7), dtype=np.float64)
for fold_num ,(tr_index,va_index) in enumerate(skf.split(train,train[["Pastry", "Z_Scratch", "K_Scatch", "Stains", "Dirtiness", "Bumps", "Other_Faults"]])):
    if fold_num==3:
        tensorflow.keras.utils.set_random_seed(1)
        # train=pd.read_feather('/content/drive/MyDrive/kaggle_multimodal_single_cell_integration/edit_data/cite_data/0913_train_col_selection_SS_float32.ftr')
        tr_x,va_x=train[features].iloc[tr_index],train[features].iloc[va_index]
    #     tr_x2,va_x2=train[features2].iloc[tr_idx],train[features2].iloc[va_idx]
        tr_y,va_y=train[["Pastry", "Z_Scratch", "K_Scatch", "Stains", "Dirtiness", "Bumps", "Other_Faults"]].iloc[tr_index],train[["Pastry", "Z_Scratch", "K_Scatch", "Stains", "Dirtiness", "Bumps", "Other_Faults"]].iloc[va_index]
        print('start')
    #     del train,test
    #     gc.collect()
        # X_tr, X_va, y_tr, y_va = train_test_split(train[features],train['target'], test_size=0.2, random_state=22,stratify=train['class'])
        tuner.search([tr_x], tr_y,
                     epochs=50,
                     validation_data=([va_x], va_y),
                     batch_size=512,
                     callbacks=callbacks, verbose=1)
        if TUNE:
            tuner.results_summary()

            # Table of the 10 best trials
            display(pd.DataFrame([hp.values for hp in tuner.get_best_hyperparameters(10)]))

            # Keep the best hyperparameters
            best_hp = tuner.get_best_hyperparameters(1)[0]
-------------------------------------
import json
import datetime
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, OrdinalEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import roc_auc_score
from xgboost import XGBClassifier
from catboost import CatBoostClassifier
from lightgbm import LGBMClassifier
# from scipy.special import expit, logit
import optuna

from sklearn.preprocessing import StandardScaler, MinMaxScaler#, LabelEncoder
from tensorflow.keras.models import Sequential#, clone_model
from tensorflow.keras.layers import Dense, Dropout, LeakyReLU

TEST = '/kaggle/input/widsdatathon2024-challenge1/test.csv'
TRAIN = '/kaggle/input/widsdatathon2024-challenge1/training.csv'

#df = pd.read_csv(TRAIN)
#test = pd.read_csv(TEST)
# The index column is removed

# Dataframes
df = pd.read_csv(TRAIN, index_col='patient_id')
test = pd.read_csv(TEST, index_col='patient_id')

# Save patient ids for submission
test_patient_ids = pd.read_csv(TEST)["patient_id"]

combined_data = pd.concat([df, test], axis=0)

columns_to_drop_for_State_prediction = ['patient_race',
                                        'payer_type',
                                        'patient_age',
                                        'patient_gender',
                                        'bmi',
                                        'breast_cancer_diagnosis_code',
                                        'breast_cancer_diagnosis_desc',
                                        'metastatic_cancer_diagnosis_code',
                                        'metastatic_first_novel_treatment',
                                        'metastatic_first_novel_treatment_type',
                                        'Region',
                                        'Division',
                                        'DiagPeriodL90D']

# Create a new DataFrame without the specified columns
df_to_predict_states = combined_data.drop(columns=columns_to_drop_for_State_prediction, axis=1)

# Splitting the DataFrame into two based on NaN values in the specific column, i.e. missing State Values
predict_states_train = df_to_predict_states[~df_to_predict_states["patient_state"].isna()]
predict_states_test = df_to_predict_states[df_to_predict_states["patient_state"].isna()]

X_predict_states_train = predict_states_train.drop("patient_state", axis=1)
X_predict_states_train_column_names = X_predict_states_train.columns
X_predict_states_train = X_predict_states_train.fillna(X_predict_states_train.mean())

# Use StandardScaler or MinMaxScaler
#X_train_minmax_OR_standardised = pd.DataFrame( MinMaxScaler().fit_transform(X_predict_states_train), columns=X_predict_states_train_column_names)
X_train_minmax_OR_standardised = pd.DataFrame( StandardScaler().fit_transform(X_predict_states_train), columns=X_predict_states_train_column_names)
# Fit the scaler to the training data and transform it

y_predict_states_train = predict_states_train["patient_state"]

# Perform one-hot encoding
y_predict_states_train_dummies = pd.get_dummies(y_predict_states_train, columns=["patient_state"])

# Make Integers of the One-Hot Encoded columns (Binary from Boolean)
y_predict_states_train_dummies_01 = y_predict_states_train_dummies.astype(int)

# Creating the List of US States from the One-Hot Column Headings
US_States_column_headings = y_predict_states_train_dummies_01.columns.tolist()

# State Prediction Model
state_prediction_model = Sequential()
state_prediction_model.add(Dense(units=128, activation='relu', input_dim= X_train_minmax_OR_standardised.shape[1])) # Input layer with 68 features

state_prediction_model.add(Dense(units=89, activation=LeakyReLU(negative_slope=0.1))) #state_prediction_model.add(Dense(units=64, activation="LeakyReLU"))
#state_prediction_model.add(Dense(units=64, activation='relu'))  # Hidden layer with 64 neurons and ReLU activation
#state_prediction_model.add(Dense(units=50, activation='sigmoid'))

state_prediction_model.add(Dense(len(US_States_column_headings), activation='softmax'))  # Output layer with 50 neurons (assuming 50 states) and softmax activation


# Compile the model
state_prediction_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
state_prediction_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
state_prediction_model.fit(X_train_minmax_OR_standardised, y_predict_states_train_dummies_01, epochs=35, batch_size=15)

# Creating Datasets for Prediction

X_predict_states_TEST = predict_states_test.drop("patient_state", axis=1)
X_predict_states_TEST_column_names = X_predict_states_TEST.columns
X_predict_states_TEST = X_predict_states_TEST.fillna(X_predict_states_TEST.mean())

# Create StandardScaler or MinMaxScaler object
#X_TEST_minmax_OR_standardized = pd.DataFrame( MinMaxScaler().fit_transform(X_predict_states_TEST), columns=X_predict_states_TEST_column_names)
X_TEST_minmax_OR_standardized = pd.DataFrame( StandardScaler().fit_transform(X_predict_states_TEST), columns=X_predict_states_TEST_column_names)
# Fit the scaler to the training data and transform it

predicted_STATE_index_values = predict_states_test.index.tolist()

# Obtain predictions for the input data
y_predictions = state_prediction_model.predict(X_TEST_minmax_OR_standardized)


# Assuming y_predictions is your array of arrays containing the predicted probabilities
# and state_columns is your list of column headings corresponding to the US states

# Map each internal array to the corresponding state
predicted_states = []
for prediction in y_predictions:
    max_index = np.argmax(prediction)  # Find the index of the maximum value
    predicted_state = US_States_column_headings[max_index]  # Get the corresponding state from the column headings
    predicted_states.append(predicted_state)

# Print the predicted states
#print(predicted_states)
#len(predicted_states)

# Include missing patient States
nan_count_per_column_before = combined_data.isna().sum()
print(nan_count_per_column_before)

print()
for row_id, value in zip(predicted_STATE_index_values, predicted_states):
    combined_data.loc[row_id, 'patient_state'] = value
print()

nan_count_per_column_after = combined_data.isna().sum()
print(nan_count_per_column_after)

# Splitting them back
df = combined_data.iloc[:len(df), :]
test = combined_data.iloc[len(df):, :]
test.drop('DiagPeriodL90D', axis=1, inplace=True)

# features = [
#     'payer_type', 'patient_state',
#     'patient_zip3', 'patient_age',
#     'breast_cancer_diagnosis_code',
#     'metastatic_cancer_diagnosis_code',
#     'patient_race', 'bmi'
# ]

features = [
    'payer_type', 'patient_state',
    'patient_zip3', 'patient_age',
    'breast_cancer_diagnosis_code',
    'metastatic_cancer_diagnosis_code',
    'patient_race',  'bmi',
    'metastatic_first_novel_treatment',
    'Ozone', 'PM25', 'N02',
]

# features = [
#     'payer_type',
#     'patient_age', 
#     'breast_cancer_diagnosis_code',
#     'metastatic_cancer_diagnosis_code',
#     'patient_race', 'bmi',
#     'metastatic_first_novel_treatment',
#     'Ozone', 'PM25', 'N02',
#     'population',
# ]

# features = [
#     'patient_race', 'payer_type','patient_age', 'bmi',
#     'breast_cancer_diagnosis_code',
#     'metastatic_cancer_diagnosis_code', 'metastatic_first_novel_treatment',
#     'population', 'density', 'age_median',  'male', 'female', 'married',
#     'divorced', 'never_married','widowed', 'family_size', 'family_dual_income',
#     'income_household_median', 'income_individual_median',
#     'home_ownership', 'housing_units', 'home_value', 'rent_median',
#     'rent_burden', 'education_less_highschool', 'education_highschool',
#     'education_some_college', 'education_bachelors', 'education_graduate',
#     'education_college_or_above', 'education_stem_degree',
#     'labor_force_participation', 'unemployment_rate', 'self_employed',
#     'farmer', 'race_white', 'race_black', 'race_asian', 'race_native',
#     'race_pacific', 'race_other', 'race_multiple', 'hispanic', 'disabled',
#     'poverty', 'limited_english', 'commute_time', 'health_uninsured',
#     'veteran', 'Ozone', 'PM25', 'N02'
# ]

target = 'DiagPeriodL90D'
cols = features + [target]
df = df[cols]
test = test[features]
            

# patient_zip3 to str
# df['patient_zip3'] = df['patient_zip3'].astype(str)
# test['patient_zip3'] = test['patient_zip3'].astype(str)
            
print(f"Train shape: {df.shape}, Test shape: {test.shape}")

# Fill categorical missing values with 'Unknown'
# Use Your NN to predict States

cat_cols = df.select_dtypes(include=['object']).columns
df[cat_cols] = df[cat_cols].fillna('Unknown')

X = df.drop(columns=['DiagPeriodL90D'])
y = df['DiagPeriodL90D']

X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=16)
#X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05, random_state=42)

print(f"Train shape: {X_train.shape}, Valid shape: {X_valid.shape}")

# List of numerical feature column names or indices
numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns
#numerical_cols = X.select_dtypes(exclude=['object']).columns
print("numerical_cols", numerical_cols)

# List of categorical feature column names or indices
categorical_cols = X.select_dtypes(include=['object']).columns
print("categorical_cols", categorical_cols)

numerical_transformer_CATB = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', MinMaxScaler())])

numerical_transformer_LGBM = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())])

numerical_transformer_XGBM = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', MinMaxScaler())])

categorical_transformer_CATB = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    # ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))])

categorical_transformer_LGBM = Pipeline(steps=[
    #('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
    #('imputer', SimpleImputer(strategy='most_frequent')),
    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),
    #('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])

categorical_transformer_XGBM = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])

preprocessor_CATB = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer_CATB, numerical_cols),
        ('cat', categorical_transformer_CATB, categorical_cols)])

preprocessor_LGBM = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer_LGBM, numerical_cols),
        ('cat', categorical_transformer_LGBM, categorical_cols)])

preprocessor_XGBM = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer_XGBM, numerical_cols),
        ('cat', categorical_transformer_XGBM, categorical_cols)])

def objective_CATB(params_CATB):

    cb_model = CatBoostClassifier(**params_CATB)
    clf_CATB = Pipeline(steps=[('preprocessor', preprocessor_CATB),
                           ('classifier', cb_model)])
    clf_CATB.fit(X_train, y_train)
    y_pred_CATB = clf_CATB.predict_proba(X_valid)[:, 1]

    return y_pred_CATB



def objective_LGBM(params_LGBM):
    
    lgb_model = LGBMClassifier(**params_LGBM)
    clf_LGBM = Pipeline(steps=[('preprocessor', preprocessor_LGBM),
                           ('classifier', lgb_model)])
    clf_LGBM.fit(X_train, y_train)
    y_pred_LGBM = clf_LGBM.predict_proba(X_valid)[:, 1]

    return y_pred_LGBM



def objective_XGBM(params_XGBM):
    
    xgb_model = XGBClassifier(**params_XGBM)
    clf_XGBM = Pipeline(steps=[('preprocessor', preprocessor_XGBM),
                           ('classifier', xgb_model)])
    clf_XGBM.fit(X_train, y_train)
    y_pred_XGBM = clf_XGBM.predict_proba(X_valid)[:, 1]

    return y_pred_XGBM

def Ensemble_Objective(trial):
    
    params_CATB = {
        'depth': trial.suggest_int('depth_CATB', 1, 5),
        #'random_state': 42,
        'eval_metric': 'AUC',
        'verbose': False,
        'loss_function': 'Logloss',
        'learning_rate': trial.suggest_float('learning_rate_CATB', 0.009, 0.501),
        'iterations': trial.suggest_int('iterations_CATB', 2000, 4000)
    } 
        
    params_LGBM = {
        'objective': 'binary',
        
        'metric': trial.suggest_categorical('metric_LGBM', ['auc', 'binary_logloss']),
        'is_unbalance': trial.suggest_categorical('is_unbalance_LGBM', [True, False]),
        'boosting': trial.suggest_categorical('boosting_LGBM', ['dart', 'gbdt', 'rf']), # Aliases: https://lightgbm.readthedocs.io/en/latest/Parameters.html
        'num_leaves': trial.suggest_int('num_leaves_LGBM', 30, 700),  # Explicitly set num_leaves
        'feature_fraction': trial.suggest_float('feature_fraction_LGBM', 0.3, 0.7),
        'bagging_fraction': trial.suggest_float('bagging_fraction_LGBM', 0.3, 0.7),
        'bagging_freq': trial.suggest_int('bagging_freq_LGBM', 5, 35),
        
        'learning_rate': trial.suggest_float('learning_rate_LGBM', 0.0001, 0.1),#'learning_rate': 0.01,
        #'learning_rate': trial.suggest_float('learning_rate', 0.0001, 0.1, log=True),
        'verbose': -1,
        
        #'num_boost_round' : trial.suggest_int('num_boost_round', 1, 100), #'num_boost_round' was 5000 on YouTube
        
        #'early_stopping_rounds' : trial.suggest_int('num_boost_round', 1, 500), #'early_stopping_rounds' was 50 on YouTube
        
        #'n_estimators': trial.suggest_int('n_estimators', 30, 40),
        #'max_depth': trial.suggest_int('max_depth', 3, 10),  # Adjusted max_depth
        #'subsample': trial.suggest_float('subsample', 0.8, 1),  # Adjusted subsample
        #'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1),  # Adjusted colsample_bytree
        'lambda': trial.suggest_float('lambda_LGBM', 1e-9, 1.0, log=True),
        #'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),
        #'min_child_samples': trial.suggest_int('min_child_samples', 5, 20),  # Adjusted min_child_samples
        #'random_state': 16,
        #'force_col_wise': True
    } #https://www.youtube.com/watch?v=SW3akc0ho7M

    params_XGBM = {
        'n_estimators': trial.suggest_int('n_estimators_XGBM', 800, 4000),
        'learning_rate': trial.suggest_float('learning_rate_XGBM', 0.0001, 0.1, log=True),
        'max_depth': trial.suggest_int('max_depth_XGBM', 3, 16),
        'subsample': trial.suggest_float('subsample_XGBM', 0.2, 1),
        'colsample_bytree': trial.suggest_float('colsample_bytree_XGBM', 0.2, 0.8),
        'gamma': trial.suggest_float('gamma_XGBM', 1e-8, 1.0, log=True),
        #'random_state': 16
    }
    
    # Train CatBoost model
    y_pred_CATB = objective_CATB(params_CATB)
    # Train LightGBM model
    y_pred_LGBM = objective_LGBM(params_LGBM)
    # Train XGBoost model
    y_pred_XGBM = objective_XGBM(params_XGBM)
    
    sum_of_weights = 0
    while sum_of_weights == 0:
        weight_CATB = trial.suggest_float('Ensemble_Wt._CATB', 0, 1)
        weight_LGBM = trial.suggest_float('Ensemble_Wt._LGBM', 0, 1)
        weight_XGBM = trial.suggest_float('Ensemble_Wt._XGBM', 0, 1)
        sum_of_weights = weight_CATB+weight_LGBM+weight_XGBM
    weight_CATB /= sum_of_weights
    weight_LGBM /= sum_of_weights
    weight_XGBM /= sum_of_weights
    
    sum_of_Ensemble_wts = weight_CATB + weight_LGBM + weight_XGBM
    # Ensure that sum_of_Ensemble_wts is not zero
    sum_of_Ensemble_wts = max(weight_CATB + weight_LGBM + weight_XGBM, 1e-6)
    
    weighted_avg_pred = (weight_CATB*y_pred_CATB + weight_LGBM*y_pred_LGBM + weight_XGBM*y_pred_XGBM) / sum_of_Ensemble_wts
    # Clip the values to be within [0, 1]
    weighted_avg_pred = np.clip(weighted_avg_pred, 0, 1)
    
    auc = roc_auc_score(y_valid, weighted_avg_pred)
    return auc

study = optuna.create_study(direction='maximize')
study.optimize(Ensemble_Objective, n_trials=1729)
best_params = study.best_params

# Save best params to file
today = datetime.date.today().strftime("%Y-%m-%d")
filename = f"best_params_{today}.json"

with open(filename, "w") as file:
    json.dump(best_params, file)

print(f"Best params: {best_params}")

def Submission_CATB(params_CATB):
    cb_model = CatBoostClassifier(**params_CATB)
    clf_CATB = Pipeline(steps=[('preprocessor', preprocessor_CATB),
                           ('classifier', cb_model)])
    clf_CATB.fit(X, y)
    y_pred_CATB = clf_CATB.predict_proba(test)[:, 1]
    return y_pred_CATB


def Submission_LGBM(params_LGBM):
    lgb_model = LGBMClassifier(**params_LGBM)
    clf_LGBM = Pipeline(steps=[('preprocessor', preprocessor_LGBM),
                           ('classifier', lgb_model)])
    clf_LGBM.fit(X, y)
    y_pred_LGBM = clf_LGBM.predict_proba(test)[:, 1]
    return y_pred_LGBM


def Submission_XGBM(params_XGBM):    
    
    xgb_model = XGBClassifier(**params_XGBM)
    clf_XGBM = Pipeline(steps=[('preprocessor', preprocessor_XGBM),
                           ('classifier', xgb_model)])
    clf_XGBM.fit(X, y)
    y_pred_XGBM = clf_XGBM.predict_proba(test)[:, 1]
    return y_pred_XGBM

def Ensemble_Submission(best_parameters):
    
    params_CATB = {
        'depth': best_parameters['depth_CATB'],
        #'random_state': 42,
        'eval_metric': 'AUC',
        'verbose': False,
        'loss_function': 'Logloss',
        'learning_rate': best_parameters['learning_rate_CATB'],
        'iterations': best_parameters['iterations_CATB']
    } 
        
    params_LGBM = {
        'objective': 'binary',
        'metric': best_parameters['metric_LGBM'],
        'is_unbalance': best_parameters['is_unbalance_LGBM'],
        'boosting_type': best_parameters['boosting_LGBM'],
        'num_leaves': best_parameters['num_leaves_LGBM'],
        'feature_fraction': best_parameters['feature_fraction_LGBM'],
        'bagging_fraction': best_parameters['bagging_fraction_LGBM'],
        'bagging_freq': best_parameters['bagging_freq_LGBM'],
        'learning_rate': best_parameters['learning_rate_LGBM'],
        'verbose': -1,
        
        #'num_boost_round' : trial.suggest_int('num_boost_round', 1, 100), #'num_boost_round' was 5000 on YouTube
        
        #'early_stopping_rounds' : trial.suggest_int('num_boost_round', 1, 500), #'early_stopping_rounds' was 50 on YouTube
        
        #'n_estimators': trial.suggest_int('n_estimators', 30, 40),
        #'max_depth': trial.suggest_int('max_depth', 3, 10),  # Adjusted max_depth
        #'subsample': trial.suggest_float('subsample', 0.8, 1),  # Adjusted subsample
        #'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1),  # Adjusted colsample_bytree
        'lambda': best_parameters['lambda_LGBM'],
        #'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 1.0, log=True),
        #'min_child_samples': trial.suggest_int('min_child_samples', 5, 20),  # Adjusted min_child_samples
        #'random_state': 16,
        #'force_col_wise': True
    } #https://www.youtube.com/watch?v=SW3akc0ho7M

    params_XGBM = {
        'n_estimators': best_parameters['n_estimators_XGBM'],
        'learning_rate': best_parameters['learning_rate_XGBM'],
        'max_depth': best_parameters['max_depth_XGBM'],
        'subsample': best_parameters['subsample_XGBM'],
        'colsample_bytree': best_parameters['colsample_bytree_XGBM'],
        'gamma': best_parameters['gamma_XGBM'],
        #'random_state': 16
    }
    
    # Submission Models are trained with the best parameter settings on the full data
    y_pred_CATB = Submission_CATB(params_CATB)
    y_pred_LGBM = Submission_LGBM(params_LGBM)
    y_pred_XGBM = Submission_XGBM(params_XGBM)
    
    weight_CATB = best_parameters['Ensemble_Wt._CATB']
    weight_LGBM = best_parameters['Ensemble_Wt._LGBM']
    weight_XGBM = best_parameters['Ensemble_Wt._XGBM']
    
    sum_of_Ensemble_wts = weight_CATB + weight_LGBM + weight_XGBM
    # Ensure that sum_of_Ensemble_wts is not zero
    sum_of_Ensemble_wts = max(weight_CATB + weight_LGBM + weight_XGBM, 1e-6)
    
    weighted_avg_pred = (weight_CATB*y_pred_CATB + weight_LGBM*y_pred_LGBM + weight_XGBM*y_pred_XGBM) / sum_of_Ensemble_wts
    # Clip the values to be within [0, 1]
    weighted_avg_pred = np.clip(weighted_avg_pred, 0, 1)
    
    return weighted_avg_pred

final_predictions = Ensemble_Submission(best_params)

final_predictions

# def adjust_array(arr):
#     adjusted_arr = np.copy(arr)  # Create a copy of the original array
    
#     for i, val in np.ndenumerate(arr):
#         if val > 0.5:
#             adjusted_arr[i] = 1 - (1 - val) / 1.5  # Halve the distance from 1
#         else:
#             adjusted_arr[i] = val / 1.5  # Halve the distance from 0
    
#     return adjusted_arr

# final_predictions = adjust_array(final_predictions)
# print(final_predictions)

submission_filename = f'submission.csv'

submission_df = pd.DataFrame({'patient_id': test_patient_ids, 'DiagPeriodL90D': final_predictions})
submission_df.to_csv(submission_filename, index=False)
-------------------------------------
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

# file manipulation and visualization
import os
import pathlib
import PIL
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler,OneHotEncoder, StandardScaler
from sklearn.model_selection import train_test_split

import warnings
warnings.filterwarnings('ignore')

# TensorFlow and its submodules for machine learning tasks
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation
import keras_tuner as kt

df = pd.read_csv("/kaggle/input/patient-survival-prediction-data/Dataset.csv")

df.head()

df.info()

df.shape

df.isnull().sum()

df.columns

df.describe()

# Droping the columns that have unique values 
column = ['encounter_id', 'patient_id', 'hospital_id','hospital_admit_source','icu_admit_source','icu_stay_type', 'icu_id', 'readmission_status']
df = df.drop(columns = column, axis = 1)
df.head()

def missing_col(df):
    missing_df = pd.DataFrame(df.isnull().sum()/df.shape[0], columns = ["Missing"])
    return missing_df[missing_df["Missing"]>= 0.50]

print(f"{len(missing_col(df).index)} column have more than 50% null values.\n")
missing_val_col = list(missing_col(df).index)
print("Columns:", missing_val_col)

df = df.drop(columns=missing_val_col)

df.head()

print(df.shape)

df.isna().sum()

df=df[df[['bmi','weight','height']].isnull().sum(axis=1)==0]
df.isna().sum()

def plot_count(df):
    # checking the target
    plt.figure(figsize=(15, 7))
    
    # Barplot
    ax1 = plt.subplot(1, 2, 1)
    cp = sns.countplot(x=df["hospital_death"])

    # Add count numbers on top of the bars
    for p in ax1.patches:
        ax1.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2., p.get_height()),
                    ha='center', va='center', xytext=(0, 10), textcoords='offset points', fontsize=14)

    ax1.set_xlabel(" ")
    ax1.set_ylabel(" ")
    plt.xticks(fontsize=14)
    plt.yticks(fontsize=14)
    sns.despine(top=True, right=True)

    # Pieplot
    ax2 = plt.subplot(1, 2, 2)
    plt.pie(df["hospital_death"].value_counts(),
            labels=list(df["hospital_death"].unique()),
            autopct='%1.2f%%',
            pctdistance=0.8,
            shadow=True,
            radius=1.3,
            textprops={'fontsize': 14},
            explode=[0.3, 0]
            )
    ax2.set_xlabel(" ")
    plt.xlabel('Composition of "Hospital Death"', fontsize=15, labelpad=20)
    plt.subplots_adjust(wspace=0.4)
    plt.show()

plot_count(df)

icu_type = df['icu_type'].value_counts()

plt.figure(figsize=(20, 10))
plt.pie(icu_type.values, labels=icu_type.index,
        startangle=50, autopct='%1.1f%%')
centre_circle = plt.Circle((0, 0), 0.7, fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.title('TYPES OF ICUs', fontdict={
          'fontname': 'Monospace', 'fontsize': 30, 'fontweight': 'bold'})
plt.axis('equal')
plt.legend(prop={'size': 15},loc='upper left')
plt.show()

Hospital_death_by_ethinicity=df[['gender','hospital_death']].value_counts()
plt.figure(figsize=(20, 10))
plt.pie(Hospital_death_by_ethinicity.values, labels=Hospital_death_by_ethinicity.index,
        startangle=50, autopct='%1.1f%%')
centre_circle = plt.Circle((0, 0), 0.7, fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.title('Death By Gender', fontdict={
          'fontname': 'Monospace', 'fontsize': 30, 'fontweight': 'bold'})
plt.axis('equal')
plt.legend(prop={'size': 15},loc='upper left')
plt.show()


new=df['hospital_death'].apply(lambda x:'Survived' if x==0 else 'Not Survived')
sns.countplot(x=new,hue=df['ethnicity'])
plt.show()

unpivot = pd.melt(df, df.describe().columns[0], df.describe().columns[1:])
g = sns.FacetGrid(unpivot, col="variable", col_wrap=4, sharex=False, sharey=False)
g.map(sns.kdeplot, "value")
plt.show()

df['hospital_death'].value_counts()/df.shape[0]*100

df.info()

cat_col = df.select_dtypes(include=object).columns.to_list()
cat_col

df.isna().sum()

imputer=SimpleImputer(strategy='most_frequent')
df.iloc[:,:]=imputer.fit_transform(df)

##after filling missing values
df.isna().sum()

df.head()

cat_df = df[cat_col]
cat_df.head()

df_encoded=pd.get_dummies(df,columns=cat_col,drop_first=False,prefix='isIN',prefix_sep='_')
df_encoded.reset_index(drop=True,inplace=True)
df_encoded=df_encoded.applymap(lambda x:1 if x==True else (0 if x==False else x))

df_encoded.head()

df_encoded.shape

X = df_encoded.drop("hospital_death", axis=1)
y = df_encoded['hospital_death']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=45)

print("Train data size: ", X_train.shape)
print("Test data size: ", y_train.shape)

# creating an instance for MinMaxScaler
scaler = MinMaxScaler()
X_train_std = scaler.fit_transform(X_train)
X_test_std = scaler.transform(X_test)

# storing the normalized data into a new dataframe
X_train_new = pd.DataFrame(X_train_std, columns= X_train.columns)
X_test_new = pd.DataFrame(X_test_std, columns= X_test.columns)

print("New train data shape:", X_train_new.shape)
print("New test data shape:", X_test_new.shape)

model = Sequential()
# adding first layer and using relu as an activation function
model.add(Dense(64, input_shape=(X_train_new.shape[-1],), activation='relu'))
# adding second layer to the sequential model
model.add(Dense(32, activation='relu'))
# Adding third layer 
model.add(Dense(16, activation='relu'))
# adding output layer to the model using sigmoid activation function which seems to be ideal for binary classification problem
model.add(Dense(1, activation='sigmoid'))

model.summary()

# metrics that might be useful for present project
metrics = [
    keras.metrics.Precision(name="precision"),
    keras.metrics.Recall(name="recall"),
    keras.metrics.AUC(curve='ROC')
]


### Compiling the model
### choosing an appropirate optimiser and loss function
model.compile(optimizer=keras.optimizers.Adam(0.01),
              loss='binary_crossentropy',
              metrics=metrics)

### Training the model
epochs = 25
batch_size = 32
history = model.fit(X_train_new.values,y_train, validation_data = (X_test_new.values, y_test), epochs=epochs, batch_size=batch_size)

acc = history.history['auc']
val_acc = history.history['val_auc']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(16, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training AUC Score')
plt.plot(epochs_range, val_acc, label='Validation AUC Score')
plt.legend(loc='lower right')
plt.title('Training and Validation AUC Score')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()


model = Sequential()
model.add(Dense(64, input_dim=X_train_new.shape[-1], activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(16, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

metrics = [
    keras.metrics.Precision(name="precision"),
    keras.metrics.Recall(name="recall"),
    keras.metrics.AUC(curve='ROC')
]

### Compiling the model
### choosing an appropirate optimiser and loss function
model.compile(optimizer=keras.optimizers.Adam(),
              loss='binary_crossentropy',
              metrics=metrics)

# specifying the weights for the two classes with class 1 given higher weight value than class 0 and then using this class_weight in training the model
class_weight = {0: 0.5, 1: 5}

### Training the model
epochs = 25
batch_size = 32
history = model.fit(X_train_new.values,y_train, 
                    validation_data = (X_test_new.values, y_test), 
                    epochs=epochs, 
                    batch_size=batch_size)

acc = history.history['auc_1']
val_acc = history.history['val_auc_1']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(15,6))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training AUC Score')
plt.plot(epochs_range, val_acc, label='Validation AUC Score')
plt.legend(loc='lower right')
plt.title('Training and Validation AUC Score')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

def model_builder(hp):
  model = keras.Sequential()
  model.add(keras.layers.Flatten(input_shape=[135]))
  
  # Tune the number of units in the first Dense layer
  # Choose an optimal value between 32-512
  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)
  model.add(keras.layers.Dense(units=hp_units, activation='relu'))
  model.add(keras.layers.Dense(units=hp_units, activation='relu'))
  model.add(keras.layers.Dense(1, activation='sigmoid'))

  # Tune the learning rate for the optimizer
  # Choose an optimal value from 0.01, 0.001, or 0.0001
  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])

  metrics = [
    keras.metrics.Precision(name="precision"),
    keras.metrics.Recall(name="recall"),
    keras.metrics.AUC(curve='ROC')]

  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),
                loss=keras.losses.BinaryCrossentropy(),
                metrics=metrics)

  return model

tuner = kt.RandomSearch(
    model_builder,
    objective='val_loss',
    max_trials=5)

 # using early stopping to stop training the model when optimal value of recall and loss values are achieved.
 stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_recall', patience=5)

tuner.search(X_train_new.values, y_train, epochs=25, validation_data = (X_test_new.values, y_test), callbacks=[stop_early])

# Get the optimal hyperparameters
best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]

print(f"""
The hyperparameter search is complete. The optimal number of units in the first densely-connected
layer is {best_hps.get('units')} and the optimal learning rate for the optimizer
is {best_hps.get('learning_rate')}.
""")

model = Sequential()
model.add(Dense(384, input_dim=X_train_new.shape[-1], activation='relu'))
model.add(Dense(384, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

metrics = [
    keras.metrics.Precision(name="precision"),
    keras.metrics.Recall(name="recall"),
    keras.metrics.AUC(curve='ROC')]

### Compiling the model
### choosing an appropirate optimiser and loss function
model.compile(optimizer=keras.optimizers.Adam(0.001),
              loss='binary_crossentropy',
              metrics=metrics)
### Training the model
epochs = 15
batch_size = 32
history = model.fit(X_train_new.values,y_train, 
                    validation_data = (X_test_new.values, y_test), 
                    epochs=epochs, 
                    batch_size=batch_size)

acc = history.history['auc_1']
val_acc = history.history['val_auc_1']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(15,6))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training AUC Score')
plt.plot(epochs_range, val_acc, label='Validation AUC Score')
plt.legend(loc='lower right')
plt.title('Training and Validation AUC Score')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()
-------------------------------------
# Training ZIP_3 specific Neural Networks
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential, clone_model
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import SGD

input_dimension_of_mnodels = 108 # which is = train_data.shape[1]-2 as two columns are dropped

# Model Combinations
model1=Sequential()
model1.add(Dense(units=128, activation='relu', input_dim=input_dimension_of_mnodels))
#model1.add(Dense(units=16, activation='sigmoid'))
model1.add(Dropout(0.4))
model1.add(Dense(units=40, activation='LeakyReLU'))
model1.add(Dropout(0.4))
model1.add(Dense(units=8, activation='LeakyReLU'))
model1.add(Dense(units=1, activation='sigmoid'))
    
model2=Sequential()
model2.add(Dense(units=40, activation='relu', input_dim=input_dimension_of_mnodels))
model2.add(Dropout(0.5))
model2.add(Dense(units=20, activation='sigmoid'))
model2.add(Dropout(0.5))
model2.add(Dense(units=10, activation='LeakyReLU'))
model2.add(Dropout(0.5))
model2.add(Dense(units=5, activation='LeakyReLU'))
model2.add(Dense(units=1, activation='sigmoid'))

model3 = Sequential()
model3.add(Dense(units=32, activation='relu', input_dim=input_dimension_of_mnodels))
model3.add(Dense(units=16, activation='LeakyReLU'))
model3.add(Dense(units=8, activation='LeakyReLU'))
model3.add(Dense(units=1, activation='sigmoid'))

model4 = Sequential()
model4.add(Dense(units=64, activation='LeakyReLU', input_dim=input_dimension_of_mnodels))
model4.add(Dense(units=32, activation='LeakyReLU'))
model4.add(Dense(units=16, activation='LeakyReLU'))
model4.add(Dense(units=8, activation='LeakyReLU'))
model4.add(Dense(units=4, activation='LeakyReLU'))
model4.add(Dense(units=2, activation='LeakyReLU'))
model4.add(Dense(units=1, activation='sigmoid'))


model5 = Sequential()
model5.add(Dense(units=128, activation='relu', input_dim=input_dimension_of_mnodels))
model5.add(Dense(units=64, activation='LeakyReLU'))
model5.add(Dense(units=32, activation='relu'))
model5.add(Dense(units=16, activation='LeakyReLU'))
model5.add(Dense(units=8, activation='relu'))
model5.add(Dense(units=4, activation='LeakyReLU'))
model5.add(Dense(units=1, activation='sigmoid'))


model6 = Sequential()
model6.add(Dense(units=128, activation='LeakyReLU', input_dim=input_dimension_of_mnodels))
model6.add(Dense(units=64, activation='LeakyReLU'))
model6.add(Dense(units=32, activation='LeakyReLU'))
model6.add(Dense(units=16, activation='LeakyReLU'))
model6.add(Dense(units=8, activation='LeakyReLU'))
model6.add(Dense(units=4, activation='LeakyReLU'))
model6.add(Dense(units=1, activation='sigmoid'))


model7 = Sequential()
model7.add(Dense(units=128, activation='relu', input_dim=input_dimension_of_mnodels))
model7.add(Dense(units=64, activation='relu'))
model7.add(Dense(units=32, activation='relu'))
model7.add(Dense(units=16, activation='relu'))
model7.add(Dense(units=8, activation='relu'))
model7.add(Dense(units=4, activation='relu'))
model7.add(Dense(units=1, activation='sigmoid'))

model8 = Sequential()
model8.add(Dense(units=128, activation='sigmoid', input_dim=input_dimension_of_mnodels))
model8.add(Dense(units=32, activation='sigmoid'))
model8.add(Dense(units=12, activation='sigmoid'))
model8.add(Dense(units=4, activation='sigmoid'))
model8.add(Dense(units=1, activation='sigmoid'))

model9 = Sequential()
model9.add(Dense(units=55, activation='relu', input_dim=input_dimension_of_mnodels))
model9.add(Dense(units=11, activation='LeakyReLU'))
model9.add(Dense(units=1, activation='sigmoid'))

model10 = Sequential()
model10.add(Dense(units=60, activation='LeakyReLU', input_dim=input_dimension_of_mnodels))
model10.add(Dense(units=10, activation='LeakyReLU'))
model10.add(Dense(units=1, activation='sigmoid'))

model11 = Sequential()
model11.add(Dense(units=50, activation='relu', input_dim=input_dimension_of_mnodels))
model11.add(Dense(units=12, activation='relu'))
model11.add(Dense(units=1, activation='sigmoid'))

# Optimizer Combinations
optimizer1='adam'
optimizer2=SGD(learning_rate=0.001) # Compile the model with a different optimizer and learning rate

# Loss Function Combinations
loss1='binary_crossentropy'# With BinaryCrossEntropy many problem combinations get associated
loss2='mean_squared_error' # Example with a different loss function

# Metric Combinations
metrics1=['accuracy']
#metrics2=['accuracy', 'precision', 'recall'] # Example with additional metrics
metrics2=['precision'] # Example with additional metrics

# Tunable Hyperparameters

do_not_fill_NaN_values_in_TRAIN_columns = False # for Train
fill_NaN_values_in_TRAIN_columns_as_wholesome = False and (not do_not_fill_NaN_values_in_TRAIN_columns)
SD_multiplier_while_filling_NaN_values_in_wholesome = 1/1.25

SD_multiplier_while_filling_NaN_values_in_cluster = 1/1.25

take_more_surrounding_zip_codes_when_NOT_in_training_set = True
more_surrounding_zip_codes_range_when_NOT_in_training_set = 50
if_more_surrounding_zips_around_TRAIN_data = True
more_surrounding_zip_codes_around_TRAIN_data = 65

model_send = model10
optimizer_send = optimizer1 #Optimizer2 learning rate may be reset above
loss_send = loss1 # With loss1 many problem combinations get associated
metrics_send = metrics1
epochs_send = 150
batch_size_send = 1250

round_predictions = False
non_linearizing_predictions = True and (not round_predictions)
a = 2 # This is the constant term added in the denominator
c = 2 # This is coefficient multiplied to (1+x)^b
b = 3 # This is the Power over 1+x

# Dependant Hyperparameters

fill_NaN_values_in_columns_in_clusters = (not fill_NaN_values_in_TRAIN_columns_as_wholesome) and (not do_not_fill_NaN_values_in_TRAIN_columns)

# For this, it may so happen that all values in the cluster contain "NaN" values in a particular column, in which case, we need to assign from the original column

import pandas as pd
train = pd.read_csv(r'/kaggle/input/widsdatathon2024-challenge1/training.csv', index_col='patient_id')
test = pd.read_csv(r'/kaggle/input/widsdatathon2024-challenge1/test.csv', index_col='patient_id')

import numpy as np

if do_not_fill_NaN_values_in_TRAIN_columns:
    train.dropna(inplace=True)

combined_data = pd.concat([train, test], axis=0)
combined_data

# Next We create our own Zip Codes accounting for the State ZIPs as well...
# We assign numbers to each of the states and append this at the BEGINNING of the ZIP3 to create a new zip5

#Also use the 3 other columns taking into account the pollution levels...

selected_columns_from_combined_data = ['patient_age', 'bmi', 'patient_zip3', 'patient_race', 'payer_type', 'breast_cancer_diagnosis_code', 'metastatic_cancer_diagnosis_code', 'metastatic_first_novel_treatment', 'metastatic_first_novel_treatment_type',  'DiagPeriodL90D']
extracted_df = combined_data[selected_columns_from_combined_data]

extracted_df

for column in extracted_df:
    print(column," : ", len(extracted_df[column].unique()))
# print()
# for column in combined_data:
#     print(column," : ", len(combined_data[column].unique()))

## Apply one-hot encoding to specific categorical columns
encoded_df = pd.get_dummies(extracted_df, columns=["patient_race","payer_type","breast_cancer_diagnosis_code","metastatic_cancer_diagnosis_code","metastatic_first_novel_treatment","metastatic_first_novel_treatment_type"])
encoded_df

# Checking if patient_zip3 has any null values

#if encoded_df['patient_zip3'].isna().any():
#if encoded_df['patient_age'].isnull().any():
if extracted_df['patient_race'].isna().any():
    print("There are null/NA values in the 'column_name' column.")
else:
    print("There are no null/NA values in the 'column_name' column.")
    #print("There are no Nan values in the 'column_name' column.")

# To Convert True/False to 1/0 in the specified columns, we drop a few columns to create the boolean df

# Assuming 'column_to_drop1', 'column_to_drop2' are the names of the columns you want to drop
non_boolean_columns_to_drop = ["patient_age","bmi","patient_zip3","DiagPeriodL90D"]


# Create a new DataFrame without the specified columns
boolean_df = encoded_df.drop(columns=non_boolean_columns_to_drop, axis=1)
boolean_df = boolean_df.astype(int)
boolean_df

non_boolean_df = encoded_df[non_boolean_columns_to_drop]
non_boolean_df

if fill_NaN_values_in_TRAIN_columns_as_wholesome:
    # Filling Missing values in the BMI from a Normal Distribution with Mean and SD from the same column of BMI

    # Generate random values from a normal distribution with the mean and std of the same column
    mean_value = non_boolean_df["bmi"].mean()
    std_value = non_boolean_df["bmi"].std()

    non_boolean_df["bmi"] = non_boolean_df["bmi"].fillna(np.random.normal(loc=mean_value, scale=std_value*SD_multiplier_while_filling_NaN_values_in_wholesome))
    non_boolean_df

# Concatenate the two DataFrames along the columns (axis=1)
merged_df = pd.concat([non_boolean_df, boolean_df], axis=1)
merged_df


if fill_NaN_values_in_columns_in_clusters:
    # Find the entire SD and Mean
    overall_mean_value = merged_df["bmi"].mean()
    overall_std_value = merged_df["bmi"].std()

# Splitting the train and test datasets back

train_data = merged_df.iloc[:len(train)]

test_data = merged_df.iloc[len(train):]
test_data.drop("DiagPeriodL90D", axis=1, inplace=True)
test_data 

ALL_ZIP3 = set(merged_df["patient_zip3"].unique())
TRAIN_ZIP3 = set(train_data["patient_zip3"].unique())
ALL_minus_TRAIN_ZIP3 = sorted(ALL_ZIP3 - TRAIN_ZIP3)
print(ALL_minus_TRAIN_ZIP3)
print(len(ALL_minus_TRAIN_ZIP3))

Replacement_zip3_for_ALL_minus_TRAIN = {} #Dictionary KEY has the values of the Zip3 and the Dictionary VALUE has the list of Zip3 which are to be combined
# We use two approaches when creating the sets
#1) Nearest Zips from the non-existent ALL_minus_TRAIN zip3 (and calculate the absolute distance from the non-available zip3 in both directions)
#2) We also include all zips on both sides of the direction to equalize the absolute values...

for zip3 in ALL_minus_TRAIN_ZIP3:
    #print(zip3)
    temp_list = sorted(TRAIN_ZIP3)
    temp_list.append(zip3)
    temp_list = sorted(temp_list)
    
    zip3_index = temp_list.index(zip3)
    zip_before = temp_list[zip3_index-1]
    zip_after = temp_list[zip3_index+1]
    
    # Comment the below two lines if the 2nd case is also to be used
    if not take_more_surrounding_zip_codes_when_NOT_in_training_set:
        Replacement_zip3_for_ALL_minus_TRAIN[zip3]=[zip_before , zip_after]
        continue # We are using only the first option currently
    
    Absolute = max(zip3-zip_before , zip_after-zip3) + more_surrounding_zip_codes_range_when_NOT_in_training_set
    temp_list = sorted(TRAIN_ZIP3)
    Replacement_zip3_for_ALL_minus_TRAIN[zip3]= [x for x in temp_list if zip3-Absolute <= x <= zip3+Absolute]

print(Replacement_zip3_for_ALL_minus_TRAIN)


if if_more_surrounding_zips_around_TRAIN_data:
    Surrounding_zips_for_TRAIN_ZIP3 = {}
    for zip3 in TRAIN_ZIP3:
        temp_list = sorted(TRAIN_ZIP3)    
        Surrounding_zips_for_TRAIN_ZIP3[zip3]= [x for x in temp_list if zip3-more_surrounding_zip_codes_around_TRAIN_data <= x <= zip3+more_surrounding_zip_codes_around_TRAIN_data]

#Training the Models
import math

Zip_Matrix_dict={}
Zip_Matrix_NNmodel={}

for zip_Code in TRAIN_ZIP3:
    #print(zip_Code)
    
    if if_more_surrounding_zips_around_TRAIN_data:
        Zip_Matrix_dict[zip_Code] = train_data[train_data["patient_zip3"].isin(Surrounding_zips_for_TRAIN_ZIP3[zip_Code])]
    else:
        Zip_Matrix_dict[zip_Code] = train_data[train_data["patient_zip3"] == zip_Code]
        
        
    X_train = Zip_Matrix_dict[zip_Code].drop(columns=['patient_zip3','DiagPeriodL90D'])
    
    if fill_NaN_values_in_columns_in_clusters:
        # Filling Missing values in the BMI from a Normal Distribution with Mean and SD from the same column of BMI
        mean_value = X_train["bmi"].mean()
        std_value = X_train["bmi"].std()
        
        if math.isnan(mean_value) or math.isnan(std_value):
            X_train["bmi"] = X_train["bmi"].fillna(np.random.normal(loc=overall_mean_value, scale=overall_std_value*SD_multiplier_while_filling_NaN_values_in_cluster))
        else:
            # Generate random values from a normal distribution with the mean and std of the same column
            X_train["bmi"] = X_train["bmi"].fillna(np.random.normal(loc=mean_value, scale=std_value*SD_multiplier_while_filling_NaN_values_in_cluster))
        
    y_train = Zip_Matrix_dict[zip_Code][['DiagPeriodL90D']]
        
    Zip_Matrix_NNmodel[zip_Code]=clone_model(model_send)
    # Compile the model
    Zip_Matrix_NNmodel[zip_Code].compile(optimizer=optimizer_send, loss=loss_send, metrics=metrics_send)
    
    #print(train_data.shape[1]-2)
    # Train the model
    Zip_Matrix_NNmodel[zip_Code].fit(X_train, y_train, epochs=epochs_send, batch_size=batch_size_send, verbose=0) #verbose=3 is the next minimal output
    #break

# For the ZipCodes which are not in the training data but in the testing data, we create sets of nearby zip codes and use then to train the NN
for zip_Code in ALL_minus_TRAIN_ZIP3:
    #print(zip_Code)
    
    #Zip_Matrix_dict[zip_Code] = train_data[train_data["patient_zip3"] in Replacement_zip3_for_ALL_minus_TRAIN[zip_code]] # Incorrect Syntax
    Zip_Matrix_dict[zip_Code] = train_data[train_data["patient_zip3"].isin(Replacement_zip3_for_ALL_minus_TRAIN[zip_Code])]
    
    X_train = Zip_Matrix_dict[zip_Code].drop(columns=['patient_zip3','DiagPeriodL90D'])
    
    if fill_NaN_values_in_columns_in_clusters:
        # Filling Missing values in the BMI from a Normal Distribution with Mean and SD from the same column of BMI
        mean_value = X_train["bmi"].mean()
        std_value = X_train["bmi"].std()
        
        if math.isnan(mean_value) or math.isnan(std_value):
            X_train["bmi"] = X_train["bmi"].fillna(np.random.normal(loc=overall_mean_value, scale=overall_std_value*SD_multiplier_while_filling_NaN_values_in_cluster))
        else:
            # Generate random values from a normal distribution with the mean and std of the same column
            X_train["bmi"] = X_train["bmi"].fillna(np.random.normal(loc=mean_value, scale=std_value*SD_multiplier_while_filling_NaN_values_in_cluster))
    
    y_train = Zip_Matrix_dict[zip_Code][['DiagPeriodL90D']]
    
    Zip_Matrix_NNmodel[zip_Code]=clone_model(model_send)
    # Compile the model
    Zip_Matrix_NNmodel[zip_Code].compile(optimizer=optimizer_send, loss=loss_send, metrics=metrics_send)
    
    # Train the model
    Zip_Matrix_NNmodel[zip_Code].fit(X_train, y_train, epochs=epochs_send, batch_size=batch_size_send, verbose=0) #verbose=3 is the next minimal output
    #break

# Submission CSV
import csv

output_file = 'submission.csv'

# Now we Test
from tensorflow.keras.models import load_model
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Open the CSV file in append mode
with open(output_file, 'w', newline='') as csvfile:
    # Create a CSV writer object
    csv_writer = csv.writer(csvfile)
    
    headers = ["patient_id" , "DiagPeriodL90D"] #'headers' is a list containing column names, write headers if needed
    csv_writer.writerow(headers)
    print("patient_id , DiagPeriodL90D")
    
    for zip_Code in sorted(test_data["patient_zip3"].unique()):
        print(zip_Code)

        # Assuming 'X_test' is your test feature data and 'y_test' is the corresponding labels
        
        #X_test = Zip_Matrix_dict[zip_Code].drop(columns=['patient_zip3','DiagPeriodL90D'])
        X_test = test_data[test_data["patient_zip3"] == zip_Code].drop(columns=['patient_zip3'])
        #y_test = ...

        
        if fill_NaN_values_in_columns_in_clusters:
            # Filling Missing values in the BMI from a Normal Distribution with Mean and SD from the same column of BMI
            mean_value = X_test["bmi"].mean()
            std_value = X_test["bmi"].std()
            
        if math.isnan(mean_value) or math.isnan(std_value):
            X_test["bmi"] = X_test["bmi"].fillna(np.random.normal(loc=overall_mean_value, scale=overall_std_value*SD_multiplier_while_filling_NaN_values_in_cluster))
        else:
            # Generate random values from a normal distribution with the mean and std of the same column
            X_test["bmi"] = X_test["bmi"].fillna(np.random.normal(loc=mean_value, scale=std_value*SD_multiplier_while_filling_NaN_values_in_cluster))
    
        # Load the trained model (replace 'your_model.pkl' with the actual filename)
        #loaded_model = load_model('your_model.pkl')

        # Make predictions on the test data
        y_pred = Zip_Matrix_NNmodel[zip_Code].predict(X_test)
        patient_ids = X_test.index
        
        # Write rows with patient IDs and corresponding predictions
        for patient_id, prediction in zip(patient_ids, y_pred):
            # Write each row to the CSV file
            #print(patient_id, prediction[0])
            if round_predictions:
                csv_writer.writerow([patient_id, round(prediction[0])])
                print(patient_id," , ", round(prediction[0]))
            elif non_linearizing_predictions:
                if prediction[0]>0.5:
                    x=1-prediction[0]
                else:
                    x=prediction[0]-0
                
                x= x / ( a + c*((1+x)**b) ) # Non-linear element
                
                if prediction[0]>0.5:
                    x=1-x
                else:
                    x=x-0
                csv_writer.writerow([patient_id, x])
                print(patient_id," , ", x)
            else:
                csv_writer.writerow([patient_id, prediction[0]])
                print(patient_id," , ", prediction[0])
        #break
-------------------------------------
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

!pip install scikeras


import matplotlib.pyplot as plt
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from statsmodels.tsa.statespace.sarimax import SARIMAX
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from tensorflow.keras.optimizers import Adam, RMSprop
from tensorflow.keras import backend as K
from sklearn.metrics import mean_squared_error, mean_absolute_error
from scikeras.wrappers import KerasRegressor
from sklearn.model_selection import GridSearchCV
from tensorflow.keras.models import Sequential
#from keras.wrappers.scikit_learn import KerasRegressor
from sklearn.model_selection import GridSearchCV
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dropout, Dense
from keras import backend as K

train_path = r"/kaggle/input/predictiva-dl-time-series-forecasting/train.csv"
test_path  = r"/kaggle/input/predictiva-dl-time-series-forecasting/test.csv"
download_path = r'/kaggle/working/'
train = pd.read_csv(train_path)
original_test = pd.read_csv(test_path)

train.head(1)

original_test.head(1)

train_data = train.copy()
original_test_data = original_test.copy()

# Filter first 1000 rows for train 
train_subset = train[:1000]
# Plot num_sold vs date
plt.figure(figsize=(12, 6))
plt.subplot(3, 1, 1)
plt.plot(train_subset['date'], train_subset['num_sold'], label='Train')

plt.title('num_sold vs date')
plt.legend()

# Plot num_sold_log vs date
plt.subplot(3, 1, 2)
plt.plot(train_subset['date'], np.log(train_subset['num_sold']), label='Train')

plt.title('num_sold_log vs date')
plt.legend()

# Plot num_sold_exp vs date
plt.subplot(3, 1, 3)
plt.plot(train_subset['date'], np.exp(np.log(train_subset['num_sold'])), label='Train')

plt.title('num_sold_exp vs date')
plt.legend()

plt.tight_layout()
plt.show()


def explore_data(data):
    """
    Display basic information about the dataset.
    """
    print("Data Overview:")
    print(data.head())
    print("\nData Info:")
    print(data.info())
    print("\nSummary Statistics:")
    print(data.describe())

def plot_distribution(data, column, title):
    """
    Plot the distribution of a numerical column.
    """
    plt.figure(figsize=(10, 6))
    sns.distplot(data[column], kde=True)
    plt.title(title)
    plt.xlabel(column)
    plt.ylabel('Frequency')
    plt.show()

def plot_before_after(data_before, data_after, column, title_before, title_after):
    """
    Plot the distribution of a numerical column before and after data cleaning.
    """
    plt.figure(figsize=(14, 6))
    
    plt.subplot(1, 2, 1)
    sns.distplot(data_before[column], kde=True)
    plt.title(title_before)
    plt.xlabel(column)
    plt.ylabel('Frequency')
    
    plt.subplot(1, 2, 2)
    sns.distplot(data_after[column], kde=True)
    plt.title(title_after)
    plt.xlabel(column)
    plt.ylabel('Frequency')
    
    plt.tight_layout()
    plt.show()

def clean_data(data):
    """
    Clean the data by handling missing values, outliers, and skewness.
    """
    # Handle missing values
    data.dropna(inplace=True)

    # Handle outliers (you can customize this based on your analysis)
    data = data[(data['num_sold'] > 0) & (data['num_sold'] < 200)]

    # Log transform to reduce skewness (assuming positive values)
    data['num_sold'] = np.log1p(data['num_sold'])

    return data

def standardize_data(data, columns_to_standardize):
    """
    Standardize numerical features in the dataset.
    """
    scaler = StandardScaler()
    data[columns_to_standardize] = scaler.fit_transform(data[columns_to_standardize])

    return data

def normalize_data(data, columns_to_normalize):
    """
    Normalize numerical features in the dataset.
    """
    scaler = MinMaxScaler()
    data[columns_to_normalize] = scaler.fit_transform(data[columns_to_normalize])

    return data

#add code here

# Explore data before cleaning
explore_data(train_data)
plot_distribution(train_data, 'num_sold', 'Distribution Before Cleaning')

# Clean the data
cleaned_train_data = clean_data(train_data)

# Explore data after cleaning
explore_data(cleaned_train_data)
plot_distribution(cleaned_train_data, 'num_sold', 'Distribution After Cleaning')

# Standardize and normalize data (assuming 'num_sold' is the only numerical feature)
columns_to_standardize = ['num_sold']
columns_to_normalize = ['num_sold']

standardized_train_data = standardize_data(cleaned_train_data.copy(), columns_to_standardize)
normalized_train_data = normalize_data(cleaned_train_data.copy(), columns_to_normalize)

# Explore data after standardization
explore_data(standardized_train_data)
plot_distribution(standardized_train_data, 'num_sold', 'Distribution After Standardization')

# Explore data after normalization
explore_data(normalized_train_data)
plot_distribution(normalized_train_data, 'num_sold', 'Distribution After Normalization')

# Data preprocessing
train_data['date'] = pd.to_datetime(train_data['date'])
original_test_data['date'] = pd.to_datetime(original_test_data['date'])


train_data['num_sold'] = np.log(train_data['num_sold'])
train_data.head(1)

train_encoded = pd.get_dummies(train, columns=['country', 'store', 'product'], drop_first=True, dtype= int)
original_test_encoded = pd.get_dummies(original_test, columns=['country', 'store', 'product'], drop_first=True, dtype= int)

train_set, temp_set= train_test_split(train_encoded, test_size=0.15, shuffle=False)

# Further split temp_set into validation (10%) and test_set (5%)
val_set, test_set = train_test_split(temp_set, test_size=1/3, shuffle=False)

# Display the shapes of the resulting sets
print("Train Set Shape:", train_set.shape)
print("Validation Set Shape:", val_set.shape)
print("Test Set Shape:", test_set.shape)

train_set.head(1)

# Assume 'num_sold' is the target variable, and other columns are features
X = train_encoded.drop(columns=['num_sold', 'date','id'])
y = train_encoded['num_sold']

# Split the data with shuffle=False
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.15, shuffle=False)

# Split the data with shuffle=False
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=1/3, shuffle=False)

print("X_train.shape",X_train.shape)
print("X_val.shape",X_val.shape)
print("X_test.shape",X_test.shape)
print("y_train.shape",y_train.shape)
print("y_val.shape",y_val.shape)
print("y_test.shape",y_test.shape)


# ACF and PACF plots
plot_acf(train_encoded['num_sold'], lags=50)
plt.title('Autocorrelation Function (ACF)')
plt.show()

plot_pacf(train_encoded['num_sold'], lags=50)
plt.title('Partial Autocorrelation Function (PACF)')
plt.show()



from statsmodels.tsa.stattools import acf, pacf
# ACF and PACF plots
lags = 30  # Adjust as needed

# Use acf and pacf directly to get values
acf_values, conf_intervals_acf = acf(train_encoded['num_sold'], nlags=lags, alpha=0.05)
pacf_values, conf_intervals_pacf = pacf(train_encoded['num_sold'], nlags=lags, alpha=0.05)

# Plot ACF and PACF plots
fig, ax = plt.subplots(1, 2, figsize=(12, 4))

# Plot ACF
plot_acf(train_data['num_sold'], lags=lags, alpha=0.05, ax=ax[0])
ax[0].set_title('ACF Plot')

# Plot PACF
plot_pacf(train_data['num_sold'], lags=lags, alpha=0.05, ax=ax[1])
ax[1].set_title('PACF Plot')

plt.show()

# Print ACF values and interpretation
print("ACF Values:")
for lag, acf_value in enumerate(acf_values):
    print(f"Lag {lag}: {acf_value:.3f}")

# Determine positive, negative, or lags outside threshold in ACF
positive_lags_acf = [lag for lag, acf_value in enumerate(acf_values) if acf_value > conf_intervals_acf[lag, 1]]
negative_lags_acf = [lag for lag, acf_value in enumerate(acf_values) if acf_value < conf_intervals_acf[lag, 0]]
outside_threshold_lags_acf = [lag for lag, acf_value in enumerate(acf_values) if lag not in positive_lags_acf and lag not in negative_lags_acf]

print("\nACF Interpretation:")
print(f"Positive Lags: {positive_lags_acf}")
print(f"Negative Lags: {negative_lags_acf}")
print(f"Lags Outside Threshold: {outside_threshold_lags_acf}")

# Print PACF values and interpretation
print("\nPACF Values:")
for lag, pacf_value in enumerate(pacf_values):
    print(f"Lag {lag}: {pacf_value:.3f}")

# Determine positive, negative, or lags outside threshold in PACF
positive_lags_pacf = [lag for lag, pacf_value in enumerate(pacf_values) if pacf_value > conf_intervals_pacf[lag, 1]]
negative_lags_pacf = [lag for lag, pacf_value in enumerate(pacf_values) if pacf_value < conf_intervals_pacf[lag, 0]]
outside_threshold_lags_pacf = [lag for lag, pacf_value in enumerate(pacf_values) if lag not in positive_lags_pacf and lag not in negative_lags_pacf]

print("\nPACF Interpretation:")
print(f"Positive Lags: {positive_lags_pacf}")
print(f"Negative Lags: {negative_lags_pacf}")
print(f"Lags Outside Threshold: {outside_threshold_lags_pacf}")


# Create SARIMAX model to create a base model
sarimax_model = SARIMAX(train_set['num_sold'], order=(0, 0, 0), seasonal_order=(1, 1, 1, 15))

# Fit the model
sarimax_fit = sarimax_model.fit(disp=False)



# Forecast on the validation set
sarimax_forecast = sarimax_fit.get_forecast(steps=len(val_set))
sarimax_forecast_mean = sarimax_forecast.predicted_mean

# Calculate Mean Squared Error
mse = mean_squared_error(val_set['num_sold'], sarimax_forecast_mean)
print(f"Mean Squared Error: {mse}")

# Plot Predicted vs Actual on Validation Data
plt.plot(val_set['date'], val_set['num_sold'], label='Actual Data')
plt.plot(val_set['date'], sarimax_forecast_mean, label='SARIMAX Forecast')
plt.xlabel('Date')
plt.ylabel('Number of Products Sold')
plt.title('SARIMAX Model - Predicted vs Actual')
plt.legend()
plt.show()


# Define SMAPE function
def smape_arima(y_true, y_pred):
    both_zero_mask = (y_pred == 0) & (y_true == 0)
    numerator = np.abs(y_pred - y_true)
    denominator = np.where(both_zero_mask, 1.0, (np.abs(y_pred) + np.abs(y_true)) / 2)
    return 100 * np.mean(numerator / denominator)


# Forecast on the validation set
sarimax_forecast = sarimax_fit.get_forecast(steps=len(test_set))
sarimax_forecast_mean = sarimax_forecast.predicted_mean

# Calculate Mean Squared Error
mse = mean_squared_error(test_set['num_sold'], sarimax_forecast_mean)
print(f"Mean Squared Error: {mse}")

# Plot Predicted vs Actual on Validation Data
plt.plot(test_set['date'], test_set['num_sold'], label='Actual Data')
plt.plot(test_set['date'], sarimax_forecast_mean, label='SARIMAX Forecast')
plt.xlabel('Date')
plt.ylabel('Number of Products Sold')
plt.title('SARIMAX Model - Predicted vs Actual')
plt.legend()
plt.show()


X_test.shape

y_test.shape

y_test.values

y_pred_test_arima.values

# Forecast on the test set
sarimax_forecast_test = sarimax_fit.get_forecast(steps=len(X_test))
y_pred_test_arima = sarimax_forecast_test.predicted_mean


y_pred_test_arima.shape

# Calculate SMAPE for the test set
smape_test = smape_arima(y_test.values, y_pred_test_arima.values)
print(f"SMAPE for Test Set: {smape_test:.2f}%")

# Display shapes of the datasets
print("Shape of X_train:", X_train.shape)
print("Shape of X_test:", X_test.shape)
print("Shape of X_val:", X_val.shape)

print("Shape of y_train:", y_train.shape)
print("Shape of y_val", y_val.shape)
print("Shape of y_test:", y_test.shape)

# Scale features
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val) 
X_test_scaled = scaler.transform(X_test)

# Reshape data for LSTM
X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])
X_val_reshaped = X_val_scaled.reshape(X_val_scaled.shape[0], 1, X_val_scaled.shape[1])
X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])



y_train = y_train.astype('float32')
y_val = y_val.astype("float32")
y_test = y_test.astype('float32')

# Create KerasRegressor for use in GridSearchCV
# lstm_regressor = KerasRegressor(build_fn=create_lstm_model, verbose=0)

# # Define hyperparameters grid including optimizers and loss functions
# param_grid = {
#     'units': [50, 100],
#     'dropout_rate': [0.0, 0.2, 0.4],
#     'optimizer': ['adam', 'rmsprop'],
#     'loss': ['mean_squared_error',  'smape']
# }

# # Perform GridSearchCV
# grid_search = GridSearchCV(estimator=lstm_regressor, param_grid=param_grid, cv=3)
# grid_result = grid_search.fit(X_train_reshaped, y_train)

# # Print best results
# print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
# means = grid_result.cv_results_['mean_test_score']
# stds = grid_result.cv_results_['std_test_score']
# params = grid_result.cv_results_['params']
# for mean, stdev, param in zip(means, stds, params):
#     print("Mean MSE: %f, Standard Deviation: %f with: %r" % (mean, stdev, param))

del sarimax_model #to free some space



# Define a function to create the LSTM model
def create_best_lstm_model():
    model = Sequential()
    model.add(LSTM(units=100, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))
    model.add(Dropout(0.0))
    model.add(Dense(units=1))
    
    # Compile the model with RMSprop optimizer and SMAPE loss function
    def smape_loss(y_true, y_pred):
        epsilon = 0.1
        summ = K.maximum(K.abs(y_true) + K.abs(y_pred) + epsilon, 0.5 + epsilon)
        smape = K.abs(y_pred - y_true) / summ * 2.0
        return smape
    model.compile(optimizer=RMSprop(), loss=smape_loss)
        
    return model

# Create the best LSTM model
best_lstm_model = create_best_lstm_model()

# Train the model
history = best_lstm_model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, verbose=1, validation_split=0.1,shuffle= False)

# Evaluate the model on test data
loss = best_lstm_model.evaluate(X_val_reshaped, y_val)
print("SMAPE on val data:", loss)



loss = best_lstm_model.evaluate(X_test_reshaped, y_test)
print("SMAPE on test data:", loss)



# Plot training loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()


y_test.shape

X_test_reshaped.shape

test_set.shape

y_test

# Make predictions on the test set
y_test_pred = best_lstm_model.predict(X_test_reshaped)

# Plot the predicted vs actual values
plt.figure(figsize=(12, 6))
plt.plot(test_set['date'], y_test, label='Actual Data', marker='o')
plt.plot(test_set['date'], y_test_pred, label='Predicted Data', marker='o')
plt.xlabel('Date')
plt.ylabel('Number of Products Sold')
plt.title('LSTM Model - Predicted vs Actual on Test Data')
plt.legend()
plt.show()

y_test_pred.flatten()

smape_arima(y_test.values, y_test_pred.flatten())

original_test_encoded.head(1)

# Assuming your training data has all relevant features except 'num_sold'
all_columns =  original_test_encoded.columns
target_column = 'date'
target_column_id = 'id'
# Extract feature columns by excluding the target column
features = [col for col in all_columns if col != target_column]
features = [col for col in features if col != target_column_id]

# Print or inspect the list of features
print("Features:", features)

X_original_test_lstm = original_test_encoded.drop(columns=['date','id'])
# Reshape the test data for LSTM
X_original_test_lstm = original_test_encoded[features].values.reshape(original_test_encoded.shape[0], 1, len(features))

print(X_original_test_lstm.shape)

# Make predictions on the test set
y_test_pred_original = best_lstm_model.predict(X_original_test_lstm)

y_test_pred_original_exp = np.exp(y_test_pred_original)

# Create submission_lstm DataFrame
submission_lstm = pd.DataFrame({
    'id': original_test_encoded['id'],
    'num_sold': y_test_pred_original_exp.flatten()})  # Assuming y_original

submission_lstm.to_csv(os.path.join(download_path, "submission_lstm.csv"), index= False)
-------------------------------------
import os
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Lambda
from tensorflow.keras.models import Sequential
from tensorflow.keras.losses import Huber
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import LearningRateScheduler
from tensorflow.keras.metrics import mean_absolute_error

# Directory containing input files
DIR_IN = "/kaggle/input/agriculture-vegetables-fruits-time-series-prices/"
# Working directory (the only writable place in a Kaggle's work)
DIR_WORK = "/kaggle/working/"
# Full path to the input file
FILE_IN = os.path.join(DIR_IN, "kalimati_tarkari_dataset.csv")
# Name of the fruit of which the price will be predicted
FRUIT_TYPE = "Potato Red"
# Date used to split the training and the test part
SPLIT_DATE = "2020-01-01"
# Size of the window applied to the time series
WINDOW_SIZE = 10
# Batch size for model training and prediction
BATCH_SIZE = 32
# Buffer size used to shuffle the training set, should be bigger than the dataset's size
SHUFFLE_BUFFER = 3000

df = pd.read_csv(FILE_IN, sep=",")
df.head()

df = df[df['Commodity'] == FRUIT_TYPE]
df.info()

df = df[['Date', 'Average']]
df.head()

df['Date'] = pd.to_datetime(df['Date'])
df.set_index('Date', inplace=True)
df.head()

df = df.resample('D').asfreq()
print(f"Number of samples after resampling: {len(df)}")

missing_values = df[df['Average'].isna()]
print(missing_values)

df = df.ffill()
print(f"After ffill, there is {len(df[df['Average'].isna()])} NaN value")

def plot_series(x, y, start=0, end=None, title=None, xlabel=None, ylabel=None):
    """
    Utility function to plot a series
    
    Args:
        x (1d Numpy array): values for the x-axis
        y (tuple of Numpy arrays or 1d Numpy array): values for the y-axis
        start (int): start index
        end (int): end index
        title (str): title of the plot
        xlabel (str): label for the x-axis
        ylabel (str): label for the y-axis
    """
    # Set figure's size
    plt.figure(figsize=(10, 6))
    
    # If y is a tuple containing multiple sets of values then plot them all
    if type(y) is tuple:
        for val_set in y:
            plt.plot(x[start: end], val_set[start: end])
    else:
        plt.plot(x[start: end], y[start: end])

    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.grid(True)    
    plt.show()

plot_series(df.index, df['Average'])

df_train = df[df.index < SPLIT_DATE]
df_test = df[df.index >= SPLIT_DATE]

time_test = df_test.index  # just used for plotting results at the end

X_train = df_train['Average'].values  # convert to Numpy array
X_test = df_test['Average'].values  # convert to Numpy array

print(f"X_train shape = {X_train.shape}; X_test shape = {X_test.shape}")
print(f"Some X_train data: {X_train[:10]}")

def window_train(series, window_size, batch_size, shuffle_buffer):
    """
    Convert the train series to Tensorflow Dataset
    
    Args:
        series (1d Numpy array): input time series data
        window_size (int): size of the sliding window
        batch_size (int): number of elements in each batch
        shuffle_buffer (int): buffer size used for shuffling
        
    Returns:
        A Tensorflow Dataset where each batch's element is a tuple ([v-N, ..., v-1], [v])
        where v, v-1, ..., v-N are values at time t, t-1, ..., t-N, respectively.
    """
    # Convert the input series into Tensorflow Dataset
    dataset = tf.data.Dataset.from_tensor_slices(series)

    # Convert dataset into a new dataset containing windows where
    # each window is itself a dataset of size (window_size + 1).
    # Hey! Note that below we use (window_size + 1) because we want the last element
    # to be the prediction result (like labels in classification problems)
    dataset = dataset.window(window_size + 1, shift=1, stride=1, drop_remainder=True)
    
    # Flatten the new dataset by converting each of its window (sub-dataset) into
    # a single batch then join them together by using the flat_map function
    dataset = dataset.flat_map(lambda w: w.batch(window_size + 1))
    
    # Separate each batch into two parts: past values and present value
    dataset = dataset.map(lambda w: (w[:-1], w[-1]))
    
    # We should shuffle the training set to avoid that the sequenced
    # order of the input data impacts the trained model
    dataset = dataset.shuffle(shuffle_buffer)
    
    # Group the single batches into bigger batches (to profit parallelism)
    dataset = dataset.batch(batch_size).prefetch(1)
    
    return dataset

def window_test(series, window_size, batch_size):
    """
    Convert the test series to Tensorflow Dataset
    """
    dataset = tf.data.Dataset.from_tensor_slices(series)
    # Note that we need to use window_size instead of window_size + 1 as for
    # the training set because we're working on the test set
    dataset = dataset.window(window_size, shift=1, stride=1, drop_remainder=True)
    dataset = dataset.flat_map(lambda w: w.batch(window_size))
    dataset = dataset.batch(batch_size).prefetch(1)
    
    return dataset

# Create the train dataset
ds_train = window_train(X_train, WINDOW_SIZE, BATCH_SIZE, SHUFFLE_BUFFER)
# Create the test set.
# Note that we have to use the last WINDOW_SIZE elements of the training set
# to predict the first element of the test set, and we have to exclude the last element
# of the test set because it won't be used to predict the value at its next timestep
ds_test = window_test(np.concatenate((X_train[-WINDOW_SIZE:], X_test[:-1])), WINDOW_SIZE, BATCH_SIZE)

# Just checking shapes
for batch in ds_train.take(1):
    print(batch[0].shape)
    print(batch[1].shape)
print("--------------------")
for batch in ds_test.take(1):
    print(batch.shape)

tf.keras.backend.clear_session()

model = Sequential([
    Lambda(lambda x: tf.expand_dims(x, axis=-1), input_shape=[WINDOW_SIZE]),
    Bidirectional(LSTM(32, return_sequences=True)),
    Bidirectional(LSTM(32)),
    Dense(1),
    Lambda(lambda x: x * 100.0)
])

# Save the init weights so that we don't need to
# recreate a new model after tuning the learning rate
init_weights = model.get_weights()

model.summary()

lr_schd = LearningRateScheduler(lambda epoch: 1e-8 * 10**(epoch / 20))

model.compile(loss=Huber(), optimizer=Adam())

hist = model.fit(ds_train, epochs=100, callbacks=[lr_schd])

lr_arr = 1e-8 * (10 ** (np.arange(100) / 20))

plt.figure(figsize=(10, 6))
plt.grid(True)
plt.semilogx(lr_arr, hist.history['loss'])
plt.tick_params('both', length=10, width=1, which='both')
plt.axis([1e-8, 1e-3, 0, 100])

model.set_weights(init_weights)

model.compile(loss=Huber(), optimizer=Adam(learning_rate=1e-4), metrics=['mae'])

hist = model.fit(ds_train, epochs=300)

hist_mae = hist.history['mae']
hist_loss = hist.history['loss']

plot_series(range(len(hist_loss)), (hist_mae, hist_loss), title="MAE & Loss", xlabel="Epochs")

forecasts = model.predict(ds_test)

forecasts = forecasts.squeeze()  # remove the single axis

plot_series(time_test, (X_test, forecasts))

mae = mean_absolute_error(X_test, forecasts).numpy()
mean = np.mean(X_test)

print(f"MAE = {mae:.2f}")
print(f"MAE / mean = {(mae/mean * 100):.2f} %")
-------------------------------------
import time
import os
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
from pickle import load
from tensorflow.keras.losses import mean_squared_error
from tensorflow.keras.layers import GRU, Dense, Flatten, Conv1D, BatchNormalization, LeakyReLU, ELU, ReLU
from tensorflow.keras import Sequential, regularizers
from tensorflow.python.client import device_lib
from sklearn.metrics import mean_squared_error

X_train = np.load("/kaggle/input/data600600/X_train_600600.npy", allow_pickle=True)
y_train = np.load("/kaggle/input/data600600/y_train_600600.npy", allow_pickle=True)
X_test = np.load("/kaggle/input/data600600/X_test_600600.npy", allow_pickle=True)
y_test = np.load("/kaggle/input/data600600/y_test_600600.npy", allow_pickle=True)
yc_train = np.load("/kaggle/input/data600600/yc_train_600600.npy", allow_pickle=True)
yc_test = np.load("/kaggle/input/data600600/yc_test_600600.npy", allow_pickle=True)

def Generator(input_dim, output_dim, feature_size) -> tf.keras.models.Model:
    model = Sequential()
    model.add(GRU(units=256,
                  return_sequences=True,
                  input_shape=(input_dim, feature_size),
                  recurrent_dropout=0.02,
                  recurrent_regularizer=regularizers.l2(1e-3)))
    model.add(GRU(units=128,
                  # return_sequences=True,
                  recurrent_dropout=0.02,
                  recurrent_regularizer=regularizers.l2(1e-3)))
    # model.add(Dense(128,
    #              kernel_regularizer=regularizers.l2(1e-3)))
    model.add(Dense(64, kernel_regularizer=regularizers.l2(1e-3)))
    model.add(Dense(32, kernel_regularizer=regularizers.l2(1e-3)))
    # model.add(Dense(16, kernel_regularizer=regularizers.l2(1e-3)))
    # model.add(Dense(8, kernel_regularizer=regularizers.l2(1e-3)))
    model.add(Dense(units=output_dim))
    return model


# Define the discriminator
def Discriminator() -> tf.keras.models.Model:
    model = tf.keras.Sequential()
    model.add(
        Conv1D(32, input_shape=(4, 1), kernel_size=3, strides=2, padding="same", activation=LeakyReLU(alpha=0.01)))
    model.add(Conv1D(64, kernel_size=3, strides=2, padding="same", activation=LeakyReLU(alpha=0.01)))
    model.add(Conv1D(128, kernel_size=3, strides=2, padding="same", activation=LeakyReLU(alpha=0.01)))
    model.add(Flatten())
    model.add(Dense(220, use_bias=True))
    model.add(LeakyReLU())
    model.add(Dense(220, use_bias=True))
    model.add(ReLU())
    model.add(Dense(1))
    return model


# Train WGAN-GP model
class GAN():
    def __init__(self, generator, discriminator):
        super(GAN, self).__init__()
        self.d_optimizer = tf.keras.optimizers.Adam(0.0001)
        self.g_optimizer = tf.keras.optimizers.Adam(0.0001)
        self.generator = generator
        self.discriminator = discriminator
        self.batch_size = 128
        checkpoint_dir = '../training_checkpoints'
        self.checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
        self.checkpoint = tf.train.Checkpoint(generator_optimizer=self.g_optimizer,
                                              discriminator_optimizer=self.d_optimizer,
                                              generator=self.generator,
                                              discriminator=self.discriminator)

    def gradient_penalty(self, batch_size, real_output, fake_output):
        """ Calculates the gradient penalty.

        This loss is calculated on an interpolated image
        and added to the discriminator loss.
        """
        # get the interpolated data
        alpha = tf.random.normal([batch_size, 4, 1], 0.0, 1.0)
        diff = fake_output - tf.cast(real_output, tf.float32)
        interpolated = tf.cast(real_output, tf.float32) + alpha * diff

        with tf.GradientTape() as gp_tape:
            gp_tape.watch(interpolated)
            # 1. Get the discriminator output for this interpolated image.
            pred = self.discriminator(interpolated, training=True)

        # 2. Calculate the gradients w.r.t to this interpolated image.
        grads = gp_tape.gradient(pred, [interpolated])[0]

        # 3. Calcuate the norm of the gradients
        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2]))

        gp = tf.reduce_mean((norm - 1.0) ** 2)
        return gp

    def train_step(self, data):
        real_input, real_price, yc = data
        batch_size = tf.shape(real_input)[0]
        for _ in range(1):
            with tf.GradientTape() as d_tape:
                # Train the discriminator
                # generate fake output
                generated_data = self.generator(real_input, training=True)
                # reshape the data
                generated_data_reshape = tf.reshape(generated_data,
                                                    [generated_data.shape[0], generated_data.shape[1], 1])
                fake_output = tf.concat([generated_data_reshape, tf.cast(yc, tf.float32)], axis=1)
                real_y_reshape = tf.reshape(real_price, [real_price.shape[0], real_price.shape[1], 1])
                real_output = tf.concat([tf.cast(real_y_reshape, tf.float32), tf.cast(yc, tf.float32)], axis=1)
                # Get the logits for the fake images
                D_real = self.discriminator(real_output, training=True)
                # Get the logits for real images
                D_fake = self.discriminator(fake_output, training=True)
                # Calculate discriminator loss using fake and real logits
                real_loss = tf.cast(tf.reduce_mean(D_real), tf.float32)
                fake_loss = tf.cast(tf.reduce_mean(D_fake), tf.float32)
                d_cost = fake_loss - real_loss
                # Calculate the gradientjiu penalty
                gp = self.gradient_penalty(batch_size, real_output, fake_output)
                # Add the gradient penalty to the original discriminator loss
                d_loss = d_cost + gp * 10

            d_grads = d_tape.gradient(d_loss, self.discriminator.trainable_variables)
            self.d_optimizer.apply_gradients(zip(d_grads, self.discriminator.trainable_variables))
        for _ in range(3):
            with tf.GradientTape() as g_tape:
                # Train the generator
                # generate fake output
                generated_data = self.generator(real_input, training=True)
                # reshape the data
                generated_data_reshape = tf.reshape(generated_data,
                                                    [generated_data.shape[0], generated_data.shape[1], 1])
                fake_output = tf.concat([generated_data_reshape, tf.cast(yc, tf.float32)], axis=1)
                # Get the discriminator logits for fake images
                G_fake = self.discriminator(fake_output, training=True)
                # Calculate the generator loss
                g_loss = -tf.reduce_mean(G_fake)
            g_grads = g_tape.gradient(g_loss, self.generator.trainable_variables)
            self.g_optimizer.apply_gradients(zip(g_grads, self.generator.trainable_variables))

        return real_price, generated_data, {'d_loss': d_loss, 'g_loss': g_loss}

    def train(self, X_train, y_train, yc, epochs):
        data = X_train, y_train, yc
        train_hist = {}
        train_hist['D_losses'] = []
        train_hist['G_losses'] = []
        train_hist['per_epoch_times'] = []
        train_hist['total_ptime'] = []

        for epoch in range(epochs):
            start = time.time()

            real_price, fake_price, loss = self.train_step(data)

            G_losses = []
            D_losses = []

            Real_price = []
            Predicted_price = []

            D_losses.append(loss['d_loss'].numpy())
            G_losses.append(loss['g_loss'].numpy())

            Predicted_price.append(fake_price)
            Real_price.append(real_price)

            # Save the model every 15 epochs
            if (epoch + 1) % 15 == 0:
                tf.keras.models.save_model(generator, 'gen_GRU_model_%d.h5' % epoch)
                self.checkpoint.save(file_prefix=self.checkpoint_prefix)
                print('epoch', epoch + 1, 'd_loss', loss['d_loss'].numpy(), 'g_loss', loss['g_loss'].numpy())

            # For printing loss
            epoch_end_time = time.time()
            per_epoch_ptime = epoch_end_time - start
            train_hist['D_losses'].append(D_losses)
            train_hist['G_losses'].append(G_losses)
            train_hist['per_epoch_times'].append(per_epoch_ptime)

        # Reshape the predicted result & real
        Predicted_price = np.array(Predicted_price)
        Predicted_price = Predicted_price.reshape(Predicted_price.shape[1], Predicted_price.shape[2])
        Real_price = np.array(Real_price)
        Real_price = Real_price.reshape(Real_price.shape[1], Real_price.shape[2])

        # Plot the loss
        plt.plot(train_hist['D_losses'], label='D_loss')
        plt.plot(train_hist['G_losses'], label='G_loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        plt.savefig('train_loss.png')
        plt.show()

        print("REAL", Real_price.shape)
        print(Real_price)
        print("PREDICTED", Predicted_price.shape)
        print(Predicted_price)

        return Predicted_price, Real_price, np.sqrt(mean_squared_error(Real_price, Predicted_price)) / np.mean(
            Real_price)

input_dim = X_train.shape[1]
feature_size = X_train.shape[2]
output_dim = y_train.shape[1]
epoch = 100

generator = Generator(X_train.shape[1], output_dim, X_train.shape[2])
discriminator = Discriminator()
gan = GAN(generator, discriminator)
Predicted_price, Real_price, RMSPE = gan.train(X_train, y_train, yc_train, epoch)

X_scaler = load(open('/kaggle/input/data600600/X_scaler_600600.pkl', 'rb'))
y_scaler = load(open('/kaggle/input/data600600/y_scaler_600600.pkl', 'rb'))
train_predict_index = np.load("/kaggle/input/data600600/index_train_600600.npy", allow_pickle=True)
test_predict_index = np.load("/kaggle/input/data600600/index_test_600600.npy", allow_pickle=True)

print("----- predicted price -----", Predicted_price)

rescaled_Real_price = y_scaler.inverse_transform(Real_price)
rescaled_Predicted_price = y_scaler.inverse_transform(Predicted_price)

print("----- rescaled predicted price -----", rescaled_Predicted_price)
print("----- SHAPE rescaled predicted price -----", rescaled_Predicted_price.shape)

predict_result = pd.DataFrame()
for i in range(rescaled_Predicted_price.shape[0]):
    y_predict = pd.DataFrame(rescaled_Predicted_price[i], columns=["predicted_price"],
                             index=train_predict_index[i:i + output_dim])
    predict_result = pd.concat([predict_result, y_predict], axis=1, sort=False)

real_price = pd.DataFrame()
for i in range(rescaled_Real_price.shape[0]):
    y_train = pd.DataFrame(rescaled_Real_price[i], columns=["real_price"], index=train_predict_index[i:i + output_dim])
    real_price = pd.concat([real_price, y_train], axis=1, sort=False)

predict_result['predicted_mean'] = predict_result.mean(axis=1)
real_price['real_mean'] = real_price.mean(axis=1)

# Plot the predicted result
plt.figure(figsize=(16, 8))
plt.plot(real_price["real_mean"])
plt.plot(predict_result["predicted_mean"], color='r')
plt.xlabel("Date")
plt.ylabel("Stock price")
plt.legend(("Real price", "Predicted price"), loc="upper left", fontsize=16)
plt.title("The result of Training", fontsize=20)
plt.savefig('train_plot.png')
plt.show()

# Calculate RMSE
predicted = predict_result["predicted_mean"]
real = real_price["real_mean"]
For_MSE = pd.concat([predicted, real], axis=1)
RMSE = np.sqrt(mean_squared_error(predicted, real))
print('-- RMSE -- ', RMSE)

# Load scaler/ index
X_scaler = load(open('/kaggle/input/data600600/X_scaler_600600.pkl', 'rb'))
y_scaler = load(open('/kaggle/input/data600600/y_scaler_600600.pkl', 'rb'))
train_predict_index = np.load("/kaggle/input/data600600/index_train_600600.npy", allow_pickle=True)
test_predict_index = np.load("/kaggle/input/data600600/index_test_600600.npy", allow_pickle=True)

# Load test dataset/ model
G_model = tf.keras.models.load_model('/kaggle/working/gen_GRU_model_89.h5')
X_test = np.load("/kaggle/input/data600600/X_test_600600.npy", allow_pickle=True)
y_test = np.load("/kaggle/input/data600600/y_test_600600.npy", allow_pickle=True)

def get_test_plot(X_test, y_test):
    # Set output steps
    output_dim = y_test.shape[1]

    # Get predicted data
    y_predicted = G_model(X_test)
    rescaled_real_y = y_scaler.inverse_transform(y_test)
    rescaled_predicted_y = y_scaler.inverse_transform(y_predicted)

    ## Predicted price
    predict_result = pd.DataFrame()
    for i in range(rescaled_predicted_y.shape[0]):
        y_predict = pd.DataFrame(rescaled_predicted_y[i], columns=["predicted_price"],
                                 index=test_predict_index[i:i + output_dim])
        predict_result = pd.concat([predict_result, y_predict], axis=1, sort=False)

    ## Real price
    real_price = pd.DataFrame()
    for i in range(rescaled_real_y.shape[0]):
        y_train = pd.DataFrame(rescaled_real_y[i], columns=["real_price"], index=test_predict_index[i:i + output_dim])
        real_price = pd.concat([real_price, y_train], axis=1, sort=False)

    predict_result['predicted_mean'] = predict_result.mean(axis=1)
    real_price['real_mean'] = real_price.mean(axis=1)

    #drop 2020
    # Input_Before = '2020-01-01'
    # predict_result = predict_result.loc[predict_result.index < Input_Before]
    # real_price = real_price.loc[real_price.index < Input_Before]

    # Plot the predicted result
    plt.figure(figsize=(16, 8))
    plt.plot(real_price["real_mean"])
    plt.plot(predict_result["predicted_mean"], color='r')
    plt.xlabel("Date")
    plt.ylabel("Stock price")
    plt.legend(("Real price", "Predicted price"), loc="upper left", fontsize=16)
    plt.title("The result of test", fontsize=20)
    plt.savefig('test_plot.png')
    plt.show()
    # Calculate RMSE
    predicted = predict_result["predicted_mean"]
    real = real_price["real_mean"]
    For_MSE = pd.concat([predicted, real], axis=1)
    RMSE = np.sqrt(mean_squared_error(predicted, real))
    print('-- RMSE -- ', RMSE)

    return predict_result, RMSE

test_predicted, test_RMSE = get_test_plot(X_test, y_test)
test_predicted.to_csv("test_predicted.csv")
-------------------------------------
!python3 --version

!pip install yfinance

# First we will import the necessary Library 

import os
import yfinance as yf
import pandas as pd
import numpy as np
import math
import datetime as dt

# For Evalution we will use these library

from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score 
from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score
from sklearn.preprocessing import MinMaxScaler

# For model building we will use these library

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.layers import LSTM, Bidirectional, GRU


# For PLotting we will use these library

import matplotlib.pyplot as plt
from itertools import cycle
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

def remove(x):
    """
    This function will strip the data column of the dataframe.
    """
    x = str(x)
    res = x.split(" ")[0]
    return res

df = yf.Ticker("ETH-USD")  
df = df.history(period="max")  # we want the max data avialable 
df.index = pd.to_datetime(df.index)  # changing the index
df.index = df.index.to_series().apply(lambda x:remove(x))  # applying preprocessing function
# df.to_csv('ETH.csv')  # saving the data in csv format
df.reset_index(inplace=True)
df

fig = px.line(df, x=df.Date, y=df.Close,labels={'date':'Date','close':'Close Stock'})
fig.update_traces(marker_line_width=2, opacity=1, marker_line_color='orange')
fig.update_layout(title_text='ETH close price 2017-2024', plot_bgcolor='white', 
                  font_size=15, font_color='black')
fig.update_xaxes(showgrid=False)
fig.update_yaxes(showgrid=False)
fig.show()

#Creat a new dataframe with only Close Price

data = df.loc[(df['Date'] > '2021-01-01') & (df['Date'] < '2024-02-06') ]
close_stock = data.filter(['Date','Close'])
data = data.filter(['Close'])
#Convert the dataframe to numpy array
closedf = data.values
# closedf
print(closedf.shape)


# Scale the data
scaler=MinMaxScaler(feature_range=(0,1))
closedf_scale=scaler.fit_transform(np.array(closedf).reshape(-1,1))
print(closedf_scale.shape)


# we keep the training set as 80% and 20% testing set

training_size=int(len(closedf_scale)*0.80)
test_size=len(closedf)-training_size
train_data,test_data=closedf_scale[0:training_size,:],closedf_scale[training_size:len(closedf_scale),:1]
print("train_data: ", train_data.shape)
print("test_data: ", test_data.shape)

# function convert an array of values into a dataset matrix

def create_dataset(dataset, time_step=1):
    dataX, dataY = [], []
    for i in range(len(dataset)-time_step-1):
        a = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 
        dataX.append(a)
        dataY.append(dataset[i + time_step, 0])
    return np.array(dataX), np.array(dataY)

time_step = 60
X_train, y_train = create_dataset(train_data, time_step)
X_test, y_test = create_dataset(test_data, time_step)

print("X_train: ", X_train.shape)
print("y_train: ", y_train.shape)
print("X_test: ", X_test.shape)
print("y_test", y_test.shape)
# reshape input to be [samples, time steps, features] which is required for LSTM
X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)
X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)

print("X_train: ", X_train.shape)
print("X_test: ", X_test.shape)

# Build LSTM model
tf.random.set_seed(42)

model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1))) # we made it like pros ;) , the simple form is "input_shape(60, 1)""
model.add(LSTM(50, return_sequences=False))
model.add(Dense(25))
model.add(Dense(1))
# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')
print(model.summary())

#Bidirection
model = Sequential()

model.add(Bidirectional(LSTM(50, return_sequences=True), input_shape=(X_train.shape[1],1)))
model.add(Bidirectional(LSTM(50, return_sequences=False)))
model.add(Dense(25))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')
print(model.summary())

# Build LSTM model with Bidirection and dropout
model = Sequential()

model.add(Bidirectional(LSTM(50, return_sequences=True), input_shape=(X_train.shape[1],1)))
model.add(Dropout(0.2))
model.add(Bidirectional(LSTM(50, return_sequences=False)))
model.add(Dropout(0.2))
model.add(Dense(25))
model.add(Dropout(0.2))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')
print(model.summary())

#GRU
model = Sequential()
model.add(GRU(50, return_sequences=True, input_shape=(X_train.shape[1], 1))) # we made it like pros ;) , the simple form is "input_shape(60, 1)""
model.add(GRU(50, return_sequences=False))
model.add(Dense(25))
model.add(Dense(1))
# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')
print(model.summary())

# Train the model
import time
start = time.time()
history = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=40,batch_size=32,verbose=1)
print("time training: ", time.time()-start)
model.save("LSTM.keras")

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(loss))

plt.plot(epochs, loss, 'r', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss of LSTM')
plt.legend(loc=0)
plt.figure()
plt.show()

# Train the model
import time
start = time.time()
history = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=40,batch_size=32,verbose=1)
print("time training: ", time.time()-start)
model.save("Bi_LSTM.keras")

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(loss))

plt.plot(epochs, loss, 'r', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss of LSTM Bidirection')
plt.legend(loc=0)
plt.figure()
plt.show()

# Train the model
import time
start = time.time()
history = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=40,batch_size=32,verbose=1)
print("time training: ", time.time()-start)
model.save("Bi_Drop_LSTM.keras")

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(loss))

plt.plot(epochs, loss, 'r', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss of LSTM-Bidirection with Drop')
plt.legend(loc=0)
plt.figure()
plt.show()

# Train the model
import time
start = time.time()
history = model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=40,batch_size=32,verbose=1)
print("time training: ", time.time()-start)
model.save("GRU.keras")

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(loss))

plt.plot(epochs, loss, 'r', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss of GRU')
plt.legend(loc=0)
plt.figure()
plt.show()

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(loss))

plt.plot(epochs, loss, 'r', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss of GRU')
plt.legend(loc=0)
plt.figure()
plt.show()

### Lets Do the prediction and check performance metrics
train_predict=model.predict(X_train)
test_predict=model.predict(X_test)
train_predict.shape, test_predict.shape


# Transform back to original form

train_predict_inverse = scaler.inverse_transform(train_predict)
test_predict_inverse = scaler.inverse_transform(test_predict)
original_ytrain = scaler.inverse_transform(y_train.reshape(-1,1)) 
original_ytest = scaler.inverse_transform(y_test.reshape(-1,1)) 
print(train_predict_inverse.shape)

# Evaluation metrices RMSE and MAE
print("Train data RMSE: ", math.sqrt(mean_squared_error(original_ytrain,train_predict_inverse)))
print("Train data MAE: ", mean_absolute_error(original_ytrain,train_predict_inverse))
print("Train data R2: ", r2_score(original_ytrain,train_predict_inverse))
print("Train data explained variance regression score:", 
      explained_variance_score(original_ytrain, train_predict_inverse))
print("-------------------------------------------------------------------------------------")
print("Test data RMSE: ", math.sqrt(mean_squared_error(original_ytest,test_predict_inverse)))
print("Test data MAE: ", mean_absolute_error(original_ytest,test_predict_inverse))
print("Test data R2: ", r2_score(original_ytest,test_predict_inverse))
print("Test data explained variance regression score:", 
      explained_variance_score(original_ytest, test_predict_inverse))

# shift train predictions for plotting

look_back=60

# shift test predictions for plotting
testPredictPlot = np.empty_like(closedf)
testPredictPlot[:, :] = np.nan
testPredictPlot[len(train_predict)+(look_back*2)+1:len(closedf)-1, :] = test_predict_inverse
print("Test predicted data: ", testPredictPlot.shape)

names = cycle(['Original close price','Test predicted close price'])


plotdf = pd.DataFrame({'date': close_stock['Date'],
                       'original_close': close_stock['Close'],
                      'test_predicted_close': testPredictPlot.reshape(1,-1)[0].tolist()})

fig = px.line(plotdf,x=plotdf['date'], y=[plotdf['original_close'],
                                          plotdf['test_predicted_close']],
              labels={'value':'Close price','date': 'Date'})
fig.update_layout(title_text='Comparision between original close price vs predicted close price',
                  plot_bgcolor='white', font_size=15, font_color='black', legend_title_text='Close Price')
fig.for_each_trace(lambda t:  t.update(name = next(names)))

fig.update_xaxes(showgrid=False)
fig.update_yaxes(showgrid=False)
fig.show()

#Parameter
time_step = 60
last_day = 100
pred_days = 15

#Predict next 15 days
x_input=test_data[-time_step:].reshape(1,-1)
print(x_input.shape)
temp_input=list(x_input)
temp_input=temp_input[0].tolist()

from numpy import array

lst_output=[]
n_steps=time_step
i=0

while(i<pred_days):
    
    if(len(temp_input)>time_step):
        
        x_input=np.array(temp_input[1:])
        #print("{} day input {}".format(i,x_input))
        x_input = x_input.reshape(1,-1)
        x_input = x_input.reshape((1, n_steps, 1))
        
        yhat = model.predict(x_input, verbose=0)
        #print("{} day output {}".format(i,yhat))
        temp_input.extend(yhat[0].tolist())
        temp_input=temp_input[1:]
        #print(temp_input)
       
        lst_output.extend(yhat.tolist())
        i=i+1
        
    else:
        
        x_input = x_input.reshape((1, n_steps,1))
        yhat = model.predict(x_input, verbose=0)
        temp_input.extend(yhat[0].tolist())
        
        lst_output.extend(yhat.tolist())
        i=i+1
               
print("Output of predicted next days: ", lst_output)

import matplotlib.pyplot as plt

# Example data
dates = np.arange(1,last_day+pred_days+1)
last_original_days_value = scaler.inverse_transform(closedf_scale[len(closedf_scale)-last_day:]).reshape(1,-1).tolist()[0]
next_predicted_days_value = scaler.inverse_transform(np.array(lst_output).reshape(-1,1)).reshape(1,-1).tolist()[0]

print(last_original_days_value)
print(next_predicted_days_value)

# Plotting
plt.plot(dates[0:last_day], last_original_days_value, color='blue', label='last_original_days_value')
plt.plot(dates[last_day:last_day+pred_days], next_predicted_days_value, color='red', label='next_predicted_days_value')
plt.ylim(1000,3000)

# Adding labels and title
plt.xlabel('Date')
plt.ylabel('ETH value')
plt.title('Compare last 100 days vs next 15 days')
plt.legend()

# Display the plot
plt.show()


#Predict value at 6/2/2024
# Scale the data to be values between 0 and 1
last_days_scaled = test_data[-time_step:]
# create an empty list
new_X_test = []
# Append the past days
new_X_test.append(last_days_scaled)
# Convert the X_test data set to a numpy array
new_X_test = np.array(new_X_test)

print(new_X_test.shape)
# Get the predicted scaled price
pred_price = model.predict(new_X_test)
print(pred_price.shape)
# Undo the scaling
predict_value = scaler.inverse_transform(pred_price)
print(predict_value)
-------------------------------------
import pandas as pd
import numpy as np
from tensorflow.keras.callbacks import LambdaCallback
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Embedding, Dropout, Input
from tensorflow.keras.optimizers import RMSprop
from tensorflow import keras

# data_folder = '/kaggle/working/data'

# import tarfile

# def extract(tar_file, path):
#     opened_tar = tarfile.open(tar_file)
     
#     if tarfile.is_tarfile(tar_file):
#         opened_tar.extractall(path)
#     else:
#         print("The tar file you entered is not a tar file")

# extract('/kaggle/input/yelpdataset/yelp_dataset.tar', data_folder)

reviews_addr = '/kaggle/input/yelpreviewsjson/yelp_academic_dataset_review.json'

f = open(reviews_addr)

def read16k():
    return f.read(16384)

chunk_gen = iter(read16k, '')

import re
import ast
!pip install tqdm
from tqdm import tqdm

X = []
y = []
exceptions = []

for chunk in tqdm(chunk_gen):
    jsons = re.findall(r'({.*})', chunk)
    for j in jsons:
        try:
            json_as_dict = ast.literal_eval(j)
        except Exception as e:
            exceptions.append(str(e))
            continue
        # get data -- check it's there
        try:
            X.append(json_as_dict['text'])
        except:
            exceptions.append('No text found')
        else:
            try:
                y.append(json_as_dict['stars'])
            except:
                exceptions.append('No stars found')
                X = X[:-1]

print(f"{len(exceptions)} Exceptions occurred")
f.close()

assert len(X) == len(y)
len(X)

type(y[0])

for i in range(5):
    print(f"{X[i]}, {y[i]}")

# it's too long!
cutoff = 1000000
X = X[:cutoff]
y = y[:cutoff]

from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=500, lower=True) # could reduce num_words to 500
tokenizer.fit_on_texts(X)
X = tokenizer.texts_to_sequences(X)
X = pad_sequences(X)

num_words = len(tokenizer.word_index) + 1
num_words

from sklearn.model_selection import train_test_split
y = np.array(y)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.02, random_state = 6)
del X, y # save a bit of memory

path_to_glove_file = "/kaggle/input/glove6b200d/glove.6B.200d.txt"

word_index = tokenizer.word_index

embeddings_index = {}
with open(path_to_glove_file) as f:
    for line in f:
        word, coefs = line.split(maxsplit=1)
        coefs = np.fromstring(coefs, "f", sep=" ")
        embeddings_index[word] = coefs

print("Found %s word vectors." % len(embeddings_index))

num_tokens = num_words
embedding_dim = 200
hits = 0
misses = 0

# Prepare embedding matrix
embedding_matrix = np.zeros((num_tokens, embedding_dim))
for word, i in word_index.items():
    embedding_vector = embeddings_index.get(word)
    if embedding_vector is not None:
        # Words not found in embedding index will be all-zeros.
        # This includes the representation for "padding" and "OOV"
        embedding_matrix[i] = embedding_vector
        hits += 1
    else:
        misses += 1
print("Converted %d words (%d misses)" % (hits, misses))

embedding_layer = Embedding(
    num_tokens,
    embedding_dim,
    trainable=False,
)
embedding_layer.build((1,))
embedding_layer.set_weights([embedding_matrix])

from keras.initializers import TruncatedNormal
from keras.regularizers import L2

int_sequences_input = Input(shape=(None,), dtype='int32')
embedded_sequences = embedding_layer(int_sequences_input)
x = Bidirectional(LSTM(128, return_sequences=True))(embedded_sequences)
x = Bidirectional(LSTM(128, return_sequences=False))(x)
x = Dense(64, activation="relu")(x)
x = Dropout(0.25)(x)
x = Dense(64, activation="relu")(x)
x = Dropout(0.25)(x)
x = Dense(16, activation="relu")(x)
x = Dropout(0.25)(x)
preds = Dense(5, activation="softmax")(x) 
# could also try regression output (linear activation), clip and round
model = Model(int_sequences_input, preds)
model.summary()

model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['categorical_crossentropy', 'accuracy']
)

from tensorflow.keras.callbacks import ModelCheckpoint

checkpoint = ModelCheckpoint('/kaggle/working/best_model.keras', 
                    monitor="val_accuracy", mode="max", 
                    save_best_only=True, verbose=1)
callbacks = [checkpoint]

history = model.fit(X_train, y_train, batch_size=200, epochs=20, 
                    validation_data=(X_test, y_test), 
                    verbose = 0, callbacks=callbacks)
-------------------------------------
import pandas as pd
import time
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from imblearn.pipeline       import Pipeline 
from functools import partial
from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.metrics import f1_score
from transformers import T5Tokenizer, T5ForConditionalGeneration
from sklearn.calibration import CalibratedClassifierCV
from imblearn.over_sampling import RandomOverSampler
from sklearn.model_selection import GridSearchCV
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing.text import Tokenizer
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.layers import Embedding
import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings("ignore")
import tensorflow as tf
from sklearn.model_selection import train_test_split
import re
import tensorflow_text as tf_text
from tensorflow.keras.layers import TextVectorization, Embedding, Bidirectional, LSTM, Conv1D, GlobalMaxPooling1D, Dense, Dropout
from tensorflow.keras import Model, Input
from keras.callbacks import EarlyStopping,ModelCheckpoint
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from imblearn.over_sampling import SMOTE

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

train_prompts = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv')
train = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_essays.csv')
test = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')
sample = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv')

# Load the first file: test.csv
file_path_test = '/kaggle/input/llm-detect-ai-generated-text/test_essays.csv'
test_essays_df = pd.read_csv(file_path_test)

test_essays_df.head()

test_essays_df.shape

file_path_train_prompts = '/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv'
train_prompts_df = pd.read_csv(file_path_train_prompts)

train_prompts_df.head()

file_path_train_prompts = '/kaggle/input/llm-detect-ai-generated-text/train_essays.csv'
train_essays_df = pd.read_csv(file_path_train_prompts)
train_essays_df.head()

import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
import seaborn as sns



basic_stats = {
    "Total Entries": len(test_essays_df),
    "Unique IDs": test_essays_df["id"].nunique(),
    "Unique Prompt IDs": test_essays_df["prompt_id"].nunique(),
}

all_words = ' '.join(test_essays_df['text']).split()
word_frequency = Counter(all_words)

test_essays_df['text_length'] = test_essays_df['text'].apply(len)

basic_stats, word_frequency, test_essays_df['text_length'].describe()

plt.figure(figsize=(10, 6))
sns.barplot(x=list(word_frequency.keys()), y=list(word_frequency.values()))
plt.title("Word Frequency in Text")
plt.xlabel("Words")
plt.ylabel("Frequency")
plt.xticks(rotation=45)
plt.show()

missing_values_train = train_essays_df.isnull().sum()
print("missing_values_train:", missing_values_train)
missing_values_test = test_essays_df.isnull().sum()
print("\nmissing_values_train:", missing_values_train)
missing_values_prompts = train_prompts_df.isnull().sum()
print("\nmissing_values_prompts:", missing_values_prompts)

train_essays_df['generated'].value_counts()

train_essays_df['essay_length'] = train_essays_df['text'].apply(len)

sns.set(style="whitegrid")
plt.figure(figsize=(14, 7))

sns.histplot(train_essays_df[train_essays_df['generated'] == 0]['essay_length'], color="skyblue", label='Student Essays', kde=True)

sns.histplot(train_essays_df[train_essays_df['generated'] == 1]['essay_length'], color="red", label='LLM Generated Essays', kde=True)

plt.title('Distribution of Essay Lengths')
plt.xlabel('Essay Length (Number of Characters)')
plt.ylabel('Frequency')
plt.legend()
plt.show()

train_essays_df['essay_length'] = train_essays_df['text'].apply(len)

merged_df = train_essays_df.merge(train_prompts_df, on='prompt_id', how='left')

prompt_usage = merged_df['prompt_id'].value_counts()

avg_length_by_prompt = merged_df.groupby('prompt_id')['essay_length'].mean()

display("Prompt Usage Frequency")
display(prompt_usage)

display("Average Essay Length by Prompt")
display(avg_length_by_prompt)

plt.figure(figsize=(10, 6))
avg_length_by_prompt.plot(kind='bar')
plt.title('Average Essay Length by Prompt')
plt.xlabel('Prompt ID')
plt.ylabel('Average Essay Length')
plt.show()

def calculate_text_metrics_simple(text):
    words = text.split()
    sentences = text.split('.')
    word_count = len(words)
    unique_word_count = len(set(words))
    sentence_count = len(sentences)
    avg_word_length = sum(len(word) for word in words) / word_count if word_count > 0 else 0
    return word_count, unique_word_count, sentence_count, avg_word_length

train_essays_df['metrics'] = train_essays_df['text'].apply(calculate_text_metrics_simple)

train_essays_df[['word_count', 'unique_word_count', 'sentence_count', 'avg_word_length']] = pd.DataFrame(train_essays_df['metrics'].tolist(), index=train_essays_df.index)

train_essays_df.drop('metrics', axis=1, inplace=True)

comparison_metrics = train_essays_df.groupby('generated')[['word_count', 'unique_word_count', 'sentence_count', 'avg_word_length']].mean()
comparison_metrics

for i in ['prompt_id', 'generated']:
    plot = sns.countplot(data=train, x=i)
    plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator

text = " ".join(i for i in train.text)
wordcloud = WordCloud().generate(text)
plt.imshow(wordcloud)
plt.axis('off')
plt.show()

for i in train['prompt_id'].unique():
    text = " ".join(i for i in train[train['prompt_id'] == i].text)
    wordcloud = WordCloud().generate(text)
    plt.imshow(wordcloud)
    plt.axis('off')
    plt.show()

for i in train['generated'].unique():
    text = " ".join(i for i in train[train['generated'] == i].text)
    wordcloud = WordCloud().generate(text)
    plt.imshow(wordcloud)
    plt.axis('off')
    plt.show()

train[train['generated'] == 1]

train['word_lengths'] = train['text'].apply(lambda x: len(x.split(' ')))
sns.histplot(data=train['word_lengths'])

sns.boxplot(data=train, y='word_lengths', x='prompt_id')

sns.boxplot(data=train, y='word_lengths', x='generated')

train['char_lengths'] = train['text'].apply(lambda x: len([*x]))
sns.histplot(data=train['char_lengths'])

sns.violinplot(data=train, y='char_lengths', x='prompt_id')

sns.violinplot(data=train, y='char_lengths', x='generated')

train['avg_char_lengths'] = train['text'].apply(lambda x: len([*x]))/train['word_lengths']
sns.histplot(data=train['avg_char_lengths'])

sns.violinplot(data=train, y='avg_char_lengths', x='prompt_id')

sns.violinplot(data=train, y='avg_char_lengths', x='generated')

train['sentence_lengths'] = train['text'].apply(lambda x: len(x.split('.')))
sns.histplot(data=train['sentence_lengths'])

sns.violinplot(data=train, y='sentence_lengths', x='prompt_id')

sns.violinplot(data=train, y='sentence_lengths', x='generated')

new_data=pd.read_csv('/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv')
new_data.head()

new_data.label.value_counts()

train_prompts.prompt_name.value_counts()

new_data.prompt_name.value_counts()

new_=new_data.iloc[:, 0:2][new_data['prompt_name'].isin(train_prompts['prompt_name'].values)]
new_

train=pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_essays.csv')
train.head()

test=pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')
test.head()

train_prompts=pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv')
train_prompts.head()

train['prompt_id'].value_counts()

plt.figure(figsize=(8,5))
ax=sns.countplot(data=train,x="prompt_id",palette='Set3')
abs_values = train['prompt_id'].value_counts().values
ax.bar_label(container=ax.containers[0], labels=abs_values)
ax.set_title("Distribution Of Prompt ID")
plt.grid(True)
plt.xticks(rotation=45)
plt.yticks(rotation=45)
plt.show()

train['generated'].value_counts()

plt.figure(figsize=(8,5))
ax=sns.countplot(data=train,x="generated",palette='Set3')
abs_values = train['generated'].value_counts().values
ax.bar_label(container=ax.containers[0], labels=abs_values)
ax.set_title("Distribution Of Generated")
plt.grid(True)
plt.xticks(rotation=45)
plt.yticks(rotation=45)
plt.show()

train_prompts.prompt_name.value_counts()

new_data.prompt_name.value_counts()

new_=new_data.iloc[:, 0:2][new_data['prompt_name'].isin(train_prompts['prompt_name'].values)]
new_

t=train.iloc[:,2:]
t.columns=['text','label']
train_data=pd.concat([new_,t])
train_data=train_data.reset_index().iloc[:,1:]
train_data.head()

train_data.label.value_counts()

plt.figure(figsize=(8,5))
ax=sns.countplot(data=train_data,x="label",palette='Set3')
abs_values = train_data['label'].value_counts().values
ax.bar_label(container=ax.containers[0], labels=abs_values)
ax.set_title("Distribution Of Label")
plt.grid(True)
plt.xticks(rotation=45)
plt.yticks(rotation=45)
plt.show()

def Clean(text):
    text = tf_text.normalize_utf8(text, 'NFKD')
    text = tf.strings.lower(text)
    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')
    text = tf.strings.regex_replace(text, '[.?!,¿]', r' \0 ')
    text = tf.strings.strip(text)
    text = tf.strings.regex_replace(text, '\.\.\.', ' ')
    text = tf.strings.join(['',text, ''], separator=' ')
    return text
def clean_text(text):
    # Remove Twitter handles starting with '@'
    text = re.sub(r'@\w+', '', text)
    # Remove non-alphanumeric characters and extra whitespace
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    # Convert multiple whitespace characters to a single space
    text = re.sub(r'\s+', ' ', text)
    # Convert the text to lowercase
    text = text.lower()
    return text

train_data['text'][0]

Clean(train_data['text'][0])

clean_text(train_data['text'][0])

max_features = 75000
embedding_dim = 64
sequence_length = 512*2
vectorize_layer = tf.keras.layers.TextVectorization(
    standardize=Clean ,
    max_tokens=max_features,
    ngrams = (3,5),
    output_mode="int",
    output_sequence_length=sequence_length,
    pad_to_max_tokens=True
)
vectorize_layer.adapt(train_data['text'])
Text = vectorize_layer(train_data['text']).numpy()
Text

sm = SMOTE(random_state=44)
Text,labels= sm.fit_resample(Text,train_data['label'])

X_train, X_test, y_train, y_test = train_test_split(Text,labels, test_size=0.2, random_state=44, shuffle =True,stratify=labels)
print('X_train shape is ' , X_train.shape)
print('X_test shape is ' , X_test.shape)
print('y_train shape is ' , y_train.shape)
print('y_test shape is ' , y_test.shape)

class TransformerBlock(tf.keras.layers.Layer):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):
        super(TransformerBlock, self).__init__()
        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.ffn = tf.keras.Sequential(
            [tf.keras.layers.Dense(ff_dim, activation="relu"), tf.keras.layers.Dense(embed_dim),]
        )
        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
        self.dropout1 = tf.keras.layers.Dropout(rate)
        self.dropout2 = tf.keras.layers.Dropout(rate)

    def call(self, inputs, training):
        attn_output = self.att(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)
inputs = Input(shape=(sequence_length,), dtype="int64")
x = Embedding(max_features, embedding_dim)(inputs)
x = Bidirectional(LSTM(32, return_sequences=True))(x)
transformer_block = TransformerBlock(embedding_dim, 2, 32)
x = transformer_block(x)
x = Conv1D(128, 7, padding="valid", activation="relu", strides=3)(x)
x = GlobalMaxPooling1D()(x)
x = Dense(128, activation="relu")(x)
x = Dropout(0.5)(x)
predictions = Dense(1, activation="sigmoid", name="predictions")(x)

model = Model(inputs=inputs, outputs=predictions)
model.summary()

tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True,show_dtype=True,dpi=120)

checkpoint_cb =ModelCheckpoint("model.h5", save_best_only=True)
early_stopping_cb =EarlyStopping(patience=3, restore_best_weights=True)
model.compile(optimizer ='adam', loss='binary_crossentropy', metrics=['accuracy'])
hist = model.fit(X_train,y_train, epochs=10, validation_split=.1, callbacks=[checkpoint_cb, early_stopping_cb])

hist_=pd.DataFrame(hist.history)
hist_

score, acc= model.evaluate(X_test,y_test)
print('Test Loss =', score)
print('Test Accuracy =', acc)

predictions = model.predict(X_test)
y_pred = np.where(predictions>=.5,1,0)
y_test_1d = np.ravel(y_test)
y_pred_1d = np.ravel(y_pred)
df = pd.DataFrame({'Actual': y_test_1d, 'Prediction': y_pred_1d})
df

CM = confusion_matrix(y_test_1d,y_pred_1d)
CM_percent = CM.astype('float') / CM.sum(axis=1)[:, np.newaxis]
sns.heatmap(CM_percent,fmt='g',center = True,cbar=False,annot=True,cmap='Blues')
CM

ClassificationReport = classification_report(y_test_1d,y_pred_1d)
print('Classification Report is : ', ClassificationReport )

test_text = vectorize_layer(test['text']).numpy()
predictions = model.predict(test_text)
y_pred = np.where(predictions>=.5,1,0)
sub=pd.DataFrame()
sub['id'],sub['generated']=test['id'],predictions
sub.to_csv('/kaggle/working/submission.csv', index=False)
sub
-------------------------------------
pip install tf-models-official

pip install livelossplot

import tensorflow as tf
from keras.preprocessing.text import Tokenizer 
from keras.preprocessing.sequence import pad_sequences   
from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.preprocessing import LabelEncoder
import warnings
import tensorflow_models as tfm
import pandas as pd
import numpy as np
from tqdm import tqdm
from livelossplot import PlotLossesKeras
warnings.filterwarnings("ignore")

data_train=pd.read_csv("/kaggle/input/malyalam-news-dataset/train.csv")
data_val=pd.read_csv("/kaggle/input/malyalam-news-dataset/valid.csv")

data_train.describe()

data_train.nunique()

data_train=data_train.drop_duplicates()
data_train.reset_index(drop=True,inplace=True)
data_train

data_val.describe()

data_val=data_val.drop_duplicates()
data_val.reset_index(drop=True,inplace=True)
data_val

overall_df=pd.concat([data_train,data_val])

overall_df.reset_index(drop=True,inplace=True)

overall_df

list_df=list(overall_df["headings"])

list_df[:5]

remove_characters=['~',
 '\xa0',
 '\xad',
 '\u200b',
 '\u200c',
 '\u200d',
 '\u200e',
'\u2060',
 '\ueb9a',
 '\uf03d',
 '\uf06e',
 '\ufeff',
    "\n"]

new_list_df=[]
for sent in tqdm(list_df):
    for char in remove_characters:
        if char in sent:
            sent=sent.replace(char,"")
    new_list_df.append(sent)
    

new_list_df[:5]

tokenizer=Tokenizer(
    num_words=20000,
    filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',
    split=' ',)

tokenizer.fit_on_texts(new_list_df)

len(tokenizer.word_index)

tokenizer.word_index[list(tokenizer.word_index.keys())[-1]]

train_sequences = tokenizer.texts_to_sequences(data_train["headings"])
train_labels=list(data_train["label"])

val_sequences = tokenizer.texts_to_sequences(data_val["headings"])
val_labels=list(data_val["label"])

train_sequences    =   pad_sequences(train_sequences,  maxlen=64, padding='post') 
val_sequences   =   pad_sequences(val_sequences, maxlen=64, padding='post')

train_sequences

np.unique(train_sequences,return_counts=True)

train_sequences=np.array(train_sequences)
val_sequences=np.array(val_sequences)

le = LabelEncoder()

train_labels=np.array(le.fit_transform(train_labels))
val_labels=np.array(le.transform(val_labels))

np.shape(train_sequences)

def build_model():
    latent_dim = 500 


    # Encoder 
    encoder_inputs = Input(shape=(64,)) 
    enc_emb = Embedding(16000,latent_dim,trainable=True)(encoder_inputs)

    #LSTM 1 
    enc_tr=tfm.nlp.layers.TransformerEncoderBlock(num_attention_heads=500,inner_dim=250,inner_activation="relu")(enc_emb)
    #dec_tr=tfm.nlp.layers.TransformerDecoderBlock(num_attention_heads=500,intermediate_size=350,intermediate_activation="relu")(enc_emb)

    #Dense layer
    encoder_lstm1 = LSTM(latent_dim,return_sequences=False)(enc_tr)
    
    decoder_dense = Dense(3,activation = "softmax")(encoder_lstm1)

    # Define the model
    model = Model(inputs=encoder_inputs,outputs=decoder_dense) 
    
    return model

# def build_model():
#     latent_dim = 500 


#     # Encoder 
#     encoder_inputs = Input(shape=(64,)) 
#     enc_emb = Embedding(16000,latent_dim,trainable=True)(encoder_inputs)

#     #LSTM 1 
#     encoder_lstm1 = LSTM(latent_dim,return_sequences=True)(enc_emb)
    
#     encoder_lstm1 = LSTM(latent_dim,return_sequences=True)(encoder_lstm1)
    
#     encoder_lstm1 = LSTM(latent_dim//2,return_sequences=False)(encoder_lstm1)


#     #Dense layer
#     decoder_dense = Dense(3,activation = "softmax")(encoder_lstm1)

#     # Define the model
#     model = Model(inputs=encoder_inputs,outputs=decoder_dense) 
    
#     return model

model=build_model()
model.summary()

model.compile(optimizer='adam',loss="sparse_categorical_crossentropy",metrics=["accuracy"])

clr=tf.keras.callbacks.ReduceLROnPlateau(
    monitor="val_loss",
    factor=0.01,
    patience=5,
    mode="auto",
    min_delta=0.01,
    cooldown=0,
    min_lr=0.0,
)

model.fit(x=train_sequences,y=train_labels,validation_data=(val_sequences,val_labels),
         epochs=100,callbacks=[PlotLossesKeras(),clr])

new_list_df[-1]

model.save("feb26_best_model.hdf5")
-------------------------------------
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import torch

from sklearn.utils.class_weight import compute_class_weight
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler
from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.metrics import accuracy_score, precision_recall_fscore_support



import os

# Define a directory to save the model checkpoints
checkpoint_dir = './model_checkpoints'
if not os.path.exists(checkpoint_dir):
    os.makedirs(checkpoint_dir)

# Read movie data
path='/kaggle/input/rotten-tomatoes-movies-rating/datasets/rotten_tomatoes_movies.csv'
df_movie = pd.read_csv(path)
df_movie.head()

df_movie.columns

df_movie=df_movie.drop('rotten_tomatoes_link',axis=1)

# Check data distribution
df_movie.describe()

df_movie.dtypes

print(f'Content Rating category: {df_movie.content_rating.unique()}')

# Visualize the distribution of each category in content_rating feature
ax = df_movie.content_rating.value_counts().plot(kind='bar', figsize=(12,9))
ax.bar_label(ax.containers[0])

#One Hot Encoding Content Rating Category
content_rating = pd.get_dummies(df_movie.content_rating)
content_rating.head()

df_movie

print(f'Audience status category: {df_movie.audience_status.unique()}')

# Visualize the distribution of each category
ax = df_movie.audience_status.value_counts().plot(kind='bar', figsize=(12,9))
ax.bar_label(ax.containers[0])

# Assisgning 0 to Spilled and 1 to Upright
audience_status = pd.DataFrame(df_movie.audience_status.replace(['Spilled','Upright'],[0,1]))
audience_status.head()

# Encode tomatometer status feature with ordinal encoding
tomatometer_status = pd.DataFrame(df_movie.tomatometer_status.replace(['Rotten','Fresh','Certified-Fresh'],[0,1,2]))
tomatometer_status

df_movie.columns

# Combine all of the features together into one dataframe
df_feature = pd.concat([df_movie[['runtime', 'tomatometer_rating', 'tomatometer_count', 'audience_rating', 'audience_count', 'tomatometer_top_critics_count', 'tomatometer_fresh_critics_count', 'tomatometer_rotten_critics_count']]
                        , content_rating, audience_status, tomatometer_status], axis=1).dropna()
df_feature.head()

# Split the data into training and test data
X_train,X_test,y_train,y_test=train_test_split(df_feature.drop(['tomatometer_status'],axis=1),df_feature['tomatometer_status'],test_size=0.2,random_state=42,shuffle=True)
print(f'Training data size:{len(X_train)}, Testing data size:{len(X_test)}')

labels=df_feature['tomatometer_status'].unique()
labels

tree=DecisionTreeClassifier(random_state=42)
tree.fit(X_train,y_train)
# Predict the test data with trained tree classifier
y_predict_tree = tree.predict(X_test)

# Visualize decision logic of decision tree model
fig, ax = plt.subplots(figsize=(12, 9))
plot_tree(tree, ax= ax)
plt.show()

print(f'Accuracy of model: {accuracy_score(y_test, y_predict_tree)}')
print(classification_report(y_test, y_predict_tree))
cm = confusion_matrix(y_test,y_predict_tree)

#Plotting Confusion Matrix
ConfusionMatrixDisplay(cm).plot()

rf = RandomForestClassifier(random_state=42)

# Train Random Forest Classifier on training data
rf.fit(X_train, y_train)

# Predict test data with trained model
y_predict_rf = rf.predict(X_test)

print(f'Accuracy of model: {accuracy_score(y_test, y_predict_rf)}')
print(classification_report(y_test, y_predict_rf))
cm = confusion_matrix(y_test,y_predict_rf)

#Plotting Confusion Matrix
ConfusionMatrixDisplay(cm).plot()

# Get the feature importance
feature_importance = rf.feature_importances_

# Print feature importance
for i, feature in enumerate(X_train.columns):
    print(f'{feature} = {feature_importance[i]}')

# Visualize feature from the most important to the least important
indices = np.argsort(feature_importance)
plt.title('Feature Importances')
plt.barh(range(len(indices)), feature_importance[indices])
plt.yticks(range(len(indices)), [X_train.columns[i] for i in indices])
plt.xlabel('Relative Importance')
plt.show()

df_feature.columns

# Split data into train and test after feature selection
X_train, X_test, y_train, y_test = train_test_split(df_feature.drop(['tomatometer_status', 'NR', 'runtime', 'PG-13', 'R', 'PG','G', 'NC17'], axis=1),df_feature.tomatometer_status, test_size= 0.2, random_state=42)
print(f'Size of training data is {len(X_train)} and the size of test data is {len(X_test)}')

# Initialize Random Forest class
rf = RandomForestClassifier(random_state=42)

# Train Random Forest on the training data after feature selection
rf.fit(X_train, y_train)

# Predict the traind model on the test data after feature selection
y_predict_rf_fsel = rf.predict(X_test)

# Print the accuracy score and the classification report
print(accuracy_score(y_test, y_predict_rf_fsel))
print(classification_report(y_test, y_predict_rf_fsel))

# Plot the confusion matrix
cm = confusion_matrix(y_test,y_predict_rf_fsel)

#Plotting Confusion Matrix
ConfusionMatrixDisplay(cm).plot()

# Check class distribution of target variable once more
ax = df_feature.tomatometer_status.value_counts().plot(kind='bar', figsize=(12,9))
ax.bar_label(ax.containers[0])

# Compute class weight
class_weight = compute_class_weight(class_weight= 'balanced', classes= np.unique(df_feature.tomatometer_status),
                      y = df_feature.tomatometer_status.values)

class_weight_dict = dict(zip(range(len(class_weight.tolist())), class_weight.tolist()))
class_weight_dict

# Initialize Random Forest model with weight information
rf_weighted = RandomForestClassifier(random_state=42, class_weight=class_weight_dict)

# Train the model on the training data
rf_weighted.fit(X_train, y_train)

# Predict the test data with the trained model
y_predict = rf_weighted.predict(X_test)

#Print accuracy score and classification report
print(accuracy_score(y_test, y_predict))
print(classification_report(y_test, y_predict))

#Plot confusion matrix
# Plot the confusion matrix
cm = confusion_matrix(y_test,y_predict)

#Plotting Confusion Matrix
ConfusionMatrixDisplay(cm).plot()

# Read critics dataframe
path='/kaggle/input/rotten-tomatoes-movies-rating/datasets/rotten_tomatoes_critic_reviews_50k.csv'
df_critics = pd.read_csv(path)
df_critics.head()

df_critics=df_critics.drop('rotten_tomatoes_link',axis=1)
df_critics

df_critics.dropna(subset=['review_content'])
df_critics.dropna(subset=['review_score'])

X=df_critics['review_content'].astype(str)
y=df_critics['review_type'].astype(str)

X

df_critics.isna()

# Print the data type of each element in X
#print(X.dtypes)

# Check for non-string values
#non_string_values = X[~X.apply(lambda x: isinstance(x, str))]

# Print the non-string values
#print(non_string_values)

# Remove non-string values
#X = X[X.apply(lambda x: isinstance(x, str))]

# Alternatively, convert non-string values to strings
#X = X.astype(str)

'''
# List all available devices to confirm GPU is detected
print("Available devices:")
print(tf.config.list_physical_devices())

# To specifically use a GPU
if tf.test.gpu_device_name():
    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))'''

'''
# Tokenize text
tokenizer = Tokenizer(num_words=10000, oov_token="<OOV>")
tokenizer.fit_on_texts(X)
X_sequences = tokenizer.texts_to_sequences(X)'''

'''
# Pad sequences to ensure uniform input size
X_padded = pad_sequences(X_sequences, maxlen=200)

# Encode the labels
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)
y_categorical = tf.keras.utils.to_categorical(y_encoded)

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X_padded, y_categorical, test_size=0.2, random_state=42)'''

'''
with tf.device('/gpu:0'):
  # Determine the number of output classes
  num_classes = y_categorical.shape[1]
  # Define a simple LSTM model
  model = Sequential([
    Embedding(input_dim=10000, output_dim=16, input_length=200),
    LSTM(64, return_sequences=True),
    Dropout(0.2),
    LSTM(32),
    Dense(num_classes, activation='sigmoid')  # Use 'sigmoid' for binary classification
  ])
'''

'''
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
'''

'''# Print model summary
model.summary()

# Train the model
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7, verbose=1)

history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=5,
    batch_size=16,
    callbacks=[early_stopping, reduce_lr]
)'''

'''# Evaluate the model on the test set
loss, accuracy = model.evaluate(X_test, y_test, verbose=2)
print(f"Test Accuracy: {accuracy*100:.2f}%")'''

'''# Example text to predict sentiment
new_reviews = ["This movie is fantastic! I loved it.", "Not great, but not terrible. It was okay.", "I hate it"]

# Preprocess the new reviews
new_reviews_sequences = tokenizer.texts_to_sequences(new_reviews)
new_reviews_padded = pad_sequences(new_reviews_sequences, maxlen=200, padding='post')

# Predict
predictions = model.predict(new_reviews_padded)

# For binary classification, the output is a probability
if predictions.shape[1] == 1:
    predicted_classes = (predictions > 0.8).astype(int)
else:
    # For multi-class classification, find the class with the highest probability
    predicted_classes = np.argmax(predictions, axis=1)

# If you used LabelEncoder, you can get the class labels back
predicted_labels = label_encoder.inverse_transform(predicted_classes)

for review, label in zip(new_reviews, predicted_labels):
    print(f"Review: {review}\nPredicted sentiment: {label}\n")
'''

df_critics['label'] = df_critics['review_type'].map({'Fresh': 1, 'Rotten': 0})  # Convert 'review_type' into numerical labels


# Initialize BERT tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Tokenize and encode sequences in the dataset
def encode_reviews(reviews, max_length=128):
    input_ids = []
    attention_masks = []
    for review in reviews:
        encoded = tokenizer.encode_plus(
            text=review,
            add_special_tokens=True,
            max_length=max_length,
            pad_to_max_length=True,
            return_attention_mask=True,
            return_tensors='pt',
        )
        input_ids.append(encoded['input_ids'])
        attention_masks.append(encoded['attention_mask'])
    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)

input_ids, attention_masks = encode_reviews(df_critics['review_content'])
labels = torch.tensor(df_critics['label'].values)

# Split the dataset into training and validation sets
train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=42, test_size=0.1)
train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=42, test_size=0.1)

# Create the DataLoader
batch_size = 32

train_data = TensorDataset(train_inputs, train_masks, train_labels)
train_sampler = RandomSampler(train_data)
train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)

validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)
validation_sampler = SequentialSampler(validation_data)
validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)
# Function to save a model checkpoint
def save_checkpoint(model, optimizer, scheduler, epoch, file_path):
    checkpoint = {
        'epoch': epoch + 1,  # Saving the next epoch number to resume training correctly
        'state_dict': model.state_dict(),
        'optimizer': optimizer.state_dict(),
        'scheduler': scheduler.state_dict(),
    }
    torch.save(checkpoint, file_path)


# Load BERT model for sequence classification
model = BertForSequenceClassification.from_pretrained(
    'bert-base-uncased',
    num_labels=2,
    output_attentions=False,
    output_hidden_states=False,
)

# Set up optimizer and schedule
optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)
epochs = 4
total_steps = len(train_dataloader) * epochs
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)

# Define accuracy metric
def flat_accuracy(preds, labels):
    pred_flat = np.argmax(preds, axis=1).flatten()
    labels_flat = labels.flatten()
    return np.sum(pred_flat == labels_flat) / len(labels_flat)

# Training loop
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

for epoch_i in range(0, epochs):
    # Training
    model.train()
    total_loss = 0
    for step, batch in enumerate(train_dataloader):
        b_input_ids, b_input_mask, b_labels = batch
        b_input_ids = b_input_ids.to(device)
        b_input_mask = b_input_mask.to(device)
        b_labels = b_labels.to(device)
        model.zero_grad()
        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)
        loss = outputs[0]
        total_loss += loss.item()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()
        scheduler.step()
    avg_train_loss = total_loss / len(train_dataloader)
    print(f"Average training loss: {avg_train_loss}")

    # Validation
    model.eval()
    eval_accuracy = 0
    eval_steps = 0
    for batch in validation_dataloader:
        b_input_ids, b_input_mask, b_labels = batch
        b_input_ids = b_input_ids.to(device)
        b_input_mask = b_input_mask.to(device)
        b_labels = b_labels.to(device)
        with torch.no_grad():
            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)
        logits = outputs[0]
        logits = logits.detach().cpu().numpy()
        label_ids = b_labels.to('cpu').numpy()
        tmp_eval_accuracy = flat_accuracy(logits, label_ids)
        eval_accuracy += tmp_eval_accuracy
        eval_steps += 1
    print(f"Validation Accuracy: {eval_accuracy/eval_steps}")
    
    #Save checkpoint
    checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pth')
    save_checkpoint(model, optimizer, scheduler, epoch, checkpoint_path)


#To Load checkpoint
def load_checkpoint(file_path, model, optimizer, scheduler):
    checkpoint = torch.load(file_path)
    model.load_state_dict(checkpoint['state_dict'])
    optimizer.load_state_dict(checkpoint['optimizer'])
    scheduler.load_state_dict(checkpoint['scheduler'])
    return checkpoint['epoch']

# Example of loading a checkpoint
epoch = load_checkpoint(checkpoint_path, model, optimizer, scheduler)

def predict_sentiment(model, reviews):
    """
    Predicts the sentiment of one or more reviews using the fine-tuned BERT model.

    Parameters:
    model (BertForSequenceClassification): The fine-tuned BERT model.
    reviews (list of str): A list containing the review(s) to be classified.

    Returns:
    list of str: A list containing the sentiment predictions ('Fresh' or 'Rotten') for each review.
    """
    model.eval()  # Put the model in evaluation mode

    predictions = []

    for review in reviews:
        # Tokenize and encode the review like we did before
        encoded_review = tokenizer.encode_plus(
            review,
            max_length=128,
            add_special_tokens=True,
            return_attention_mask=True,
            pad_to_max_length=True,
            return_tensors='pt',
        )

        input_ids = encoded_review['input_ids'].to(device)
        attention_mask = encoded_review['attention_mask'].to(device)

        # Predict
        with torch.no_grad():
            outputs = model(input_ids, token_type_ids=None, attention_mask=attention_mask)

        logits = outputs[0]
        # Move logits and labels to CPU
        logits = logits.detach().cpu().numpy()

        # Determine the class with the highest probability
        prediction = np.argmax(logits, axis=1).flatten()

        # Convert prediction to 'Fresh' or 'Rotten'
        predictions.append('Fresh' if prediction == 1 else 'Rotten')

    return predictions

# Example usage
reviews = [
    "This movie was excellent! The performances were oscar-worthy.",
    "Movie seems pretty long to me",
]

predictions = predict_sentiment(model, reviews)
for review, prediction in zip(reviews, predictions):
    print(f"Review: {review}\nPredicted Sentiment: {prediction}\n")

-------------------------------------
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

from IPython.display import clear_output
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers # 神經網路層
from tensorflow.keras.layers import Add
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score
from tensorflow import keras
from IPython.display import SVG,Image
import matplotlib.pyplot as plt
import re

df = pd.read_csv('/kaggle/input/sql-test-csv/newbigdataset.csv')

def data2char_index(X, max_len, is_remove_comment = False):
    alphabet = " abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\"/\\|_@#$%^&*~`+-=<>()[]{}"
    result = [] 
    for data in X:
        data = str(data)
        mat = []
        if is_remove_comment == True : 
          data = remove_comment(data) #移除註解(實驗性)
        for ch in data:
            ch = ch.lower()
            if ch not in alphabet:
                continue
            mat.append(alphabet.index(ch))
        result.append(mat)
    X_char = tf.keras.preprocessing.sequence.pad_sequences(np.array(result, dtype=object), padding='post',truncating='post', maxlen=max_len)
    return X_char

def data_to_symbol_tag(X, max_len ,is_remove_comment = False):
    symbol = " -,;.!?:'\"/\\|_@#$%^&*~`+-=<>()[]{}"
    result = [] 
    for data in X:
        data = str(data)
        mat = []
        if is_remove_comment == True : 
          data = remove_comment(data) #移除註解(實驗性)
        for ch in data:
            ch = ch.lower()
            if ch not in symbol:
                mat.append(0)
            else :
                mat.append(symbol.index(ch))
        result.append(mat)
    X_char = tf.keras.preprocessing.sequence.pad_sequences(np.array(result, dtype=object), padding='post',truncating='post', maxlen=max_len)
    return X_char

df = df.sample(frac=1)
df

SQLInjectio_string = df['Query'].values
SQLInjection_label_1 = df['Label'].values
SQLInjection_label_2 = 1 - SQLInjection_label_1
y_train = np.array([SQLInjection_label_1, SQLInjection_label_2]).T

trainX_text = data2char_index(SQLInjectio_string,max_len=1000)
trainX_symbol = data_to_symbol_tag(SQLInjectio_string,max_len=1000)

def model_struct(max_len):

  pool_siz = 10
  num_heads = 3
  embed_dim = 100

  # 文字輸入層
  input_text = tf.keras.layers.Input(shape=(max_len,))
  # 嵌入層
  embed1 = tf.keras.layers.Embedding(input_dim=70,  output_dim=105, input_length=max_len, trainable=False)(input_text)
  cnn1 = tf.keras.layers.Conv1D(32, 3, padding='same', strides=1, activation='relu')(embed1)
  cnn1 = tf.keras.layers.MaxPooling1D(pool_size=pool_siz)(cnn1)
  # GRU
  GRU0 = layers.Bidirectional(tf.keras.layers.GRU(32, return_sequences=True, go_backwards=True))(cnn1)
  # 注意力機制  
  MHA0 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=1)(GRU0,GRU0)
  LayerNormalization0 = layers.LayerNormalization(epsilon=1e-6)(GRU0 + MHA0)
  x = tf.keras.Model(inputs=input_text, outputs=LayerNormalization0)

  
  # 符號輸入層
  input_symbol = tf.keras.layers.Input(shape=(max_len,))
  embed2 = tf.keras.layers.Embedding(input_dim=34,  output_dim=51, input_length=max_len, trainable=False)(input_symbol)
  cnn1s = tf.keras.layers.Conv1D(32, 3, padding='same', strides=1, activation='relu')(embed2)
  cnn1s = tf.keras.layers.MaxPooling1D(pool_size=pool_siz)(cnn1s)
  # GRU
  GRU0s = layers.Bidirectional(tf.keras.layers.GRU(32, return_sequences=True, go_backwards=True))(cnn1s)
  # 注意力機制
  MHA0s = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=1)(GRU0s,GRU0s)
  LayerNormalization0s = layers.LayerNormalization(epsilon=1e-6)(GRU0s + MHA0s)
  y = tf.keras.Model(inputs=input_symbol, outputs=LayerNormalization0s)
  
  # 將上方兩分支結合
  combined = tf.keras.layers.concatenate([x.output, y.output])
        
  flat = tf.keras.layers.Flatten()(combined)
  dnn1 = tf.keras.layers.Dense(2, activation="softmax")(flat)

  # 輸出模型
  model = tf.keras.Model(inputs=[x.input, y.input], outputs=dnn1)
  return model

model = model_struct(max_len=1000)
model.compile("adam", "categorical_crossentropy", metrics=["accuracy"])
model.summary()

history_log= model.fit([trainX_text,trainX_symbol], y_train, batch_size=64, epochs=10)

df = pd.read_csv('/kaggle/input/sql-test-csv/Modified_SQL_Dataset.csv',encoding='gbk')
test_text = df['Query'].values
test_label = df['Label'].values


y_test_1 = np.array(test_label)
y_test_2 = 1 - y_test_1
y_test = np.array([y_test_1, y_test_2]).T

testX_text = data2char_index(test_text,max_len=1000)
testX_symbol = data_to_symbol_tag(test_text,max_len=1000)

pred = model.predict([testX_text,testX_symbol])
y_pred = np.int64(pred>0.5)
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred,average='micro')
recall = recall_score(y_test, y_pred,average='micro')
print(" Accuracy : {0} \n Precision : {1} \n Recall : {2}".format(accuracy, precision, recall))
-------------------------------------
from wordcloud import WordCloud
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.layers import Dense, LSTM, Embedding, Input, TimeDistributed, Concatenate
from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint
from tensorflow.keras.models import Model, load_model, Sequential
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import warnings, re
warnings.filterwarnings('ignore')
import tensorflow as tf
from tqdm.notebook import tqdm
tqdm.pandas()
from tensorflow.keras import backend as K
logger = tf.get_logger()
from tensorflow.keras.utils import plot_model
from sklearn.model_selection import train_test_split
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction

df = pd.read_csv('/kaggle/input/global-news-dataset/data.csv',nrows=80000)
df = df[['description','title']]
df.head()

df.shape

df.info()

df.isna().sum()

df = df.dropna()
df.shape

df.duplicated().sum()

df = df.drop_duplicates()
df.shape

df.rename({'description': 'text','title': 'summary'},axis=1,inplace=True)

wc = WordCloud(width=600,height=300).generate(' '.join(df.text))
plt.imshow(wc);

wc = WordCloud(width=600,height=300).generate(' '.join(df.summary))
plt.imshow(wc);

df.summary = df.summary.apply(lambda x: '<start> ' + x + ' <end>')

df['text_len'] = df['text'].apply(len)
df['summary_len'] = df['summary'].apply(len)

fig, axes = plt.subplots(nrows=1,ncols=2,figsize=(14,4))
sns.distplot(df['text_len'],ax=axes[0])
sns.distplot(df['summary_len'],ax=axes[1])

df.describe()

max_text_len = 190
max_summary_len = 80

for i in np.arange(0.9,1.0,0.01):
    print(f"{i} percentile value of text length is ",df['text_len'].quantile(i))
    print(f"{i} percentile value of summary length is ",df['summary_len'].quantile(i))

x_tokenizer = Tokenizer()
x_tokenizer.fit_on_texts(df.text)

text_vocab_length = len(x_tokenizer.index_word) + 1
text_vocab_length

text_sequences = x_tokenizer.texts_to_sequences(df.text)
text_pad_sequences = pad_sequences(text_sequences,maxlen=max_text_len,padding='post')

y_tokenizer = Tokenizer()
y_tokenizer.fit_on_texts(df.summary)

summary_vocab_length = len(y_tokenizer.index_word) + 1
summary_vocab_length

summary_sequences = y_tokenizer.texts_to_sequences(df.summary)
summary_pad_sequences = pad_sequences(summary_sequences,maxlen=max_summary_len,padding='post')

X_train, X_test, y_train, y_test = train_test_split(text_pad_sequences,summary_pad_sequences,test_size=0.25,shuffle=True,random_state=101)

class LuongAttention(tf.keras.layers.Layer):
  def _init_(self, units):
    super(LuongAttention, self)._init_()
    self.W1 = tf.keras.layers.Dense(units)
    self.W2 = tf.keras.layers.Dense(units)
    self.V = tf.keras.layers.Dense(1)

  def call(self, query, values):
    print('\n*** Luong Attention  STARTS****')
    print('query (decoder hidden state): (batch_size, hidden size) ', query.shape)
    print('values (encoder all hidden state): (batch_size, max_len, hidden size) ', values.shape)

    # query hidden state shape == (batch_size, hidden size)
    # query_with_time_axis shape == (batch_size, 1, hidden size)
    # values shape == (batch_size, max_len, hidden size)
    # we are doing this to broadcast addition along the time axis to calculate the score
    query_with_time_axis = tf.expand_dims(query, 1)
    
    print('query_with_time_axis:(batch_size, 1, hidden size) ', query_with_time_axis.shape)


    values_transposed = tf.transpose(values, perm=[0, 2, 1])
    print('values_transposed:(batch_size, hidden size, max_len) ', values_transposed.shape)

    # score shape == (batch_size, max_length, 1)
    # we get 1 at the last axis because we are applying score to self.V
    # the shape of the tensor before applying self.V is (batch_size, max_length, units)
    #BAHDANAU ADDITIVE:
    #score = self.V(tf.nn.tanh(
    #    self.W1(query_with_time_axis) + self.W2(values)))
    
    #LUONGH Dot-product
    score = tf.transpose(tf.matmul(query_with_time_axis, values_transposed) , perm=[0, 2, 1])

    print('score: (batch_size, max_length, 1) ',score.shape)
    # attention_weights shape == (batch_size, max_length, 1)
    attention_weights = tf.nn.softmax(score, axis=1)
    print('attention_weights: (batch_size, max_length, 1) ',attention_weights.shape)
    # context_vector shape after sum == (batch_size, hidden_size)
    context_vector = attention_weights * values
    print('context_vector before reduce_sum: (batch_size, max_length, hidden_size) ',context_vector.shape)
    context_vector = tf.reduce_sum(context_vector, axis=1)
    print('context_vector after reduce_sum: (batch_size, hidden_size) ',context_vector.shape)


    print('\n*** Luong Attention ENDS****')
    return context_vector, attention_weights

K.clear_session()

latent_dim = 300
embedding_dim = 200

# Encoder
encoder_inputs = Input(shape=(max_text_len,))

# Encoder Embedding Layer
enc_emb =  Embedding(text_vocab_length, embedding_dim,trainable=True)(encoder_inputs)

# Encoder LSTM 1
encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True, dropout=0.4, recurrent_dropout=0.4)
encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)

# Encoder LSTM 2
encoder_lstm2 = LSTM(latent_dim,return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)
encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)

# Encoder LSTM 3
encoder_lstm3 = LSTM(latent_dim, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)
encoder_outputs, state_h, state_c = encoder_lstm3(encoder_output2)

# Set up the decoder, using `encoder_states` as initial state.
decoder_inputs = Input(shape=(max_summary_len,))

# Decoder Embedding Layer
dec_emb_layer = Embedding(summary_vocab_length, embedding_dim, trainable=True)
dec_emb = dec_emb_layer(decoder_inputs)

# Decoder LSTM Layer
decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)
decoder_outputs, decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])

# Dense Layer
decoder_dense = TimeDistributed(Dense(summary_vocab_length, activation='softmax'))
decoder_outputs = decoder_dense(decoder_outputs)

# Define the model 
model = Model([encoder_inputs, decoder_inputs], decoder_outputs)
model.summary()

model.compile(loss='sparse_categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate=0.1,weight_decay=0.01,clipnorm=1.0),metrics=['accuracy'])

def time_based_decay(epoch, lr):
    decay_rate = 0.1
    decay_steps = 5
    return lr * (1 / (1 + decay_rate * epoch / decay_steps))

es = EarlyStopping(monitor='val_accuracy',mode='max',verbose=1,patience=40)
mc = ModelCheckpoint('text_summarizer.keras',monitor='val_accuracy',verbose=1,mode='max',save_best_only=True)
lrs = LearningRateScheduler(time_based_decay,verbose=2)

r = model.fit([X_train,y_train],
             y_train.reshape(y_train.shape[0],y_train.shape[1],1),
             epochs=100,
             batch_size=128,
             callbacks=[es,lrs,mc],
             validation_data = ([X_test,y_test],y_test.reshape(y_test.shape[0],y_test.shape[1],1)))

plt.plot(r.history['loss'],'r',label='train loss')
plt.plot(r.history['val_loss'],'b',label='test loss')
plt.xlabel('No. of Epochs')
plt.ylabel('Loss')
plt.title('Loss Graph')
plt.legend();

plt.plot(r.history['accuracy'],'r',label='train accuracy')
plt.plot(r.history['val_accuracy'],'b',label='test accuracy')
plt.xlabel('No. of Epochs')
plt.ylabel('Accuracy')
plt.title('Accuracy Graph')
plt.legend();

loss, acc = model.evaluate([X_test,y_test],y_test.reshape(y_test.shape[0],y_test.shape[1],1))
print(f"Loss: {np.round(loss*100,2)}%")
print(f"Accuracy: {np.round(acc*100,2)}%")

reverse_target_word_index=y_tokenizer.index_word
reverse_source_word_index=x_tokenizer.index_word
target_word_index=y_tokenizer.word_index

# Encode the input sequence to get the feature vector
encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])

# Decoder setup
# Below tensors will hold the states of the previous time step
decoder_state_input_h = Input(shape=(latent_dim,))
decoder_state_input_c = Input(shape=(latent_dim,))
decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))

# Get the embeddings of the decoder sequence
dec_emb2= dec_emb_layer(decoder_inputs) 
# To predict the next word in the sequence, set the initial states to the states from the previous time step
decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])

# A dense softmax layer to generate prob dist. over the target vocabulary
decoder_outputs2 = decoder_dense(decoder_outputs2) 

# Final decoder model
decoder_model = Model(
    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],
    [decoder_outputs2] + [state_h2, state_c2])

def decode_sequence(input_seq):
    # Encode the input as state vectors.
    e_out, e_h, e_c = encoder_model.predict(input_seq)
    
    # Generate empty target sequence of length 1.
    target_seq = np.zeros((1,1))
    
    # Populate the first word of target sequence with the start word.
    target_seq[0, 0] = target_word_index['start']

    stop_condition = False
    decoded_sentence = ''
    while not stop_condition:
      
        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])

        # Sample a token
        sampled_token_index = np.argmax(output_tokens[0, -1, :])
        sampled_token = reverse_target_word_index[sampled_token_index]
        
        if(sampled_token!='end'):
            decoded_sentence += ' '+sampled_token

        # Exit condition: either hit max length or find stop word.
        if (sampled_token == 'end'  or len(decoded_sentence.split()) >= (max_summary_len-1)):
            stop_condition = True

        # Update the target sequence (of length 1).
        target_seq = np.zeros((1,1))
        target_seq[0, 0] = sampled_token_index

        # Update internal states
        e_h, e_c = h, c

    return decoded_sentence

def seq2summary(input_seq):
    newString=''
    for i in input_seq:
        if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):
            newString=newString+reverse_target_word_index[i]+' '
    return newString

def seq2text(input_seq):
    newString=''
    for i in input_seq:
        if(i!=0):
            newString=newString+reverse_source_word_index[i]+' '
    return newString

for i in range(0,100):
    print("Review:",seq2text(X_train[i]))
    print("Original summary:",seq2summary(y_train[i]))
    print("Predicted summary:",decode_sequence(X_train[i].reshape(1,max_text_len)))
    print("\n")

encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])

decoder_initial_state_a = Input(shape=(latent_dim,))
decoder_initial_state_c = Input(shape=(latent_dim,))
decoder_hidden_state = Input(shape=(max_text_len, latent_dim))

decoder_out, decoder_state_a, decoder_state_c = decoder_lstm(decoder_emb, initial_state=[decoder_initial_state_a, decoder_initial_state_c])

decoder_final = decoder_dense(decoder_out)
decoder_model = Model([decoder_inputs]+[decoder_hidden_state, decoder_initial_state_a, decoder_initial_state_c], [decoder_final]+[decoder_state_a, decoder_state_c])

def decode_sequences(input_sequence):
    encoder_out, encoder_a, encoder_c = encoder_model.predict(input_sequence)
    next_input = np.zeros((1,1))
    next_input[0,0] = y_tokenizer.word_index['start']
    output_sequence = ''
    stop = False
    while not stop:
        decoded_out, trans_state_a, trans_state_c = decoder_model.predict([next_input] + [encoder_out, encoder_a, encoder_c])
        output_idx = np.argmax(decoded_out[0, -1, :])
        if output_idx == y_tokenizer.word_index['end']: 
            stop = True
        elif output_idx > 0 and output_idx != y_tokenizer.word_index['start']:
            output_token = y_tokenizer.index_word[output_idx] 
            output_sequence = output_sequence + ' ' + output_token 
        next_input[0,0] = output_idx
        # Continously update the transient state vectors in decoder.
        encoder_a, encoder_c = trans_state_a, trans_state_c
        
    return output_sequence  

def sequence_to_text(input_sequence,mode):
    res = ''
    
    if mode == 'input':
        for idx in input_sequence:
            if idx:
                res = res + x_tokenizer.index_word[idx] + ' '
    
    elif mode == 'output':
        for idx in input_sequence:
            if idx:
                if y_tokenizer.index_word[idx] != 'start' and y_tokenizer.index_word[idx] != 'end':
                    res = res + y_tokenizer.index_word[idx] + ' '
    
    return res

predicted_summaries = []

for i in range(20):
    print("News Article:",sequence_to_text(X_test[i],'input'))
    print("Original Article Summary:",sequence_to_text(y_test[i],'output'))
    pred_summary = decode_sequences(X_test[i].reshape(1,max_text_len))
    print("Predicted Article Summary:",pred_summary)
    predicted_summaries.append(pred_summary)
    print()
    print('---------------------------')
    print()
-------------------------------------
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Dense
from sklearn.model_selection import train_test_split
import subprocess

from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments
import torch

# Download and unzip wordnet
try:
    nltk.data.find('wordnet.zip')
    nltk.download('stopwords.zip')
    nltk.download('punkt.zip')
except:
    nltk.download('wordnet', download_dir='/kaggle/working/')
    nltk.download('stopwords', download_dir='/kaggle/working/')
    nltk.download('punkt', download_dir='/kaggle/working/')
    command = "unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora"
    subprocess.run(command.split())
    nltk.data.path.append('/kaggle/working/')

import pandas as pd
from sklearn.model_selection import train_test_split
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import re

# Load the dataset
data = pd.read_csv('/kaggle/input/arabic-text-summarization-30-000/wikiHow.csv')

# Preprocessing
data['text'] = data['text'].astype(str)
data['summary'] = data['summary'].astype(str)

# Split the data into training and testing sets
train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)

#############################preprocessing#####################
stop_words = set(stopwords.words('arabic'))
lemmatizer = WordNetLemmatizer()
url_pattern = re.compile(r'https?://\S+')


def preprocess_text(text):
    # Replace Arabic letter "أ" with "ا"
    text = text.replace('أ', 'ا')

    # Remove punctuation marks
    text = re.sub(r'[،.():/%-]+', '', text)

    # Remove links
    text = url_pattern.sub('', text)
    #text = BeautifulSoup(text, "html.parser").get_text() #(not working)

    # Tokenization
    tokens = word_tokenize(text)

    # Remove numerical tokens
    filtered_tokens = [token for token in tokens if not token.isdigit()]

    # Lemmatization
    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]

    # Remove stopwords
    filtered_tokens = [token for token in lemmatized_tokens if token.lower() not in stop_words]

    # Convert tokens back to text
    preprocessed_text = ' '.join(filtered_tokens)

    return preprocessed_text

# Apply preprocessing to the training data
train_data['preprocessed_train_text'] = train_data['text'].apply(preprocess_text)
train_data['preprocessed_train_summary'] = train_data['summary'].apply(preprocess_text)

# Check the format of the preprocessed text
print("First example of preprocessed text:")
print(train_data['preprocessed_train_text'].iloc[0])

# Check the format of the preprocessed summary
print("First example of preprocessed summary:")
print(train_data['preprocessed_train_summary'].iloc[0])

print("done")



test_data['preprocessed_test_text'] = test_data['text'].apply(preprocess_text)
test_data['preprocessed_test_summary'] = test_data['summary'].apply(preprocess_text)

print("done")# Save preprocessed data to CSV
train_data.to_csv('./preprocessed_train_data.csv', columns=['preprocessed_train_text', 'preprocessed_train_summary'], index=False)
test_data.to_csv('./preprocessed_test_data.csv', columns=['preprocessed_test_text', 'preprocessed_test_summary'], index=False)
print("done")



from transformers import GPT2Tokenizer
import torch
import pandas as pd



# Extract the text data from your dataset
text_data = data['text'].tolist()

# Initialize the GPT-2 tokenizer
tokenizer = GPT2Tokenizer.from_pretrained('/kaggle/input/local-model')
tokenizer.add_special_tokens({'pad_token': '[PAD]'})

# Tokenize the text data
tokenized_data = tokenizer(text_data, padding=True, truncation=True, max_length=512, return_tensors='pt')
# Inspect the tokenized data
print(tokenized_data)

# # Now you can use tokenized_data as input to your GPT-2 model


# # Assuming train_texts and test_texts are lists of strings
# train_texts = ['This is an example.', 'Another example sentence.']
# test_texts = ['Test example 1.', 'Test example 2.']

# # Initialize the GPT2 tokenizer
# tokenizer = GPT2Tokenizer.from_pretrained('local_model')
# tokenizer.add_special_tokens({'pad_token': '[PAD]'})
# # Tokenize the data
# train_encodings = tokenizer(train_texts, padding=True, truncation=True, max_length=512, return_tensors='pt', return_token_type_ids=False)
# test_encodings = tokenizer(test_texts, padding=True, truncation=True, max_length=512, return_tensors='pt', return_token_type_ids=False)

# # Check the format of the tokenized encodings
# print(train_encodings)
# print(test_encodings)


import torch
from torch.utils.data import random_split
from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, TextDataset, \
    DataCollatorForLanguageModeling

# Load the preprocessed data from CSV files
train_data = pd.read_csv('preprocessed_train_data.csv')
test_data = pd.read_csv('preprocessed_test_data.csv')


# Step 1: Load the pre-trained GPT-2 model
model = GPT2LMHeadModel.from_pretrained('/kaggle/input/local-model')

# Step 2: Tokenize the training data
tokenizer = GPT2Tokenizer.from_pretrained('/kaggle/input/local-model')
tokenizer.add_special_tokens({'pad_token': '[PAD]'})

# Create the TextDataset for training
train_dataset = TextDataset(
    tokenizer=tokenizer,
    file_path='preprocessed_train_data.csv',  # Provide the path to your preprocessed training data CSV file
    block_size=128,
    overwrite_cache=False,  # Set this to False to avoid overwriting the cached tokenized data
)

# Split the training dataset into training and evaluation sets
train_size = int(0.9 * len(train_dataset))
eval_size = len(train_dataset) - train_size
eval_dataset, train_dataset = random_split(train_dataset, [eval_size, train_size])

# Initialize the DataCollatorForLanguageModeling
data_collator = DataCollatorForLanguageModeling(
    tokenizer=tokenizer,
    mlm=False
)

print(f"torch.backends.mps.is_available(): {torch.backends.mps.is_available()}")

# Step 4: Create a TrainingArguments object
training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=1,
    per_device_train_batch_size=2,
    per_device_eval_batch_size=2,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir='./logs',
    logging_steps=1000,
    save_steps=5000,
    evaluation_strategy='steps',
    eval_steps=5000,
    load_best_model_at_end=True,
    use_mps_device=torch.backends.mps.is_available(),
)

# Step 5: Instantiate a Trainer object
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    data_collator=data_collator,
)

# Step 6: Train the model
trainer.train()
trainer.save_model("/kaggle/working/gpt2_fine_tune")

from transformers import AutoTokenizer, AutoModelForCausalLM

from transformers import AutoTokenizer

# # Replace 'model_name_or_path' with the path to your fine-tuned AraGPT2 tokenizer
# tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/local-model')
# tokenizer.save_pretrained('/kaggle/working/gpt2_fine_tune')


# Load the fine-tuned AraGPT2 tokenizer and model
model_path = '/kaggle/input/local-model'
tokenizer = AutoTokenizer.from_pretrained(model_path)
tokenizer.add_special_tokens({'pad_token': '[PAD]'})
model = AutoModelForCausalLM.from_pretrained(model_path)

# Input Arabic Text
sequence = "قبل از به وجود آمدن دی سی، در خلا و فضایی عاری از هرگونه حیات که تنها پرایمال مانیتور بود، یهوه بوسیله قدرت های نامحدود دو برادر خلق کرد؛ یکی از آن ها میکائیل دمیورگوس، و دیگری سمائیل نام گرفت که بعدها با عنوان لوسیفر مورنینگ استار شناخته شد. پس از شکل گیری این دو تن، یهوه آن ها را هدایت نمود و به آن ها چگونگی استفاده از قدرت هایشان را آموخت، در نتیجه آن ها شکلی از خلقت را ایجاد کردند که هم اکنون به عنوان فرضیه چندجهانی دی سی شناخته می شود. میلیاردها سال پیش، لوسیفر فرشته مقرب دست به شورشی علیه پادشاهی بهشت زد و در نتیجه به فضایی عاری از ماده و فاقد هر گونه شکل تحت عنوان چائوپلازم تبعید شد. سپس چائوپلازم تبدیل بهک فضای متروک، ویران و گستره ای تهی با عنوان دوزخ شد، مقصد نهایی برای ارواح ملعون، جایی که مورنینگ استار فرمانروایی می کرد و در انتظار روزی بود تا بتواند دوباره آزاد شود. زمانی که تاریکی اعظم (شیطان وحشی بزرگ) بیدار شده و بازگشت، لوسیفر مجبور شد قدرت خود را با او سهیم شود و فرمانروایی خود را با بعل الذباب و عزازیل به اشتراک گذاشت. بدین سبب سه قدرت مثلثی شکل گرفتند، اما با این حال لوسیفر بخش کثیر قدرت را برای خود نگاه داشت. زمانی فرار رسید که دیریم یکی از اندلس برای جستجوی سکان خود که از او به سرقت رفته بود وارد دوزخ شد. دیریم پس از ورود به جهنم در یک نبرد ذهنی با یک دیو خبیث قدرتمند شرکت کرد و خواستار سکان دزدیده شده خود بود. دیریم پس از اینکه سکان خود را بازیافت لوسیفر را در مقابل تمام شیاطین دوزخ تحقیر کرد، و مورنینگ استار در آن روز سوگند به نابودی دیریم نمود"

inputs = tokenizer([sequence], padding="max_length", truncation=True, max_length=512, return_tensors="pt")
input_ids = inputs.input_ids
attention_mask = inputs.attention_mask

outputs = model.generate(input_ids, attention_mask=attention_mask)
generated = tokenizer.batch_decode(outputs, skip_special_tokens=True)
print(f'YOUR GENERATED TEXT: {generated}')

-------------------------------------
import numpy as np
import pandas as pd 
import re
from bs4 import BeautifulSoup
from keras.preprocessing.text import Tokenizer 
from keras.preprocessing.sequence import pad_sequences
from nltk.corpus import stopwords
from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Attention
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import warnings
pd.set_option("display.max_colwidth", 200)
warnings.filterwarnings("ignore")

import pandas as pd

# Try different encodings
encodings_to_try = ['utf-8', 'latin1', 'ISO-8859-1', 'utf-16']

for encoding in encodings_to_try:
    try:
        df1 = pd.read_csv('/kaggle/input/news-summary/news_summary.csv', encoding=encoding)
        df2 = pd.read_csv('/kaggle/input/news-summary/news_summary_more.csv', encoding=encoding)
        print(f"Successfully read CSV files using encoding: {encoding}")
        break  # Stop trying encodings if successful
    except UnicodeDecodeError:
        print(f"Failed to read CSV files using encoding: {encoding}")

df1.head(1)

df2.head(1)

print(df1.columns)
print(df2.columns)

import pandas as pd

# Combine 'text' columns from df1 and df2
syntext = pd.concat([df1['text'], df2['text']], ignore_index=True)

# Combine 'headlines' columns from df1 and df2
summary = pd.concat([df1['headlines'], df2['headlines']], ignore_index=True)

# Create a new DataFrame with 'syntext' and 'Summary' columns
data = pd.DataFrame({'text': syntext, 'summary': summary})



data.head(1)

print('Content: ', data['text'][1])
print('\n')
print('summary: ', data['summary'][1])

!pip install keras-self-attention

#Removes non-alphabetic characters:
def text_cleaner(column):
    for row in column:
        
        #ORDER OF REGEX IS VERY VERY IMPORTANT!!!!!!
        
        row=re.sub("(\\t)", ' ', str(row)).lower() #remove escape charecters
        row=re.sub("(\\r)", ' ', str(row)).lower() 
        row=re.sub("(\\n)", ' ', str(row)).lower()
        
        row=re.sub("(__+)", ' ', str(row)).lower()   #remove _ if it occors more than one time consecutively
        row=re.sub("(--+)", ' ', str(row)).lower()   #remove - if it occors more than one time consecutively
        row=re.sub("(~~+)", ' ', str(row)).lower()   #remove ~ if it occors more than one time consecutively
        row=re.sub("(\+\++)", ' ', str(row)).lower()   #remove + if it occors more than one time consecutively
        row=re.sub("(\.\.+)", ' ', str(row)).lower()   #remove . if it occors more than one time consecutively
        
        row=re.sub(r"[<>()|&©ø\[\]\'\",;?~*!]", ' ', str(row)).lower() #remove <>()|&©ø"',;?~*!
        
        row=re.sub("(mailto:)", ' ', str(row)).lower() #remove mailto:
        row=re.sub(r"(\\x9\d)", ' ', str(row)).lower() #remove \x9* in text
        row=re.sub("([iI][nN][cC]\d+)", 'INC_NUM', str(row)).lower() #replace INC nums to INC_NUM
        row=re.sub("([cC][mM]\d+)|([cC][hH][gG]\d+)", 'CM_NUM', str(row)).lower() #replace CM# and CHG# to CM_NUM
        
        
        row=re.sub("(\.\s+)", ' ', str(row)).lower() #remove full stop at end of words(not between)
        row=re.sub("(\-\s+)", ' ', str(row)).lower() #remove - at end of words(not between)
        row=re.sub("(\:\s+)", ' ', str(row)).lower() #remove : at end of words(not between)
        
        row=re.sub("(\s+.\s+)", ' ', str(row)).lower() #remove any single charecters hanging between 2 spaces
        
        #Replace any url as such https://abc.xyz.net/browse/sdf-5327 ====> abc.xyz.net
        try:
            url = re.search(r'((https*:\/*)([^\/\s]+))(.[^\s]+)', str(row))
            repl_url = url.group(3)
            row = re.sub(r'((https*:\/*)([^\/\s]+))(.[^\s]+)',repl_url, str(row))
        except:
            pass #there might be emails with no url in them
        

        
        row = re.sub("(\s+)",' ',str(row)).lower() #remove multiple spaces
        
        #Should always be last
        row=re.sub("(\s+.\s+)", ' ', str(row)).lower() #remove any single charecters hanging between 2 spaces

        
        
        yield row

clean_text = text_cleaner(data['text'])
clean_summary = text_cleaner(data['summary'])

from time import time 
import spacy
from tqdm.notebook import tqdm

nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])  # Load English model
t = time()
text = [str(doc) for doc in tqdm(nlp.pipe(clean_text, batch_size=5000, n_process=-1))]

print('Time to Clean up Data: {} Mins'.format(round((time() - t) / 60, 2)))


t = time()
summary = ['_START ' + str(doc) + ' _END_' for doc in tqdm(nlp.pipe(clean_summary, batch_size=5000, n_process=-1))]
print('Time to clean up summary data: {} Mins'.format(round((time() - t)/ 60, 2)))

data1 = pd.DataFrame({
    'clean_txt': cleaned_text,
    'clean_summary': cleaned_summaries
})

text[1]

summary[1]

data['text'] = pd.Series(text)
data['summary'] = pd.Series(summary)

text_count = []
summary_count = []

max_text_len = 100
max_summary_len = 15

cleaned_text = np.array(data['text'])
cleaned_summary = np.array(data['summary'])

short_text = []
short_summary = []

for i in tqdm(range(len(cleaned_text))):
    # Check if the element is not NaN (assuming NaNs are represented as float)
    if not isinstance(cleaned_summary[i], float) and not isinstance(cleaned_text[i], float):
        if(len(cleaned_summary[i].split()) <= max_summary_len and len(cleaned_text[i].split()) <= max_text_len):
            short_text.append(str(cleaned_text[i]))  # Convert to string before appending
            short_summary.append(str(cleaned_summary[i]))  # Convert to string before appending

post_data = pd.DataFrame({
    'text': short_text,
    'summary': short_summary
})

post_data.head(3)

post_data['summary'] = post_data['summary'].apply(lambda x : 'sostok ' + x + ' eostok')

post_data.head(1)

from sklearn.model_selection import train_test_split
xtrain, xtest, ytrain, ytest = train_test_split(np.array(post_data['text']), np.array(post_data['summary']), test_size=0.1, random_state=0, shuffle=True)

from keras.preprocessing.text import Tokenizer
from keras.preprocessing .sequence import pad_sequences

# prepare a tokenizer for review on training data
x_tokenizer = Tokenizer()
x_tokenizer.fit_on_texts(list(xtrain))

thresh=4

cnt=0
tot_cnt=0
freq=0
tot_freq=0

for key,value in x_tokenizer.word_counts.items():
    tot_cnt=tot_cnt+1
    tot_freq=tot_freq+value
    if(value<thresh):
        cnt=cnt+1
        freq=freq+value
    
print("% of rare words in vocabulary:",(cnt/tot_cnt)*100)
print("Total Coverage of rare words:",(freq/tot_freq)*100)

x_tokenizer = Tokenizer(num_words=tot_cnt-cnt)
x_tokenizer.fit_on_texts(list(xtrain))

# Convert text sequences to interger sequences
x_train_seq = x_tokenizer.texts_to_sequences(xtrain)
x_test_seq = x_tokenizer.texts_to_sequences(xtest)

# Padding zero upto maximum length
xtrain = pad_sequences(x_train_seq, maxlen = max_text_len, padding='post')
xtest = pad_sequences(x_test_seq, maxlen=max_text_len, padding='post')

# size of vocabulary
x_voc = x_tokenizer.num_words + 1
print('Size of vocabulary in x = {}'.format(x_voc))

y_tokenizer = Tokenizer()
y_tokenizer.fit_on_texts(list(ytrain))

thresh=4

cnt=0
tot_cnt=0
freq=0
tot_freq=0

for key,value in y_tokenizer.word_counts.items():
    tot_cnt=tot_cnt+1
    tot_freq=tot_freq+value
    if(value<thresh):
        cnt=cnt+1
        freq=freq+value
    
print("% of rare words in vocabulary:",(cnt/tot_cnt)*100)
print("Total Coverage of rare words:",(freq/tot_freq)*100)

y_tokenizer = Tokenizer(num_words=tot_cnt-cnt)
y_tokenizer.fit_on_texts(list(ytrain))

# converage text sequences into integer sequences
y_trian_seq = y_tokenizer.texts_to_sequences(ytrain)
y_test_seq = y_tokenizer.texts_to_sequences(ytest)

# padding zero upto maximum length
ytrain = pad_sequences(y_trian_seq, maxlen=max_summary_len, padding='post')
ytest = pad_sequences(y_test_seq, maxlen=max_summary_len, padding = 'post')

# size of vocabulary 
y_voc = y_tokenizer.num_words + 1
print('Size of Vocabulary in Y = {}'.format(y_voc))

ind=[]
for i in range(len(ytest)):
    cnt=0
    for j in ytest[i]:
        if j!=0:
            cnt=cnt+1
    if(cnt==2):
        ind.append(i)

ytrian=np.delete(ytest,ind, axis=0)
xtrian=np.delete(xtest,ind, axis=0)

xtrain.shape

from keras import backend as K 
import gensim
from numpy import *
import numpy as np
import pandas as pd 
import re
from bs4 import BeautifulSoup
from keras.preprocessing.text import Tokenizer 
from keras.preprocessing.sequence import pad_sequences
from nltk.corpus import stopwords
from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional
from tensorflow.keras.layers import AdditiveAttention
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping
import warnings
pd.set_option("display.max_colwidth", 200)
warnings.filterwarnings("ignore")

print("Size of vocabulary from the w2v model = {}".format(x_voc))


K.clear_session()
laten_dim = 300
embedding_dim = 200

encoder_inputs  = Input(shape=(max_text_len,))

# Embedding layer
enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)

# Encoder lstm 1
encoder_lstm1  = LSTM(laten_dim, return_sequences=True, return_state=True, dropout=0.2, recurrent_dropout=0.2)
encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)

# encoder lstm 2
encoder_lstm2 = LSTM(laten_dim, return_sequences=True, return_state=True, dropout=0.2, recurrent_dropout=0.2)
encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)

# Encoder lstem 3
encoder_lstm3 = LSTM(laten_dim, return_sequences=True, return_state=True, dropout=0.2, recurrent_dropout=0.2)
encoder_outputs, state_h, state_c = encoder_lstm3(encoder_output2)


decoder_inputs = Input(shape=(None,))

# Embedding layer
dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)
dec_emb = dec_emb_layer(decoder_inputs)

# Decoder LSTM
decoder_lstm = LSTM(laten_dim, return_sequences=True, return_state=True, dropout=0.2, recurrent_dropout=0.2)
decoder_outputs, decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb, initial_state=[state_h, state_c])

# dense layer
decoder_dense = TimeDistributed(Dense(y_voc,activation='softmax'))
decoder_outputs = decoder_dense(decoder_outputs)

# Define the model
model = Model([encoder_inputs, decoder_inputs], decoder_outputs)

model.summary()

from keras.utils import plot_model
plot_model(model)

from tensorflow.keras.optimizers import Adam
optimizer = Adam(lr=0.001)
model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy')

es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)

history=model.fit([xtrain,ytrain[:,:-1]], ytrain.reshape(ytrain.shape[0],ytrain.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([xtest,ytest[:,:-1]], ytest.reshape(ytest.shape[0],ytest.shape[1], 1)[:,1:]))

reverse_target_word_index=y_tokenizer.index_word
reverse_source_word_index=x_tokenizer.index_word
target_word_index=y_tokenizer.word_index

encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])

# Decoder setup
# Below tensors will hold the states of the previous time step
decoder_state_input_h = Input(shape=(latent_dim,))
decoder_state_input_c = Input(shape=(latent_dim,))
decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))

# Get the embeddings of the decoder sequence
dec_emb2= dec_emb_layer(decoder_inputs) 
# To predict the next word in the sequence, set the initial states to the states from the previous time step
decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])

# A dense softmax layer to generate prob dist. over the target vocabulary
decoder_outputs2 = decoder_dense(decoder_outputs2) 

# Final decoder model
decoder_model = Model(
    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],
    [decoder_outputs2] + [state_h2, state_c2])

def decode_sequence(input_seq):
    # Encode the input as state vectors.
    e_out, e_h, e_c = encoder_model.predict(input_seq)
    
    # Generate empty target sequence of length 1.
    target_seq = np.zeros((1,1))
    
    # Populate the first word of target sequence with the start word.
    target_seq[0, 0] = target_word_index['sostok']

    stop_condition = False
    decoded_sentence = ''
    while not stop_condition:
      
        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])

        # Sample a token
        sampled_token_index = np.argmax(output_tokens[0, -1, :])
        sampled_token = reverse_target_word_index[sampled_token_index]
        
        if(sampled_token!='eostok'):
            decoded_sentence += ' '+sampled_token

        # Exit condition: either hit max length or find stop word.
        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):
            stop_condition = True

        # Update the target sequence (of length 1).
        target_seq = np.zeros((1,1))
        target_seq[0, 0] = sampled_token_index

        # Update internal states
        e_h, e_c = h, c

    return decoded_sentence

def seq2summary(input_seq):
    newString=''
    for i in input_seq:
        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):
            newString=newString+reverse_target_word_index[i]+' '
    return newString

def seq2text(input_seq):
    newString=''
    for i in input_seq:
        if(i!=0):
            newString=newString+reverse_source_word_index[i]+' '
    return newString

for i in range(0,5):
    print("Review:",seq2text(xtrain[i]))
    print("Original summary:",seq2summary(ytrain[i]))
    print("Predicted summary:",decode_sequence(xtrain[i].reshape(1,max_text_len)))
    print("\n")

with open('decode_sequence1.pkl', 'rb') as handle:
    decode_sequence1 = pickle.load(handle)
    
def preprocess_input_content(input_content):
    cleaned_input = list(text_cleaner([input_content]))[0]
    input_sequence = x_tokenizer.texts_to_sequences([cleaned_input])
    padded_input_sequence = pad_sequences(input_sequence, maxlen=max_text_len, padding='post')
    return padded_input_sequence
def generate_summary(input_content):
    preprocessed_input = preprocess_input_content(input_content)
    summary = decode_sequence1(preprocessed_input)
    return summary
# Example usage in your app
input_content = "This is the input text that needs to be summarized."
summary = generate_summary(input_content)
print("Generated Summary:", summary)


# Save model architecture and weights
model.save('text_summarization_model.h5')

# Save tokenizers
import pickle
with open('x_tokenizer.pkl', 'wb') as handle:
    pickle.dump(x_tokenizer, handle)
with open('y_tokenizer.pkl', 'wb') as handle:
    pickle.dump(y_tokenizer, handle)
with open('decode_sequence1.pkl', 'wb') as handle:
    pickle.dump(decode_sequence, handle)
-------------------------------------
import warnings
warnings.filterwarnings('ignore')

import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import plotly.express as px
from tqdm.auto import tqdm 

import re
from nltk.corpus import stopwords 
from collections import Counter 
from string import punctuation 

from sklearn.model_selection import train_test_split 

import tensorflow as tf 
from tensorflow import keras 
from tensorflow.keras.preprocessing.text import Tokenizer 
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Bidirectional , Dense , LSTM , Embedding , Concatenate , Dropout , TimeDistributed
from tensorflow.keras.losses import SparseCategoricalCrossentropy
from tensorflow.keras.optimizers import Adam

gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
    print("Name:", gpu.name, "  Type:", gpu.device_type)

tf.test.is_gpu_available()

df = pd.read_csv('/kaggle/input/en-fr-translation-dataset/en-fr.csv' , nrows=500000)

def french_preprocessing(data , col) : 
    data[col] = data[col].astype(str) 
    data[col] = data[col].apply(lambda x: x.lower())
    data[col] = data[col].apply(lambda x: re.sub("[^A-Za-z\s]","",x)) 
    data[col] = data[col].apply(lambda x: x.replace("\s+"," "))
    data[col] = data[col].apply(lambda x: " ".join([word for word in x.split()]))
    return data 

def english_preprocessing(data , col) : 
    data[col] = data[col].astype(str) 
    data[col] = data[col].apply(lambda x : x.lower()) 
    data[col] = data[col].apply(lambda x: re.sub(r'\d','',x))
    data[col] = data[col].apply(lambda x: re.sub(r'\s+',' ',x))
    data[col] = data[col].apply(lambda x: re.sub(r"[-()\"#/@;:<>{}`+=~|.!?,।]", "", x))
    data[col] = data[col].apply(lambda x: x.strip()) 
    data[col] = "<sos> " + data[col] + " <eos>" 
    return data

df = french_preprocessing(df , 'fr')
df = english_preprocessing(df , 'en')

df["en_len"] = [len(text.split()) for text in df.en]
df['fr_len'] = [len(text.split()) for text in df.fr]

df = df[~(df['en_len'] < 5) & ~(df['en_len'] > 20)]
df = df[~(df['fr_len'] < 5) & ~(df['fr_len'] > 20)]

df.head()

px.histogram(df , x = 'en_len' , height = 600 , title = "English Sentences Length Distribution" , marginal="box")

px.histogram(df , x = 'fr_len' , height = 600 , title = "French Sentences Length Distribution" , marginal="box")

def MostWordsUsed(text , n_words) : 
    all_text = ''.join(df[text].values)
    
    words = all_text.split() 
    
    # remove puncs 
    puncs = list(punctuation)
    words = [word for word in words if word not in puncs]
    
    # remove stopwords 
    if text == 'en' : 
        stop_words = set(stopwords.words('english'))
    elif text == 'fr' : 
        stop_words = set(stopwords.words('french'))
        
    words = [word for word in words if not word in stop_words]
    
    word_counts = Counter(words)
    
    top_words = word_counts.most_common(n_words)
    
    return top_words

top_en_words = MostWordsUsed('en' , 50)

xaxis = [word[0] for word in top_en_words]
yaxis = [word[1] for word in top_en_words]

plt.figure(figsize=(16,5))
plt.bar(xaxis , yaxis)
plt.xlabel('Word')
plt.ylabel('Frequency')
plt.title('Most Commonly Used Words in english', fontsize=25)
plt.xticks(rotation=65)
plt.subplots_adjust(bottom=0.15)
plt.show()

top_fr_words = MostWordsUsed('fr' , 50)

xaxis = [word[0] for word in top_fr_words]
yaxis = [word[1] for word in top_fr_words]

plt.figure(figsize=(16,5))
plt.bar(xaxis , yaxis)
plt.xlabel('Word')
plt.ylabel('Frequency')
plt.title('Most Commonly Used Words in french', fontsize=25)
plt.xticks(rotation=65)
plt.subplots_adjust(bottom=0.15)
plt.show()

def Vectorization(col , MAXLEN = 20) : 
    sents = df[col].tolist() 
    
    # Build vocabulary 
    corpus = [word for text in df[col] for word in text.split()] 
    vocab_size = len(Counter(corpus)) 
    
    tokenizer = Tokenizer(num_words=vocab_size , oov_token = "<OOV>" , 
                          filters='!#$%&()*+,-/:;<=>@«»""[\\]^_`{|}~\t\n'
                         )
    tokenizer.fit_on_texts(sents) 
    
    tokenizer.word_index['<pad>'] = 0 
    tokenizer.index_word[0] = '<pad>' 
    
    vocab_to_idx = tokenizer.word_index 
    idx_to_vocab = tokenizer.index_word 
    
    # Text Vectorization 
    seqs = tokenizer.texts_to_sequences(sents) 
    
    pad_seqs = pad_sequences(seqs , maxlen = MAXLEN , padding='post')
    
    return vocab_to_idx , idx_to_vocab , pad_seqs

en_vocab , en_inv_vocab , en_seqs = Vectorization('en')
fr_vocab , fr_inv_vocab , fr_seqs = Vectorization('fr')

x_train , x_test , y_train , y_test = train_test_split(fr_seqs , en_seqs , train_size = 0.95 , random_state = 42)
x_train , x_val , y_train , y_val = train_test_split(x_train , y_train , train_size = 0.75, random_state = 42)

x_train.shape , x_val.shape , x_test.shape

BATCH_SIZE = 128
BUFFER_SIZE = 1000

train_set = tf.data.Dataset.from_tensor_slices((x_train , y_train))
train_set = train_set.shuffle(BUFFER_SIZE).batch(BATCH_SIZE , drop_remainder = True)

val_set = tf.data.Dataset.from_tensor_slices((x_val , y_val))
val_set = val_set.batch(BATCH_SIZE , drop_remainder = True)

test_set = tf.data.Dataset.from_tensor_slices((x_test , y_test))
test_set = test_set.batch(BATCH_SIZE , drop_remainder = True)

print(f"the size of the training set {len(train_set)} batches of {BATCH_SIZE}")

print(f"the size of the validation set {len(val_set)} batches of {BATCH_SIZE}")

print(f"the size of the testing set {len(test_set)} batches of {BATCH_SIZE}")

# define parameters
EMBEDDING_DIM = 256
SRC_VOCAB_SIZE = len(fr_vocab) + 1 # 72393
TRG_VOCAB_SIZE = len(en_vocab) + 1 # 62118
HIDDEN_DIM = 512
EPOCHS = 100
LR = 0.001

class Attention(Model) : # BahdanauAttention
    def __init__(self , hidden_dim) : 
        super(Attention , self).__init__() 
        
        self.W1 = Dense(hidden_dim) 
        self.W2 = Dense(hidden_dim) 
        self.V = Dense(1)
        
    def call(self , s_hidden , h_hidden) : 
        s_hidden = tf.expand_dims(s_hidden , axis = 1) 
        
        score = tf.nn.tanh(self.W1(s_hidden) + self.W2(h_hidden))
        
        attention_weights = tf.nn.softmax(self.V(score) , axis = 1)
        
        context_vector = attention_weights * h_hidden 
        
        context_vector = tf.reduce_sum(context_vector , axis = 1)
        
        context_vector = tf.expand_dims(context_vector , axis = 1)
        
        return context_vector , attention_weights 

class Encoder(Model) : 
    def __init__(self , vocab_size , embedding_dim , hidden_dim) : 
        super(Encoder , self).__init__() 
        
        self.embedding = Embedding(vocab_size , embedding_dim , mask_zero = True)
        self.lstm = Bidirectional(
            LSTM(hidden_dim // 2 , return_sequences=True , return_state= True)
        )
        
    def call(self , x) : 
        embed = self.embedding(x) 
        
        enc_output , forward_h , forward_c , backward_h , backward_c = self.lstm(embed) 
        
        state_h = Concatenate()([forward_h , backward_h]) 
        state_c = Concatenate()([forward_c , backward_c])
        
        return enc_output , state_h , state_c
    
    def summary(self) : 
        x = tf.keras.layers.Input(shape = (None ,))
        model = Model(inputs = [x] , outputs = self.call(x))
        return model.summary()

encoder = Encoder(SRC_VOCAB_SIZE , EMBEDDING_DIM , HIDDEN_DIM)

encoder.summary()

class Decoder(Model) : 
    def __init__(self , vocab_size , embedding_dim , hidden_dim) : 
        super(Decoder , self).__init__() 
        self.units = hidden_dim 
        
        self.embedding = Embedding(vocab_size , embedding_dim , mask_zero = True) 
        
        self.lstm = LSTM(hidden_dim , return_sequences=True , return_state=True) 
        
        self.attention = Attention(hidden_dim) 
        
        self.fc = TimeDistributed(Dense(vocab_size , activation = 'softmax'))
        
    def call(self , x , enc_output , state_h , state_c) : 
        embed = self.embedding(x)
        
        context_vector , attention_weights = self.attention(state_h , enc_output) 
        
        context_vector = Concatenate(axis = -1)([context_vector , embed]) 
        
        dec_output , dec_h , dec_c = self.lstm(context_vector , initial_state=[state_h , state_c])
        
        output = self.fc(dec_output)
        
        return output , dec_h , dec_c , attention_weights
    
    def summary(self) : 
        x = tf.keras.layers.Input(shape=(None,))
        enc_output = tf.keras.layers.Input(shape=(None, self.units))
        state_h = tf.keras.layers.Input(shape=(self.units,))
        state_c = tf.keras.layers.Input(shape=(self.units,))
        model = Model(inputs=[x, enc_output, state_h, state_c], outputs=self.call(x, enc_output, state_h, state_c))
        return model.summary()

decoder = Decoder(TRG_VOCAB_SIZE , EMBEDDING_DIM , HIDDEN_DIM)

decoder.summary()

optimizer = Adam(learning_rate=LR)
loss_object = SparseCategoricalCrossentropy() 
# This is done to diminish the output prediction of 0 
# which has no importance and is used only for padding the inputs
def criterion(real , pred) : 
    # Create a mask to exclude the padding tokens
    mask = tf.math.logical_not(tf.math.equal(real , 0)) 
    
    # Compute the loss value using the loss object
    loss = loss_object(real , pred) 
    
    # Apply the mask to exclude the padding tokens
    mask = tf.cast(mask , dtype = loss.dtype)
    
    loss *= mask 
    
    loss = tf.reduce_mean(loss)
    
    return loss

@tf.function 
def train_step(src , trg) : 
    loss = 0 
    with tf.GradientTape() as tape : 
        enc_output , state_h , state_c = encoder(src)
        dec_input = tf.expand_dims(trg[: , 0] , 1)
        
        for i in range(1 , trg.shape[1]) : 
            dec_output , state_h , state_c , _ = decoder(dec_input , enc_output , state_h , state_c)
            
            loss += criterion(trg[: , i] , dec_output[:, 0, :]) 
            
            dec_input = tf.expand_dims(trg[: , i] , 1)
            
    batch_loss = (loss / int(trg.shape[1])) 
    ModelWeights = encoder.trainable_variables + decoder.trainable_variables 
    gradients = tape.gradient(loss , ModelWeights)
    optimizer.apply_gradients(zip(gradients , ModelWeights))
    
    return batch_loss 


@tf.function 
def val_step(src , trg) : 
    loss = 0 
    enc_output , state_h , state_c = encoder(src) 
    dec_input = tf.expand_dims(trg[: , 0] , 1)
    
    for i in range(1 , trg.shape[1]) : 
        dec_output , state_h , state_c , _ = decoder(dec_input , enc_output , state_h , state_c)
        
        loss += criterion(trg[: , i] , dec_output[: , 0 , :])
        
        dec_input = tf.expand_dims(trg[: , i] , 1)
        
    batch_loss = (loss / int(trg.shape[1]))
    
    return batch_loss

with tf.device("/GPU:0") : 
    training_losses = []
    val_losses = []
    for epoch in tqdm(range(EPOCHS)) : 
        epoch_loss = [] 
        epoch_val_loss = [] 

        for x_train , y_train in train_set : 
            loss = train_step(x_train , y_train)
            epoch_loss.append(loss)

        for x_val , y_val in val_set : 
            val_loss = val_step(x_val , y_val) 
            epoch_val_loss.append(val_loss) 

        training_losses.append(np.mean(epoch_loss))
        val_losses.append(np.mean(epoch_val_loss))
        if (epoch + 1) % 10 == 0 : 
            print(f"Epoch : {epoch+1} , Training Loss : {training_losses[-1]} , Validation Loss : {val_losses[-1]}\n")
-------------------------------------
import tensorflow as tf
import numpy as np

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, GRU, Embedding, LSTM
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.utils import pad_sequences

# Bosluk karakteri diger kelimeye yapismamasi icin.
mark_start= "baslangicccccccc "
mark_end= " endddddddddddddddd"

data_src = []
data_dest = []

for line in open('/kaggle/input/turkish-to-english-translation-dataset/TR2EN.txt', encoding='UTF-8'):
    en_text, tr_text = line.rstrip().split('\t')
    
    tr_text = mark_start + tr_text + mark_end
    
    data_src.append(en_text)
    data_dest.append(tr_text)

data_src[100]

data_dest[100]

data_src[200000]

data_dest[200000]

len(data_src)

def tokenize_texts(texts, num_words=None):
    tokenizer = Tokenizer(num_words=num_words)
    tokenizer.fit_on_texts(texts)

    return tokenizer

def reverse_tokens(tokens):
    return [list(reversed(x)) for x in tokens]

def pad_tokens(tokens, maxlen, padding, truncating):
    return pad_sequences(tokens, maxlen=maxlen, padding=padding, truncating=truncating)

def calculate_max_tokens(num_tokens):
    return int(np.mean(num_tokens) + 2 * np.std(num_tokens))

def token_to_word(token, index_to_word):
    word=" " if token == 0 else index_to_word[token]
    return word
def tokens_to_string(tokens, index_to_word):
    words = [index_to_word[token] for token in tokens if token != 0]
    return " ".join(words)

def text_to_tokens(text, tokenizer, maxlen, padding, reverse=False):
    tokens = tokenizer.texts_to_sequences([text])
    tokens = np.array(tokens)

    if reverse:
        tokens = np.flip(tokens, axis=1)
        truncating = "pre"
    else:
        truncating = "post"

    return pad_sequences(tokens, maxlen=maxlen, padding=padding, truncating=truncating)

def tokenize_and_preprocess(texts, padding, reverse=False, num_words=None):
    tokenizer = tokenize_texts(texts, num_words=num_words)
    index_to_word = dict(zip(tokenizer.word_index.values(), tokenizer.word_index.keys()))
    
    tokens = tokenizer.texts_to_sequences(texts)

    if reverse:
        tokens = reverse_tokens(tokens)
        truncating = "pre"
    else:
        truncating = "post"

    num_tokens = [len(x) for x in tokens]
    max_tokens = calculate_max_tokens(num_tokens)

    tokens_padded = pad_tokens(tokens, maxlen=max_tokens, padding=padding, truncating=truncating)

    return {
        'tokenizer': tokenizer,
        'index_to_word': index_to_word,
        'tokens': tokens,
        'max_tokens': max_tokens,
        'tokens_padded': tokens_padded,
    }


# Prepadding sayesinde düşünce vektörü üretilmeden tüm kelimeleri görüyor. post olsaydı önce kelimeler daha sonra 0lar ile karşılaşacaktı. Network en son gördüklerini daha iyi aklında tutacağı için prepadding.
# 0lar kelime uzunluğunu eşitlemek için kullanılır. 
tokenizer_src=tokenize_and_preprocess(texts=data_src,padding="pre",reverse=True,num_words=None)

# Decoderın başlangıçta 0lar ile uğraşmaması için postpadding uygulanır. 
tokenizer_dest=tokenize_and_preprocess(texts=data_dest,padding="post",reverse=False,num_words=None)

tokens_src = tokenizer_src["tokens_padded"]
tokens_dest = tokenizer_dest["tokens_padded"]
print(tokens_src.shape)
print(tokens_dest.shape)

tokens_dest[200000]

tokenizer_dest_word_index = tokenizer_dest["tokenizer"].word_index
tokenizer_src_word_index = tokenizer_src["tokenizer"].word_index

tokens_src[200000]

print(tokens_to_string(tokenizer_src['tokens_padded'][200000], tokenizer_src['index_to_word']))

data_src[200000]

token_start = tokenizer_dest_word_index.get(mark_start.strip(), None)
token_start

token_end = tokenizer_dest_word_index.get(mark_end.strip(), None)
token_end

encoder_input_data = tokens_src

decoder_input_data = tokens_dest[:, :-1]
decoder_output_data = tokens_dest[:, 1:]

encoder_input_data[200000]

decoder_input_data[200000]

decoder_output_data[200000]

print(tokens_to_string(decoder_input_data[200000], tokenizer_dest["index_to_word"]))

print(tokens_to_string(decoder_output_data[200000], tokenizer_dest['index_to_word']))

num_encoder_words = len(tokenizer_src_word_index)
num_decoder_words = len(tokenizer_dest_word_index)

num_encoder_words

num_decoder_words

embedding_size = 100

word2vec = {}
with open('/kaggle/input/glove6b100dtxt/glove.6B.100d.txt', encoding='UTF-8') as f:
    for line in f:
        values = line.split()
        word = values[0]
        vec = np.asarray(values[1:], dtype='float32')
        word2vec[word] = vec

embedding_matrix = np.random.uniform(-1, 1, (num_encoder_words, embedding_size))
for word, i in tokenizer_src_word_index.items():
    if i < num_encoder_words:
        embedding_vector = word2vec.get(word)
        if embedding_vector is not None:
            embedding_matrix[i] = embedding_vector

embedding_matrix.shape

encoder_input = Input(shape=(None,), name='encoder_input')

encoder_embedding = Embedding(input_dim=num_encoder_words,
                              output_dim=embedding_size,
                              weights=[embedding_matrix],
                              trainable=True,
                              name='encoder_embedding')

state_size = 256
dropout_rate = 0.2


encoder_lstm1 = LSTM(state_size,dropout=dropout_rate, name='encoder_lstm1', return_sequences=True)
encoder_lstm2 = LSTM(state_size,dropout=dropout_rate, name='encoder_lstm2', return_sequences=True)
encoder_lstm3 = LSTM(state_size,dropout=dropout_rate, name='encoder_lstm3', return_sequences=False)

def connect_encoder():
    net = encoder_input
    
    net = encoder_embedding(net)
    
    net = encoder_lstm1(net)
    net = encoder_lstm2(net)
    net = encoder_lstm3(net)
    
    encoder_output = net
    
    return encoder_output

encoder_output = connect_encoder()

decoder_initial_state = Input(shape=(state_size,), name='decoder_initial_state')

decoder_input = Input(shape=(None,), name='decoder_input')

decoder_embedding = Embedding(input_dim=num_decoder_words,
                              output_dim=embedding_size,
                              name='decoder_embedding')

decoder_lstm1 = LSTM(state_size,dropout=dropout_rate, name='decoder_lstm1', return_sequences=True)
decoder_lstm2 = LSTM(state_size,dropout=dropout_rate, name='decoder_lstm2', return_sequences=True)
decoder_lstm3 = LSTM(state_size,dropout=dropout_rate, name='decoder_lstm3', return_sequences=True)

decoder_dense = Dense(num_decoder_words,
                      activation='linear',
                      name='decoder_output')

def connect_decoder(initial_state):
    net = decoder_input
    
    net = decoder_embedding(net)
    
    net = decoder_lstm1(net, initial_state=[initial_state, initial_state])
    net = decoder_lstm2(net, initial_state=[initial_state, initial_state])
    net = decoder_lstm3(net, initial_state=[initial_state, initial_state])
    
    decoder_output = decoder_dense(net)
    
    return decoder_output

decoder_output = connect_decoder(initial_state=encoder_output)

model_train = Model(inputs=[encoder_input, decoder_input], outputs=[decoder_output])

model_encoder = Model(inputs=[encoder_input], outputs=[encoder_output])

decoder_output = connect_decoder(initial_state=decoder_initial_state)

model_decoder = Model(inputs=[decoder_input, decoder_initial_state], outputs=[decoder_output])

def sparse_cross_entropy(y_true, y_pred):
    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true, logits=y_pred)
    loss_mean = tf.reduce_mean(loss)
    return loss_mean

optimizer = RMSprop(lr=0.001)

model_train.compile(optimizer=optimizer,
                    loss=sparse_cross_entropy)

path_checkpoint = 'checkpoint.keras'
checkpoint = ModelCheckpoint(filepath=path_checkpoint,monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_weights_only=True)

x_data = {'encoder_input': encoder_input_data, 'decoder_input': decoder_input_data}

y_data = {'decoder_output': decoder_output_data}

model_train.fit(x=x_data,
                y=y_data,
                batch_size=512,
                epochs=20,
                callbacks=[checkpoint])

model_decoder.save_weights("model_decoder_weights2.keras")
model_encoder.save_weights("model_encoder_weights2.keras")

def translate(input_text, true_output_text=None):
    input_tokens =  text_to_tokens(input_text,tokenizer_src["tokenizer"],tokenizer_src["max_tokens"],"pre",False)
    initial_state = model_encoder.predict(input_tokens)
    max_tokens = tokenizer_dest["max_tokens"]
    
    decoder_input_data = np.zeros(shape=(1, max_tokens), dtype=np.int32)
    
    token_int = token_start
    output_text = ''
    count_tokens = 0
    
    while token_int != token_end and count_tokens < max_tokens:
        decoder_input_data[0, count_tokens] = token_int
        x_data = {'decoder_initial_state': initial_state, 'decoder_input': decoder_input_data}
        
        decoder_output = model_decoder.predict(x_data)
        token_onehot = decoder_output[0, count_tokens, :]

        token_int = np.argmax(token_onehot)
        sampled_word = token_to_word(token_int,tokenizer_dest["index_to_word"])
        output_text += ' ' + sampled_word
        count_tokens += 1
        
    print('Input text:')
    print(input_text)
    print()
    
    print('Translated text:')
    print(output_text)
    print()
    
    if true_output_text is not None:
        print('True output text:')
        print(true_output_text)
        print()

translate(input_text=data_src[100], true_output_text=data_dest[100])
-------------------------------------
import warnings
warnings.filterwarnings('ignore')

import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import plotly.express as px
import seaborn as sns
from tqdm.auto import tqdm 

import re
from nltk.corpus import stopwords 
from collections import Counter 
from string import punctuation 

from sklearn.model_selection import train_test_split 

import tensorflow as tf 
from tensorflow import keras 
from tensorflow.keras.preprocessing.text import Tokenizer 
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Bidirectional , Dense , LSTM , Embedding , Concatenate , Dropout , TimeDistributed
from tensorflow.keras.losses import SparseCategoricalCrossentropy
from tensorflow.keras.optimizers import Adam

gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
    print("Name:", gpu.name, "  Type:", gpu.device_type)

tf.test.is_gpu_available()

df = pd.read_csv('/kaggle/input/en-fr-translation-dataset/en-fr.csv' , nrows=500000)

def english_preprocessing(data , col) : 
    data[col] = data[col].astype(str) 
    data[col] = data[col].apply(lambda x: x.lower())
    data[col] = data[col].apply(lambda x: re.sub("[^A-Za-z\s]","",x)) 
    data[col] = data[col].apply(lambda x: x.replace("\s+"," "))
    data[col] = data[col].apply(lambda x: " ".join([word for word in x.split()]))
    return data 

def french_preprocessing(data , col) : 
    data[col] = data[col].astype(str) 
    data[col] = data[col].apply(lambda x : x.lower()) 
    data[col] = data[col].apply(lambda x: re.sub(r'\d','',x))
    data[col] = data[col].apply(lambda x: re.sub(r'\s+',' ',x))
    data[col] = data[col].apply(lambda x: re.sub(r"[-()\"#/@;:<>{}`+=~|.!?,।]", "", x))
    data[col] = data[col].apply(lambda x: x.strip()) 
    data[col] = "<sos> " + data[col] + " <eos>" 
    return data

df = french_preprocessing(df , 'fr')
df = english_preprocessing(df , 'en')

df["en_len"] = [len(text.split()) for text in df.en]
df['fr_len'] = [len(text.split()) for text in df.fr]

df = df[~(df['en_len'] < 5) & ~(df['en_len'] > 20)]
df = df[~(df['fr_len'] < 5) & ~(df['fr_len'] > 20)]

df.head()

px.histogram(df , x = 'en_len' , height = 600 , title = "English Sentences Length Distribution" , marginal="box")

px.histogram(df , x = 'fr_len' , height = 600 , title = "French Sentences Length Distribution" , marginal="box")

def MostWordsUsed(text , n_words) : 
    all_text = ''.join(df[text].values)
    
    words = all_text.split() 
    
    # remove puncs 
    puncs = list(punctuation)
    words = [word for word in words if word not in puncs]
    
    # remove stopwords 
    if text == 'en' : 
        stop_words = set(stopwords.words('english'))
    elif text == 'fr' : 
        stop_words = set(stopwords.words('french'))
        
    words = [word for word in words if not word in stop_words]
    
    word_counts = Counter(words)
    
    top_words = word_counts.most_common(n_words)
    
    return top_words

top_en_words = MostWordsUsed('en' , 50)

xaxis = [word[0] for word in top_en_words]
yaxis = [word[1] for word in top_en_words]

plt.figure(figsize=(16,5))
plt.bar(xaxis , yaxis)
plt.xlabel('Word')
plt.ylabel('Frequency')
plt.title('Most Commonly Used Words in english', fontsize=25)
plt.xticks(rotation=65)
plt.subplots_adjust(bottom=0.15)
plt.show()

top_fr_words = MostWordsUsed('fr' , 50)

xaxis = [word[0] for word in top_fr_words]
yaxis = [word[1] for word in top_fr_words]

plt.figure(figsize=(16,5))
plt.bar(xaxis , yaxis)
plt.xlabel('Word')
plt.ylabel('Frequency')
plt.title('Most Commonly Used Words in french', fontsize=25)
plt.xticks(rotation=65)
plt.subplots_adjust(bottom=0.15)
plt.show()

def Vectorization(col , MAXLEN = 20) : 
    sents = df[col].tolist() 
    
    # Build vocabulary 
    corpus = [word for text in df[col] for word in text.split()] 
    vocab_size = len(Counter(corpus)) 
    
    tokenizer = Tokenizer(num_words=vocab_size , oov_token = "<OOV>" , 
                          filters='!#$%&()*+,-/:;<=>@«»""[\\]^_`{|}~\t\n'
                         )
    tokenizer.fit_on_texts(sents) 
    
    tokenizer.word_index['<pad>'] = 0 
    tokenizer.index_word[0] = '<pad>' 
    
    vocab_to_idx = tokenizer.word_index 
    idx_to_vocab = tokenizer.index_word 
    
    # Text Vectorization 
    seqs = tokenizer.texts_to_sequences(sents) 
    
    pad_seqs = pad_sequences(seqs , maxlen = MAXLEN , padding='post')
    
    return vocab_to_idx , idx_to_vocab , pad_seqs , tokenizer

en_vocab , en_inv_vocab , en_seqs , en_tokenizer = Vectorization('en')
fr_vocab , fr_inv_vocab , fr_seqs , fr_tokenizer = Vectorization('fr')

x_train , x_val , y_train , y_val = train_test_split(en_seqs , fr_seqs , train_size = 0.80, random_state = 42)

x_train.shape , x_val.shape

BATCH_SIZE = 128
BUFFER_SIZE = 1000

train_set = tf.data.Dataset.from_tensor_slices((x_train , y_train))
train_set = train_set.shuffle(BUFFER_SIZE).batch(BATCH_SIZE , drop_remainder = True)

val_set = tf.data.Dataset.from_tensor_slices((x_val , y_val))
val_set = val_set.batch(BATCH_SIZE , drop_remainder = True)

print(f"the size of the training set {len(train_set)} batches of {BATCH_SIZE}")

print(f"the size of the validation set {len(val_set)} batches of {BATCH_SIZE}")

# define parameters
EMBEDDING_DIM = 256
SRC_VOCAB_SIZE = len(en_vocab) + 1 # 55126
TRG_VOCAB_SIZE = len(fr_vocab) + 1 # 73164
HIDDEN_DIM = 512
MAXLEN = 20
EPOCHS = 50
LR = 0.001

class Attention(Model) : # Bahdanau Attention
    def __init__(self , hidden_dim) : 
        super(Attention , self).__init__() 
        
        self.W1 = Dense(hidden_dim) 
        self.W2 = Dense(hidden_dim) 
        self.V = Dense(1)
        
    def call(self , s_hidden , h_hidden) : 
        s_hidden = tf.expand_dims(s_hidden , axis = 1) 
        
        score = tf.nn.tanh(self.W1(s_hidden) + self.W2(h_hidden))
        
        attention_weights = tf.nn.softmax(self.V(score) , axis = 1)
        
        context_vector = attention_weights * h_hidden 
        
        context_vector = tf.reduce_sum(context_vector , axis = 1)
        
        context_vector = tf.expand_dims(context_vector , axis = 1)
        
        return context_vector , attention_weights 

class Encoder(Model) : 
    def __init__(self , vocab_size , embedding_dim , hidden_dim) : 
        super(Encoder , self).__init__() 
        
        self.embedding = Embedding(vocab_size , embedding_dim , mask_zero = True)
        self.lstm = Bidirectional(
            LSTM(hidden_dim // 2 , return_sequences=True , return_state= True)
        )
        
    def call(self , x) : 
        embed = self.embedding(x) 
        
        enc_output , forward_h , forward_c , backward_h , backward_c = self.lstm(embed) 
        
        state_h = Concatenate()([forward_h , backward_h]) 
        state_c = Concatenate()([forward_c , backward_c])
        
        return enc_output , state_h , state_c
    
    def summary(self) : 
        x = tf.keras.layers.Input(shape = (None ,))
        model = Model(inputs = [x] , outputs = self.call(x))
        return model.summary()

encoder = Encoder(SRC_VOCAB_SIZE , EMBEDDING_DIM , HIDDEN_DIM)

encoder.summary()

class Decoder(Model) : 
    def __init__(self , vocab_size , embedding_dim , hidden_dim) : 
        super(Decoder , self).__init__() 
        self.units = hidden_dim 
        
        self.embedding = Embedding(vocab_size , embedding_dim , mask_zero = True) 
        
        self.lstm = LSTM(hidden_dim , return_sequences=True , return_state=True) 
        
        self.attention = Attention(hidden_dim) 
        
        self.fc = TimeDistributed(Dense(vocab_size , activation = 'softmax'))
        
    def call(self , x , enc_output , state_h , state_c) : 
        embed = self.embedding(x)
        
        context_vector , attention_weights = self.attention(state_h , enc_output) 
        
        context_vector = Concatenate(axis = -1)([context_vector , embed]) 
        
        dec_output , dec_h , dec_c = self.lstm(context_vector , initial_state=[state_h , state_c])
        
        output = self.fc(dec_output)
        
        return output , dec_h , dec_c , attention_weights
    
    def summary(self) : 
        x = tf.keras.layers.Input(shape=(None,))
        enc_output = tf.keras.layers.Input(shape=(None, self.units))
        state_h = tf.keras.layers.Input(shape=(self.units,))
        state_c = tf.keras.layers.Input(shape=(self.units,))
        model = Model(inputs=[x, enc_output, state_h, state_c], outputs=self.call(x, enc_output, state_h, state_c))
        return model.summary()

decoder = Decoder(TRG_VOCAB_SIZE , EMBEDDING_DIM , HIDDEN_DIM)

decoder.summary()

optimizer = Adam(learning_rate=LR)
loss_object = SparseCategoricalCrossentropy() 
# This is done to diminish the output prediction of 0 
# which has no importance and is used only for padding the inputs
def criterion(real , pred) : 
    # Create a mask to exclude the padding tokens
    mask = tf.math.logical_not(tf.math.equal(real , 0)) 
    
    # Compute the loss value using the loss object
    loss = loss_object(real , pred) 
    
    # Apply the mask to exclude the padding tokens
    mask = tf.cast(mask , dtype = loss.dtype)
    
    loss *= mask 
    
    loss = tf.reduce_mean(loss)
    
    return loss

@tf.function 
def train_step(src , trg) : 
    loss = 0 
    with tf.GradientTape() as tape : 
        enc_output , state_h , state_c = encoder(src)
        dec_input = tf.expand_dims(trg[: , 0] , 1)
        
        for i in range(1 , trg.shape[1]) : 
            dec_output , state_h , state_c , _ = decoder(dec_input , enc_output , state_h , state_c)
            
            loss += criterion(trg[: , i] , dec_output[:, 0, :]) 
            
            dec_input = tf.expand_dims(trg[: , i] , 1)
            
    batch_loss = (loss / int(trg.shape[1])) 
    ModelWeights = encoder.trainable_variables + decoder.trainable_variables 
    gradients = tape.gradient(loss , ModelWeights)
    optimizer.apply_gradients(zip(gradients , ModelWeights))
    
    return batch_loss 


@tf.function 
def val_step(src , trg) : 
    loss = 0 
    enc_output , state_h , state_c = encoder(src) 
    dec_input = tf.expand_dims(trg[: , 0] , 1)
    
    for i in range(1 , trg.shape[1]) : 
        dec_output , state_h , state_c , _ = decoder(dec_input , enc_output , state_h , state_c)
        
        loss += criterion(trg[: , i] , dec_output[: , 0 , :])
        
        dec_input = tf.expand_dims(trg[: , i] , 1)
        
    batch_loss = (loss / int(trg.shape[1]))
    
    return batch_loss

with tf.device("/GPU:0") : 
    training_losses = []
    val_losses = []
    for epoch in tqdm(range(EPOCHS)) : 
        epoch_loss = [] 
        epoch_val_loss = [] 

        for x_train , y_train in train_set : 
            loss = train_step(x_train , y_train)
            epoch_loss.append(loss)

        for x_val , y_val in val_set : 
            val_loss = val_step(x_val , y_val) 
            epoch_val_loss.append(val_loss) 

        training_losses.append(np.mean(epoch_loss))
        val_losses.append(np.mean(epoch_val_loss))
        if (epoch + 1) % 10 == 0 : 
            print(f"Epoch : {epoch+1} , Training Loss : {training_losses[-1]} , Validation Loss : {val_losses[-1]}\n")

plt.plot(training_losses , label = 'train') 
plt.plot(val_losses , label = 'validation') 
plt.title('Traning/Valiadtion measure over Epochs') 
plt.xlabel('epoch') 
plt.ylabel('Training/Validation Losses') 
plt.legend() 
plt.show()

encoder.save_weights('NMT encoder.h5') 
decoder.save_weights('NMT decoder.h5')

# load weights 
encoder.load_weights('/kaggle/working/NMT encoder.h5') 
decoder.load_weights('/kaggle/working/NMT decoder.h5')

fr_tokenizer.word_index['eos']

def predict_sentence(en_input) : 
    eng_seq = en_tokenizer.texts_to_sequences([en_input]) 
    en_input = pad_sequences(eng_seq , maxlen = MAXLEN , padding = 'post') 
    
    hidden_state , next_h , next_c = encoder(en_input) 
    
    attn_plot = [] 
    
    curr_token = np.zeros((1,1)) 
    curr_token[0,0] = fr_tokenizer.word_index['sos'] 
    
    pred_sent = ''
    
    for i in range(MAXLEN) : 
        output , next_h , next_c , attn_w = decoder(curr_token , hidden_state , next_h , next_c)
        
        attn_plot.append(attn_w.numpy().reshape(-1 , )) 
        next_token = np.argmax(output[: , 0 , :] , axis = 1)[0] 
        next_word = fr_tokenizer.index_word[next_token] 
        
        if next_word == 'eos':
            break
        else:
            pred_sent += ' ' + next_word
            curr_token[0,0] = next_token
            
    return pred_sent.strip(), np.array(attn_plot)

test_sample = df.sample(1000)

test_sample = test_sample[~(test_sample['en_len'] < 5) & ~(test_sample['en_len'] > 10)]
test_sample = test_sample[~(test_sample['fr_len'] < 5) & ~(test_sample['fr_len'] > 10)]

x_test = test_sample['en'].tolist() 
y_test = test_sample['fr'].tolist()

def plot_attention(attention , sent , pred_sent) : 
    plt.figure(figsize=(9,6))
    plt.rcParams['font.size'] = 7
    g = sns.heatmap(attention, annot=True, fmt='.2f')
    g.set_xticklabels(sent)
    g.set_yticklabels(pred_sent)
    plt.show()

for en_sent in x_test[-10:]:
    result, attention_plot = predict_sentence(en_sent)
    print(f"English sentence: {en_sent}")
    print(f"Predicted translation: {result}")
    attention_plot = attention_plot[:len(result.split()), :len(en_sent.split())]
    plot_attention(attention_plot, en_sent.split(), result.split())
-------------------------------------
#Libraries
import pathlib
import random
import string
import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers import TextVectorization
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import callbacks

eng_file1 = '/kaggle/input/tamil-english/data.en1'
tamil_file1 = '/kaggle/input/tamil-english/data.ta1'
eng_file2 = '/kaggle/input/tamil-english/data.en2'
tamil_file2 = '/kaggle/input/tamil-english/data.ta2'
eng_file3 = '/kaggle/input/tamil-english/data.en3'
tamil_file3 = '/kaggle/input/tamil-english/data.ta3'
eng_file4 = '/kaggle/input/tamil-english/data.en4'
tamil_file4 = '/kaggle/input/tamil-english/data.ta4'
eng_file5 = '/kaggle/input/tamil-english/data.en5'
tamil_file5 = '/kaggle/input/tamil-english/data.ta5'

with open(eng_file1, 'r') as file:
    english_sentences1 = file.readlines()
with open(tamil_file1, 'r') as file:
    tamil_sentences1 = file.readlines()
with open(eng_file2, 'r') as file:
    english_sentences2 = file.readlines()
with open(tamil_file2, 'r') as file:
    tamil_sentences2 = file.readlines()
with open(eng_file3, 'r') as file:
    english_sentences3 = file.readlines()
with open(tamil_file3, 'r') as file:
    tamil_sentences3 = file.readlines()
with open(eng_file4, 'r') as file:
    english_sentences4 = file.readlines()
with open(tamil_file4, 'r') as file:
    tamil_sentences4 = file.readlines()
with open(eng_file5, 'r') as file:
    english_sentences5 = file.readlines()
with open(tamil_file5, 'r') as file:
    tamil_sentences5 = file.readlines()

english_sentences = [item for sublist in zip(english_sentences1, english_sentences2, english_sentences3, english_sentences4, english_sentences5) for item in sublist]
tamil_sentences = [item for sublist in zip(tamil_sentences1, tamil_sentences2, tamil_sentences3, tamil_sentences4, tamil_sentences5) for item in sublist]

english_sentences = [sentence.rstrip('\n').lower() for sentence in english_sentences]
tamil_sentences = [sentence.rstrip('\n') for sentence in tamil_sentences]

print(len(english_sentences))
print(len(tamil_sentences))

# filter out sentences which contains letters other than whats listed below
tamil_vocabulary = [ ' ', '!', '"', '#', '$', '%', '&', "'", '(', ')', '*', '+', ',', '-', '.', '/',
                      '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', 'ˌ',
                      "ஃ", "அ", "ஆ", "இ", "ஈ", "உ", "ஊ", "எ", "ஏ", "ஐ", "ஒ", "ஓ", "ஔ",
                      "க", "ங", "ச", "ஜ", "ஞ", "ட", "ண",
                      "த", "ந", "ன", "ப", "ம", "ய", "ர",
                      "ற", "ல", "ள", "ழ", "வ", "ஶ", "ஷ", "ஸ", "ஹ",
                      "ா", "ி", "ீ", "ு", "ூ", "ெ", "ே", "ை", "ொ", "ோ", "ௌ", "்", "ௗ",
                      "௦", "௧", "௨", "௫", "௬", "௲", "௳"
                      ]

english_vocabulary = [' ', '!', '"', '#', '$', '%', '&', "'", '(', ')', '*', '+', ',', '-', '.', '/',
                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',
                        ':', '<', '=', '>', '?', '@',
                        '[', '\\', ']', '^', '_', '`',
                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',
                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',
                        'y', 'z',
                        '{', '|', '}', '~']

def is_valid_tokens(sentence , vocab):
    for token in list(set(sentence)):
        if token not in vocab:
            return False
    return True

valid_sentence_indicies = []
for index in range(len(english_sentences[:400000])):
    tamil_sentence, english_sentence = tamil_sentences[index], english_sentences[index]
    if is_valid_tokens(tamil_sentence, tamil_vocabulary) \
      and is_valid_tokens(english_sentence , english_vocabulary):
        valid_sentence_indicies.append(index)

TOTAL_SENTENCES = 200000 # only the first 200000 valid sentences are taken to train the model
x = [english_sentences[i] for i in valid_sentence_indicies[:TOTAL_SENTENCES]]
y = [tamil_sentences[i] for i in valid_sentence_indicies[:TOTAL_SENTENCES]]

import pandas as pd
dataset =  pd.DataFrame({"English":x , "Tamil":y })
dataset.info()

dataset.sample(5)

dataset.to_csv('/kaggle/working/data.csv' , index = False )
dataset = pd.read_csv('/kaggle/working/data.csv')
dataset.head()

text_pairs = []

#adding [start] and [end] tokens
for i in range(dataset.shape[0]) :
    eng = str(dataset["English"][i])
    tam = "[start] " + str(dataset["Tamil"][i]) + " [end]"
    text_pairs.append((eng,tam))

len(text_pairs)

train_sample_size = len(text_pairs) - int(0.1*len(text_pairs))
train_pairs = text_pairs[:train_sample_size]
test_pairs = text_pairs[train_sample_size:]

print("Total pairs :", len(text_pairs))
print("Train pairs :", len(train_pairs))
print("Test pairs :", len(test_pairs))

strip_chars = string.punctuation + "|"
strip_chars = strip_chars.replace("[", "")
strip_chars = strip_chars.replace("]", "")
strip_chars = strip_chars.replace('""', "")

vocab_size = 50000
sequence_length = 30
batch_size = 128

def custom_standardization(input_string):
    lowercase = tf.strings.lower(input_string)
    return tf.strings.regex_replace(lowercase, "[%s]" % re.escape(strip_chars), "")

eng_vectorization = TextVectorization(
    max_tokens=vocab_size, output_mode="int", output_sequence_length=sequence_length,
)

tam_vectorization = TextVectorization(
    max_tokens=vocab_size,
    output_mode="int",
    output_sequence_length=sequence_length + 1,
    standardize=custom_standardization,
)

train_eng_texts = [pair[0] for pair in train_pairs]
train_tam_texts = [pair[1] for pair in train_pairs]

# Adapt the TextVectorization layers to the training data
eng_vectorization.adapt(train_eng_texts)
tam_vectorization.adapt(train_tam_texts)

import json

# Get the vocabulary
eng_vocab = eng_vectorization.get_vocabulary()
tam_vocab = tam_vectorization.get_vocabulary()


# Save the vocabulary
with open('/kaggle/working/eng_vocab.json', 'w') as f:
    json.dump(eng_vocab, f)
with open('/kaggle/working/tam_vocab.json', 'w') as f:
    json.dump(tam_vocab, f)

vocab_size = 50000
sequence_length = 30
batch_size = 128


# Load the vocabulary
with open('/kaggle/working/eng_vocab.json', 'r') as f:
    eng_vocab = json.load(f)
with open('/kaggle/working/tam_vocab.json', 'r') as f:
    tam_vocab = json.load(f)

# Create a TextVectorization layer with the loaded vocabulary
eng_vectorization = TextVectorization(vocabulary=eng_vocab,output_mode="int", output_sequence_length=sequence_length)
tam_vectorization = TextVectorization(vocabulary=tam_vocab,output_mode="int",
    output_sequence_length=sequence_length + 1,
    standardize=custom_standardization)

def format_dataset(eng, tam):
    eng = eng_vectorization(eng)
    tam = tam_vectorization(tam)
    return ({"encoder_inputs": eng, "decoder_inputs": tam[:, :-1],}, tam[:, 1:])

def make_dataset(pairs):
    eng_texts, tam_texts = zip(*pairs)
    eng_texts = list(eng_texts)
    tam_texts = list(tam_texts)
    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, tam_texts))
    dataset = dataset.batch(batch_size)
    dataset = dataset.map(format_dataset)
    return dataset.shuffle(2048).prefetch(16).cache()

train_ds = make_dataset(train_pairs)
test_ds = make_dataset(test_pairs)

for inputs, targets in train_ds.take(2):
    print(f'inputs["encoder_inputs"].shape: {inputs["encoder_inputs"].shape}')
    print(f'inputs["decoder_inputs"].shape: {inputs["decoder_inputs"].shape}')
    print(f"targets.shape: {targets.shape}")

class TransformerEncoder(layers.Layer):
    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):
        super().__init__(**kwargs)
        self.embed_dim = embed_dim
        self.dense_dim = dense_dim
        self.num_heads = num_heads
        self.attention = layers.MultiHeadAttention(
            num_heads=num_heads, key_dim=embed_dim
        )
        self.dense_proj = keras.Sequential(
            [layers.Dense(dense_dim, activation="relu"), layers.Dense(embed_dim),]
        )
        self.layernorm_1 = layers.LayerNormalization()
        self.layernorm_2 = layers.LayerNormalization()
        self.supports_masking = True

    def call(self, inputs, mask=None):
        if mask is not None:
            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype="int32")
        attention_output = self.attention(
            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask
        )
        proj_input = self.layernorm_1(inputs + attention_output)
        proj_output = self.dense_proj(proj_input)
        return self.layernorm_2(proj_input + proj_output)

class PositionalEmbedding(layers.Layer):
    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):
        super().__init__(**kwargs)
        self.token_embeddings = layers.Embedding(
            input_dim=vocab_size, output_dim=embed_dim
        )
        self.position_embeddings = layers.Embedding(
            input_dim=sequence_length, output_dim=embed_dim
        )
        self.sequence_length = sequence_length
        self.vocab_size = vocab_size
        self.embed_dim = embed_dim

    def call(self, inputs):
        length = tf.shape(inputs)[-1]
        positions = tf.range(start=0, limit=length, delta=1)
        embedded_tokens = self.token_embeddings(inputs)
        embedded_positions = self.position_embeddings(positions)
        embedded = embedded_tokens + embedded_positions
        
        # Compute mask
        mask = tf.not_equal(inputs, 0)
        return embedded, mask


class TransformerDecoder(layers.Layer):
    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):
        super().__init__(**kwargs)
        self.embed_dim = embed_dim
        self.latent_dim = latent_dim
        self.num_heads = num_heads
        self.attention_1 = layers.MultiHeadAttention(
            num_heads=num_heads, key_dim=embed_dim
        )
        self.attention_2 = layers.MultiHeadAttention(
            num_heads=num_heads, key_dim=embed_dim
        )
        self.dense_proj = keras.Sequential(
            [layers.Dense(latent_dim, activation="relu"), layers.Dense(embed_dim),]
        )
        self.layernorm_1 = layers.LayerNormalization()
        self.layernorm_2 = layers.LayerNormalization()
        self.layernorm_3 = layers.LayerNormalization()
        self.supports_masking = True

    def call(self, inputs, encoder_outputs, mask=None):
        causal_mask = self.get_causal_attention_mask(inputs)
        if mask is not None:
            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype="int32")
            padding_mask = tf.minimum(padding_mask, causal_mask)

        attention_output_1 = self.attention_1(
            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask
        )
        out_1 = self.layernorm_1(inputs + attention_output_1)

        attention_output_2  = self.attention_2(
            query=out_1,
            value=encoder_outputs,
            key=encoder_outputs,
            attention_mask=padding_mask,
        )

        out_2 = self.layernorm_2(out_1 + attention_output_2)

        proj_output = self.dense_proj(out_2)
        return self.layernorm_3(out_2 + proj_output)

    def get_causal_attention_mask(self, inputs):
        input_shape = tf.shape(inputs)
        batch_size, sequence_length = input_shape[0], input_shape[1]
        i = tf.range(sequence_length)[:, tf.newaxis]
        j = tf.range(sequence_length)
        mask = tf.cast(i >= j, dtype="int32")
        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))
        mult = tf.concat(
            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],
            axis=0,
        )
        return tf.tile(mask, mult)

embed_dim = 512
latent_dim = 1024
num_heads = 8

encoder_inputs = keras.Input(shape=(None,), dtype="int64", name="encoder_inputs")
x, mask = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)
encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x, mask)
encoder = keras.Model(encoder_inputs, encoder_outputs)

decoder_inputs = keras.Input(shape=(None,), dtype="int64", name="decoder_inputs")
encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name="decoder_state_inputs")
x, mask = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)
x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs, mask)
x = layers.Dropout(0.5)(x)
decoder_outputs = layers.Dense(vocab_size, activation="softmax")(x)
decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)

decoder_outputs = decoder([decoder_inputs, encoder_outputs])
transformer = keras.Model(
    [encoder_inputs, decoder_inputs], decoder_outputs, name="transformer"
)

transformer.summary()

class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):
  def __init__(self, d_model, warmup_steps=4000):
    super().__init__()

    self.d_model = d_model
    self.d_model = tf.cast(self.d_model, tf.float32)

    self.warmup_steps = warmup_steps

  def __call__(self, step):
    step = tf.cast(step, dtype=tf.float32)
    arg1 = tf.math.rsqrt(step)
    arg2 = step * (self.warmup_steps ** -1.5)

    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)

  def get_config(self):
    return {"d_model": self.d_model.numpy(), "warmup_steps": self.warmup_steps}

learning_rate = CustomSchedule(latent_dim)

optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,
                                     epsilon=1e-9)

plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))
plt.ylabel('Learning Rate')
plt.xlabel('Train Step')

## call backs
early_stopping = callbacks.EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)

checkpoint_filepath = '/kaggle/working/checkpoint.keras'
model_checkpoint_callback = callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    save_weights_only=False,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True)

csv_logger = callbacks.CSVLogger('/kaggle/working/training_log.csv' , append=True)


backup_callback = callbacks.BackupAndRestore(backup_dir="/kaggle/working/backup" ,
                                             delete_checkpoint=False)

epochs = 30
transformer.compile(
    optimizer=optimizer,
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

history = transformer.fit(train_ds,
                epochs=epochs,
                validation_data=test_ds ,
                callbacks=[
                      early_stopping ,
                      model_checkpoint_callback ,
                      csv_logger ,
                      backup_callback ] )

transformer.save('/kaggle/working/V1-50k-106M.h5')

import os
def plot_loss_and_accuracy(history, save_dir=None, filename=None):
    # Extract the loss and accuracy values from the history object
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    accuracy = history.history['accuracy']
    val_accuracy = history.history['val_accuracy']

    # Get the number of epochs
    epochs = range(1, len(loss) + 1)

    # Plot training and validation loss
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(epochs, loss, 'bo-', label='Training Loss')
    plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # Plot training and validation accuracy
    plt.subplot(1, 2, 2)
    plt.plot(epochs, accuracy, 'bo-', label='Training Accuracy')
    plt.plot(epochs, val_accuracy, 'ro-', label='Validation Accuracy')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.tight_layout()

    # Save the figure if save_dir and filename are provided
    if save_dir and filename:
        os.makedirs(save_dir, exist_ok=True)
        save_path = os.path.join(save_dir, filename)
        plt.savefig(save_path)
        print(f"Plots saved as '{save_path}'")

    plt.show()
plot_loss_and_accuracy(history ,"/content/drive/MyDrive/NMT-Project", "V1-50k-106M_trainloss.png" )

tam_vocab = tam_vectorization.get_vocabulary()
tam_index_lookup = dict(zip(range(len(tam_vocab)), tam_vocab))
max_decoded_sentence_length = 20

def decode_sequence(input_sentence):
    tokenized_input_sentence = eng_vectorization([input_sentence])
    decoded_sentence = "[start]"
    for i in range(max_decoded_sentence_length):
        tokenized_target_sentence = tam_vectorization([decoded_sentence])[:, :-1]
        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])

        sampled_token_index = np.argmax(predictions[0, i, :])
        sampled_token = tam_index_lookup[sampled_token_index]
        decoded_sentence += " " + sampled_token

        if sampled_token == "[end]":
            break
    return decoded_sentence

input_sentence = 'I came late'
output = decode_sequence(input_sentence)
print(output)

input_sentence = 'I think you are great'
output = decode_sequence(input_sentence)
print(output)
