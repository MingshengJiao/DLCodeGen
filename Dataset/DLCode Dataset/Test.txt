{  "User Requirement": "I want to build a model that can classify images as either depicting violence or non-violence using deep learning techniques.",  "Dataset Attributes": "The dataset consists of images representing real-life violence and non-violence scenarios. It contains a total of several thousand instances, with each instance being an RGB image of size 224x224 pixels. The target labels are categorical: 'violence' and 'non-violence'."}
{  "User Requirement": "I want to build a convolutional neural network model to classify images of fresh and stale items from a dataset.",  "Dataset Attributes": "The dataset consists of images representing two classes: Fresh and Stale. The total number of instances is not specified, but the dataset is divided into training, validation, and test sets. Each instance consists of image data, and the target labels are binary (0 for Fresh, 1 for Stale)."}
{  "User Requirement": "I want to build a model that can classify images of different types of skin diseases using a dataset of retinal images.",  "Dataset Attributes": {    "dataset represent": "Images of retinal diseases",    "total instance number": 120,    "data each instance consists of": "Images resized to 224x224 pixels",    "target labels list": [      "Very mild Dementia",      "Non Demented",      "Moderate Dementia",      "Mild Dementia"    ]  }}
{  "User Requirement": "I want to build a model to classify images of different types of skin lesions using a dataset of labeled images.",  "Dataset Attributes": {    "description": "The dataset consists of images of skin lesions categorized into four classes: Healthy, Bunchy top, Fusarium wilt, and Moko.",    "total instance number": "The dataset contains a total of 10,222 images.",    "data each instance consists of": "Each instance consists of an image file path and its corresponding label.",    "target labels list": ["Healthy", "Bunchy top", "Fusarium wilt", "Moko"]  }}
{  "User Requirement": "I want to analyze and process brain tumor MRI images using deep learning techniques, including data preprocessing, model training, and evaluation.",  "Dataset Attributes": "The dataset consists of MRI images of brain tumors, categorized into different types such as 'meningioma', 'glioma', 'pituitary', and 'no tumor'. The dataset is organized into training, validation, and testing directories."}
{  "User Requirement": "I want to build a Super Resolution Generative Adversarial Network (SRGAN) to enhance low-resolution images to high-resolution images.",  "Dataset Attributes": "The dataset consists of images representing faces in both low and high resolutions. It contains a variable number of instances, with each instance consisting of RGB images. The data is associated with two target labels: high-resolution images and low-resolution images."}
{  "User Requirement": "I want to develop a U-Net model for image denoising, specifically to remove noise from images using Gaussian smoothing and wavelet transformation techniques.",  "Dataset Attributes": "The dataset consists of noisy images for denoising tasks. The total number of instances is unspecified, but it includes various images stored in a directory. Each instance consists of raw image data. The target labels are the corresponding denoised images after applying Gaussian smoothing and wavelet transformation."}
{  "User Requirement": "I want to develop a model that can dehaze images, transforming hazy images into clearer versions using a deep learning approach.",  "Dataset Attributes": "The dataset consists of images representing hazy and clear versions of the same scenes. The total number of instances is not specified, but it includes images in PNG format for training and validation. Each instance consists of a hazy image and its corresponding clear image, which serves as the target label."}
{  "User Requirement": "I want to implement a CycleGAN model to transform photos into Monet-style paintings and vice versa.",  "Dataset Attributes": "The dataset consists of images of Monet paintings and corresponding photos. The total number of instances is not specified, but it includes TFRecord files for both categories."}
{  "User Requirement": "I want to develop a U-Net deep learning model to predict and reconstruct images from a dataset of complex images.",  "Dataset Attributes": "The dataset consists of complex images represented as numpy arrays, with a total of 25,000 instances. Each instance consists of image data with a shape of (64, 64, 2) for the stacked images and (20, 8, 1) for the input data."}
{  "User Requirement": "I want to create a model that generates textual descriptions (captions) for images using a combination of computer vision and natural language processing techniques.",  "Dataset Attributes": "The dataset consists of images and their corresponding captions from the Flickr8k dataset. It contains thousands of images, with each image associated with multiple captions. Each instance consists of image files and a text file containing captions."}
{  "User Requirement": "I want to develop a model that can recognize American Sign Language (ASL) fingerspelling gestures and convert them into written text using keypoint data.",  "Dataset Attributes": "The dataset consists of ASL fingerspelling gestures represented as keypoint data. It contains multiple instances, with each instance consisting of sequences of hand landmarks (keypoints) and corresponding phrases. The target labels are the phrases represented in text format."}
{  "User Requirement": "I want to create a model that generates captions for satellite images using a combination of image features and text sequences.",  "Dataset Attributes": "The dataset consists of satellite images and their corresponding captions. It contains a training set and a test set, with each instance consisting of an image file path and a caption. The target labels are the captions associated with each image."}
{  "User Requirement": "I want to build and test a license plate recognition model using a CNN and LSTM architecture to predict characters from images of license plates.",  "Dataset Attributes": "The dataset consists of grayscale images of license plates, with each image corresponding to a sequence of characters. The total number of instances is not specified, but the model is trained on images from a specific directory."}
{  "User Requirement": "I want to build a model that generates captions for images using a combination of image feature extraction and text processing.",  "Dataset Attributes": "The dataset consists of images and their corresponding captions. The total instance number is not explicitly stated. Each instance consists of an image and a list of captions associated with that image."}
{  "User Requirement": "I want to develop a segmentation model to classify brain tumor regions in MRI scans using a 3D U-Net architecture.",  "Dataset Attributes": "The dataset consists of MRI scans in NIfTI format, specifically for brain tumor segmentation. It contains multiple volumes, each with several slices. Each instance consists of 4 channels representing different MRI modalities (flair, t1, t1ce, t2) and a segmentation mask. The target labels include 0 for 'NOT tumor', 1 for 'NECROTIC/CORE', 2 for 'EDEMA', and 3 for 'ENHANCING'."}
{  "User Requirement": "I want to build a model that can segment blood vessels in images using a convolutional neural network.",  "Dataset Attributes": "The dataset consists of images for blood vessel segmentation. It includes training images and their corresponding labels, with a total of several images organized in subfolders by microorganism type. The images are processed to extract bounding box coordinates for segmentation."}
{  "User Requirement": "I want to build a model that can segment images of plants affected by diseases, specifically focusing on identifying and masking the affected areas.",  "Dataset Attributes": "The dataset consists of images of plants with labels indicating the type of disease. It includes images and corresponding masks for three classes: 'Cercospora', 'Coffee Rust', and 'Phoma'."}
{  "User Requirement": "I want to perform semantic image segmentation to analyze football player positions on the field using a U-Net model.",  "Dataset Attributes": "The dataset consists of 512 images and corresponding segmentation masks stored in a JSON file. Each image is resized to 512x512 pixels for training."}
{  "User Requirement": "I want to build a deep learning model to segment gliomas in pre-operative MRI scans, labeling each pixel as part of a tumor or not.",  "Dataset Attributes": {    "Dataset Represent": "MRI scans of gliomas",    "Total Instance Number": "Not specified in the code",    "Data Each Instance Consists": "Images in NIfTI format, with corresponding segmentation masks",    "Target Labels List": ["0 (not tumor)", "1 (necrotic/core)", "2 (edema)", "3 (enhancing)"]  }}
{  "User Requirement": "I want to build and evaluate multiple deep learning models for facial keypoints detection using various architectures.",  "Dataset Attributes": "The dataset consists of images of faces with associated keypoints. The total number of instances is not explicitly stated, but it is derived from the training data. Each instance consists of a grayscale image reshaped to 96x96 pixels, converted to RGB format, and normalized. The target labels are the coordinates of facial keypoints."}
{  "User Requirement": "I want to build a depth estimation model using a ResNet-based U-Net architecture, train it on a dataset of RGB images and depth maps, and evaluate its performance.",  "Dataset Attributes": "The dataset consists of RGB images and corresponding depth maps. The training and testing data paths are specified in CSV files, with the training set used for model training and validation."}
{  "User Requirement": "I want to develop a model that can predict crowd density in images using a deep learning approach.",  "Dataset Attributes": "The dataset represents images from the ShanghaiTech dataset, specifically part B, containing a total of 1,200 instances. Each instance consists of a digital image and its corresponding ground truth density map stored in HDF5 format. The target labels are density maps indicating the number of people in each image."}
{  "User Requirement": "I want to build a model that predicts occupancy flow from video data using a combination of StopNet and EfficientNet architectures.",  "Dataset Attributes": "The dataset consists of images and labels stored in TFRecord format. Each instance includes an image (JPEG format) and a corresponding label (integer)."}
{  "User Requirement": "I want to build a bi-directional LSTM model to classify network traffic data as either normal or a DoS attack based on various features extracted from the dataset.",  "Dataset Attributes": "The dataset consists of network traffic data with a total of multiple instances. Each instance includes features such as flow duration, total forward packets, and flow bytes per second, along with a target label indicating whether the traffic is normal or a DoS attack."}
{  "User Requirement": "I want to build a convolutional neural network model to classify audio data into 10 different classes using Keras and TensorFlow.",  "Dataset Attributes": "The dataset consists of audio features represented as 2D arrays (num_rows=40, num_columns=249, num_channels=1) with corresponding labels. The labels are one-hot encoded into 10 classes."}
{  "User Requirement": "I want to build a multi-label classification model using deep learning and various preprocessing techniques to classify different faults in a dataset.",  "Dataset Attributes": "The dataset consists of training and testing data with multiple features related to faults. The training data includes labels for seven different fault categories."}
{  "User Requirement": "I want to build a machine learning model to predict patient states and diagnose periods based on various health-related features.",  "Dataset Attributes": "The dataset consists of patient health records with various features, including demographic information and health indicators. The target label is 'DiagPeriodL90D', indicating the diagnosis period."}
{  "User Requirement": "I want to analyze patient survival data, preprocess it, build a deep learning model to predict hospital death, and evaluate its performance.",  "Dataset Attributes": "The dataset consists of patient survival data with 178 numerical features and 8 categorical features, totaling several instances. Each instance includes various health metrics and a target label indicating whether the patient survived or not."}
{  "User Requirement": "I want to train multiple neural network models to predict a specific diagnosis period based on patient data, while handling missing values and optimizing model performance.",  "Dataset Attributes": "The dataset represents patient records with various attributes. It contains a total of 10,000 instances, with each instance consisting of features such as age, BMI, zip code, race, payer type, and diagnosis codes. The target label is 'DiagPeriodL90D', which indicates the diagnosis period."}
{  "User Requirement": "I want to build a time series forecasting model using LSTM and SARIMAX to predict the number of products sold based on historical sales data.",  "Dataset Attributes": "The dataset consists of sales data with attributes including date and number of products sold. The training dataset has multiple instances, while the test dataset is used for predictions."}
{  "User Requirement": "I want to predict the prices of a specific type of fruit using an LSTM model, focusing on time series data to understand price trends.",  "Dataset Attributes": "The dataset consists of time series data for various fruits, specifically focusing on 'Potato Red'. It contains 2746 rows of data with columns for 'Commodity', 'Date', and 'Average' price."}
{  "User Requirement": "I want to train a GAN model to predict stock prices using time series data, evaluate its performance, and visualize the results.",  "Dataset Attributes": "The dataset consists of time series data for stock prices, with training and testing sets containing features and target prices. The training set includes 600,600 instances, and the target labels are continuous stock prices."}
{  "User Requirement": "I want to build and train a model to predict Ethereum's closing prices using historical data, and evaluate its performance.",  "Dataset Attributes": "The dataset consists of historical daily closing prices of Ethereum (ETH-USD) obtained from Yahoo Finance. The total number of instances is determined by the available historical data, and each instance consists of a date and a closing price."}
{  "User Requirement": "I want to build and train a bidirectional LSTM model to classify Yelp reviews based on their star ratings.",  "Dataset Attributes": "The dataset consists of text reviews from Yelp, with a total of 1,000,000 instances (limited from the original dataset). Each instance consists of raw text data and corresponding star ratings (1 to 5)."}
{  "User Requirement": "I want to build a model to detect AI-generated text from essays using a dataset, and evaluate its performance through various metrics and visualizations.",  "Dataset Attributes": "The dataset consists of essays with labels indicating whether they are generated by AI or written by students. The training set includes prompts and essays, while the test set contains essays for evaluation. The target labels are binary (0 for student essays, 1 for AI-generated essays)."}
{  "User Requirement": "I want to build and train a text classification model using LSTM and Transformer layers to classify Malayalam news headlines into different categories.",  "Dataset Attributes": "The dataset consists of text documents (news headlines) with associated labels. The training set contains unique headlines and their corresponding labels, while the validation set is used for model evaluation."}
{  "User Requirement": "I want to build a sentiment analysis model using BERT to classify movie reviews as 'Fresh' or 'Rotten' based on their content.",  "Dataset Attributes": "The dataset consists of movie reviews with associated sentiment labels ('Fresh' or 'Rotten'). The total number of reviews is not specified, but the data is read from a CSV file."}
{  "User Requirement": "I want to build a model to detect SQL injection attacks using a dataset of SQL queries, and evaluate its performance based on accuracy, precision, and recall.",  "Dataset Attributes": "The dataset consists of SQL queries with a total of 2 labels indicating whether a query is an SQL injection or not. Each query is processed into character and symbol indices with a maximum length of 1000."}
{  "User Requirement": "I want to build a text summarization model using LSTM and attention mechanisms to generate concise summaries from news articles.",  "Dataset Attributes": "The dataset consists of news articles with their corresponding summaries. Each instance includes a description (text) and a title (summary)."}
{  "User Requirement": "I want to preprocess Arabic text data for summarization and fine-tune a GPT-2 model to generate summaries based on the preprocessed text.",  "Dataset Attributes": "The dataset consists of Arabic text and corresponding summaries. The total number of instances is not explicitly stated, but it is loaded from a CSV file."}
{  "User Requirement": "I want to build a text summarization model using an encoder-decoder architecture with LSTM cells to condense text while retaining key information.",  "Dataset Attributes": "The dataset consists of combined text and summary columns from two CSV files, providing a large corpus for training the summarization model."}
{  "User Requirement": "I want to build a sequence-to-sequence model using LSTM and GRU layers for translating French sentences to English, while also implementing attention mechanisms.",  "Dataset Attributes": "The dataset consists of 500,000 pairs of English and French sentences. Each sentence is preprocessed to remove unwanted characters and is tokenized for model input."}
{  "User Requirement": "I want to build a model that translates Turkish sentences into English using a sequence-to-sequence architecture with LSTM.",  "Dataset Attributes": "The dataset consists of Turkish to English sentence pairs. It contains a large number of instances, with each instance consisting of a source sentence in English and a target sentence in Turkish. The data is associated with no specific target labels as it is a translation task."}
{  "User Requirement": "I want to build a neural machine translation model that translates English sentences to French and visualize the attention scores between the source and target sentences.",  "Dataset Attributes": "The dataset represents English-French sentence pairs from a translation dataset. It contains 500,000 instances, with each instance consisting of an English sentence and its corresponding French translation. The data is associated with no specific target labels as it is a translation task."}
{  "User Requirement": "I want to build a neural machine translation model to translate English sentences into Tamil using a transformer architecture.",  "Dataset Attributes": "The dataset consists of parallel sentences in English and Tamil. It contains 200,000 valid sentence pairs, where each pair consists of an English sentence and its corresponding Tamil translation."}
{  "User Requirement": "I want to build a multi-class prediction model for obesity risk using ensemble methods, specifically combining LGBM and XGBoost classifiers.",  "Dataset Attributes": "The dataset consists of synthetic data generated for obesity risk classification, with a total of unspecified instances. Each instance includes various features related to health metrics, and the target label is 'NObeyesdad', which has multiple classes representing different obesity levels."}
{  "User Requirement": "I want to develop a U-Net deep learning model to predict and reconstruct images from a dataset of complex images.",  "Dataset Attributes": "The dataset consists of complex images represented as numpy arrays, with a total of 25,000 instances. Each instance consists of image data with a shape of (64, 64, 2) for the stacked images and (20, 8, 1) for the input data."}
{  "User Requirement": "I want to predict product sales over time using a time series model, specifically an LSTM, and evaluate its performance.",  "Dataset Attributes": "The dataset consists of time series data for product sales, with a total number of instances not specified. Each instance includes features such as date, country, store, product, and the number sold."}
{  "User Requirement": "I want to build and evaluate a neural network model to predict diabetes using the Pima Indians Diabetes Database.",  "Dataset Attributes": "The dataset consists of medical records related to diabetes, with a total of 768 instances. Each instance includes features such as glucose levels, blood pressure, and other medical measurements, with the target label indicating the presence or absence of diabetes."}
{  "User Requirement": "I want to build a model that generates captions for images using a combination of image feature extraction and sequence modeling.",  "Dataset Attributes": "The dataset consists of images from the Flickr8k dataset, with a total of 8,000 images and corresponding captions. Each image has multiple captions describing its content."}
{  "User Requirement": "I want to build a deep learning model to classify ECG signals into different arrhythmia categories and evaluate its performance using accuracy metrics and confusion matrices.",  "Dataset Attributes": "The dataset consists of processed ECG signals, represented as a CSV file. The total number of instances is not specified, but the data is split into training and test sets. Each instance consists of 5000 features corresponding to ECG readings, and the target labels include 'atrial fibrillation', 'sinus bradycardia', 'sinus rhythm', and 'sinus tachycardia'."}
{  "User Requirement": "I want to build a Named Entity Recognition (NER) model using LSTM that incorporates word embeddings, POS tags, and dependency tags to classify words in sentences.",  "Dataset Attributes": "The dataset consists of sentences with words and their corresponding entity tags. The total number of instances is not specified, but it includes various words and tags."}
{  "User Requirement": "I want to build an image captioning model using a combination of CNN and Transformer architectures to generate captions for images from the Flickr30k dataset.",  "Dataset Attributes": "The dataset consists of images from the Flickr30k dataset, each associated with multiple captions. The total number of instances is not specified, but it includes training and validation sets derived from the captions."}
{  "User Requirement": "I want to build and test a license plate recognition model using a CNN and LSTM architecture to predict characters from images of license plates.",  "Dataset Attributes": "The dataset consists of grayscale images of license plates, with each image corresponding to a sequence of characters. The total number of instances is not specified, but the model is trained on images from a specific directory."}
{  "User Requirement": "I want to build a segmentation model using a ResNet50 U-Net architecture to identify and classify buildings in images from the Massachusetts Buildings Dataset.",  "Dataset Attributes": "The dataset consists of images of buildings and their corresponding segmentation masks. The training set includes images and masks, while validation and test sets are also provided. Each image is resized to (224, 224) for processing."}
{  "User Requirement": "I want to build a deep learning model to classify ECG signals into different heart conditions using a combination of convolutional and LSTM layers.",  "Dataset Attributes": "The dataset consists of ECG signal data with 5000 features per instance. The target labels include four classes: atrial fibrillation, sinus bradycardia, sinus rhythm, and sinus tachycardia. The dataset is split into training and testing sets."}
{  "User Requirement": "I want to implement a CycleGAN model to translate images between two domains, specifically from horses to zebras and vice versa.",  "Dataset Attributes": "The dataset consists of images from two domains: horses and zebras. Each image is resized to 256x256 pixels. The dataset is split into training and testing sets, with images stored in a compressed numpy array format."}
{  "User Requirement": "I want to build a model that can detect whether a piece of text is generated by AI or written by a human, using machine learning techniques and evaluating its performance.",  "Dataset Attributes": "The dataset consists of essays labeled as either AI-generated or human-written. It includes training and test sets, with various prompts and examples for training the model."}
{  "User Requirement": "I want to build a model to detect SQL injection attacks using a dataset of SQL queries, and evaluate its performance based on accuracy, precision, and recall.",  "Dataset Attributes": "The dataset consists of SQL queries with a total of 2 labels indicating whether a query is an SQL injection or not. Each query is processed into character and symbol indices with a maximum length of 1000."}
{  "User Requirement": "I want to build a model to classify emails as fraudulent or not using a dataset of labeled emails, incorporating both text and metadata features.",  "Dataset Attributes": "The dataset consists of labeled email data with attributes including Subject, Sender-Type, Body, and Label. The total number of instances used is 25,000, with 736 labeled as fraud (Label=1)."}
{  "User Requirement": "I want to build and train a deep learning model to classify harmful brain activity using EEG and spectrogram data, and evaluate its performance.",  "Dataset Attributes": "The dataset consists of EEG and spectrogram data for brain activity classification. The total number of instances is not specified, but the dataset includes multiple classes for brain activity. Each instance consists of spectrogram images and EEG data, with target labels indicating the type of brain activity."}
{  "User Requirement": "I want to develop a deep learning model (UNet) that processes and predicts images from augmented datasets, focusing on improving performance through data augmentation and model training.",  "Dataset Attributes": "The dataset consists of two numpy arrays: Es_Data_concat and Stacked_img_concat, each containing 499 samples of shape (64, 64, 2). The target labels are the stacked images used for training the model."}
{  "User Requirement": "I want to build a deep learning model to classify obesity risk levels based on various features, using hyperparameter tuning to optimize the model's performance.",  "Dataset Attributes": "The dataset consists of a training set with features related to obesity risk and a test set for predictions. The training set has multiple numeric and categorical features, and the target variable is 'NObeyesdad', which indicates obesity risk levels."}
{  "User Requirement": "I want to build a model to detect AI-generated text from essays using deep learning techniques, including preprocessing, model training, and evaluation.",  "Dataset Attributes": "The dataset consists of essays with features including prompt IDs, text content, and labels indicating whether the text is AI-generated. The training set has a significant class imbalance."}
{  "User Requirement": "I want to build and evaluate models to forecast sales data using both a simple neural network and an LSTM model, and prepare the results for submission.",  "Dataset Attributes": "The dataset consists of sales data from Rossmann stores, with a total of 1,000,000+ instances. Each instance includes features such as date, store information, and promotional details, with the target label being the sales amount."}
{  "User Requirement": "I want to analyze and predict the risks associated with obesity and cardiovascular disease using various machine learning techniques, including clustering and deep learning.",  "Dataset Attributes": "The dataset consists of health-related features with a total of several thousand instances. Each instance includes features such as age, height, weight, and categorical variables, with the target label being 'NObeyesdad', which indicates obesity risk."}
{  "User Requirement": "I want to build a model that generates captions for images using a combination of image feature extraction and text processing techniques.",  "Dataset Attributes": "The dataset consists of images from the Flickr8k dataset and their corresponding captions. Each image has multiple captions associated with it, and the total number of images is around 8,000. Each instance consists of image data and text captions."}
{  "User Requirement": "I want to analyze and predict the risks associated with obesity and cardiovascular disease using a dataset, employing various data exploration techniques and machine learning models.",  "Dataset Attributes": "The dataset consists of features related to obesity and cardiovascular disease risk, with a target variable 'NObeyesdad' indicating the risk category. The total number of instances is not specified, but it includes both training and test datasets. Each instance consists of various health-related features and categorical labels."}
{  "User Requirement": "I want to analyze a dataset related to obesity and cardiovascular disease risk, visualize the data, perform clustering, and build predictive models to classify the risk associated with NObeyesdad.",  "Dataset Attributes": "The dataset consists of health-related features for individuals, including attributes like age, height, weight, and various health indicators. The total number of instances is not specified, but it includes training and test datasets. Each instance consists of multiple features and a target label indicating the risk class (NObeyesdad)."}
{  "User Requirement": "I want to train multiple neural network models to predict patient states based on various features, including demographic and medical data.",  "Dataset Attributes": "The dataset consists of patient records with features such as age, BMI, zip code, race, payer type, and diagnosis codes. The target variable is 'DiagPeriodL90D'."}
{  "User Requirement": "I want to train neural network models to predict patient states based on various features, including demographic and medical data, while handling missing values appropriately.",  "Dataset Attributes": "The dataset consists of patient records with features such as age, BMI, zip code, race, payer type, and diagnosis codes. The target variable is 'DiagPeriodL90D'."}
{  "User Requirement": "I want to train a GAN model to enhance satellite images by generating high-resolution outputs from low-resolution inputs.",  "Dataset Attributes": "The dataset consists of satellite images stored in an HDF5 file, with input images (X) and target high-resolution images (y). Each image has a shape of (256, 256, 6)."}
{  "User Requirement": "I want to classify ECG signals into four categories: atrial fibrillation, sinus bradycardia, sinus rhythm, and sinus tachycardia using a deep learning model.",  "Dataset Attributes": "The dataset consists of ECG signal features with 5000 data points each, categorized into four classes: atrial fibrillation, sinus bradycardia, sinus rhythm, and sinus tachycardia. The total number of instances is not specified."}
{  "User Requirement": "I want to segment liver tumors from CT scans using deep learning models, specifically by training a U-Net architecture.",  "Dataset Attributes": "The dataset consists of CT scan images and corresponding segmentation masks in NIfTI format. Each CT scan has a shape of (depth, height, width), and the masks are binary images indicating tumor presence. The total number of instances is not specified."}
{  "User Requirement": "I want to build a sentiment analysis model using BERT to classify movie reviews as 'Fresh' or 'Rotten' based on their content.",  "Dataset Attributes": "The dataset consists of movie reviews with associated sentiment labels ('Fresh' or 'Rotten'). The total number of reviews is not specified, but the data is read from a CSV file."}
{  "User Requirement": "I want to predict the prices of a specific type of fruit using an LSTM model, focusing on time series data to understand price trends.",  "Dataset Attributes": "The dataset consists of time series data for various fruits, specifically focusing on 'Potato Red'. It contains 2746 rows of data with columns for 'Commodity', 'Date', and 'Average' price."}
{  "User Requirement": "I want to analyze movie ratings and sentiments using machine learning techniques, including decision trees, random forests, and BERT for sentiment classification.",  "Dataset Attributes": "The dataset consists of movie ratings and reviews from Rotten Tomatoes, with a total of several thousand entries. Each instance includes features like runtime, tomatometer ratings, audience ratings, and review content, with target labels indicating the tomatometer status (Rotten, Fresh, Certified-Fresh)."}
{  "User Requirement": "I want to build and train a GAN model to predict stock prices using time series data, specifically leveraging GRU for the generator and a convolutional network for the discriminator.",  "Dataset Attributes": "The dataset consists of time series data for stock prices, with training and testing sets containing features and corresponding labels. Each instance includes multiple time steps and features."}
{  "User Requirement": "I want to develop a GAN model to predict stock prices based on time series data, utilizing GRU for the generator and a convolutional network for the discriminator.",  "Dataset Attributes": "The dataset consists of time series data for stock prices, with training and testing sets containing features and corresponding labels. Each instance includes multiple time steps and features."}
{  "User Requirement": "I want to predict the quality of red wine using various machine learning models, including XGBoost and neural networks, while optimizing hyperparameters with Optuna.",  "Dataset Attributes": "The dataset consists of red wine quality attributes, with 11 features including acidity, sugar, and alcohol content, and a target label indicating quality on a scale from 1 to 10."}
{  "User Requirement": "I want to build and train a GAN model to predict stock prices using GRU and Conv1D layers, and evaluate its performance on test data.",  "Dataset Attributes": "The dataset consists of time series data for stock prices, with training and testing sets containing features and corresponding labels."}
{  "User Requirement": "I want to build and train a Generative Adversarial Network (GAN) to generate images based on class labels.",  "Dataset Attributes": "The dataset consists of images categorized into different classes, with each image being a PNG file. The total number of images is determined by the files in the specified directory."}
{  "User Requirement": "I want to build an image captioning model that generates descriptive captions for images using a combination of image features and text sequences.",  "Dataset Attributes": "The dataset consists of images and their corresponding captions. The total number of images is determined by the entries in the 'Images' directory and the 'captions.txt' file. Each image is processed to extract features, and each caption is preprocessed for training."}
{  "User Requirement": "I want to build a super-resolution model using a Residual Dense Network (RDN) to enhance the quality of low-resolution images.",  "Dataset Attributes": "The dataset consists of high-resolution (HR) and low-resolution (LR) images for training and validation. The total number of images is determined by the contents of the specified directories. Each instance consists of image data, with HR images being the target output."}
{  "User Requirement": "I want to build a text classification model to predict whether tweets are related to disasters using both XGBoost and LSTM with GloVe embeddings.",  "Dataset Attributes": "The dataset consists of tweets with associated keywords and a binary target label indicating whether the tweet is disaster-related. The training set contains multiple instances, while the test set is used for predictions."}
{  "User Requirement": "I want to identify hate speech and offensive language in Twitter tweets using both traditional machine learning and advanced deep learning techniques, specifically LSTM networks.",  "Dataset Attributes": "The dataset consists of tweets labeled as hate speech, offensive language, or neutral. The training set contains multiple instances, and the target labels are binary, indicating whether a tweet is neutral or contains hate speech/offensive language."}
{  "User Requirement": "I want to build a regression model using Keras to predict the number of rings in a dataset, while performing extensive data preprocessing and feature engineering.",  "Dataset Attributes": "The dataset consists of training and test data for predicting the number of rings. The training set includes various features, with the target variable being 'Rings'. The total number of instances is not specified."}
{  "User Requirement": "I want to preprocess medical images, extract features using PyRadiomics, and build a classification model to predict labels based on these features.",  "Dataset Attributes": "The dataset consists of medical images and associated features. The training data includes features extracted from images, with the target variable being 'Label' (CE or LAA). The total number of instances is not specified."}
{  "User Requirement": "I want to build a segmentation model using U-Net architecture to classify medical images and predict masks for anomalies.",  "Dataset Attributes": "The dataset consists of medical images and their corresponding masks. The total number of instances is not specified, but it includes images with labels indicating the presence of anomalies (1 for anomaly, 0 for normal)."}
{  "User Requirement": "I want to preprocess a dataset, create new features, and build a regression model using Keras to predict the number of rings in a dataset related to marine life.",  "Dataset Attributes": "The dataset consists of numerical and categorical features related to marine organisms, with a target variable 'Rings' indicating the age of the organism. The training dataset has multiple features, while the test dataset is used for predictions."}
{  "User Requirement": "I want to build an image captioning model that generates captions for images using a combination of CNN for feature extraction and LSTM for sequence generation.",  "Dataset Attributes": "The dataset consists of images from the Flickr30k dataset along with corresponding captions. Each image is processed to extract features, and captions are preprocessed for training. The total number of images is not explicitly stated, but captions are mapped to image IDs."}
{  "User Requirement": "I want to build a model that classifies respiratory sounds into different disease categories using audio feature extraction and a 1D CNN.",  "Dataset Attributes": "The dataset consists of audio files (.wav) of respiratory sounds along with corresponding patient diagnosis labels. The total number of audio files is not explicitly stated, but they are associated with various respiratory conditions."}
{  "User Requirement": "I want to predict student performance based on game play data using an LSTM model, preprocess the data, and evaluate the model's performance across multiple questions.",  "Dataset Attributes": "The dataset consists of game play data with various features including elapsed time, event names, and coordinates. It contains multiple sessions with categorical and numerical attributes, and the target variable is the student's performance label."}
{  "User Requirement": "I want to build a DeepLabV3Plus model for multi-class image segmentation using the Oxford Pets dataset, preprocess the images and masks, train the model, and evaluate its performance.",  "Dataset Attributes": "The dataset consists of images and their corresponding segmentation masks for pet breeds. It contains training and testing splits, with images resized to 512x512 pixels and masks containing class labels."}
{  "User Requirement": "I want to build a binary classification model using BERT and CNN to classify comments as toxic or non-toxic, preprocess the data, train the model, and evaluate its performance.",  "Dataset Attributes": "The dataset consists of comments labeled as toxic or non-toxic. It contains a total of 6 toxicity labels, which are combined into a single binary label indicating whether a comment is toxic (1) or non-toxic (0)."}
{  "User Requirement": "I want to build and train an ensemble model using EfficientNet, DenseNet, and Xception for flower classification, leveraging TPU or GPU resources, and generate predictions for a Kaggle competition.",  "Dataset Attributes": "The dataset consists of flower images in TFRecord format, with a total of 104 classes. It includes training, validation, and test datasets, with images resized to 224x224 pixels."}
{  "User Requirement": "I want to develop a demonstration version of an image search system that outputs a similarity score between images and text queries, using a trained model to generate vector representations for both.",  "Dataset Attributes": "The dataset includes training data in 'train_dataset.csv', images in 'train_images', and annotations in 'CrowdAnnotations.tsv' and 'ExpertAnnotations.tsv'. The test data is in 'test_queries.csv' and 'test_images.csv'."}
{  "User Requirement": "I want to build an image captioning model that generates captions for images using a combination of CNN for feature extraction and LSTM for sequence generation.",  "Dataset Attributes": "The dataset consists of images and their corresponding captions, with a total of several thousand images. Each instance consists of an image file and a text caption."}
{  "User Requirement": "I want to build an ensemble model for image classification using multiple pre-trained architectures (Xception, DenseNet, EfficientNet) and optimize the model's performance on a Kaggle competition dataset.",  "Dataset Attributes": "The dataset consists of images and their corresponding labels, with a total of several thousand images. Each instance consists of an image file and a class label."}
