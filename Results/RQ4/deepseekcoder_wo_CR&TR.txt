```python
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Flatten, Dropout, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping

# Constants
IM_SIZE = 224
BATCH_SIZE = 32
EPOCHS = 20
DATA_DIR = '/path/to/your/dataset'

# Data preprocessing function
def preprocess_image(image, label):
    image = tf.cast(image, tf.float32) / 255.0
    return image, label

# Data augmentation and preprocessing
datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Load dataset
train_generator = datagen.flow_from_directory(
    DATA_DIR,
    target_size=(IM_SIZE, IM_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='binary',
    subset='training'
)

validation_generator = datagen.flow_from_directory(
    DATA_DIR,
    target_size=(IM_SIZE, IM_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='binary',
    subset='validation'
)

# Build the model using InceptionV3 as the base model
def build_model(input_shape=(IM_SIZE, IM_SIZE, 3)):
    # Load the InceptionV3 model without the top layers
    base_model = InceptionV3(include_top=False, weights='imagenet', input_shape=input_shape)
    
    # Freeze the base model layers
    base_model.trainable = False

    # Add custom layers on top of the base model
    inputs = Input(shape=input_shape)
    x = base_model(inputs, training=False)
    x = Flatten()(x)
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.5)(x)
    outputs = Dense(1, activation='sigmoid')(x)

    # Create the model
    model = Model(inputs, outputs)
    return model

# Compile the model
model = build_model()
model.compile(optimizer=Adam(learning_rate=0.001), loss=BinaryCrossentropy(), metrics=['accuracy'])

# Early stopping callback
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Train the model
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=EPOCHS,
    callbacks=[early_stopping]
)

# Evaluate the model
test_loss, test_accuracy = model.evaluate(validation_generator)
print(f'Test Accuracy: {test_accuracy * 100:.2f}%')

# Save the model
model.save('violence_detection_model.h5')
```
------------------------------------- 0
```python
import os
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D, Dropout, Dense, Conv2D, SeparableConv2D, MaxPooling2D, Flatten
from tensorflow.keras.models import Model, Sequential
import tensorflow as tf

# Load the dataset
train_dir = 'path_to_train_directory'
val_dir = 'path_to_validation_directory'
test_dir = 'path_to_test_directory'

# Define image parameters
image_size = 224
batch_size = 32
num_classes = 2  # Fresh and Stale

# Data preprocessing and augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=45,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.25,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(image_size, image_size),
    batch_size=batch_size,
    class_mode='binary'
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(image_size, image_size),
    batch_size=batch_size,
    class_mode='binary'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(image_size, image_size),
    batch_size=batch_size,
    class_mode='binary'
)

# Build the model
def build_model():
    base_model = ResNet50V2(input_shape=(image_size, image_size, 3), weights='imagenet', include_top=False)
    for layer in base_model.layers:
        layer.trainable = False

    x = base_model.output
    x = BatchNormalization()(x)
    x = GlobalAveragePooling2D()(x)
    x = Dense(1024, activation='relu')(x)
    x = Dropout(0.5)(x)
    x = Dense(512, activation='relu')(x)
    x = Dropout(0.5)(x)
    predictions = Dense(1, activation='sigmoid')(x)

    model = Model(inputs=base_model.input, outputs=predictions)
    return model

model = build_model()

# Compile the model
learning_rate = 1e-4
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    validation_data=val_generator,
    validation_steps=val_generator.samples // batch_size,
    epochs=15
)

# Plot training and validation accuracy
plt.figure(figsize=(7, 5))
plt.plot(history.history['accuracy'], label="Train Accuracy", color="blue", marker="*")
plt.plot(history.history['val_accuracy'], label="Validation Accuracy", color="red", marker="P")
plt.grid(True)
plt.legend()
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.show()

# Plot training and validation loss
plt.figure(figsize=(7, 5))
plt.plot(history.history['loss'], color="green", marker="D")
plt.plot(history.history['val_loss'], color="navy", marker="H")
plt.grid(True)
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train Loss', 'Validation Loss'], loc='upper left')
plt.show()

# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // batch_size)
print(f'Test Accuracy: {test_accuracy:.4f}')

# Save the model
model.save('fresh_stale_classifier.h5')
```
------------------------------------- 1
```python
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.applications.resnet50 import ResNet50
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import os
import pandas as pd
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

# Define the root directory
root_dir = '/path/to/your/dataset'

# Initialize lists to store data
image_paths = []
subsets = []
targets = []

# Iterate through the train and test directories
for subset in ['train', 'test']:
    subset_path = os.path.join(root_dir, subset)

    # Iterate through each class folder
    for class_folder in os.listdir(subset_path):
        class_path = os.path.join(subset_path, class_folder)

        # Iterate through images in the class folder
        for image_filename in os.listdir(class_path):
            image_path = os.path.join(class_path, image_filename)

            # Append data to lists
            image_paths.append(image_path)
            subsets.append(subset)
            targets.append(class_folder)

# Create DataFrame
df = pd.DataFrame({
    'Image Path': image_paths,
    'Subset': subsets,
    'Target': targets
})

# Filter the DataFrame to get only the "train" subset
train_df = df[df['Subset'] == 'train']
test_df = df[df['Subset'] == 'test']

# Data preprocessing and augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2
)

valid_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

classes = ['Very mild Dementia', 'Non Demented', 'Moderate Dementia', 'Mild Dementia']

# k-fold cross-validation
kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
accuracy_list = []
precision_list = []
recall_list = []

for train_idx, val_idx in kfold.split(train_df['Image Path'], train_df['Target']):
    x_train_df = train_df.iloc[train_idx]
    x_valid_df = train_df.iloc[val_idx]

    train_batches = train_datagen.flow_from_dataframe(
        dataframe=x_train_df,
        x_col="Image Path", y_col="Target",
        class_mode="categorical",
        classes=classes,
        target_size=(224, 224), batch_size=32, shuffle=True
    )

    valid_batches = valid_datagen.flow_from_dataframe(
        dataframe=x_valid_df,
        x_col="Image Path", y_col="Target",
        class_mode="categorical", classes=classes,
        target_size=(224, 224), batch_size=32, shuffle=False
    )

    test_batches = test_datagen.flow_from_dataframe(
        dataframe=test_df, classes=classes,
        x_col="Image Path", y_col="Target",
        class_mode=None,
        target_size=(224, 224), shuffle=False
    )

    # Load ResNet50 with pre-trained weights, excluding the top layer
    resnet50_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

    # Freeze the layers of ResNet50
    for layer in resnet50_model.layers:
        layer.trainable = False

    # Add custom layers on top of ResNet50
    x = resnet50_model.output
    x = Flatten()(x)
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.5)(x)
    predictions = Dense(4, activation='softmax')(x)

    # Create the final model
    skin_disease_classifier = Model(inputs=resnet50_model.input, outputs=predictions)

    # Compile the model
    skin_disease_classifier.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

    # Callbacks
    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
    model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)

    # Train the model
    history = skin_disease_classifier.fit(
        train_batches,
        validation_data=valid_batches,
        epochs=50,
        callbacks=[early_stopping, model_checkpoint]
    )

    # Evaluate the model on the validation set
    valid_batches.reset()
    valid_pred = skin_disease_classifier.predict(valid_batches)
    valid_predicted_class_indices = np.argmax(valid_pred, axis=1)

    # Calculate metrics for the current fold on the validation set
    val_true_labels = valid_batches.classes
    val_accuracy = accuracy_score(val_true_labels, valid_predicted_class_indices)
    val_precision = precision_score(val_true_labels, valid_predicted_class_indices, average='macro')
    val_recall = recall_score(val_true_labels, valid_predicted_class_indices, average='macro')

    # Store metrics for the current fold on the validation set
    accuracy_list.append(val_accuracy)
    precision_list.append(val_precision)
    recall_list.append(val_recall)

    # Generate classification report
    report = classification_report(val_true_labels, valid_predicted_class_indices, target_names=classes, digits=4)
    print(report)

# After all folds, calculate average and standard deviation of metrics on the validation set
average_val_accuracy = np.mean(accuracy_list)
std_dev_val_accuracy = np.std(accuracy_list)

average_val_precision = np.mean(precision_list)
std_dev_val_precision = np.std(precision_list)

average_val_recall = np.mean(recall_list)
std_dev_val_recall = np.std(recall_list)

# Print the means and standard deviations
mean_and_std_dev = {
    'accuracy_mean': average_val_accuracy,
    'accuracy_std_dev': std_dev_val_accuracy,
    'precision_mean': average_val_precision,
    'precision_std_dev': std_dev_val_precision,
    'recall_mean': average_val_recall,
    'recall_std_dev': std_dev_val_recall
}

print(mean_and_std_dev)

# Evaluate the model on the test set
test_batches.reset()
test_pred = skin_disease_classifier.predict(test_batches)
test_predicted_class_indices = np.argmax(test_pred, axis=1)

# Generate classification report for the test set
test_true_labels = test_batches.classes
test_report = classification_report(test_true_labels, test_predicted_class_indices, target_names=classes, digits=4)
print(test_report)

# Plot confusion matrix for the test set
cm = confusion_matrix(test_true_labels, test_predicted_class_indices)
plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(classes))
plt.xticks(tick_marks, classes, rotation=45)
plt.yticks(tick_marks, classes)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()
```
------------------------------------- 2
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import to_categorical
import os
import cv2

# Define paths and constants
DATA_DIR = 'path_to_dataset'  # Replace with the path to your dataset
IMG_SIZE = (224, 224)
NUM_CLASSES = 4
BATCH_SIZE = 32
EPOCHS = 100

# Load and preprocess data
def load_data(data_dir, img_size):
    images = []
    labels = []
    class_names = ['Healthy', 'Bunchy top', 'Fusarium wilt', 'Moko']
    for class_name in class_names:
        class_dir = os.path.join(data_dir, class_name)
        for img_name in os.listdir(class_dir):
            img_path = os.path.join(class_dir, img_name)
            img = cv2.imread(img_path, cv2.IMREAD_COLOR)
            img = cv2.resize(img, img_size)
            img = img / 255.0  # Normalize pixel values
            images.append(img)
            labels.append(class_names.index(class_name))
    return np.array(images), np.array(labels)

X, y = load_data(DATA_DIR, IMG_SIZE)

# Split data into training, validation, and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)

# Convert labels to one-hot encoding
y_train = to_categorical(y_train, NUM_CLASSES)
y_val = to_categorical(y_val, NUM_CLASSES)
y_test = to_categorical(y_test, NUM_CLASSES)

# Data augmentation
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
datagen.fit(X_train)

# Build the model
def build_model(input_shape, num_classes):
    inputs = Input(shape=input_shape)
    
    # Convolutional layers
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)
    x = BatchNormalization()(x)
    x = MaxPooling2D((2, 2))(x)
    
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D((2, 2))(x)
    
    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D((2, 2))(x)
    
    # Fully connected layers
    x = Flatten()(x)
    x = Dense(512, activation='relu')(x)
    x = Dropout(0.5)(x)
    x = BatchNormalization()(x)
    x = Dense(256, activation='relu')(x)
    x = Dropout(0.5)(x)
    x = BatchNormalization()(x)
    
    # Output layer
    outputs = Dense(num_classes, activation='softmax')(x)
    
    model = Model(inputs, outputs)
    return model

input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3)
model = build_model(input_shape, NUM_CLASSES)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)

# Train the model
history = model.fit(
    datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),
    epochs=EPOCHS,
    validation_data=(X_val, y_val),
    callbacks=[early_stopping, model_checkpoint]
)

# Evaluate the model
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f'Test accuracy: {test_acc:.4f}')

# Save the model
model.save('skin_lesion_classifier.h5')
```
------------------------------------- 3
```python
import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns
import os
import cv2
import tensorflow as tf
from tensorflow import keras   
from sklearn.utils import shuffle
from tensorflow.keras.utils import to_categorical
from keras.models import load_model
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Dropout, Input, LSTM, Reshape
from keras.models import Sequential, Model
from keras.layers import Conv2D, GlobalMaxPooling2D, MaxPooling2D, GlobalAveragePooling2D
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import datasets, layers, models
from keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Dropout
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score
from keras import regularizers
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

# Set seed for reproducibility
seed = 42
np.random.seed(seed)
tf.random.set_seed(seed)

# Define paths
train_path = 'path_to_train_directory'
val_path = 'path_to_validation_directory'
test_path = 'path_to_test_directory'

# Image parameters
IMG_SIZE = 224
ColorChannels = 3
batch_size = 32

# Data preprocessing and augmentation
train_datagen = ImageDataGenerator(
    rescale=1.0/255.0,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(rescale=1.0/255.0)
test_datagen = ImageDataGenerator(rescale=1.0/255.0)

train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=(IMG_SIZE, IMG_SIZE),
    color_mode='rgb',
    batch_size=batch_size,
    class_mode='categorical',
)

validation_generator = val_datagen.flow_from_directory(
    val_path,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=batch_size,
    color_mode='rgb',
    class_mode='categorical',
)

test_generator = test_datagen.flow_from_directory(
    test_path,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=batch_size,
    color_mode='rgb',
    class_mode='categorical',
    shuffle=False
)

# Visualize some training images
plt.figure(figsize=(15, 10))
plt.suptitle("Train Images", fontsize=20)
for i in range(30):
    img, label = train_generator.next()
    plt.subplot(5, 6, i + 1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(img[0])
    plt.xlabel(train_generator.class_indices)
plt.show()

# Define the model architecture
def Inception_model():
    input_tensor = Input(shape=(IMG_SIZE, IMG_SIZE, ColorChannels))
    baseModel = InceptionV3(include_top=False, weights='imagenet', input_tensor=input_tensor)
    
    headModel = baseModel.output
    headModel = GlobalAveragePooling2D()(headModel)
    headModel = Dense(128, activation="relu")(headModel)
    headModel = BatchNormalization()(headModel)
    headModel = Dropout(0.5)(headModel)
    headModel = Dense(4, activation="softmax")(headModel)  # 4 classes: meningioma, glioma, pituitary, no tumor
    
    model = Model(inputs=baseModel.input, outputs=headModel)

    for layer in baseModel.layers:
        layer.trainable = False

    return model

model = Inception_model()
model.summary()

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# Define callbacks
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.6, patience=20, min_lr=0.00005, verbose=1)
checkpoint = ModelCheckpoint("inception_brain_tumor.h5", save_best_only=True, monitor='val_accuracy', mode='max')
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train the model
epochs = 30
history = model.fit(
    train_generator,
    epochs=epochs,
    validation_data=validation_generator,
    callbacks=[early_stopping, checkpoint, reduce_lr]
)

# Evaluate the model
score, acc = model.evaluate(test_generator)
print('Test Loss =', score)
print('Test Accuracy =', acc)

# Generate predictions on the test set
predictions = model.predict(test_generator)
predicted_classes = np.argmax(predictions, axis=1)
true_classes = test_generator.classes
class_labels = list(test_generator.class_indices.keys())

# Print classification report and confusion matrix
print("Classification Report:")
print(classification_report(true_classes, predicted_classes, target_names=class_labels))

print("Confusion Matrix:")
print(confusion_matrix(true_classes, predicted_classes))

# Visualize predictions on test data
plt.figure(figsize=(16, 25))
class_label = ['meningioma', 'glioma', 'pituitary', 'no tumor']
image, label = test_generator.next()
for i in range(18):
    model_pred = model.predict(np.expand_dims(image[i], axis=0))
    plt.subplot(7, 3, i + 1)
    plt.imshow(image[i])
    plt.title(f"Prediction: {class_label[np.argmax(model_pred)]}\nOriginal: {class_label[np.argmax(label[i])]}")
    plt.axis("off")
plt.show()
```
------------------------------------- 4
```python
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, LeakyReLU, BatchNormalization, PReLU, Add, UpSampling2D, Dense, Flatten
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Hyperparameters
LEARNING_RATE = 0.0002
BATCH_SIZE = 8
EPOCHS = 50
IMAGE_SIZE_HR = 128
IMAGE_SIZE_LR = 32

# Data Preprocessing
def preprocess_image(image, target_size):
    image = tf.image.resize(image, target_size)
    image = (image - 127.5) / 127.5  # Normalize to [-1, 1]
    return image

def load_dataset(hr_dir, lr_dir):
    hr_images = []
    lr_images = []
    for filename in os.listdir(hr_dir):
        hr_path = os.path.join(hr_dir, filename)
        lr_path = os.path.join(lr_dir, filename)
        if os.path.exists(hr_path) and os.path.exists(lr_path):
            hr_image = tf.keras.preprocessing.image.load_img(hr_path)
            lr_image = tf.keras.preprocessing.image.load_img(lr_path)
            hr_image = preprocess_image(np.array(hr_image), (IMAGE_SIZE_HR, IMAGE_SIZE_HR))
            lr_image = preprocess_image(np.array(lr_image), (IMAGE_SIZE_LR, IMAGE_SIZE_LR))
            hr_images.append(hr_image)
            lr_images.append(lr_image)
    return np.array(lr_images), np.array(hr_images)

# Load Dataset
lr_images, hr_images = load_dataset('/path/to/high_res_images', '/path/to/low_res_images')

# Split data
X_train, X_test, y_train, y_test = train_test_split(lr_images, hr_images, test_size=0.2, random_state=42)

# Generator Model
def build_generator():
    def residual_block(layer_input):
        d = Conv2D(64, kernel_size=3, strides=1, padding='same')(layer_input)
        d = BatchNormalization(momentum=0.8)(d)
        d = PReLU()(d)
        d = Conv2D(64, kernel_size=3, strides=1, padding='same')(d)
        d = BatchNormalization(momentum=0.8)(d)
        d = Add()([d, layer_input])
        return d

    img_lr = Input(shape=(IMAGE_SIZE_LR, IMAGE_SIZE_LR, 3))
    
    c1 = Conv2D(64, kernel_size=9, strides=1, padding='same')(img_lr)
    c1 = PReLU()(c1)

    r = residual_block(c1)
    for _ in range(16):
        r = residual_block(r)

    c2 = Conv2D(64, kernel_size=3, strides=1, padding='same')(r)
    c2 = BatchNormalization(momentum=0.8)(c2)
    c2 = Add()([c2, c1])

    u1 = UpSampling2D(size=2)(c2)
    u1 = Conv2D(256, kernel_size=3, strides=1, padding='same')(u1)
    u1 = PReLU()(u1)

    u2 = UpSampling2D(size=2)(u1)
    u2 = Conv2D(256, kernel_size=3, strides=1, padding='same')(u2)
    u2 = PReLU()(u2)

    gen_hr = Conv2D(3, kernel_size=9, strides=1, padding='same', activation='tanh')(u2)

    return Model(img_lr, gen_hr)

# Discriminator Model
def build_discriminator():
    def d_block(layer_input, filters, strides=1, bn=True):
        d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)
        d = LeakyReLU(alpha=0.2)(d)
        if bn:
            d = BatchNormalization(momentum=0.8)(d)
        return d

    d0 = Input(shape=(IMAGE_SIZE_HR, IMAGE_SIZE_HR, 3))

    d1 = d_block(d0, 64, bn=False)
    d2 = d_block(d1, 64, strides=2)
    d3 = d_block(d2, 128)
    d4 = d_block(d3, 128, strides=2)
    d5 = d_block(d4, 256)
    d6 = d_block(d5, 256, strides=2)
    d7 = d_block(d6, 512)
    d8 = d_block(d7, 512, strides=2)

    d9 = Flatten()(d8)
    d10 = Dense(1024)(d9)
    d10 = LeakyReLU(alpha=0.2)(d10)
    validity = Dense(1, activation='sigmoid')(d10)

    return Model(d0, validity)

# SRGAN Model
class SRGAN:
    def __init__(self):
        self.generator = build_generator()
        self.discriminator = build_discriminator()
        self.discriminator.compile(optimizer=Adam(LEARNING_RATE, beta_1=0.5), loss='binary_crossentropy', metrics=['accuracy'])
        
        self.combined = self.build_combined()
        self.combined.compile(optimizer=Adam(LEARNING_RATE, beta_1=0.5), loss=['binary_crossentropy', 'mse'], loss_weights=[1e-3, 1])
    
    def build_combined(self):
        self.discriminator.trainable = False
        gan_input = Input(shape=(IMAGE_SIZE_LR, IMAGE_SIZE_LR, 3))
        gen_output = self.generator(gan_input)
        gan_output = self.discriminator(gen_output)
        combined = Model(gan_input, [gan_output, gen_output])
        return combined

    def train(self, lr_images, hr_images, epochs, batch_size, save_interval=50):
        for epoch in range(epochs):
            idx = np.random.randint(0, lr_images.shape[0], batch_size)
            lr_batch = lr_images[idx]
            hr_batch = hr_images[idx]
            
            generated_hr_images = self.generator.predict(lr_batch)
            
            valid = np.ones((batch_size, 1))
            fake = np.zeros((batch_size, 1))
            
            d_loss_real = self.discriminator.train_on_batch(hr_batch, valid)
            d_loss_fake = self.discriminator.train_on_batch(generated_hr_images, fake)
            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)
            
            g_loss = self.combined.train_on_batch(lr_batch, [valid, hr_batch])
            
            print(f"{epoch}/{epochs} [D loss: {d_loss[0]}, acc.: {100*d_loss[1]}%] [G loss: {g_loss[0]}]")

            if epoch % save_interval == 0:
                self.save_imgs(epoch)

    def save_imgs(self, epoch):
        r, c = 2, 2
        imgs_lr = X_test[:r*c]
        imgs_hr = y_test[:r*c]
        gen_hr = self.generator.predict(imgs_lr)

        gen_hr = 0.5 * gen_hr + 0.5
        imgs_hr = 0.5 * imgs_hr + 0.5
        imgs_lr = 0.5 * imgs_lr + 0.5

        fig, axs = plt.subplots(r, c)
        cnt = 0
        for i in range(r):
            for j in range(c):
                axs[i, j].imshow(imgs_lr[cnt])
                axs[i, j].axis('off')
                cnt += 1
        fig.savefig(f"images/lr_{epoch}.png")
        plt.close()

        fig, axs = plt.subplots(r, c)
        cnt = 0
        for i in range(r):
            for j in range(c):
                axs[i, j].imshow(gen_hr[cnt])
                axs[i, j].axis('off')
                cnt += 1
        fig.savefig(f"images/gen_{epoch}.png")
        plt.close()

        fig, axs = plt.subplots(r, c)
        cnt = 0
        for i in range(r):
            for j in range(c):
                axs[i, j].imshow(imgs_hr[cnt])
                axs[i, j].axis('off')
                cnt += 1
        fig.savefig(f"images/hr_{epoch}.png")
        plt.close()

# Train SRGAN
srgan = SRGAN()
srgan.train(X_train, y_train, EPOCHS, BATCH_SIZE, save_interval=50)

# Save the generator model
srgan.generator.save("srgan_generator.h5")
```
------------------------------------- 5
```python
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from skimage.metrics import peak_signal_noise_ratio, structural_similarity
from skimage.restoration import denoise_wavelet
from scipy.ndimage import gaussian_filter
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Constants
IMG_HEIGHT, IMG_WIDTH = 256, 256
BATCH_SIZE = 8
EPOCHS = 10
LEARNING_RATE = 0.001

# Load and preprocess dataset
def load_and_preprocess_data(data_dir):
    images = []
    denoised_images = []
    
    for img_name in os.listdir(data_dir):
        img_path = os.path.join(data_dir, img_name)
        img = load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
        img_array = img_to_array(img) / 255.0  # Normalize to [0, 1]
        
        # Apply Gaussian smoothing and wavelet transformation
        denoised_img = gaussian_filter(img_array, sigma=1.5)
        denoised_img = denoise_wavelet(denoised_img, multichannel=True, convert2ycbcr=True, method='BayesShrink', mode='soft')
        
        images.append(img_array)
        denoised_images.append(denoised_img)
    
    return np.array(images), np.array(denoised_images)

# U-Net model architecture
def build_unet_model():
    inputs = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))
    
    # Encoder
    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)
    pool1 = MaxPooling2D((2, 2))(conv1)
    drop1 = Dropout(0.5)(pool1)
    
    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(drop1)
    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)
    pool2 = MaxPooling2D((2, 2))(conv2)
    drop2 = Dropout(0.5)(pool2)
    
    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(drop2)
    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)
    
    # Decoder
    up4 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv3)
    merge4 = concatenate([conv2, up4], axis=3)
    drop4 = Dropout(0.5)(merge4)
    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(drop4)
    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv4)
    
    up5 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv4)
    merge5 = concatenate([conv1, up5], axis=3)
    drop5 = Dropout(0.5)(merge5)
    conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(drop5)
    conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv5)
    
    outputs = Conv2D(3, (1, 1), padding='same', activation='sigmoid')(conv5)
    
    model = Model(inputs=[inputs], outputs=[outputs])
    return model

# Custom evaluation metrics
def psnr(y_true, y_pred):
    return peak_signal_noise_ratio(y_true, y_pred)

def ssim(y_true, y_pred):
    return structural_similarity(y_true, y_pred, multichannel=True)

# Load dataset
data_dir = '../input/noisy_images'
images, denoised_images = load_and_preprocess_data(data_dir)

# Split dataset into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(images, denoised_images, test_size=0.2, random_state=42)

# Build and compile the model
model = build_unet_model()
model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='mse', metrics=[psnr, ssim])

# Train the model
history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_val, y_val))

# Save the model
model.save('unet_denoising_model.h5')

# Evaluation function
def evaluate(model, test_img_path):
    test_img = os.listdir(test_img_path)
    random.shuffle(test_img)
    
    for img_name in test_img:
        img_path = os.path.join(test_img_path, img_name)
        img = load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))
        img_array = img_to_array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        denoised_img = model.predict(img_array)
        
        plt.figure(figsize=(15, 12))
        display_list = [img_array[0], denoised_img[0]]
        title = ['Noisy Image', 'Denoised Image']
        
        for i in range(2):
            plt.subplot(1, 2, i+1)
            plt.title(title[i])
            plt.imshow(display_list[i])
            plt.axis('off')
        
        plt.show()

# Load the trained model and evaluate
test_model = tf.keras.models.load_model('unet_denoising_model.h5', compile=False)
evaluate(test_model, '../input/test_noisy_images')
```
------------------------------------- 6
```python
import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Dropout, LeakyReLU, ReLU, Concatenate, BatchNormalization
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Constants
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 16
EPOCHS = 50
LEARNING_RATE = 0.0002

# Load and preprocess images
def load_and_preprocess_images(image_paths, target_size=IMAGE_SIZE):
    images = []
    for path in image_paths:
        img = load_img(path, target_size=target_size)
        img_array = img_to_array(img) / 127.5 - 1  # Normalize to [-1, 1]
        images.append(img_array)
    return np.array(images)

# Load dataset
def load_dataset(hazy_image_dir, clear_image_dir):
    hazy_images = [os.path.join(hazy_image_dir, img) for img in os.listdir(hazy_image_dir) if img.endswith('.png')]
    clear_images = [os.path.join(clear_image_dir, img) for img in os.listdir(clear_image_dir) if img.endswith('.png')]
    
    hazy_images = load_and_preprocess_images(hazy_images)
    clear_images = load_and_preprocess_images(clear_images)
    
    return hazy_images, clear_images

# Split dataset into training and validation sets
def split_dataset(hazy_images, clear_images, test_size=0.2):
    X_train, X_val, y_train, y_val = train_test_split(hazy_images, clear_images, test_size=test_size, random_state=42)
    return X_train, X_val, y_train, y_val

# Define the generator model
def build_generator():
    def conv_block(filters, kernel_size, strides=2, activation=LeakyReLU(0.2)):
        return keras.Sequential([
            Conv2D(filters, kernel_size, strides=strides, padding='same', use_bias=False),
            BatchNormalization(),
            activation
        ])

    def deconv_block(filters, kernel_size, strides=2, activation=ReLU()):
        return keras.Sequential([
            Conv2DTranspose(filters, kernel_size, strides=strides, padding='same', use_bias=False),
            BatchNormalization(),
            activation
        ])

    inputs = Input(shape=[*IMAGE_SIZE, 3])
    x = conv_block(64, 4)(inputs)
    x = conv_block(128, 4)(x)
    x = conv_block(256, 4)(x)
    x = conv_block(512, 4)(x)
    x = conv_block(512, 4)(x)
    x = conv_block(512, 4)(x)
    x = conv_block(512, 4)(x)
    x = conv_block(512, 4)(x)

    x = deconv_block(512, 4)(x)
    x = deconv_block(512, 4)(x)
    x = deconv_block(512, 4)(x)
    x = deconv_block(512, 4)(x)
    x = deconv_block(256, 4)(x)
    x = deconv_block(128, 4)(x)
    x = deconv_block(64, 4)(x)

    outputs = Conv2DTranspose(3, 4, strides=2, padding='same', activation='tanh')(x)

    return Model(inputs, outputs)

# Define the loss function
def dehaze_loss(y_true, y_pred):
    return MeanSquaredError()(y_true, y_pred)

# Compile and train the model
def train_model(model, X_train, y_train, X_val, y_val, epochs=EPOCHS, batch_size=BATCH_SIZE):
    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE, beta_1=0.5), loss=dehaze_loss)
    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size)

# Function to visualize results
def visualize_results(generator, X_val, y_val, num_samples=5):
    for i in range(num_samples):
        hazy = X_val[i]
        clear = y_val[i]
        generated = generator.predict(np.expand_dims(hazy, axis=0))[0]
        
        hazy = (hazy * 127.5 + 127.5).astype(np.uint8)
        generated = (generated * 127.5 + 127.5).astype(np.uint8)
        clear = (clear * 127.5 + 127.5).astype(np.uint8)

        plt.figure(figsize=(15, 5))
        plt.subplot(1, 3, 1)
        plt.title('Hazy Image')
        plt.imshow(hazy)
        plt.axis('off')

        plt.subplot(1, 3, 2)
        plt.title('Generated Clear Image')
        plt.imshow(generated)
        plt.axis('off')

        plt.subplot(1, 3, 3)
        plt.title('Clear Image')
        plt.imshow(clear)
        plt.axis('off')

        plt.show()

# Main function to execute the pipeline
def main():
    # Paths to the dataset
    hazy_image_dir = '/path/to/hazy/images'
    clear_image_dir = '/path/to/clear/images'
    
    # Load and preprocess the dataset
    hazy_images, clear_images = load_dataset(hazy_image_dir, clear_image_dir)
    X_train, X_val, y_train, y_val = split_dataset(hazy_images, clear_images)
    
    # Build the model
    generator = build_generator()
    
    # Train the model
    train_model(generator, X_train, y_train, X_val, y_val)
    
    # Visualize the results
    visualize_results(generator, X_val, y_val)

if __name__ == "__main__":
    main()
```
------------------------------------- 7
```python
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, BatchNormalization, Activation, Concatenate, LeakyReLU
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import numpy as np
import matplotlib.pyplot as plt

# Hyperparameters
IMG_SIZE = 256
BATCH_SIZE = 1
EPOCHS = 200
LEARNING_RATE = 0.0002
LAMBDA_CYCLE = 10.0

# Load and preprocess the dataset
def preprocess_image(image):
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])
    image = (image / 127.5) - 1  # Normalize to [-1, 1]
    return image

def load_dataset(tfrecord_path):
    raw_dataset = tf.data.TFRecordDataset(tfrecord_path)
    dataset = raw_dataset.map(lambda x: tf.io.parse_tensor(x, tf.uint8))
    dataset = dataset.map(preprocess_image)
    dataset = dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE)
    return dataset

# Define the generator and discriminator models
def build_generator(input_shape):
    """Builds a generator model using U-Net architecture."""
    def conv_block(x, filters, kernel_size=4, strides=2, padding='same', use_bn=True):
        x = Conv2D(filters, kernel_size, strides=strides, padding=padding)(x)
        if use_bn:
            x = BatchNormalization()(x)
        x = LeakyReLU(alpha=0.2)(x)
        return x

    def deconv_block(x, skip_input, filters, kernel_size=4, strides=2, padding='same', use_bn=True):
        x = Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding)(x)
        if use_bn:
            x = BatchNormalization()(x)
        x = Activation('relu')(x)
        x = Concatenate()([x, skip_input])
        return x

    inputs = Input(shape=input_shape)
    
    # Encoder
    e1 = conv_block(inputs, 64, use_bn=False)
    e2 = conv_block(e1, 128)
    e3 = conv_block(e2, 256)
    e4 = conv_block(e3, 512)
    e5 = conv_block(e4, 512)
    e6 = conv_block(e5, 512)
    e7 = conv_block(e6, 512)
    
    # Bottleneck
    b = conv_block(e7, 512, strides=1)
    
    # Decoder
    d1 = deconv_block(b, e7, 512)
    d2 = deconv_block(d1, e6, 512)
    d3 = deconv_block(d2, e5, 512)
    d4 = deconv_block(d3, e4, 512)
    d5 = deconv_block(d4, e3, 256)
    d6 = deconv_block(d5, e2, 128)
    d7 = deconv_block(d6, e1, 64)
    
    outputs = Conv2DTranspose(3, kernel_size=4, strides=2, padding='same', activation='tanh')(d7)
    
    return Model(inputs, outputs, name="Generator")

def build_discriminator(input_shape):
    """Builds a discriminator model using PatchGAN architecture."""
    def d_layer(x, filters, kernel_size=4, strides=2, padding='same', use_bn=True):
        x = Conv2D(filters, kernel_size, strides=strides, padding=padding)(x)
        if use_bn:
            x = BatchNormalization()(x)
        x = LeakyReLU(alpha=0.2)(x)
        return x

    inputs = Input(shape=input_shape)
    
    x = d_layer(inputs, 64, use_bn=False)
    x = d_layer(x, 128)
    x = d_layer(x, 256)
    x = d_layer(x, 512, strides=1)
    
    outputs = Conv2D(1, kernel_size=4, strides=1, padding='same')(x)
    
    return Model(inputs, outputs, name="Discriminator")

# Define the CycleGAN model
class CycleGAN:
    def __init__(self, img_shape):
        self.img_shape = img_shape
        
        # Build and compile the discriminators
        self.d_A = build_discriminator(img_shape)
        self.d_B = build_discriminator(img_shape)
        self.d_A.compile(loss='mse', optimizer=Adam(learning_rate=LEARNING_RATE, beta_1=0.5), metrics=['accuracy'])
        self.d_B.compile(loss='mse', optimizer=Adam(learning_rate=LEARNING_RATE, beta_1=0.5), metrics=['accuracy'])
        
        # Build the generators
        self.g_AB = build_generator(img_shape)
        self.g_BA = build_generator(img_shape)
        
        # Input images from both domains
        img_A = Input(shape=img_shape)
        img_B = Input(shape=img_shape)
        
        # Translate images to the other domain
        fake_B = self.g_AB(img_A)
        fake_A = self.g_BA(img_B)
        
        # Translate images back to original domain
        reconstr_A = self.g_BA(fake_B)
        reconstr_B = self.g_AB(fake_A)
        
        # Identity mapping of images
        img_A_id = self.g_BA(img_A)
        img_B_id = self.g_AB(img_B)
        
        # For the combined model we will only train the generators
        self.d_A.trainable = False
        self.d_B.trainable = False
        
        # Discriminators determine validity of translated images
        valid_A = self.d_A(fake_A)
        valid_B = self.d_B(fake_B)
        
        # Combined model trains generators to fool discriminators
        self.combined = Model(inputs=[img_A, img_B], outputs=[valid_A, valid_B, reconstr_A, reconstr_B, img_A_id, img_B_id])
        self.combined.compile(loss=['mse', 'mse', 'mae', 'mae', 'mae', 'mae'],
                              loss_weights=[1, 1, LAMBDA_CYCLE, LAMBDA_CYCLE, LAMBDA_CYCLE, LAMBDA_CYCLE],
                              optimizer=Adam(learning_rate=LEARNING_RATE, beta_1=0.5))

    def train(self, data_A, data_B, epochs, batch_size=1, sample_interval=50):
        valid = np.ones((batch_size,) + self.d_A.output_shape[1:])
        fake = np.zeros((batch_size,) + self.d_A.output_shape[1:])
        
        for epoch in range(epochs):
            for batch_i, (imgs_A, imgs_B) in enumerate(zip(data_A, data_B)):
                # Translate images to opposite domain
                fake_B = self.g_AB.predict(imgs_A)
                fake_A = self.g_BA.predict(imgs_B)
                
                # Train discriminators
                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)
                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)
                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)
                
                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)
                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)
                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)
                
                # Total discriminator loss
                d_loss = 0.5 * np.add(dA_loss, dB_loss)
                
                # Train generators
                g_loss = self.combined.train_on_batch([imgs_A, imgs_B], [valid, valid, imgs_A, imgs_B, imgs_A, imgs_B])
                
                # Plot the progress
                if batch_i % sample_interval == 0:
                    print(f"Epoch {epoch}/{epochs} Batch {batch_i}/{len(data_A)} [D loss: {d_loss[0]}, acc: {100*d_loss[1]}] [G loss: {g_loss[0]}]")
                    self.sample_images(epoch, batch_i)

    def sample_images(self, epoch, batch_i):
        r, c = 2, 3
        imgs_A = next(iter(data_A))
        imgs_B = next(iter(data_B))
        
        fake_B = self.g_AB.predict(imgs_A)
        fake_A = self.g_BA.predict(imgs_B)
        
        gen_imgs = np.concatenate([imgs_A, fake_B, imgs_B, fake_A])
        gen_imgs = 0.5 * gen_imgs + 0.5
        
        titles = ['Original', 'Translated', 'Reconstructed']
        fig, axs = plt.subplots(r, c)
        cnt = 0
        for i in range(r):
            for j in range(c):
                axs[i, j].imshow(gen_imgs[cnt])
                axs[i, j].set_title(titles[j])
                axs[i, j].axis('off')
                cnt += 1
        fig.savefig(f"images/{epoch}_{batch_i}.png")
        plt.close()

# Load the datasets
data_A = load_dataset('path_to_monet_tfrecords')
data_B = load_dataset('path_to_photos_tfrecords')

# Initialize and train the CycleGAN model
cycle_gan = CycleGAN(img_shape=(IMG_SIZE, IMG_SIZE, 3))
cycle_gan.train(data_A, data_B, epochs=EPOCHS, batch_size=BATCH_SIZE, sample_interval=200)
```
------------------------------------- 8
```python
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Dropout, UpSampling2D, Conv2DTranspose, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Load the dataset
# Assuming the dataset is stored in numpy files: 'input_data.npy' and 'output_data.npy'
input_data = np.load('input_data.npy')  # Shape: (25000, 20, 8, 1)
output_data = np.load('output_data.npy')  # Shape: (25000, 64, 64, 2)

# Split the dataset into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(input_data, output_data, test_size=0.2, random_state=42)

# Define the U-Net architecture
def build_unet(input_shape):
    inputs = Input(input_shape)

    # Encoder
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)
    conv1 = BatchNormalization()(conv1)
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)
    conv1 = BatchNormalization()(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)
    conv2 = BatchNormalization()(conv2)
    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)
    conv2 = BatchNormalization()(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)
    conv3 = BatchNormalization()(conv3)
    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)
    conv3 = BatchNormalization()(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)

    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)
    conv4 = BatchNormalization()(conv4)
    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)
    conv4 = BatchNormalization()(conv4)
    drop4 = Dropout(0.5)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)

    # Bridge
    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)
    conv5 = BatchNormalization()(conv5)
    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)
    conv5 = BatchNormalization()(conv5)
    drop5 = Dropout(0.5)(conv5)

    # Decoder
    up6 = Conv2DTranspose(512, 2, activation='relu', padding='same', strides=(2, 2))(drop5)
    merge6 = concatenate([drop4, up6], axis=3)
    conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)
    conv6 = BatchNormalization()(conv6)
    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)
    conv6 = BatchNormalization()(conv6)

    up7 = Conv2DTranspose(256, 2, activation='relu', padding='same', strides=(2, 2))(conv6)
    merge7 = concatenate([conv3, up7], axis=3)
    conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)
    conv7 = BatchNormalization()(conv7)
    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)
    conv7 = BatchNormalization()(conv7)

    up8 = Conv2DTranspose(128, 2, activation='relu', padding='same', strides=(2, 2))(conv7)
    merge8 = concatenate([conv2, up8], axis=3)
    conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)
    conv8 = BatchNormalization()(conv8)
    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)
    conv8 = BatchNormalization()(conv8)

    up9 = Conv2DTranspose(64, 2, activation='relu', padding='same', strides=(2, 2))(conv8)
    merge9 = concatenate([conv1, up9], axis=3)
    conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)
    conv9 = BatchNormalization()(conv9)
    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)
    conv9 = BatchNormalization()(conv9)

    # Output layer
    outputs = Conv2D(2, 1, activation='sigmoid')(conv9)

    model = Model(inputs=inputs, outputs=outputs)
    return model

# Build the U-Net model
input_shape = (20, 8, 1)
unet = build_unet(input_shape)

# Compile the model
unet.compile(optimizer=Adam(learning_rate=1e-4), loss='mean_squared_error', metrics=['accuracy'])

# Define callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = unet.fit(
    X_train, y_train,
    batch_size=16,
    epochs=50,
    validation_data=(X_val, y_val),
    callbacks=[early_stopping]
)

# Plot the training and validation loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Save the model
unet.save('unet_model.h5')

# Example of using the model to predict
test_input = X_val[0:1]
predicted_output = unet.predict(test_input)

# Display the input and predicted output
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(test_input[0, :, :, 0], cmap='gray')
plt.title('Input Image')
plt.subplot(1, 2, 2)
plt.imshow(predicted_output[0, :, :, 0], cmap='gray')
plt.title('Predicted Output')
plt.show()
```
------------------------------------- 9
```python
import numpy as np
import pandas as pd
import os
import tensorflow as tf
from tensorflow.keras.layers import LSTM, Bidirectional, Dropout, Embedding, Dense, Input, Conv2D, MaxPooling2D, Flatten, add
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
from tqdm.notebook import tqdm
import warnings
warnings.filterwarnings("ignore")

# Load the dataset
def load_flickr8k_data(image_dir, caption_file):
    with open(caption_file, 'r') as f:
        captions = f.readlines()
    
    data = {}
    for line in captions:
        parts = line.strip().split('\t')
        image_id = parts[0].split('#')[0]
        caption = parts[1]
        if image_id not in data:
            data[image_id] = []
        data[image_id].append(caption)
    
    image_captions = []
    for image_id, captions in data.items():
        image_path = os.path.join(image_dir, image_id)
        for caption in captions:
            image_captions.append((image_path, caption))
    
    return image_captions

# Preprocess images using VGG16
def preprocess_image(image_path, model):
    img = load_img(image_path, target_size=(224, 224))
    img = img_to_array(img)
    img = np.expand_dims(img, axis=0)
    img = preprocess_input(img)
    feature = model.predict(img, verbose=0)
    return feature.flatten()

# Preprocess captions
def preprocess_caption(caption, tokenizer, max_length):
    caption = caption.lower()
    caption = 'startseq ' + caption + ' endseq'
    seq = tokenizer.texts_to_sequences([caption])[0]
    return pad_sequences([seq], maxlen=max_length, padding='post')[0]

# Tokenize captions
def create_tokenizer(captions):
    tokenizer = Tokenizer()
    caption_texts = []
    for caption_list in captions.values():
        caption_texts.extend(caption_list)
    tokenizer.fit_on_texts(caption_texts)
    return tokenizer

# Data generator
def data_generator(image_captions, tokenizer, max_length, batch_size, model):
    while True:
        np.random.shuffle(image_captions)
        for start in range(0, len(image_captions), batch_size):
            batch_images = []
            batch_captions = []
            for image_path, caption in image_captions[start:start + batch_size]:
                img = preprocess_image(image_path, model)
                cap = preprocess_caption(caption, tokenizer, max_length)
                batch_images.append(img)
                batch_captions.append(cap)
            yield [np.array(batch_images), np.array(batch_captions)], np.zeros(len(batch_images))

# Define the model
def define_model(vocab_size, max_length):
    # Image feature extraction model
    inputs1 = Input(shape=(4096,))
    fe1 = Dropout(0.4)(inputs1)
    fe2 = Dense(256, activation='relu')(fe1)
    
    # Sequence model
    inputs2 = Input(shape=(max_length,))
    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)
    se2 = Dropout(0.4)(se1)
    se3 = LSTM(256)(se2)
    
    # Merging both models
    decoder1 = add([fe2, se3])
    decoder2 = Dense(256, activation='relu')(decoder1)
    outputs = Dense(vocab_size, activation='softmax')(decoder2)
    
    # Tie it together [image, seq] [word]
    model = Model(inputs=[inputs1, inputs2], outputs=outputs)
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Load and preprocess data
image_dir = 'path_to_flickr8k_images'
caption_file = 'path_to_flickr8k_captions.txt'
image_captions = load_flickr8k_data(image_dir, caption_file)

# Load VGG16 model
vgg16 = VGG16(weights='imagenet', include_top=False, pooling='avg')
vgg16.trainable = False

# Tokenize captions
captions_dict = {}
for image_path, caption in image_captions:
    if image_path not in captions_dict:
        captions_dict[image_path] = []
    captions_dict[image_path].append(caption)

tokenizer = create_tokenizer(captions_dict)
vocab_size = len(tokenizer.word_index) + 1
max_length = max(len(seq) for cap in captions_dict.values() for seq in tokenizer.texts_to_sequences([cap])[0])

# Split data into training and validation sets
train_captions, val_captions = train_test_split(image_captions, test_size=0.2, random_state=42)

# Model parameters
batch_size = 32

# Define the model
model = define_model(vocab_size, max_length)
model.summary()

# Training
train_generator = data_generator(train_captions, tokenizer, max_length, batch_size, vgg16)
val_generator = data_generator(val_captions, tokenizer, max_length, batch_size, vgg16)

epochs = 10
steps_per_epoch = len(train_captions) // batch_size
validation_steps = len(val_captions) // batch_size

model.fit(train_generator, epochs=epochs, steps_per_epoch=steps_per_epoch, validation_data=val_generator, validation_steps=validation_steps)

# Inference
def generate_caption(image_path, model, tokenizer, max_length):
    image = preprocess_image(image_path, vgg16)
    image = np.expand_dims(image, axis=0)
    caption = ['startseq']
    for _ in range(max_length):
        sequence = tokenizer.texts_to_sequences([caption])[0]
        sequence = pad_sequences([sequence], maxlen=max_length, padding='post')
        preds = model.predict([image, sequence], verbose=0)
        pred_word_index = np.argmax(preds[0, -1, :])
        pred_word = tokenizer.index_word[pred_word_index]
        if pred_word == 'endseq':
            break
        caption.append(pred_word)
    return ' '.join(caption[1:-1])

# Example usage
image_path = 'path_to_test_image.jpg'
caption = generate_caption(image_path, model, tokenizer, max_length)
print(caption)
```
------------------------------------- 10
```python
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dropout, Dense, Embedding, TimeDistributed, Concatenate
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import SparseCategoricalCrossentropy
from tensorflow.keras.metrics import SparseCategoricalAccuracy
from tensorflow.keras.callbacks import EarlyStopping

# Hyperparameters
MAX_FRAMES = 300  # Maximum number of frames in a gesture sequence
NUM_LANDMARKS = 21  # Number of hand landmarks
MAX_CHARACTERS = 100  # Maximum number of characters in the output phrase
EMBEDDING_DIM = 512
BATCH_SIZE = 32
EPOCHS = 100
LEARNING_RATE = 1e-3

# Character mapping
char_to_index = {char: idx for idx, char in enumerate("abcdefghijklmnopqrstuvwxyz ")}
index_to_char = {idx: char for char, idx in char_to_index.items()}

# Load the dataset
train_df = pd.read_csv("path_to_train_dataset.csv")
test_df = pd.read_csv("path_to_test_dataset.csv")

# Tokenize the text data
tokenizer = Tokenizer(filters="")
tokenizer.fit_on_texts(train_df["phrases"].values)
voc_size = len(tokenizer.word_index) + 1

# Preprocessing function
def preprocess_data(df, max_frames, max_characters):
    """
    Preprocesses the keypoint data and phrases.
    :param df: DataFrame containing keypoints and phrases
    :param max_frames: Maximum number of frames in a gesture sequence
    :param max_characters: Maximum number of characters in the output phrase
    :return: Padded keypoint sequences and phrase indices
    """
    keypoints = df['keypoints'].apply(lambda x: np.array(eval(x)))
    phrases = df['phrases'].values
    
    # Pad keypoint sequences to MAX_FRAMES
    keypoints_padded = pad_sequences(keypoints, maxlen=max_frames, padding='post', dtype='float32')
    
    # Convert phrases to character indices and pad to MAX_CHARACTERS
    phrase_indices = [[char_to_index[char] for char in phrase] for phrase in phrases]
    phrase_indices_padded = pad_sequences(phrase_indices, maxlen=max_characters, padding='post', dtype='int32')
    
    return keypoints_padded, phrase_indices_padded

# Custom Data Generator
class CustomDataGenerator(tf.keras.utils.Sequence):
    def __init__(self, df, batch_size, max_frames, max_characters, shuffle=True):
        self.df = df.copy()
        self.batch_size = batch_size
        self.max_frames = max_frames
        self.max_characters = max_characters
        self.shuffle = shuffle
        self.n = len(self.df)

    def on_epoch_end(self):
        if self.shuffle:
            self.df = self.df.sample(frac=1).reset_index(drop=True)

    def __len__(self):
        return self.n // self.batch_size

    def __getitem__(self, index):
        batch = self.df.iloc[index * self.batch_size:(index + 1) * self.batch_size, :]
        X, y = self.__get_data(batch)
        return X, y

    def __get_data(self, batch):
        keypoints, phrases = preprocess_data(batch, self.max_frames, self.max_characters)
        return keypoints, phrases

# Initialize Data Generators
train_generator = CustomDataGenerator(df=train_df, batch_size=BATCH_SIZE, max_frames=MAX_FRAMES, max_characters=MAX_CHARACTERS)
test_generator = CustomDataGenerator(df=test_df, batch_size=BATCH_SIZE, max_frames=MAX_FRAMES, max_characters=MAX_CHARACTERS)

# Model definition
def create_model():
    """
    Creates the ASL fingerspelling recognition model.
    :return: Keras model
    """
    # Input layer for keypoint sequences
    input_seq = Input(shape=(MAX_FRAMES, NUM_LANDMARKS))
    
    # Convolutional layers
    x = Conv1D(512, 8, padding='same', activation='relu')(input_seq)
    x = MaxPooling1D()(x)
    x = Conv1D(512, 5, padding='same', activation='relu')(x)
    x = MaxPooling1D()(x)
    
    # Bidirectional LSTM layers
    x = Bidirectional(LSTM(512, return_sequences=True))(x)
    x = Dropout(0.3)(x)
    x = Bidirectional(LSTM(512, return_sequences=True))(x)
    x = Bidirectional(LSTM(512, return_sequences=True))(x)
    
    # Dense layers
    x = TimeDistributed(Dense(512, activation='relu'))(x)
    x = TimeDistributed(Dense(len(char_to_index), activation='softmax'))(x)
    
    # Model compilation
    model = Model(inputs=input_seq, outputs=x)
    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),
                  loss=SparseCategoricalCrossentropy(from_logits=False),
                  metrics=[SparseCategoricalAccuracy(name='accuracy')])
    
    return model

# Create and train the model
model = create_model()
model.summary()
model.fit(train_generator, epochs=EPOCHS, validation_data=test_generator, callbacks=[EarlyStopping(monitor='val_loss', patience=3)])

# Save the model
model.save("asl_fingerspelling_model.h5")

# Function to predict phrases from keypoints
def predict_phrase(model, keypoints, max_length):
    keypoints = np.array([keypoints])
    in_text = 'sos'
    for i in range(max_length):
        phrase_indices = [[char_to_index[char] for char in in_text]]
        phrase_indices_padded = pad_sequences(phrase_indices, maxlen=max_length, padding='post', dtype='int32')
        y_pred = model.predict([keypoints, phrase_indices_padded])
        y_pred = np.argmax(y_pred, axis=-1)
        word = index_to_char[y_pred[-1]]
        if word is None or word == 'eos':
            break
        in_text += " " + word
    return in_text

# Example usage
example_keypoints = train_df.iloc[0]['keypoints']
predicted_phrase = predict_phrase(model, eval(example_keypoints), MAX_CHARACTERS)
print("Predicted Phrase:", predicted_phrase)
```
------------------------------------- 11
```python
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Dense, Lambda, Bidirectional, LSTM, Embedding, Concatenate, Flatten, Dropout, Reshape
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.optimizers import Adam
import pickle

# Hyperparameters
BATCH_SIZE = 32
EPOCHS = 10
LEARNING_RATE = 0.001
MAX_SEQ_LENGTH = 20
EMBEDDING_DIM = 256

# Load and preprocess the dataset
def load_data(image_paths, captions, max_caption_length):
    images = []
    tokenizer = Tokenizer(char_level=True)
    tokenizer.fit_on_texts(captions)
    sequences = tokenizer.texts_to_sequences(captions)
    padded_sequences = pad_sequences(sequences, maxlen=max_caption_length, padding='post')
    for path in image_paths:
        img = load_img(path, target_size=(224, 224), color_mode='rgb')
        img = img_to_array(img)
        img = img / 255.0
        images.append(img)
    return np.array(images), np.array(padded_sequences), tokenizer

# Feature extraction using VGG16
def extract_features(images):
    vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    features = vgg_model.predict(images)
    return features

# Define the model architecture
def build_model(vocab_size, max_caption_length):
    # Image feature input
    image_input = Input(shape=(7, 7, 512))
    x = MaxPooling2D()(image_input)
    x = Flatten()(x)
    x = Dense(512, activation='relu')(x)
    x = Reshape((1, 512))(x)
    
    # Text sequence input
    caption_input = Input(shape=(max_caption_length,))
    embedding = Embedding(vocab_size, EMBEDDING_DIM, input_length=max_caption_length)(caption_input)
    
    # Concatenate image features and text sequences
    merged = Concatenate()([x, embedding])
    
    # LSTM layers
    blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(merged)
    blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(blstm_1)
    
    # Output layer
    outputs = Dense(vocab_size, activation='softmax')(blstm_2)
    
    # Define the model
    model = Model(inputs=[image_input, caption_input], outputs=outputs)
    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss='categorical_crossentropy', metrics=['accuracy'])
    return model

# Load the dataset
train_image_paths = ['path_to_train_images/image1.jpg', 'path_to_train_images/image2.jpg', ...]
train_captions = ['caption for image1', 'caption for image2', ...]
test_image_paths = ['path_to_test_images/image1.jpg', 'path_to_test_images/image2.jpg', ...]
test_captions = ['caption for test image1', 'caption for test image2', ...]

train_images, train_sequences, tokenizer = load_data(train_image_paths, train_captions, MAX_SEQ_LENGTH)
test_images, test_sequences, _ = load_data(test_image_paths, test_captions, MAX_SEQ_LENGTH)

# Extract features
train_features = extract_features(train_images)
test_features = extract_features(test_images)

# Prepare the labels
vocab_size = len(tokenizer.word_index) + 1
train_labels = to_categorical(train_sequences, num_classes=vocab_size)
test_labels = to_categorical(test_sequences, num_classes=vocab_size)

# Build the model
model = build_model(vocab_size, MAX_SEQ_LENGTH)

# Define callbacks
checkpoint = ModelCheckpoint('model_weights.h5', monitor='val_loss', save_best_only=True, mode='min')

# Train the model
model.fit([train_features, train_sequences], train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=([test_features, test_sequences], test_labels), callbacks=[checkpoint])

# Save the model and tokenizer
model.save('full_model.h5')
with open('tokenizer.pkl', 'wb') as f:
    pickle.dump(tokenizer, f)

# Load the model for inference
loaded_model = tf.keras.models.load_model('full_model.h5')
with open('tokenizer.pkl', 'rb') as f:
    tokenizer = pickle.load(f)

# Inference on a new image
def predict_caption(image_path, model, tokenizer, max_caption_length):
    img = load_img(image_path, target_size=(224, 224), color_mode='rgb')
    img = img_to_array(img)
    img = img / 255.0
    img = np.expand_dims(img, axis=0)
    img_features = extract_features(img)
    
    # Start token
    start_token = tokenizer.texts_to_sequences(['start'])[0]
    start_token = pad_sequences([start_token], maxlen=max_caption_length, padding='post')
    
    # Predict the caption
    for i in range(max_caption_length):
        preds = model.predict([img_features, start_token])
        pred_word_index = np.argmax(preds[0, i, :])
        start_token[0, i+1] = pred_word_index
    
    # Convert the sequence to text
    caption_sequence = start_token[0]
    caption_text = tokenizer.sequences_to_texts([caption_sequence])[0]
    return caption_text

# Example usage
image_path = 'path_to_test_image/test_image.jpg'
predicted_caption = predict_caption(image_path, loaded_model, tokenizer, MAX_SEQ_LENGTH)
print("Predicted Caption:", predicted_caption)
```
------------------------------------- 12
```python
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Dense, Bidirectional, LSTM, Reshape, Dropout, Embedding, add
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import CategoricalCrossentropy
from tensorflow.keras.metrics import CategoricalAccuracy
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tqdm import tqdm

# Define paths
BASE_DIR = '/path/to/license_plate_images'
WORKING_DIR = '/path/to/working_directory'

# Define constants
IMAGE_HEIGHT = 32
IMAGE_WIDTH = 128
NUM_CHANNELS = 1
MAX_SEQUENCE_LENGTH = 8  # Maximum number of characters in a license plate

# Preprocessing function
def preprocess_image(image_path):
    img = load_img(image_path, color_mode='grayscale', target_size=(IMAGE_HEIGHT, IMAGE_WIDTH))
    img_array = img_to_array(img) / 255.0
    return img_array

# Load dataset
def load_dataset(data_dir):
    images = []
    labels = []
    for filename in os.listdir(data_dir):
        if filename.endswith('.jpg') or filename.endswith('.png'):
            image_path = os.path.join(data_dir, filename)
            images.append(preprocess_image(image_path))
            # Assuming the filename contains the label
            label = filename.split('.')[0]  # Extract label from filename
            labels.append(label)
    return np.array(images), labels

# Tokenize labels
def tokenize_labels(labels):
    tokenizer = Tokenizer(char_level=True)
    tokenizer.fit_on_texts(labels)
    sequences = tokenizer.texts_to_sequences(labels)
    sequences = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')
    return sequences, tokenizer

# Data generator
def data_generator(images, labels, tokenizer, batch_size, vocab_size):
    num_samples = len(images)
    while True:
        for offset in range(0, num_samples, batch_size):
            batch_images = images[offset:offset + batch_size]
            batch_labels = labels[offset:offset + batch_size]
            batch_labels_one_hot = [to_categorical(label, vocab_size) for label in batch_labels]
            yield batch_images, np.array(batch_labels_one_hot)

# Build the model
def build_model(vocab_size, max_length):
    inputs = Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS))
    
    # CNN layers for feature extraction
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)
    x = BatchNormalization()(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)
    
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)
    
    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)
    
    # Reshape for LSTM
    x = Reshape((-1, x.shape[-1] * x.shape[-2]))(x)
    
    # Bidirectional LSTM layers
    x = Bidirectional(LSTM(128, return_sequences=True))(x)
    x = Dropout(0.5)(x)
    x = Bidirectional(LSTM(128, return_sequences=True))(x)
    x = Dropout(0.5)(x)
    
    # Dense layer for output
    outputs = Dense(vocab_size, activation='softmax')(x)
    
    model = Model(inputs, outputs)
    return model

# Load and preprocess the dataset
images, labels = load_dataset(os.path.join(BASE_DIR, 'Images'))
sequences, tokenizer = tokenize_labels(labels)
vocab_size = len(tokenizer.word_index) + 1

# Split the dataset into training and validation sets
from sklearn.model_selection import train_test_split
train_images, val_images, train_labels, val_labels = train_test_split(images, sequences, test_size=0.2, random_state=42)

# Define batch size and number of epochs
BATCH_SIZE = 32
EPOCHS = 50

# Define data generators
train_generator = data_generator(train_images, train_labels, tokenizer, BATCH_SIZE, vocab_size)
val_generator = data_generator(val_images, val_labels, tokenizer, BATCH_SIZE, vocab_size)

# Define callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Build and compile the model
model = build_model(vocab_size, MAX_SEQUENCE_LENGTH)
model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=[CategoricalAccuracy()])

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=len(train_images) // BATCH_SIZE,
    validation_data=val_generator,
    validation_steps=len(val_images) // BATCH_SIZE,
    epochs=EPOCHS,
    callbacks=[early_stopping]
)

# Save the model
model.save(os.path.join(WORKING_DIR, 'license_plate_recognition_model.h5'))

# Function to convert index to word
def idx_to_word(integer, tokenizer):
    for word, index in tokenizer.word_index.items():
        if index == integer:
            return word
    return None

# Function to predict caption
def predict_caption(model, image, tokenizer, max_length):
    in_text = ''
    for i in range(max_length):
        sequence = tokenizer.texts_to_sequences([in_text])[0]
        sequence = pad_sequences([sequence], max_length)
        yhat = model.predict(image, verbose=0)
        yhat = np.argmax(yhat)
        word = idx_to_word(yhat, tokenizer)
        if word is None:
            break
        in_text += word
    return in_text

# Evaluate the model
actual, predicted = list(), list()
for i in tqdm(range(len(val_images))):
    y_pred = predict_caption(model, val_images[i], tokenizer, MAX_SEQUENCE_LENGTH)
    actual_caption = ''.join([idx_to_word(idx, tokenizer) for idx in val_labels[i] if idx != 0])
    predicted.append(y_pred)
    actual.append(actual_caption)

# Calculate BLEU score
from nltk.translate.bleu_score import corpus_bleu
print("BLEU-1: %f" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))
print("BLEU-2: %f" % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))
```
------------------------------------- 13
```python
import os
import pickle
import numpy as np
from tqdm import tqdm
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.utils import to_categorical, plot_model
from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn.model_selection import train_test_split
from nltk.translate.bleu_score import sentence_bleu
import re
from PIL import Image
import matplotlib.pyplot as plt

# Define directories
BASE_DIR = '/path/to/dataset'
WORKING_DIR = '/path/to/working/directory'

# Load VGG16 model and restructure it
vgg_model = VGG16()
vgg_model = Model(inputs=vgg_model.inputs, outputs=vgg_model.layers[-2].output)

# Function to extract features from images
def extract_features(directory):
    features = {}
    for img_name in tqdm(os.listdir(directory)):
        img_path = os.path.join(directory, img_name)
        image = load_img(img_path, target_size=(224, 224))
        image = img_to_array(image)
        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))
        image = preprocess_input(image)
        feature = vgg_model.predict(image, verbose=0)
        image_id = img_name.split('.')[0]
        features[image_id] = feature
    return features

# Extract features from the dataset
image_directory = os.path.join(BASE_DIR, 'Images')
features = extract_features(image_directory)

# Save features to a pickle file
pickle.dump(features, open(os.path.join(WORKING_DIR, 'features.pkl'), 'wb'))

# Load features from the pickle file
with open(os.path.join(WORKING_DIR, 'features.pkl'), 'rb') as f:
    features = pickle.load(f)

# Load captions
with open(os.path.join(BASE_DIR, 'captions.txt'), 'r') as f:
    next(f)
    captions_doc = f.read()

# Create mapping of image to captions
mapping = {}
for line in tqdm(captions_doc.split('\n')):
    tokens = line.split(',')
    if len(line) < 2:
        continue
    image_id, caption = tokens[0], tokens[1:]
    image_id = image_id.split('.')[0]
    caption = " ".join(caption)
    if image_id not in mapping:
        mapping[image_id] = []
    mapping[image_id].append(caption)

# Clean and preprocess text
def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^a-zA-Z]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    text = 'startseq ' + text + ' endseq'
    return text

def clean(mapping):
    for key, captions in mapping.items():
        for i in range(len(captions)):
            captions[i] = clean_text(captions[i])

clean(mapping)

# Tokenize the text
all_captions = []
for key in mapping:
    for caption in mapping[key]:
        all_captions.append(caption)

tokenizer = Tokenizer()
tokenizer.fit_on_texts(all_captions)
vocab_size = len(tokenizer.word_index) + 1

# Get maximum length of the caption available
max_length = max(len(caption.split()) for caption in all_captions)

# Split data into training and testing sets
image_ids = list(mapping.keys())
train_ids, test_ids = train_test_split(image_ids, test_size=0.2, random_state=42)

# Data generator
def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size):
    X1, X2, y = list(), list(), list()
    n = 0
    while 1:
        for key in data_keys:
            n += 1
            captions = mapping[key]
            for caption in captions:
                seq = tokenizer.texts_to_sequences([caption])[0]
                for i in range(1, len(seq)):
                    in_seq, out_seq = seq[:i], seq[i]
                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]
                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]
                    X1.append(features[key][0])
                    X2.append(in_seq)
                    y.append(out_seq)
            if n == batch_size:
                X1, X2, y = np.array(X1), np.array(X2), np.array(y)
                yield [X1, X2], y
                X1, X2, y = list(), list(), list()
                n = 0

# Encoder model
inputs1 = Input(shape=(4096,))
fe1 = Dropout(0.4)(inputs1)
fe2 = Dense(256, activation='relu')(fe1)

# Sequence feature layers
inputs2 = Input(shape=(max_length,))
se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)
se2 = Dropout(0.4)(se1)
se3 = LSTM(256)(se2)

# Decoder model
decoder1 = add([fe2, se3])
decoder2 = Dense(256, activation='relu')(decoder1)
outputs = Dense(vocab_size, activation='softmax')(decoder2)

model = Model(inputs=[inputs1, inputs2], outputs=outputs)
model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])

# Plot the model
plot_model(model, show_shapes=True)

# Train the model
epochs = 30
batch_size = 64
steps = len(train_ids) // batch_size
checkpoint_filepath = os.path.join(WORKING_DIR, 'Image_model.h5')
model_checkpoint = ModelCheckpoint(checkpoint_filepath, save_best_only=True, save_weights_only=True)

history = model.fit(
    data_generator(train_ids, mapping, features, tokenizer, max_length, vocab_size, batch_size),
    epochs=epochs,
    steps_per_epoch=steps,
    verbose=1,
    callbacks=[model_checkpoint]
)

# Save the model
model.save(os.path.join(WORKING_DIR, 'Image_model.h5'))

# Load the best weights
model.load_weights(checkpoint_filepath)

# Function to convert index to word
def idx_to_word(integer, tokenizer):
    for word, index in tokenizer.word_index.items():
        if index == integer:
            return word
    return None

# Function to generate caption for an image
def predict_caption(model, image, tokenizer, max_length):
    in_text = 'startseq'
    for i in range(max_length):
        sequence = tokenizer.texts_to_sequences([in_text])[0]
        sequence = pad_sequences([sequence], max_length)
        yhat = model.predict([image, sequence], verbose=0)
        yhat = np.argmax(yhat)
        word = idx_to_word(yhat, tokenizer)
        if word is None:
            break
        in_text += " " + word
        if word == 'endseq':
            break
    return in_text

# Function to generate caption for a given image path
def generate_caption(image_path):
    image = load_img(image_path, target_size=(224, 224))
    image = img_to_array(image)
    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))
    image = preprocess_input(image)
    feature = vgg_model.predict(image, verbose=0)
    predicted_caption = predict_caption(model, feature, tokenizer, max_length)
    img = Image.open(image_path)
    plt.imshow(img)
    plt.title('Predicted Caption: ' + predicted_caption)
    plt.show()

# Example usage:
generate_caption("/path/to/test/image.jpg")

# Evaluate the model using BLEU score
def evaluate_model(model, test_ids, mapping, features, tokenizer, vocab_size, max_length):
    bleu_scores = []
    for key in test_ids:
        captions = mapping[key]
        image = features[key]
        for caption in captions:
            predicted_caption = predict_caption(model, image, tokenizer, max_length)
            actual_caption = caption.replace('startseq', '').replace('endseq', '').strip()
            bleu_scores.append(sentence_bleu([actual_caption.split()], predicted_caption.split()))
    return np.mean(bleu_scores)

# Calculate BLEU score
bleu_score = evaluate_model(model, test_ids, mapping, features, tokenizer, vocab_size, max_length)
print(f"BLEU Score: {bleu_score}")
```
------------------------------------- 14
```python
import os
import numpy as np
import nibabel as nib
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, Dropout, concatenate, BatchNormalization, Activation
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.metrics import MeanIoU
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler

# Constants
IMG_SIZE = 128
VOLUME_SLICES = 64
BATCH_SIZE = 2
EPOCHS = 50
NUM_CLASSES = 4
DATA_DIR = '/path/to/your/dataset/'

# Load and preprocess data
def load_data(data_dir, img_size, volume_slices):
    images = []
    masks = []
    for root, dirs, files in os.walk(data_dir):
        for file in files:
            if file.endswith('.nii.gz'):
                file_path = os.path.join(root, file)
                nifti_img = nib.load(file_path)
                img_data = nifti_img.get_fdata()
                
                # Resize and normalize the image
                img_data = np.resize(img_data, (img_size, img_size, volume_slices, 4))
                img_data = (img_data - np.mean(img_data)) / np.std(img_data)
                
                # Load the corresponding mask
                mask_path = file_path.replace('.nii.gz', '_mask.nii.gz')
                nifti_mask = nib.load(mask_path)
                mask_data = nifti_mask.get_fdata()
                
                # Resize and one-hot encode the mask
                mask_data = np.resize(mask_data, (img_size, img_size, volume_slices))
                mask_data = to_categorical(mask_data, num_classes=NUM_CLASSES)
                
                images.append(img_data)
                masks.append(mask_data)
    
    return np.array(images), np.array(masks)

# Load and preprocess the dataset
images, masks = load_data(DATA_DIR, IMG_SIZE, VOLUME_SLICES)

# Split the dataset into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)

# Define the 3D U-Net model
def unet_3d(input_shape, num_classes):
    inputs = Input(input_shape)
    
    # Encoder
    conv1 = Conv3D(32, 3, activation='relu', padding='same')(inputs)
    conv1 = Conv3D(32, 3, activation='relu', padding='same')(conv1)
    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)
    
    conv2 = Conv3D(64, 3, activation='relu', padding='same')(pool1)
    conv2 = Conv3D(64, 3, activation='relu', padding='same')(conv2)
    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)
    
    conv3 = Conv3D(128, 3, activation='relu', padding='same')(pool2)
    conv3 = Conv3D(128, 3, activation='relu', padding='same')(conv3)
    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3)
    
    conv4 = Conv3D(256, 3, activation='relu', padding='same')(pool3)
    conv4 = Conv3D(256, 3, activation='relu', padding='same')(conv4)
    drop4 = Dropout(0.2)(conv4)
    
    # Decoder
    up5 = Conv3D(128, 2, activation='relu', padding='same')(UpSampling3D(size=(2, 2, 2))(drop4))
    merge5 = concatenate([conv3, up5], axis=4)
    conv5 = Conv3D(128, 3, activation='relu', padding='same')(merge5)
    conv5 = Conv3D(128, 3, activation='relu', padding='same')(conv5)
    
    up6 = Conv3D(64, 2, activation='relu', padding='same')(UpSampling3D(size=(2, 2, 2))(conv5))
    merge6 = concatenate([conv2, up6], axis=4)
    conv6 = Conv3D(64, 3, activation='relu', padding='same')(merge6)
    conv6 = Conv3D(64, 3, activation='relu', padding='same')(conv6)
    
    up7 = Conv3D(32, 2, activation='relu', padding='same')(UpSampling3D(size=(2, 2, 2))(conv6))
    merge7 = concatenate([conv1, up7], axis=4)
    conv7 = Conv3D(32, 3, activation='relu', padding='same')(merge7)
    conv7 = Conv3D(32, 3, activation='relu', padding='same')(conv7)
    
    outputs = Conv3D(num_classes, (1, 1, 1), activation='softmax')(conv7)
    
    model = Model(inputs, outputs)
    return model

# Compile the model
model = unet_3d((IMG_SIZE, IMG_SIZE, VOLUME_SLICES, 4), NUM_CLASSES)
model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy', MeanIoU(num_classes=NUM_CLASSES)])

# Callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min')
lr_scheduler = LearningRateScheduler(lambda epoch, lr: lr * 0.9 if epoch % 10 == 0 else lr, verbose=1)

# Train the model
history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_val, y_val), callbacks=[early_stopping, model_checkpoint, lr_scheduler])

# Evaluate the model
val_loss, val_accuracy, val_mean_iou = model.evaluate(X_val, y_val)
print(f"Validation Loss: {val_loss}")
print(f"Validation Accuracy: {val_accuracy}")
print(f"Validation Mean IoU: {val_mean_iou}")
```
------------------------------------- 15
```python
# Install necessary libraries
!pip install keras==2.10
!pip install segmentation-models==1.0.1

import os
import glob
import cv2
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import tifffile
from PIL import Image
import albumentations as A
from tqdm import tqdm
from sklearn.model_selection import train_test_split

import segmentation_models as sm
from segmentation_models import Unet
from segmentation_models import get_preprocessing
from segmentation_models import metrics
from segmentation_models.metrics import iou_score
from segmentation_models import set_framework
from tensorflow.keras.layers import Conv2DTranspose, Dropout, Conv2D
from tensorflow.keras import regularizers
from keras.models import Model
from segmentation_models.utils import set_trainable
from segmentation_models import losses

sm.set_framework('tf.keras')

# Load dataset function
def load_dataset(root_dir):
    data_list = []
    label_mapping = {
        'Cercospora': 0,
        'Coffee Rust': 1,
        'Phoma': 2
    }

    for folder in ["Images", "Leaf Masks", "Biotic Stress Masks"]:
        image_folder = os.path.join(root_dir, folder)
        leaf_folder = os.path.join(root_dir, "Leaf Masks")
        stress_folder = os.path.join(root_dir, "Biotic Stress Masks")

        for image_class in os.listdir(image_folder):
            class_images = glob.glob(os.path.join(image_folder, image_class, "*.jpg"))
            for img_path in class_images:
                img_name = os.path.basename(img_path).split(".")[0]

                leaf_mask_name = img_name.replace(" ", "_") + "_leaf.ome.tiff"
                leaf_mask_path = os.path.join(leaf_folder, image_class, leaf_mask_name)

                if image_class == 'Coffee Rust':
                    stress_mask_name = img_name.replace(" ", "_") + "_rust.ome.tiff"
                else:
                    stress_mask_name = img_name.replace(" ", "_") + "_" + image_class.lower() + ".ome.tiff"
                stress_mask_path = os.path.join(stress_folder, image_class, stress_mask_name)

                data_list.append((img_path, leaf_mask_path, stress_mask_path, image_class, label_mapping[image_class]))

    return data_list, label_mapping

# Load train and test datasets
train_data, train_label_mapping = load_dataset("/kaggle/input/segmentation-v6/Segmentation Coffee Dataset/Train")
test_data, test_label_mapping = load_dataset("/kaggle/input/segmentation-v6/Segmentation Coffee Dataset/Test")

train_df = pd.DataFrame(train_data, columns=['ImagePath', 'LeafMaskPath', 'BioticStressMaskPath', 'ClassName', 'Label'])
test_df = pd.DataFrame(test_data, columns=['ImagePath', 'LeafMaskPath', 'BioticStressMaskPath', 'ClassName', 'Label'])

# Augmentation function
def augment_image_and_mask(image, mask):
    augmentations = A.Compose([
        A.Resize(height=256, width=512, p=1.0),
        A.HorizontalFlip(p=0.5),
        A.Rotate(limit=30, p=0.3),
        A.VerticalFlip(p=0.3),
    ])

    mask = mask.astype(np.uint8)

    augmented = augmentations(image=image, mask=mask)
    augmented_image = augmented['image']
    augmented_mask = augmented['mask']
    return augmented_image, augmented_mask

# Read TIFF mask function
def read_tiff_mask(mask_path):
    return tifffile.imread(mask_path)

# Load and augment training data
train_images = []
train_leaf_masks = []
train_label = []

for index, row in tqdm(train_df.iterrows(), total=len(train_df)):
    img_path = row['ImagePath']
    leaf_mask_path = row['LeafMaskPath']

    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    leaf_mask = read_tiff_mask(leaf_mask_path)

    for _ in range(3):
        augmented_image, augmented_leaf_mask = augment_image_and_mask(img, leaf_mask)

        train_images.append(augmented_image)
        train_leaf_masks.append(np.where(augmented_leaf_mask==0, 0, 1))
        train_label.append(row['Label'])

norm_train_images = np.array(train_images)
norm_train_leaf_masks = np.array(train_leaf_masks)
norm_train_label = np.array(train_label)

# Load and augment test data
test_images = []
test_leaf_masks = []
test_label = []

for index, row in tqdm(test_df.iterrows(), total=len(test_df)):
    img_path = row['ImagePath']
    leaf_mask_path = row['LeafMaskPath']

    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    leaf_mask = read_tiff_mask(leaf_mask_path)

    for _ in range(3):
        augmented_image, augmented_leaf_mask = augment_image_and_mask(img, leaf_mask)

        test_images.append(augmented_image)
        test_leaf_masks.append(np.where(augmented_leaf_mask==0, 0, 1))
        test_label.append(row['Label'])

norm_test_images = np.array(test_images)
norm_test_leaf_masks = np.array(test_leaf_masks)
norm_test_label = np.array(test_label)

# Scale images
def scale_image(data):
    return (data - np.min(data)) / (np.max(data) - np.min(data))

norm_train_images = np.array([scale_image(i) for i in norm_train_images])
norm_test_images = np.array([scale_image(i) for i in norm_test_images])

# Visualize samples
num_samples_to_visualize = 3

for i in range(num_samples_to_visualize):
    img = norm_train_images[i]
    leaf_mask = norm_train_leaf_masks[i]

    fig, axs = plt.subplots(1, 2, figsize=(8, 5))

    axs[0].imshow(img)
    axs[0].set_title('Image')

    axs[1].imshow(leaf_mask)
    axs[1].set_title('Leaf Mask')

    plt.show()

# Split data into training and validation sets
x_train, x_val, y_train, y_val = norm_train_images, norm_test_images, norm_train_leaf_masks, norm_test_leaf_masks

input_shape = (256, 512, 3)
y_train = y_train.astype(np.float32)
y_val = y_val.astype(np.float32)

# Define model
BACKBONE = 'resnet34'
preprocess_input = sm.get_preprocessing(BACKBONE)
x_train_preprocessed = preprocess_input(x_train)
x_val_preprocessed = preprocess_input(x_val)

model = sm.Unet(BACKBONE, input_shape=input_shape, encoder_weights='imagenet')

for layer in model.layers:
    if isinstance(layer, Conv2D):
        layer.kernel_regularizer = regularizers.l2(1e-4)
    if isinstance(layer, Dropout):
        layer.rate = 0.5

num_classes = 1
output = Conv2DTranspose(num_classes, (1, 1), activation='sigmoid')(model.output)

DiceLoss = losses.DiceLoss()

model = Model(inputs=model.input, outputs=output)
model.compile(optimizer='adam', loss=DiceLoss, metrics=['binary_accuracy', metrics.FScore(), iou_score])

# Train model
history = model.fit(
    x=x_train_preprocessed,
    y=y_train,
    batch_size=16,
    epochs=40,
    validation_data=(x_val_preprocessed, y_val),
)

# Save results
results_df = pd.DataFrame(history.history)
results_df.to_csv('resnet50.csv', index=False)

# Plot metrics
loss = history.history['loss']
val_loss = history.history['val_loss']
binary_accuracy = history.history['binary_accuracy']
val_binary_accuracy = history.history['val_binary_accuracy']
fscore = history.history['f1-score']
val_fscore = history.history['val_f1-score']
iou_score = history.history['iou_score']
val_iou_score = history.history['val_iou_score']

epochs = range(1, len(loss) + 1)

plt.figure(figsize=(8, 5))
plt.plot(epochs, loss, 'r', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.figure(figsize=(8, 5))
plt.plot(epochs, binary_accuracy, 'r', label='Binary Accuracy')
plt.plot(epochs, val_binary_accuracy, 'b', label='Validation Binary Accuracy')
plt.title('Binary Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.figure(figsize=(8, 5))
plt.plot(epochs, fscore, 'r', label='F1-score')
plt.plot(epochs, val_fscore, 'b', label='Validation F1-score')
plt.title('F1-score')
plt.xlabel('Epochs')
plt.ylabel('F1-score')
plt.legend()

plt.figure(figsize=(8, 5))
plt.plot(epochs, iou_score, 'r', label='IoU-score')
plt.plot(epochs, val_iou_score, 'b', label='Validation IoU-score')
plt.title('IoU-score')
plt.xlabel('Epochs')
plt.ylabel('IoU-score')
plt.legend()

plt.tight_layout()
plt.show()

# Save model
model.save('resnet50.h5')

# Load saved model
saved_model = tf.keras.models.load_model('/kaggle/working/resnet50.h5', compile=False)

# Preprocess function
def preprocess(image_array):
    image = cv2.resize(image_array, (512, 256))
    normalized_image = image / 255.0
    return np.expand_dims(normalized_image, axis=0)

# Prediction function
def predict(image, threshold=0.7):
    preprocessed_image = preprocess(image)
    prediction = saved_model.predict(preprocessed_image)
    pred_image = np.squeeze(prediction > threshold)
    return pred_image

# Test prediction
image_path = '/kaggle/input/sample/Try/Rust(516).jpg'
image = cv2.imread(image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

predicted_image = predict(image)

plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(image)
plt.title('Original Image')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.imshow(predicted_image)
plt.title('Predicted Mask')
plt.axis('off')

plt.tight_layout()
plt.show()
```
------------------------------------- 16
```python
import os
import numpy as np
import json
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow.keras.layers as tfl
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from PIL import Image, ImageDraw
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# Set random seed for reproducibility
tf.random.set_seed(221)

# Constants
INPUT_SIZE = (1920, 1080)
IMG_SIZE = 256  # image size for the network
N = 512  # Number of images

# Paths
path = ''
image_path = os.path.join(path, '/kaggle/input/plant-disease-segmentation/images/')
mask_path = os.path.join(path, '/kaggle/input/plant-disease-segmentation/annotations/')

# Load annotations
with open('/kaggle/input/plant-disease-segmentation/annotations/instances_default.json') as f:
    annotations = json.load(f)

# Create a dictionary mapping image IDs to filenames
image_id_dict = {image['id']: image['file_name'] for image in annotations['images']}

# Load and resize images
images = np.zeros((N, IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
for img_id, img_filename in image_id_dict.items():
    img = Image.open(os.path.join(image_path, img_filename))
    img = img.resize((IMG_SIZE, IMG_SIZE))
    images[img_id - 1] = img

# Show first 9 images
fig = plt.figure(figsize=(12, 6))
for i in range(9):
    plt.subplot(3, 3, i+1)
    plt.imshow(images[i]/255)
    plt.axis('off')
fig.tight_layout()

# Load and resize masks
masks = np.zeros((N, IMG_SIZE, IMG_SIZE), dtype=bool)
for annotation in annotations['annotations']:
    img_id = annotation['image_id']
    mask = Image.new('1', INPUT_SIZE)
    mask_draw = ImageDraw.Draw(mask, '1')
    segmentation = annotation['segmentation'][0]
    mask_draw.polygon(segmentation, fill=1)
    bool_array = np.array(mask.resize((IMG_SIZE, IMG_SIZE))) > 0
    masks[img_id - 1] = masks[img_id - 1] | bool_array

masks = masks.reshape(N, IMG_SIZE, IMG_SIZE, 1)  # add channel dimension

# Show masks applied on top of the images
fig = plt.figure(figsize=(12, 6))
for i in range(9):
    plt.subplot(3, 3, i+1)
    plt.imshow(images[i]/255)
    plt.imshow(masks[i], alpha=0.5)
    plt.axis('off')
fig.tight_layout()

# Split data into training and testing sets
images_train, images_test, masks_train, masks_test = train_test_split(images, masks, test_size=0.1, random_state=42)
print(f"Train images shape: {images_train.shape}, Train masks shape: {masks_train.shape}")
print(f"Test images shape: {images_test.shape}, Test masks shape: {masks_test.shape}")

# Jaccard Index (IoU) metric
def jaccard_index(y_true, y_pred):
    y_true = tf.keras.backend.flatten(y_true)
    y_pred = tf.keras.backend.flatten(y_pred)
    intersection = tf.keras.backend.sum(y_true * y_pred)
    union = tf.keras.backend.sum(y_true) + tf.keras.backend.sum(y_pred) - intersection
    return (intersection + 1e-7) / (union + 1e-7)

# Convolution block for U-Net
def conv_block(inputs, n_filters, maxpooling=True):
    x = tfl.Conv2D(filters=n_filters, kernel_size=3, padding='same')(inputs)
    x = tfl.BatchNormalization()(x)
    x = tfl.Activation('relu')(x)
    x = tfl.Conv2D(filters=n_filters, kernel_size=3, padding='same')(x)
    x = tfl.BatchNormalization()(x)
    skip = tfl.Activation('relu')(x)
    if maxpooling:
        out = tfl.MaxPool2D(pool_size=(2, 2), strides=(2, 2))(skip)
    else:
        out = skip
    return out, skip

# Upsampling block for U-Net
def upsampling_block(expansive_input, contractive_input, n_filters):
    up = tfl.Conv2DTranspose(n_filters, kernel_size=2, strides=2, padding='same')(expansive_input)
    input = tfl.concatenate([up, contractive_input], axis=3)
    out, _ = conv_block(input, n_filters, False)
    return out

# U-Net model
def unet_model(input_size=(256, 256, 3), n_filters=64):
    inputs = tfl.Input(input_size)
    cblock1 = conv_block(inputs, n_filters)
    cblock2 = conv_block(cblock1[0], n_filters*2)
    cblock3 = conv_block(cblock2[0], n_filters*4)
    cblock4 = conv_block(cblock3[0], n_filters*8)
    cblock5 = conv_block(cblock4[0], n_filters*16, maxpooling=False)

    ublock6 = upsampling_block(cblock5[0], cblock4[1], n_filters*8)
    ublock7 = upsampling_block(ublock6, cblock3[1], n_filters*4)
    ublock8 = upsampling_block(ublock7, cblock2[1], n_filters*2)
    ublock9 = upsampling_block(ublock8, cblock1[1], n_filters)

    out = tfl.Conv2D(1, 1, padding='same', activation='sigmoid')(ublock9)
    model = tf.keras.Model(inputs=inputs, outputs=out)
    return model

# Create and compile the model
unet = unet_model()
unet.compile(optimizer=tf.keras.optimizers.Adam(),
             loss=tf.keras.losses.BinaryCrossentropy(),
             metrics=[jaccard_index, 'accuracy'])

# Data augmentation
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Train the model
history = unet.fit(
    datagen.flow(images_train, masks_train, batch_size=16),
    steps_per_epoch=len(images_train) // 16,
    validation_data=(images_test, masks_test),
    epochs=40
)

# Evaluate the model
unet.evaluate(images_test, masks_test, batch_size=16)

# Predict masks
predicted_mask = unet.predict(images_test, batch_size=16)
predicted_mask2 = (predicted_mask > 0.5).astype(np.uint8)

# Display predicted masks
fig, ax = plt.subplots(5, 3, figsize=(12, 10))
for i in range(5):
    ax[i, 0].imshow(images_test[i])
    ax[i, 0].axis('off')
    ax[i, 1].imshow(masks_test[i])
    ax[i, 1].axis('off')
    ax[i, 2].imshow(predicted_mask2[i])
    ax[i, 2].axis('off')

ax[0, 0].set_title('Original image')
ax[0, 1].set_title('True mask')
ax[0, 2].set_title('Predicted mask')
fig.tight_layout()

# Classification report
cr = classification_report(masks_test.flatten(), predicted_mask2.flatten())
print(cr)
```
------------------------------------- 17
```python
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, concatenate, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.callbacks import EarlyStopping
import numpy as np
import json
import os
from sklearn.model_selection import train_test_split

# Load and preprocess the dataset
def load_dataset(image_dir, json_file):
    images = []
    masks = []
    
    # Load segmentation masks from JSON
    with open(json_file, 'r') as f:
        mask_data = json.load(f)
    
    for img_name, mask_coords in mask_data.items():
        # Load and resize image
        img_path = os.path.join(image_dir, img_name)
        img = load_img(img_path, target_size=(512, 512))
        img_array = img_to_array(img) / 255.0
        images.append(img_array)
        
        # Create mask from coordinates
        mask = np.zeros((512, 512, 1), dtype=np.float32)
        for coords in mask_coords:
            x, y, width, height = coords['x'], coords['y'], coords['width'], coords['height']
            mask[y:y+height, x:x+width, 0] = 1.0
        masks.append(mask)
    
    return np.array(images), np.array(masks)

# Define U-Net model
def unet_model(input_shape):
    inputs = Input(input_shape)
    
    # Encoder
    conv1 = Conv2D(64, kernel_size=3, padding='same')(inputs)
    conv1 = BatchNormalization()(conv1)
    conv1 = Activation('relu')(conv1)
    conv1 = Conv2D(64, kernel_size=3, padding='same')(conv1)
    conv1 = BatchNormalization()(conv1)
    conv1 = Activation('relu')(conv1)
    pool1 = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(conv1)
    
    conv2 = Conv2D(128, kernel_size=3, padding='same')(pool1)
    conv2 = BatchNormalization()(conv2)
    conv2 = Activation('relu')(conv2)
    conv2 = Conv2D(128, kernel_size=3, padding='same')(conv2)
    conv2 = BatchNormalization()(conv2)
    conv2 = Activation('relu')(conv2)
    pool2 = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(conv2)
    
    conv3 = Conv2D(256, kernel_size=3, padding='same')(pool2)
    conv3 = BatchNormalization()(conv3)
    conv3 = Activation('relu')(conv3)
    conv3 = Conv2D(256, kernel_size=3, padding='same')(conv3)
    conv3 = BatchNormalization()(conv3)
    conv3 = Activation('relu')(conv3)
    pool3 = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(conv3)
    
    conv4 = Conv2D(512, kernel_size=3, padding='same')(pool3)
    conv4 = BatchNormalization()(conv4)
    conv4 = Activation('relu')(conv4)
    conv4 = Conv2D(512, kernel_size=3, padding='same')(conv4)
    conv4 = BatchNormalization()(conv4)
    conv4 = Activation('relu')(conv4)
    drop4 = Dropout(0.5)(conv4)
    pool4 = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(drop4)
    
    # Bottleneck
    conv5 = Conv2D(1024, kernel_size=3, padding='same')(pool4)
    conv5 = BatchNormalization()(conv5)
    conv5 = Activation('relu')(conv5)
    conv5 = Conv2D(1024, kernel_size=3, padding='same')(conv5)
    conv5 = BatchNormalization()(conv5)
    conv5 = Activation('relu')(conv5)
    drop5 = Dropout(0.5)(conv5)
    
    # Decoder
    up6 = Conv2DTranspose(512, kernel_size=2, strides=2, padding='same')(conv5)
    merge6 = concatenate([drop4, up6], axis=3)
    conv6 = Conv2D(512, kernel_size=3, padding='same')(merge6)
    conv6 = BatchNormalization()(conv6)
    conv6 = Activation('relu')(conv6)
    conv6 = Conv2D(512, kernel_size=3, padding='same')(conv6)
    conv6 = BatchNormalization()(conv6)
    conv6 = Activation('relu')(conv6)
    
    up7 = Conv2DTranspose(256, kernel_size=2, strides=2, padding='same')(conv6)
    merge7 = concatenate([conv3, up7], axis=3)
    conv7 = Conv2D(256, kernel_size=3, padding='same')(merge7)
    conv7 = BatchNormalization()(conv7)
    conv7 = Activation('relu')(conv7)
    conv7 = Conv2D(256, kernel_size=3, padding='same')(conv7)
    conv7 = BatchNormalization()(conv7)
    conv7 = Activation('relu')(conv7)
    
    up8 = Conv2DTranspose(128, kernel_size=2, strides=2, padding='same')(conv7)
    merge8 = concatenate([conv2, up8], axis=3)
    conv8 = Conv2D(128, kernel_size=3, padding='same')(merge8)
    conv8 = BatchNormalization()(conv8)
    conv8 = Activation('relu')(conv8)
    conv8 = Conv2D(128, kernel_size=3, padding='same')(conv8)
    conv8 = BatchNormalization()(conv8)
    conv8 = Activation('relu')(conv8)
    
    up9 = Conv2DTranspose(64, kernel_size=2, strides=2, padding='same')(conv8)
    merge9 = concatenate([conv1, up9], axis=3)
    conv9 = Conv2D(64, kernel_size=3, padding='same')(merge9)
    conv9 = BatchNormalization()(conv9)
    conv9 = Activation('relu')(conv9)
    conv9 = Conv2D(64, kernel_size=3, padding='same')(conv9)
    conv9 = BatchNormalization()(conv9)
    conv9 = Activation('relu')(conv9)
    
    # Output layer
    outputs = Conv2D(1, kernel_size=1, padding='same', activation='sigmoid')(conv9)
    
    model = Model(inputs=[inputs], outputs=[outputs])
    return model

# Load and preprocess the dataset
image_dir = "path_to_image_directory"
json_file = "path_to_json_file"
images, masks = load_dataset(image_dir, json_file)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size=0.2, random_state=42)

# Define the model
model = unet_model((512, 512, 3))

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss=BinaryCrossentropy(), metrics=['accuracy'])

# Define callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train, batch_size=4, epochs=50, validation_data=(X_test, y_test), callbacks=[early_stopping])

# Evaluate the model
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"Test accuracy: {test_acc}")

# Save the model
model.save('semantic_segmentation_model.h5')
```
------------------------------------- 18
```python
import os
import numpy as np
import nibabel as nib
import cv2
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Constants
IMG_SIZE = 256
VOLUME_SLICES = 100
VOLUME_START_AT = 22
SEGMENT_CLASSES = {
    0: 'NOT tumor',
    1: 'NECROTIC/CORE',
    2: 'EDEMA',
    3: 'ENHANCING'
}

# Path to the dataset
TRAIN_DATASET_PATH = './BraTS2021_Training_Data/'

# Function to load and preprocess data
def load_data(ids, dataset_path):
    X = np.zeros((len(ids) * VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))
    y = np.zeros((len(ids) * VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 4))
    
    for i, case_id in enumerate(ids):
        case_path = os.path.join(dataset_path, case_id)
        
        flair = nib.load(os.path.join(case_path, f'{case_id}_flair.nii.gz')).get_fdata()
        t1ce = nib.load(os.path.join(case_path, f'{case_id}_t1ce.nii.gz')).get_fdata()
        seg = nib.load(os.path.join(case_path, f'{case_id}_seg.nii.gz')).get_fdata()
        
        for j in range(VOLUME_SLICES):
            X[i * VOLUME_SLICES + j, :, :, 0] = cv2.resize(flair[:, :, j + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))
            X[i * VOLUME_SLICES + j, :, :, 1] = cv2.resize(t1ce[:, :, j + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))
            y_resized = cv2.resize(seg[:, :, j + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)
            y[i * VOLUME_SLICES + j, :, :, :] = tf.one_hot(y_resized.astype(int), depth=4)
    
    return X / np.max(X), y

# Function to build the U-Net model
def build_unet(input_shape):
    inputs = Input(input_shape)
    
    conv1 = Conv2D(32, 3, activation='relu', padding='same')(inputs)
    conv1 = Conv2D(32, 3, activation='relu', padding='same')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    
    conv2 = Conv2D(64, 3, activation='relu', padding='same')(pool1)
    conv2 = Conv2D(64, 3, activation='relu', padding='same')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    
    conv3 = Conv2D(128, 3, activation='relu', padding='same')(pool2)
    conv3 = Conv2D(128, 3, activation='relu', padding='same')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    
    conv4 = Conv2D(256, 3, activation='relu', padding='same')(pool3)
    conv4 = Conv2D(256, 3, activation='relu', padding='same')(conv4)
    drop4 = Dropout(0.5)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)
    
    conv5 = Conv2D(512, 3, activation='relu', padding='same')(pool4)
    conv5 = Conv2D(512, 3, activation='relu', padding='same')(conv5)
    drop5 = Dropout(0.5)(conv5)
    
    up6 = Conv2D(256, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop5))
    merge6 = concatenate([drop4, up6], axis=3)
    conv6 = Conv2D(256, 3, activation='relu', padding='same')(merge6)
    conv6 = Conv2D(256, 3, activation='relu', padding='same')(conv6)
    
    up7 = Conv2D(128, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv6))
    merge7 = concatenate([conv3, up7], axis=3)
    conv7 = Conv2D(128, 3, activation='relu', padding='same')(merge7)
    conv7 = Conv2D(128, 3, activation='relu', padding='same')(conv7)
    
    up8 = Conv2D(64, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv7))
    merge8 = concatenate([conv2, up8], axis=3)
    conv8 = Conv2D(64, 3, activation='relu', padding='same')(merge8)
    conv8 = Conv2D(64, 3, activation='relu', padding='same')(conv8)
    
    up9 = Conv2D(32, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv8))
    merge9 = concatenate([conv1, up9], axis=3)
    conv9 = Conv2D(32, 3, activation='relu', padding='same')(merge9)
    conv9 = Conv2D(32, 3, activation='relu', padding='same')(conv9)
    
    conv10 = Conv2D(4, 1, activation='softmax')(conv9)
    
    model = Model(inputs=inputs, outputs=conv10)
    return model

# Custom Dice Coefficient for multi-class segmentation
def dice_coef(y_true, y_pred, smooth=1.0):
    y_true_f = tf.reshape(y_true, [-1])
    y_pred_f = tf.reshape(y_pred, [-1])
    intersection = tf.reduce_sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)

# Data augmentation
def create_data_generator(X, y, batch_size):
    datagen = ImageDataGenerator(
        rotation_range=20,
        width_shift_range=0.1,
        height_shift_range=0.1,
        brightness_range=(0.8, 1.2),
        horizontal_flip=True,
        vertical_flip=True,
        fill_mode='nearest'
    )
    
    image_generator = datagen.flow(X, batch_size=batch_size, shuffle=True)
    mask_generator = datagen.flow(y, batch_size=batch_size, shuffle=True)
    
    return zip(image_generator, mask_generator)

# Load and split data
all_ids = [f for f in os.listdir(TRAIN_DATASET_PATH) if os.path.isdir(os.path.join(TRAIN_DATASET_PATH, f))]
train_ids, test_ids = train_test_split(all_ids, test_size=0.2)
train_ids, val_ids = train_test_split(train_ids, test_size=0.15)

X_train, y_train = load_data(train_ids, TRAIN_DATASET_PATH)
X_val, y_val = load_data(val_ids, TRAIN_DATASET_PATH)
X_test, y_test = load_data(test_ids, TRAIN_DATASET_PATH)

# Create data generators for training and validation
train_generator = create_data_generator(X_train, y_train, batch_size=8)
val_generator = create_data_generator(X_val, y_val, batch_size=8)

# Build and compile the model
input_shape = (IMG_SIZE, IMG_SIZE, 2)
model = build_unet(input_shape)
model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=[dice_coef])

# Callbacks
checkpoint = ModelCheckpoint('unet_glioma_segmentation.h5', monitor='val_loss', save_best_only=True)
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
csv_logger = CSVLogger('training_log.csv')

# Train the model
history = model.fit(train_generator, 
                    steps_per_epoch=len(X_train) // 8, 
                    validation_data=val_generator, 
                    validation_steps=len(X_val) // 8, 
                    epochs=50, 
                    callbacks=[checkpoint, early_stop, csv_logger])

# Evaluate the model
test_loss, test_dice = model.evaluate(X_test, y_test)
print(f'Test Loss: {test_loss}, Test Dice Coefficient: {test_dice}')
```
------------------------------------- 19
```python
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate, LeakyReLU, BatchNormalization, Flatten, Dense
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import LearningRateScheduler
from tensorflow.keras.applications import ResNet50, VGG16
import numpy as np
import pandas as pd
import cv2
import random
import csv
import os
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

# Constants
HEIGHT = 96
WIDTH = 96
CHANNELS = 3
INIT_LR = 0.001
EPOCHS = 50
TRAIN_PATH = "./data/train.csv"
TEST_PATH = "./data/test.csv"

# Check for GPU availability
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
    raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

# Helper functions
def downsampling_block(input_tensor, n_filters):
    x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same')(input_tensor)
    x = LeakyReLU(alpha=0.2)(x)
    x = BatchNormalization()(x)
    x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same')(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = BatchNormalization()(x)
    return x

def upsampling_block(input_tensor, n_filters, name, concat_with):
    x = UpSampling2D((2, 2), interpolation='bilinear', name=name)(input_tensor)
    x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same', name=name + "_convA")(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = concatenate([x, concat_with], axis=3)
    x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same', name=name + "_convB")(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = BatchNormalization()(x)
    x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same', name=name + "_convC")(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = BatchNormalization()(x)
    return x

def build_resnet_model(height, width, channels):
    i = Input(shape=(height, width, channels))
    resnet50 = ResNet50(include_top=False, weights="imagenet", input_tensor=i)
    conv1 = resnet50.get_layer("conv1_relu").output
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    conv2 = resnet50.get_layer("conv2_block3_out").output
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    conv3 = resnet50.get_layer("conv3_block4_out").output
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    conv4 = resnet50.get_layer("conv4_block6_out").output
    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)
    conv5 = resnet50.get_layer("conv5_block3_out").output
    conv5 = LeakyReLU(alpha=0.2)(conv5)
    conv6 = upsampling_block(conv5, 256, "up1", concat_with=conv4)
    conv7 = upsampling_block(conv6, 128, "up2", concat_with=conv3)
    conv8 = upsampling_block(conv7, 64, "up3", concat_with=conv2)
    conv9 = upsampling_block(conv8, 32, "up4", concat_with=conv1)
    o = Conv2D(filters=1, kernel_size=3, strides=(1, 1), activation='sigmoid', padding='same', name='conv10')(conv9)
    model = Model(inputs=i, outputs=o)
    return model

def build_vgg_model(height, width, channels):
    i = Input(shape=(height, width, channels))
    vgg16 = VGG16(include_top=False, weights="imagenet", input_tensor=i)
    conv1 = vgg16.get_layer("block1_conv2").output
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    conv2 = vgg16.get_layer("block2_conv2").output
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    conv3 = vgg16.get_layer("block3_conv3").output
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    conv4 = vgg16.get_layer("block4_conv3").output
    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)
    conv5 = vgg16.get_layer("block5_conv3").output
    conv5 = LeakyReLU(alpha=0.2)(conv5)
    conv6 = upsampling_block(conv5, 256, "up1", concat_with=conv4)
    conv7 = upsampling_block(conv6, 128, "up2", concat_with=conv3)
    conv8 = upsampling_block(conv7, 64, "up3", concat_with=conv2)
    conv9 = upsampling_block(conv8, 32, "up4", concat_with=conv1)
    o = Conv2D(filters=1, kernel_size=3, strides=(1, 1), activation='sigmoid', padding='same', name='conv10')(conv9)
    model = Model(inputs=i, outputs=o)
    return model

def create_custom_model(height, width, channels):
    model = Sequential([
        Conv2D(128, (11, 11), strides=(4, 4), activation='relu', input_shape=(height, width, channels)),
        BatchNormalization(),
        MaxPooling2D(pool_size=(2, 2)),
        Conv2D(256, (5, 5), strides=(1, 1), activation='relu', padding='same'),
        BatchNormalization(),
        MaxPooling2D(pool_size=(3, 3)),
        Conv2D(256, (3, 3), strides=(1, 1), activation='relu', padding='same'),
        BatchNormalization(),
        Conv2D(256, (1, 1), strides=(1, 1), activation='relu', padding='same'),
        BatchNormalization(),
        Conv2D(256, (1, 1), strides=(1, 1), activation='relu', padding='same'),
        BatchNormalization(),
        MaxPooling2D(pool_size=(2, 2)),
        Flatten(),
        Dense(256, activation='relu'),
        Dense(128, activation='relu'),
        Dense(30)
    ])
    return model

def load_data(csv_file_path):
    data = pd.read_csv(csv_file_path)
    images = np.array([np.fromstring(img, sep=' ').reshape(HEIGHT, WIDTH, 1) for img in data['image']])
    images = np.repeat(images, 3, axis=-1)  # Convert grayscale to RGB
    images = images / 255.0  # Normalize to [0, 1]
    keypoints = np.array([np.fromstring(kp, sep=' ') for kp in data['keypoints']])
    return images, keypoints

def train_val_split(images, keypoints, val_size):
    return train_test_split(images, keypoints, test_size=val_size, random_state=42)

def poly_decay(epoch):
    maxEpochs = EPOCHS
    baseLR = INIT_LR
    power = 1.0
    alpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power
    return alpha

# Load and preprocess data
images, keypoints = load_data(TRAIN_PATH)
X_train, X_val, y_train, y_val = train_val_split(images, keypoints, 0.2)

# Build models
resnet_model = build_resnet_model(HEIGHT, WIDTH, CHANNELS)
vgg_model = build_vgg_model(HEIGHT, WIDTH, CHANNELS)
custom_model = create_custom_model(HEIGHT, WIDTH, CHANNELS)

# Compile models
opt = Adam(lr=INIT_LR, amsgrad=True)
callbacks = [LearningRateScheduler(poly_decay)]
resnet_model.compile(optimizer=opt, loss='mean_squared_error', metrics=['accuracy'])
vgg_model.compile(optimizer=opt, loss='mean_squared_error', metrics=['accuracy'])
custom_model.compile(optimizer=opt, loss='mean_squared_error', metrics=['accuracy'])

# Train models
resnet_history = resnet_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=EPOCHS, callbacks=callbacks)
vgg_history = vgg_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=EPOCHS, callbacks=callbacks)
custom_history = custom_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=EPOCHS, callbacks=callbacks)

# Save models
resnet_model.save("resnet_keypoints_model.h5")
vgg_model.save("vgg_keypoints_model.h5")
custom_model.save("custom_keypoints_model.h5")

# Plot training history
plt.style.use('ggplot')
plt.figure()
plt.plot(resnet_history.history['loss'], label='ResNet Train Loss')
plt.plot(resnet_history.history['val_loss'], label='ResNet Val Loss')
plt.plot(vgg_history.history['loss'], label='VGG Train Loss')
plt.plot(vgg_history.history['val_loss'], label='VGG Val Loss')
plt.plot(custom_history.history['loss'], label='Custom Train Loss')
plt.plot(custom_history.history['val_loss'], label='Custom Val Loss')
plt.title('Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Evaluate models on test data
test_images, test_keypoints = load_data(TEST_PATH)
resnet_results = resnet_model.evaluate(test_images, test_keypoints)
vgg_results = vgg_model.evaluate(test_images, test_keypoints)
custom_results = custom_model.evaluate(test_images, test_keypoints)
print(f"ResNet Model Test Loss: {resnet_results[0]}, Test Accuracy: {resnet_results[1]}")
print(f"VGG Model Test Loss: {vgg_results[0]}, Test Accuracy: {vgg_results[1]}")
print(f"Custom Model Test Loss: {custom_results[0]}, Test Accuracy: {custom_results[1]}")
```
------------------------------------- 20
```python
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, BatchNormalization, Activation, concatenate
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
import pandas as pd
import numpy as np
import os
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import matplotlib.pyplot as plt

# Load the dataset paths from CSV files
def load_data_paths(csv_path):
    df = pd.read_csv(csv_path)
    return df['image_path'].values, df['depth_path'].values

train_image_paths, train_depth_paths = load_data_paths('train.csv')
test_image_paths, test_depth_paths = load_data_paths('test.csv')

# Load images and depth maps
def load_data(image_paths, depth_paths, target_size=(256, 256)):
    images = []
    depths = []
    for img_path, depth_path in zip(image_paths, depth_paths):
        img = load_img(img_path, target_size=target_size)
        depth = load_img(depth_path, target_size=target_size, color_mode="grayscale")
        img = img_to_array(img) / 255.0
        depth = img_to_array(depth) / 255.0
        images.append(img)
        depths.append(depth)
    return np.array(images), np.array(depths)

train_images, train_depths = load_data(train_image_paths, train_depth_paths)
test_images, test_depths = load_data(test_image_paths, test_depth_paths)

# Split training data into training and validation sets
train_images, val_images, train_depths, val_depths = train_test_split(train_images, train_depths, test_size=0.2, random_state=42)

# Define the ResNet-based U-Net model
def build_resnet_unet(input_shape=(256, 256, 3)):
    # Load pre-trained ResNet50
    resnet = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)
    
    # Encoder
    encoder_output = resnet.output
    
    # Decoder
    x = Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same')(encoder_output)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    
    x = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    
    x = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    
    x = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    
    # Output layer
    outputs = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)
    
    model = Model(inputs=resnet.input, outputs=outputs)
    return model

# Custom loss function for depth estimation
def depth_loss(y_true, y_pred):
    return tf.reduce_mean(tf.abs(y_true - y_pred))

# Custom metric for depth accuracy
def depth_acc(y_true, y_pred):
    return tf.reduce_mean(tf.square(y_true - y_pred))

# Build the model
model = build_resnet_unet()

# Compile the model
model.compile(optimizer=Adam(learning_rate=1e-4), loss=depth_loss, metrics=[depth_acc])

# Callbacks
checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')
early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)

# Train the model
history = model.fit(
    train_images, train_depths,
    validation_data=(val_images, val_depths),
    epochs=50,
    batch_size=8,
    callbacks=[checkpoint, early_stopping, reduce_lr]
)

# Evaluate the model
test_loss, test_acc = model.evaluate(test_images, test_depths)
print(f'Test Loss: {test_loss}, Test Accuracy: {test_acc}')

# Predict and visualize results
def visualize_results(model, test_images, test_depths, num_samples=5):
    for i in range(num_samples):
        pred_depth = model.predict(np.expand_dims(test_images[i], axis=0))
        pred_depth = pred_depth.squeeze()
        plt.figure(figsize=(15, 5))
        plt.subplot(1, 3, 1)
        plt.title('Input Image')
        plt.imshow(test_images[i])
        plt.subplot(1, 3, 2)
        plt.title('Ground Truth Depth')
        plt.imshow(test_depths[i].squeeze(), cmap='gray')
        plt.subplot(1, 3, 3)
        plt.title('Predicted Depth')
        plt.imshow(pred_depth, cmap='gray')
        plt.show()

visualize_results(model, test_images, test_depths)
```
------------------------------------- 21
```python
import os
import numpy as np
import h5py
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, BatchNormalization, Activation
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Load the dataset
def load_data(data_dir):
    images = []
    density_maps = []
    for filename in os.listdir(data_dir):
        if filename.endswith('.h5'):
            with h5py.File(os.path.join(data_dir, filename), 'r') as hf:
                images.append(hf['image'][:])
                density_maps.append(hf['density'][:])
    return np.array(images), np.array(density_maps)

# Preprocess the data
def preprocess(images, density_maps):
    images = images.astype('float32') / 255.0  # Normalize images
    density_maps = density_maps.astype('float32') / np.max(density_maps)  # Normalize density maps
    return images, density_maps

# Define the model architecture
def create_model(input_shape):
    inputs = Input(shape=input_shape)
    
    # Encoder
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)
    conv1 = BatchNormalization()(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    
    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)
    conv2 = BatchNormalization()(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    
    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)
    conv3 = BatchNormalization()(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    
    # Bottleneck
    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)
    conv4 = BatchNormalization()(conv4)
    
    # Decoder
    up5 = UpSampling2D(size=(2, 2))(conv4)
    conv5 = Conv2D(256, 3, activation='relu', padding='same')(up5)
    conv5 = BatchNormalization()(conv5)
    
    up6 = UpSampling2D(size=(2, 2))(conv5)
    conv6 = Conv2D(128, 3, activation='relu', padding='same')(up6)
    conv6 = BatchNormalization()(conv6)
    
    up7 = UpSampling2D(size=(2, 2))(conv6)
    conv7 = Conv2D(64, 3, activation='relu', padding='same')(up7)
    conv7 = BatchNormalization()(conv7)
    
    # Output layer
    outputs = Conv2D(1, 1, activation='linear')(conv7)
    
    model = Model(inputs=inputs, outputs=outputs)
    return model

# Define custom evaluation metric: Mean Absolute Error on Density Map
def density_mae(y_true, y_pred):
    return tf.reduce_mean(tf.abs(y_true - y_pred))

# Data Augmentation
datagen = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.01,
    zoom_range=[0.9, 1.25],
    horizontal_flip=True,
    vertical_flip=False,
    fill_mode='reflect',
    data_format='channels_last'
)

# Load and preprocess the data
data_dir = '/path/to/ShanghaiTech/part_B/train_data'
images, density_maps = load_data(data_dir)
images, density_maps = preprocess(images, density_maps)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(images, density_maps, test_size=0.2, random_state=42)

# Create and compile the model
model = create_model(input_shape=(images.shape[1], images.shape[2], images.shape[3]))
model.compile(optimizer=Adam(), loss='mse', metrics=[density_mae])

# Train the model with data augmentation
model.fit(datagen.flow(X_train, y_train, batch_size=16), epochs=50, steps_per_epoch=len(X_train) // 16, validation_data=(X_test, y_test))

# Evaluate the model
loss, mae = model.evaluate(X_test, y_test)
print(f'Test Loss: {loss}')
print(f'Test MAE: {mae}')

# Predict density maps for test images
predictions = model.predict(X_test)

# Example: Display a predicted density map
plt.imshow(predictions[0, :, :, 0], cmap='jet')
plt.colorbar()
plt.show()
```
------------------------------------- 22
```python
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, Concatenate, Dense, Flatten, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import numpy as np
import matplotlib.pyplot as plt

# Configuration class
class Config:
    img_size = (224, 224, 3)
    batch_size = 32
    epochs = 10
    validation_split = 0.15
    random_state = 42

config = Config()

# Function to parse TFRecord
def parse_tfrecord(example_proto):
    feature_description = {
        'image': tf.io.FixedLenFeature([], tf.string),
        'label': tf.io.FixedLenFeature([], tf.int64),
    }
    example = tf.io.parse_single_example(example_proto, feature_description)
    image = tf.image.decode_jpeg(example['image'], channels=3)
    image = tf.image.resize(image, [config.img_size[0], config.img_size[1]])
    image = image / 255.0  # Normalize to [0, 1]
    label = tf.one_hot(example['label'], depth=2)  # Assuming binary classification
    return image, label

# Load and preprocess dataset
def load_dataset(filenames):
    dataset = tf.data.TFRecordDataset(filenames)
    dataset = dataset.map(parse_tfrecord, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    dataset = dataset.shuffle(buffer_size=1024).batch(config.batch_size).prefetch(tf.data.experimental.AUTOTUNE)
    return dataset

train_filenames = ['path/to/train.tfrecord']
val_filenames = ['path/to/val.tfrecord']

train_dataset = load_dataset(train_filenames)
val_dataset = load_dataset(val_filenames)

# Define EfficientNet encoder
def efficientnet_encoder(input_shape):
    base_model = EfficientNetB0(input_shape=input_shape, include_top=False, weights='imagenet')
    for layer in base_model.layers:
        layer.trainable = False
    return base_model

# Define StopNet encoder (placeholder)
def stopnet_encoder(input_shape):
    inputs = Input(shape=input_shape)
    x = Conv2D(32, (3, 3), activation='relu')(inputs)
    x = Conv2D(64, (3, 3), activation='relu')(x)
    x = Flatten()(x)
    model = Model(inputs, x)
    return model

# Combine EfficientNet and StopNet encoders
def combined_model(input_shape):
    efficientnet_input = Input(shape=input_shape)
    stopnet_input = Input(shape=input_shape)

    efficientnet = efficientnet_encoder(input_shape)(efficientnet_input)
    stopnet = stopnet_encoder(input_shape)(stopnet_input)

    combined = Concatenate()([efficientnet, stopnet])
    x = Dense(128, activation='relu')(combined)
    x = Dropout(0.5)(x)
    x = Dense(64, activation='relu')(x)
    x = Dropout(0.5)(x)
    x = Dense(2, activation='softmax')(x)  # Output layer for binary classification

    model = Model([efficientnet_input, stopnet_input], x)
    return model

# Build the model
input_shape = (config.img_size[0], config.img_size[1], config.img_size[2])
model = combined_model(input_shape)

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

# Callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')

# Training
history = model.fit(
    [train_dataset.map(lambda x, y: x), train_dataset.map(lambda x, y: x)], 
    train_dataset.map(lambda x, y: y), 
    epochs=config.epochs, 
    batch_size=config.batch_size, 
    validation_data=([val_dataset.map(lambda x, y: x), val_dataset.map(lambda x, y: x)], val_dataset.map(lambda x, y: y)),
    callbacks=[early_stopping, checkpoint]
)

# Evaluation
test_filenames = ['path/to/test.tfrecord']
test_dataset = load_dataset(test_filenames)
test_loss, test_accuracy = model.evaluate([test_dataset.map(lambda x, y: x), test_dataset.map(lambda x, y: x)], test_dataset.map(lambda x, y: y))
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")

# Visualization
def visualize_predictions(dataset, model):
    for images, labels in dataset.take(1):
        predictions = model.predict([images, images])
        for i in range(len(images)):
            plt.imshow(images[i].numpy().astype("uint8"))
            plt.title(f"True: {np.argmax(labels[i])}, Pred: {np.argmax(predictions[i])}")
            plt.show()

visualize_predictions(test_dataset, model)
```
------------------------------------- 23
```python
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers, models, regularizers
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# Load the dataset
# Replace 'your_dataset.csv' with the actual path to your dataset
data = pd.read_csv('your_dataset.csv')

# Preprocessing
# Handle null values
data.dropna(inplace=True)

# Separate features and target
X = data.drop('target', axis=1)  # Assuming 'target' is the column name for the labels
y = data['target']

# Encode target labels (assuming binary classification: 0 for normal, 1 for DoS attack)
y = y.map({'normal': 0, 'DoS': 1})

# Standardize numerical features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Perform PCA for dimensionality reduction
pca = PCA(n_components=10)  # Adjust the number of components as needed
X_pca = pca.fit_transform(X_scaled)

# Reshape data to include a time step dimension
# Assuming each instance represents a time step, reshape to (num_samples, 1, num_features)
X_reshaped = X_pca.reshape((X_pca.shape[0], 1, X_pca.shape[1]))

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y, test_size=0.2, random_state=42)

def create_model(input_shape):
    model = models.Sequential()

    # Bi-directional LSTM layer
    model.add(layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=input_shape))
    model.add(layers.Dropout(0.5))

    # Another Bi-directional LSTM layer
    model.add(layers.Bidirectional(layers.LSTM(64)))
    model.add(layers.Dropout(0.5))

    # Fully connected layer
    model.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))
    model.add(layers.Dropout(0.5))

    # Output layer
    model.add(layers.Dense(1, activation='sigmoid'))

    return model

# Define the input shape
input_shape = (X_train.shape[1], X_train.shape[2])

# Create the model
model = create_model(input_shape)

# Compile the model
optimizer = Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])

# Set the number of folds for cross-validation
num_folds = 5
skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)

# Initialize lists to store training and validation accuracies
train_accuracies = []
val_accuracies = []

# Iterate through folds
for fold_index, (train_index, val_index) in enumerate(skf.split(X_train, y_train)):
    print(f"Training fold {fold_index + 1}/{num_folds}")

    # Split the data into training and validation sets
    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]
    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]

    # Train the model
    history = model.fit(X_train_fold, y_train_fold, batch_size=64, epochs=50, validation_data=(X_val_fold, y_val_fold), verbose=1)

    # Evaluate and store training accuracy
    train_loss, train_acc = model.evaluate(X_train_fold, y_train_fold, verbose=0)
    train_accuracies.append(train_acc)

    # Evaluate and store validation accuracy
    val_loss, val_acc = model.evaluate(X_val_fold, y_val_fold, verbose=0)
    val_accuracies.append(val_acc)

    # Save the model for each fold
    model.save(f"model_fold_{fold_index+1}.h5")

# Print average training and validation accuracies
print(f"\nAverage Training Accuracy: {np.mean(train_accuracies):.4f}")
print(f"Average Validation Accuracy: {np.mean(val_accuracies):.4f}")

# Evaluate the model on the test set
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {test_acc:.4f}")

# Summary of the model
model.summary()
```
------------------------------------- 24
```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, LeakyReLU, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np

# Assuming X is your 2D audio feature array and y is your one-hot encoded labels
# X.shape = (num_samples, 40, 249, 1)
# y.shape = (num_samples, 10)

# Preprocess the data
scaler = StandardScaler()
X = scaler.fit_transform(X.reshape(X.shape[0], -1)).reshape(X.shape)

# Split the data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the CNN model
def create_model(input_shape, num_classes):
    model = Sequential()
    
    # First set of convolutional layers
    model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01), input_shape=input_shape))
    model.add(LeakyReLU(alpha=0.1))
    model.add(BatchNormalization())
    model.add(MaxPooling2D((2, 2)))
    
    # Second set of convolutional layers
    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01)))
    model.add(LeakyReLU(alpha=0.1))
    model.add(BatchNormalization())
    model.add(MaxPooling2D((2, 2)))
    
    # Third set of convolutional layers
    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01)))
    model.add(LeakyReLU(alpha=0.1))
    model.add(BatchNormalization())
    model.add(MaxPooling2D((2, 2)))
    
    # Flatten and dense layers
    model.add(Flatten())
    model.add(Dense(256, activation='relu'))
    model.add(Dropout(0.5))
    model.add(BatchNormalization())
    
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))
    model.add(BatchNormalization())
    
    # Output layer
    model.add(Dense(num_classes, activation='softmax'))
    
    # Compile the model
    model.compile(optimizer=Adam(learning_rate=0.001),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    
    return model

# Define input shape and number of classes
input_shape = (40, 249, 1)
num_classes = 10

# Create the model
model = create_model(input_shape, num_classes)

# Print the model summary
model.summary()

# Define callbacks
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train,
                    epochs=50,
                    batch_size=32,
                    validation_data=(X_val, y_val),
                    callbacks=[reduce_lr, early_stopping])

# Evaluate the model
val_loss, val_acc = model.evaluate(X_val, y_val)
print(f'Validation Loss: {val_loss}')
print(f'Validation Accuracy: {val_acc}')
```
------------------------------------- 25
```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.decomposition import PCA
from sklearn.ensemble import IsolationForest
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from kerastuner.tuners import RandomSearch

# Load the dataset
TRAIN = 'path_to_training_data.csv'
TEST = 'path_to_testing_data.csv'

df = pd.read_csv(TRAIN)
test = pd.read_csv(TEST)

# Define features and target
features = df.columns.drop(['fault_category_1', 'fault_category_2', 'fault_category_3', 'fault_category_4', 'fault_category_5', 'fault_category_6', 'fault_category_7'])
target = ['fault_category_1', 'fault_category_2', 'fault_category_3', 'fault_category_4', 'fault_category_5', 'fault_category_6', 'fault_category_7']

# Preprocessing
numerical_cols = df[features].select_dtypes(include=['int64', 'float64']).columns
categorical_cols = df[features].select_dtypes(include=['object']).columns

numerical_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

# Split the data
X = df[features]
y = df[target]
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)

# Preprocess the data
X_train = preprocessor.fit_transform(X_train)
X_valid = preprocessor.transform(X_valid)

# PCA for dimensionality reduction
pca = PCA(n_components=0.95)  # Retain 95% of the variance
X_train_pca = pca.fit_transform(X_train)
X_valid_pca = pca.transform(X_valid)

# Anomaly detection using Isolation Forest
iso_forest = IsolationForest(contamination=0.05)  # Assume 5% of the data is anomalous
anomalies = iso_forest.fit_predict(X_train_pca)
X_train_clean = X_train_pca[anomalies == 1]
y_train_clean = y_train[anomalies == 1]

# Define the model architecture
def build_model(hp):
    model = Sequential()
    
    # Input layer
    model.add(Dense(units=hp.Choice('unit1', [8, 16, 32]), input_shape=(X_train_clean.shape[1],)))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.1))
    model.add(Dropout(rate=hp.Choice('dropout1', [0.3, 0.5, 0.7])))
    
    # Hidden layers
    model.add(Dense(units=hp.Choice('unit2', [8, 16, 32])))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.1))
    model.add(Dropout(rate=hp.Choice('dropout2', [0.3, 0.5, 0.7])))
    
    model.add(Dense(units=hp.Choice('unit3', [8, 16, 32])))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.1))
    model.add(Dropout(rate=hp.Choice('dropout3', [0.3, 0.5, 0.7])))
    
    # Output layer
    model.add(Dense(units=len(target), activation='sigmoid'))  # Multi-label classification
    
    # Compile the model
    model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    
    return model

# Hyperparameter tuning
tuner = RandomSearch(
    build_model,
    objective='val_loss',
    max_trials=10,
    executions_per_trial=2,
    directory='fault_classification',
    project_name='fault_detection'
)

# Early stopping to prevent overfitting
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Search for the best hyperparameters
tuner.search(X_train_clean, y_train_clean, epochs=50, batch_size=32, validation_data=(X_valid_pca, y_valid), callbacks=[early_stopping])

# Get the best model
best_model = tuner.get_best_models(num_models=1)[0]

# Evaluate the best model on the validation set
val_loss, val_accuracy = best_model.evaluate(X_valid_pca, y_valid)
print(f'Validation Loss: {val_loss}')
print(f'Validation Accuracy: {val_accuracy}')

# Make predictions on the test set
test_preprocessed = preprocessor.transform(test[features])
test_pca = pca.transform(test_preprocessed)
predictions = best_model.predict(test_pca)

# Convert predictions to binary labels
predicted_labels = (predictions > 0.5).astype(int)

# Save predictions to a CSV file
submission_df = pd.DataFrame(predicted_labels, columns=target)
submission_df.to_csv('fault_predictions.csv', index=False)
```
------------------------------------- 26
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
import keras_tuner as kt

# Load the dataset
df = pd.read_csv("/kaggle/input/patient-health-records/Dataset.csv")

# Display basic information about the dataset
df.head()
df.info()
df.shape
df.isnull().sum()
df.columns
df.describe()

# Drop columns with unique values that are not useful for prediction
columns_to_drop = ['encounter_id', 'patient_id', 'hospital_id', 'hospital_admit_source', 'icu_admit_source', 'icu_stay_type', 'icu_id', 'readmission_status']
df = df.drop(columns=columns_to_drop, axis=1)

# Function to identify columns with more than 50% missing values
def missing_col(df):
    missing_df = pd.DataFrame(df.isnull().sum() / df.shape[0], columns=["Missing"])
    return missing_df[missing_df["Missing"] >= 0.50]

# Drop columns with more than 50% missing values
missing_val_col = list(missing_col(df).index)
df = df.drop(columns=missing_val_col)

# Ensure no rows with missing values in 'bmi', 'weight', 'height'
df = df[df[['bmi', 'weight', 'height']].isnull().sum(axis=1) == 0]

# Impute missing values with the most frequent value
imputer = SimpleImputer(strategy='most_frequent')
df.iloc[:, :] = imputer.fit_transform(df)

# Identify categorical and numerical columns
categorical_cols = df.select_dtypes(include=['object']).columns
numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns

# Preprocessing pipeline for numerical and categorical data
numerical_transformer = Pipeline(steps=[
    ('scaler', MinMaxScaler())
])

categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

# Prepare features and target variable
X = df.drop("DiagPeriodL90D", axis=1)
y = df['DiagPeriodL90D']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=45)

# Preprocess the data
X_train = preprocessor.fit_transform(X_train)
X_test = preprocessor.transform(X_test)

# Convert target labels to numpy arrays
y_train = np.array(y_train)
y_test = np.array(y_test)

# Define the model architecture
def build_model(hp):
    model = Sequential()
    model.add(Dense(units=hp.Int('units', min_value=32, max_value=512, step=32), 
                    input_shape=(X_train.shape[1],), activation='relu'))
    model.add(Dropout(hp.Float('dropout', min_value=0.1, max_value=0.5, step=0.1)))
    model.add(Dense(units=hp.Int('units', min_value=32, max_value=512, step=32), activation='relu'))
    model.add(Dropout(hp.Float('dropout', min_value=0.1, max_value=0.5, step=0.1)))
    model.add(Dense(1, activation='sigmoid'))

    # Tune the learning rate for the optimizer
    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])

    metrics = [
        keras.metrics.Precision(name="precision"),
        keras.metrics.Recall(name="recall"),
        keras.metrics.AUC(curve='ROC')
    ]

    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),
                  loss='binary_crossentropy',
                  metrics=metrics)

    return model

# Hyperparameter tuning with Keras Tuner
tuner = kt.RandomSearch(
    build_model,
    objective='val_loss',
    max_trials=5,
    directory='keras_tuner_dir',
    project_name='patient_diagnosis'
)

# Early stopping to prevent overfitting
stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_recall', patience=5)

tuner.search(X_train, y_train, epochs=25, validation_data=(X_test, y_test), callbacks=[stop_early])

# Get the optimal hyperparameters
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]

print(f"""
The hyperparameter search is complete. The optimal number of units in the first densely-connected
layer is {best_hps.get('units')} and the optimal learning rate for the optimizer
is {best_hps.get('learning_rate')}.
""")

# Build the final model with the best hyperparameters
model = Sequential()
model.add(Dense(best_hps.get('units'), input_dim=X_train.shape[1], activation='relu'))
model.add(Dropout(best_hps.get('dropout')))
model.add(Dense(best_hps.get('units'), activation='relu'))
model.add(Dropout(best_hps.get('dropout')))
model.add(Dense(1, activation='sigmoid'))

metrics = [
    keras.metrics.Precision(name="precision"),
    keras.metrics.Recall(name="recall"),
    keras.metrics.AUC(curve='ROC')
]

model.compile(optimizer=keras.optimizers.Adam(best_hps.get('learning_rate')),
              loss='binary_crossentropy',
              metrics=metrics)

# Train the final model
epochs = 15
batch_size = 32
history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size)

# Plot final training and validation metrics
acc = history.history['auc']
val_acc = history.history['val_auc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(15, 6))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training AUC Score')
plt.plot(epochs_range, val_acc, label='Validation AUC Score')
plt.legend(loc='lower right')
plt.title('Training and Validation AUC Score')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()
```
------------------------------------- 27
```python
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam

# Load the dataset
df = pd.read_csv('patient_survival_data.csv')

# Display the first few rows of the dataset
print("First few rows of the dataset:")
print(df.head())

# Display the dimensions of the dataset
print("\nDimensions of the dataset:")
print(df.shape)

# Display basic statistics for numerical columns in the dataset
print("\nSummary statistics for numerical columns in the dataset:")
print(df.describe())

# Display information about the dataset
print("\nInformation about the dataset:")
print(df.info())

# Check for null values
print("\nChecking for null values...")
null_values = df.isnull().sum()
null_columns = null_values[null_values > 0]
if not null_columns.empty:
    print('Columns with null values:')
    print(null_columns)
else:
    print('No null values found in the dataset.')

# Drop columns with more than 50% missing values
threshold = 0.5 * len(df)
df = df.dropna(thresh=threshold, axis=1)

# Identify numerical and categorical columns
numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns
categorical_cols = df.select_dtypes(include=['object', 'category']).columns

# Impute null values in numerical columns with the mean
numerical_imputer = SimpleImputer(strategy='mean')
df[numerical_cols] = numerical_imputer.fit_transform(df[numerical_cols])

# One-hot encode categorical columns
categorical_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')
categorical_encoded = categorical_encoder.fit_transform(df[categorical_cols])
categorical_encoded_df = pd.DataFrame(categorical_encoded, columns=categorical_encoder.get_feature_names_out(categorical_cols))

# Concatenate numerical and encoded categorical features
df = pd.concat([df[numerical_cols].reset_index(drop=True), categorical_encoded_df.reset_index(drop=True)], axis=1)

# Split the dataset into features (X) and target (y)
X = df.drop('Survival_Status', axis=1)
y = df['Survival_Status']

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the dataset into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Build the deep learning model
model = Sequential()
model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['AUC'])

# Set early stopping
early_stopping = EarlyStopping(patience=10, monitor='val_loss')

# Train the model
history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[early_stopping])

# Evaluate the model
y_pred_probs = model.predict(X_val)
y_pred = (y_pred_probs > 0.5).astype(int)

# Calculate ROC curve and AUC
fpr, tpr, thresholds = roc_curve(y_val, y_pred_probs)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Generate confusion matrix
conf_matrix = confusion_matrix(y_val, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=True)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.xticks([0.5, 1.5], ['Not Survived', 'Survived'])
plt.yticks([0.5, 1.5], ['Not Survived', 'Survived'])
plt.show()

# Calculate metrics
accuracy = accuracy_score(y_val, y_pred)
precision = precision_score(y_val, y_pred)
recall = recall_score(y_val, y_pred)
f1 = f1_score(y_val, y_pred)

# Print metrics
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

# Print classification report
print("Classification Report:")
print(classification_report(y_val, y_pred))
```
------------------------------------- 28
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM
from tensorflow.keras.optimizers import Adam, RMSprop
from tensorflow.keras.callbacks import EarlyStopping
from scikeras.wrappers import KerasRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error

# Load the dataset
train_path = r"/kaggle/input/predictiva-dl-time-series-forecasting/train.csv"
test_path = r"/kaggle/input/predictiva-dl-time-series-forecasting/test.csv"
train_data = pd.read_csv(train_path)
test_data = pd.read_csv(test_path)

# Explore data before cleaning
def explore_data(data):
    """
    Display basic information about the dataset.
    """
    print("Data Overview:")
    print(data.head())
    print("\nData Info:")
    print(data.info())
    print("\nSummary Statistics:")
    print(data.describe())

explore_data(train_data)

# Handle missing values by filling with random values from a normal distribution
for column in train_data.columns:
    if train_data[column].isnull().any():
        mean = train_data[column].mean()
        std = train_data[column].std()
        train_data[column].fillna(np.random.normal(mean, std), inplace=True)

# Encode categorical variables using OneHotEncoder
categorical_columns = ['zip_code', 'race', 'payer_type', 'diagnosis_codes']
train_data = pd.get_dummies(train_data, columns=categorical_columns)

# Split the data into features and target
X = train_data.drop(columns=['DiagPeriodL90D'])
y = train_data['DiagPeriodL90D']

# Split the data into training, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

# Reshape data for LSTM
X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])
X_val_reshaped = X_val_scaled.reshape(X_val_scaled.shape[0], 1, X_val_scaled.shape[1])
X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])

# Define a function to create the LSTM model
def create_lstm_model(units=50, dropout_rate=0.2, optimizer='adam', loss='mean_squared_error'):
    model = Sequential()
    model.add(LSTM(units=units, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))
    model.add(Dropout(dropout_rate))
    model.add(Dense(units=1))
    model.compile(optimizer=optimizer, loss=loss)
    return model

# Create KerasRegressor for use in GridSearchCV
lstm_regressor = KerasRegressor(build_fn=create_lstm_model, verbose=0)

# Define hyperparameters grid including optimizers and loss functions
param_grid = {
    'units': [50, 100],
    'dropout_rate': [0.0, 0.2, 0.4],
    'optimizer': ['adam', 'rmsprop'],
    'loss': ['mean_squared_error', 'mean_absolute_error']
}

# Perform GridSearchCV
grid_search = GridSearchCV(estimator=lstm_regressor, param_grid=param_grid, cv=3)
grid_result = grid_search.fit(X_train_reshaped, y_train)

# Print best results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("Mean MSE: %f, Standard Deviation: %f with: %r" % (mean, stdev, param))

# Train the best model with early stopping
best_lstm_model = create_lstm_model(**grid_result.best_params_)
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
history = best_lstm_model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, verbose=1, validation_data=(X_val_reshaped, y_val), callbacks=[early_stopping])

# Evaluate the model on test data
loss = best_lstm_model.evaluate(X_test_reshaped, y_test)
print("Loss on test data:", loss)

# Plot training loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Make predictions on the test set
y_test_pred = best_lstm_model.predict(X_test_reshaped)

# Plot the predicted vs actual values
plt.figure(figsize=(12, 6))
plt.plot(y_test.values, label='Actual Data', marker='o')
plt.plot(y_test_pred, label='Predicted Data', marker='o')
plt.xlabel('Sample Index')
plt.ylabel('Diagnosis Period (L90D)')
plt.title('LSTM Model - Predicted vs Actual on Test Data')
plt.legend()
plt.show()

# Prepare the test data for prediction
test_data_encoded = test_data.copy()
test_data_encoded = pd.get_dummies(test_data_encoded, columns=categorical_columns)

# Ensure the test data has the same columns as the training data
for col in X.columns:
    if col not in test_data_encoded.columns:
        test_data_encoded[col] = 0

X_test_final = test_data_encoded[X.columns]
X_test_final_scaled = scaler.transform(X_test_final)
X_test_final_reshaped = X_test_final_scaled.reshape(X_test_final_scaled.shape[0], 1, X_test_final_scaled.shape[1])

# Make predictions on the final test set
y_test_final_pred = best_lstm_model.predict(X_test_final_reshaped)

# Create submission DataFrame
submission = pd.DataFrame({
    'id': test_data['id'],
    'DiagPeriodL90D': y_test_final_pred.flatten()
})

# Save the submission file
submission.to_csv('submission.csv', index=False)
```
------------------------------------- 29
```python
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Lambda, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.losses import Huber
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import LearningRateScheduler
from tensorflow.keras.metrics import mean_absolute_error
from statsmodels.tsa.statespace.sarimax import SARIMAX
from sklearn.preprocessing import StandardScaler

# Directory containing input files
DIR_IN = "/kaggle/input/sales-data/"
# Working directory (the only writable place in a Kaggle's work)
DIR_WORK = "/kaggle/working/"
# Full path to the input file
FILE_IN = os.path.join(DIR_IN, "sales_data.csv")
# Date used to split the training and the test part
SPLIT_DATE = "2023-01-01"
# Size of the window applied to the time series
WINDOW_SIZE = 10
# Batch size for model training and prediction
BATCH_SIZE = 32
# Buffer size used to shuffle the training set, should be bigger than the dataset's size
SHUFFLE_BUFFER = 3000

# Load the dataset
df = pd.read_csv(FILE_IN, sep=",")
df.head()

# Preprocess the data
df['Date'] = pd.to_datetime(df['Date'])
df.set_index('Date', inplace=True)
df = df.resample('D').asfreq()
df = df.ffill()

# Log transformation to handle skewness
df['Number_of_Products_Sold'] = np.log1p(df['Number_of_Products_Sold'])

# Normalize the data
scaler = StandardScaler()
df['Number_of_Products_Sold'] = scaler.fit_transform(df[['Number_of_Products_Sold']])

# Split the data into training and test sets
df_train = df[df.index < SPLIT_DATE]
df_test = df[df.index >= SPLIT_DATE]

time_test = df_test.index  # just used for plotting results at the end

X_train = df_train['Number_of_Products_Sold'].values  # convert to Numpy array
X_test = df_test['Number_of_Products_Sold'].values  # convert to Numpy array

print(f"X_train shape = {X_train.shape}; X_test shape = {X_test.shape}")
print(f"Some X_train data: {X_train[:10]}")

# Utility function to plot a series
def plot_series(x, y, start=0, end=None, title=None, xlabel=None, ylabel=None):
    """
    Utility function to plot a series
    
    Args:
        x (1d Numpy array): values for the x-axis
        y (tuple of Numpy arrays or 1d Numpy array): values for the y-axis
        start (int): start index
        end (int): end index
        title (str): title of the plot
        xlabel (str): label for the x-axis
        ylabel (str): label for the y-axis
    """
    plt.figure(figsize=(10, 6))
    if type(y) is tuple:
        for val_set in y:
            plt.plot(x[start: end], val_set[start: end])
    else:
        plt.plot(x[start: end], y[start: end])
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.grid(True)    
    plt.show()

# Function to create windowed dataset for training
def window_train(series, window_size, batch_size, shuffle_buffer):
    """
    Convert the train series to Tensorflow Dataset
    
    Args:
        series (1d Numpy array): input time series data
        window_size (int): size of the sliding window
        batch_size (int): number of elements in each batch
        shuffle_buffer (int): buffer size used for shuffling
        
    Returns:
        A Tensorflow Dataset where each batch's element is a tuple ([v-N, ..., v-1], [v])
        where v, v-1, ..., v-N are values at time t, t-1, ..., t-N, respectively.
    """
    dataset = tf.data.Dataset.from_tensor_slices(series)
    dataset = dataset.window(window_size + 1, shift=1, stride=1, drop_remainder=True)
    dataset = dataset.flat_map(lambda w: w.batch(window_size + 1))
    dataset = dataset.map(lambda w: (w[:-1], w[-1]))
    dataset = dataset.shuffle(shuffle_buffer)
    dataset = dataset.batch(batch_size).prefetch(1)
    return dataset

# Function to create windowed dataset for testing
def window_test(series, window_size, batch_size):
    """
    Convert the test series to Tensorflow Dataset
    """
    dataset = tf.data.Dataset.from_tensor_slices(series)
    dataset = dataset.window(window_size, shift=1, stride=1, drop_remainder=True)
    dataset = dataset.flat_map(lambda w: w.batch(window_size))
    dataset = dataset.batch(batch_size).prefetch(1)
    return dataset

# Create the train and test datasets
ds_train = window_train(X_train, WINDOW_SIZE, BATCH_SIZE, SHUFFLE_BUFFER)
ds_test = window_test(np.concatenate((X_train[-WINDOW_SIZE:], X_test[:-1])), WINDOW_SIZE, BATCH_SIZE)

# LSTM Model
tf.keras.backend.clear_session()

model = Sequential([
    Lambda(lambda x: tf.expand_dims(x, axis=-1), input_shape=[WINDOW_SIZE]),
    Bidirectional(LSTM(32, return_sequences=True)),
    Bidirectional(LSTM(32)),
    Dropout(0.2),
    Dense(1),
    Lambda(lambda x: x * 100.0)
])

# Save the initial weights
init_weights = model.get_weights()

model.summary()

# Learning rate scheduler
lr_schd = LearningRateScheduler(lambda epoch: 1e-8 * 10**(epoch / 20))

model.compile(loss=Huber(), optimizer=Adam())

# Train the model
hist = model.fit(ds_train, epochs=100, callbacks=[lr_schd])

# Plot learning rate vs loss
lr_arr = 1e-8 * (10 ** (np.arange(100) / 20))
plt.figure(figsize=(10, 6))
plt.grid(True)
plt.semilogx(lr_arr, hist.history['loss'])
plt.tick_params('both', length=10, width=1, which='both')
plt.axis([1e-8, 1e-3, 0, 100])

# Reset model weights and compile with optimal learning rate
model.set_weights(init_weights)
model.compile(loss=Huber(), optimizer=Adam(learning_rate=1e-4), metrics=['mae'])

# Train the model again with optimal learning rate
hist = model.fit(ds_train, epochs=300)

# Plot MAE and Loss
hist_mae = hist.history['mae']
hist_loss = hist.history['loss']
plot_series(range(len(hist_loss)), (hist_mae, hist_loss), title="MAE & Loss", xlabel="Epochs")

# Make predictions using LSTM model
forecasts_lstm = model.predict(ds_test)
forecasts_lstm = forecasts_lstm.squeeze()  # remove the single axis

# SARIMAX Model
model_sarimax = SARIMAX(X_train, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))
results_sarimax = model_sarimax.fit(disp=False)
forecasts_sarimax = results_sarimax.get_forecast(steps=len(X_test)).predicted_mean

# Combine predictions from SARIMAX and LSTM
final_predictions = (forecasts_lstm + forecasts_sarimax) / 2

# Inverse transform the predictions to get the original scale
final_predictions = scaler.inverse_transform(final_predictions.reshape(-1, 1))
final_predictions = np.expm1(final_predictions)

# Plot actual vs predicted values
plot_series(time_test, (X_test, forecasts_lstm, forecasts_sarimax), title="Actual vs Predicted Sales", xlabel="Date", ylabel="Number of Products Sold")

# Calculate MAE for LSTM and SARIMAX
mae_lstm = mean_absolute_error(X_test, forecasts_lstm).numpy()
mae_sarimax = mean_absolute_error(X_test, forecasts_sarimax).numpy()
mean = np.mean(X_test)

print(f"LSTM MAE = {mae_lstm:.2f}")
print(f"SARIMAX MAE = {mae_sarimax:.2f}")
print(f"LSTM MAE / mean = {(mae_lstm/mean * 100):.2f} %")
print(f"SARIMAX MAE / mean = {(mae_sarimax/mean * 100):.2f} %")
```
------------------------------------- 30
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, Lambda
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_squared_error, mean_absolute_error

# Constants
WINDOW_SIZE = 50
EPOCHS = 100
BATCH_SIZE = 32
LEARNING_RATE = 0.0001

# Load the dataset
def load_data(file_path):
    df = pd.read_csv(file_path)
    return df

# Preprocess the data
def preprocess_data(df, commodity_name):
    # Filter for the specific commodity
    df = df[df['Commodity'] == commodity_name]
    
    # Convert 'Date' to datetime
    df['Date'] = pd.to_datetime(df['Date'])
    
    # Sort by date
    df = df.sort_values('Date')
    
    # Resample to fill missing dates and forward fill NaN values
    df = df.set_index('Date').resample('D').ffill().reset_index()
    
    # Drop the 'Commodity' column as it's no longer needed
    df = df.drop(columns=['Commodity'])
    
    return df

# Create sequences for LSTM
def create_sequences(data, window_size):
    X, y = [], []
    for i in range(len(data) - window_size):
        X.append(data[i:i+window_size])
        y.append(data[i+window_size])
    return np.array(X), np.array(y)

# Build the LSTM model
def build_model(window_size):
    model = Sequential([
        Lambda(lambda x: tf.expand_dims(x, axis=-1), input_shape=[window_size]),
        Bidirectional(LSTM(50, return_sequences=True)),
        Dropout(0.2),
        Bidirectional(LSTM(50, return_sequences=False)),
        Dropout(0.2),
        Dense(25),
        Dense(1)
    ])
    
    optimizer = Adam(learning_rate=LEARNING_RATE)
    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])
    
    return model

# Main function to train and evaluate the model
def main():
    # Load the dataset
    file_path = 'fruit_prices.csv'
    df = load_data(file_path)
    
    # Preprocess the data for 'Potato Red'
    commodity_name = 'Potato Red'
    df = preprocess_data(df, commodity_name)
    
    # Extract the 'Average' price column
    prices = df['Average'].values
    
    # Normalize the data
    scaler = MinMaxScaler()
    prices_scaled = scaler.fit_transform(prices.reshape(-1, 1))
    
    # Create sequences
    X, y = create_sequences(prices_scaled, WINDOW_SIZE)
    
    # Split into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
    
    # Build the model
    model = build_model(WINDOW_SIZE)
    
    # Train the model
    early_stop = EarlyStopping(monitor='val_loss', patience=10)
    history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.2, callbacks=[early_stop], verbose=1)
    
    # Plot training & validation loss values
    plt.figure(figsize=(12, 6))
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('Model loss')
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Validation'], loc='upper right')
    plt.show()
    
    # Make predictions
    train_predict = model.predict(X_train)
    test_predict = model.predict(X_test)
    
    # Inverse transform the predictions and actual values
    train_predict = scaler.inverse_transform(train_predict)
    y_train_actual = scaler.inverse_transform(y_train)
    test_predict = scaler.inverse_transform(test_predict)
    y_test_actual = scaler.inverse_transform(y_test)
    
    # Plot the results
    plt.figure(figsize=(16, 8))
    plt.plot(df['Date'][WINDOW_SIZE:len(train_predict) + WINDOW_SIZE], y_train_actual, label='Train Actual')
    plt.plot(df['Date'][WINDOW_SIZE:len(train_predict) + WINDOW_SIZE], train_predict, label='Train Predicted')
    plt.plot(df['Date'][len(train_predict) + WINDOW_SIZE:], y_test_actual, label='Test Actual')
    plt.plot(df['Date'][len(train_predict) + WINDOW_SIZE:], test_predict, label='Test Predicted')
    plt.xlabel('Date')
    plt.ylabel('Price')
    plt.title('Potato Red Price Prediction')
    plt.legend()
    plt.show()
    
    # Calculate RMSE
    train_rmse = np.sqrt(mean_squared_error(y_train_actual, train_predict))
    test_rmse = np.sqrt(mean_squared_error(y_test_actual, test_predict))
    print(f'Train RMSE: {train_rmse}')
    print(f'Test RMSE: {test_rmse}')
    
    # Calculate MAE
    train_mae = mean_absolute_error(y_train_actual, train_predict)
    test_mae = mean_absolute_error(y_test_actual, test_predict)
    print(f'Train MAE: {train_mae}')
    print(f'Test MAE: {test_mae}')

if __name__ == "__main__":
    main()
```
------------------------------------- 31
```python
import os
import yfinance as yf
import pandas as pd
import numpy as np
import math
import datetime as dt
from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM, GRU, LeakyReLU
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from itertools import cycle

# Function to preprocess date strings
def remove(x):
    x = str(x)
    res = x.split(" ")[0]
    return res

# Fetch and preprocess data
df = yf.Ticker("ETH-USD").history(period="max")
df.index = pd.to_datetime(df.index)
df.index = df.index.to_series().apply(lambda x: remove(x))
df.reset_index(inplace=True)

# Visualize the data
fig = px.line(df, x=df.Date, y=df.Close, labels={'date':'Date','close':'Close Stock'})
fig.update_traces(marker_line_width=2, opacity=1, marker_line_color='orange')
fig.update_layout(title_text='ETH close price 2017-2024', plot_bgcolor='white', font_size=15, font_color='black')
fig.update_xaxes(showgrid=False)
fig.update_yaxes(showgrid=False)
fig.show()

# Prepare the dataset
data = df.loc[(df['Date'] > '2021-01-01') & (df['Date'] < '2024-02-06')]
close_stock = data.filter(['Date', 'Close'])
data = data.filter(['Close'])
closedf = data.values

# Scale the data
scaler = MinMaxScaler(feature_range=(0, 1))
closedf_scale = scaler.fit_transform(np.array(closedf).reshape(-1, 1))

# Split the data into training and testing sets
training_size = int(len(closedf_scale) * 0.80)
test_size = len(closedf) - training_size
train_data, test_data = closedf_scale[0:training_size, :], closedf_scale[training_size:len(closedf_scale), :1]

# Function to create dataset for LSTM
def create_dataset(dataset, time_step=1):
    dataX, dataY = [], []
    for i in range(len(dataset) - time_step - 1):
        a = dataset[i:(i + time_step), 0]
        dataX.append(a)
        dataY.append(dataset[i + time_step, 0])
    return np.array(dataX), np.array(dataY)

time_step = 60
X_train, y_train = create_dataset(train_data, time_step)
X_test, y_test = create_dataset(test_data, time_step)

# Reshape input to be [samples, time steps, features]
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# Build GAN model
def build_generator(input_shape):
    model = Sequential()
    model.add(GRU(256, return_sequences=True, recurrent_dropout=0.02, recurrent_regularizer=l2(1e-3), input_shape=input_shape))
    model.add(GRU(128, recurrent_dropout=0.02, recurrent_regularizer=l2(1e-3)))
    model.add(Dense(64, kernel_regularizer=l2(1e-3)))
    model.add(Dense(32, kernel_regularizer=l2(1e-3)))
    model.add(Dense(1))
    return model

def build_discriminator(input_shape):
    model = Sequential()
    model.add(GRU(256, return_sequences=True, recurrent_dropout=0.02, recurrent_regularizer=l2(1e-3), input_shape=input_shape))
    model.add(GRU(128, recurrent_dropout=0.02, recurrent_regularizer=l2(1e-3)))
    model.add(Dense(64, kernel_regularizer=l2(1e-3)))
    model.add(Dense(32, kernel_regularizer=l2(1e-3)))
    model.add(Dense(1, activation='sigmoid'))
    return model

def build_gan(generator, discriminator):
    discriminator.trainable = False
    model = Sequential()
    model.add(generator)
    model.add(discriminator)
    return model

# Compile models
input_shape = (X_train.shape[1], 1)
generator = build_generator(input_shape)
discriminator = build_discriminator(input_shape)
discriminator.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])
gan = build_gan(generator, discriminator)
gan.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy')

# Training the GAN
epochs = 100
batch_size = 32
half_batch = int(batch_size / 2)

for epoch in range(epochs):
    idx = np.random.randint(0, X_train.shape[0], half_batch)
    real_samples = X_train[idx]
    noise = np.random.normal(0, 1, (half_batch, time_step, 1))
    generated_samples = generator.predict(noise)

    X = np.concatenate([real_samples, generated_samples])
    y_dis = np.zeros(batch_size)
    y_dis[:half_batch] = 0.9

    discriminator.trainable = True
    d_loss = discriminator.train_on_batch(X, y_dis)

    noise = np.random.normal(0, 1, (batch_size, time_step, 1))
    y_gen = np.ones(batch_size)
    discriminator.trainable = False
    g_loss = gan.train_on_batch(noise, y_gen)

    print(f"Epoch {epoch+1}/{epochs}, Discriminator Loss: {d_loss[0]}, Generator Loss: {g_loss}")

# Generate predictions
train_predict = generator.predict(X_train)
test_predict = generator.predict(X_test)

# Inverse transform predictions
train_predict_inverse = scaler.inverse_transform(train_predict)
test_predict_inverse = scaler.inverse_transform(test_predict)
original_ytrain = scaler.inverse_transform(y_train.reshape(-1, 1))
original_ytest = scaler.inverse_transform(y_test.reshape(-1, 1))

# Evaluation metrics
print("Train data RMSE: ", math.sqrt(mean_squared_error(original_ytrain, train_predict_inverse)))
print("Train data MAE: ", mean_absolute_error(original_ytrain, train_predict_inverse))
print("Train data R2: ", r2_score(original_ytrain, train_predict_inverse))
print("Train data explained variance regression score:", explained_variance_score(original_ytrain, train_predict_inverse))
print("-------------------------------------------------------------------------------------")
print("Test data RMSE: ", math.sqrt(mean_squared_error(original_ytest, test_predict_inverse)))
print("Test data MAE: ", mean_absolute_error(original_ytest, test_predict_inverse))
print("Test data R2: ", r2_score(original_ytest, test_predict_inverse))
print("Test data explained variance regression score:", explained_variance_score(original_ytest, test_predict_inverse))

# Plotting predictions
look_back = 60
testPredictPlot = np.empty_like(closedf)
testPredictPlot[:, :] = np.nan
testPredictPlot[len(train_predict) + (look_back * 2) + 1:len(closedf) - 1, :] = test_predict_inverse

names = cycle(['Original close price', 'Test predicted close price'])

plotdf = pd.DataFrame({'date': close_stock['Date'],
                       'original_close': close_stock['Close'],
                       'test_predicted_close': testPredictPlot.reshape(1, -1)[0].tolist()})

fig = px.line(plotdf, x=plotdf['date'], y=[plotdf['original_close'], plotdf['test_predicted_close']],
              labels={'value': 'Close price', 'date': 'Date'})
fig.update_layout(title_text='Comparison between original close price vs predicted close price',
                  plot_bgcolor='white', font_size=15, font_color='black', legend_title_text='Close Price')
fig.for_each_trace(lambda t: t.update(name=next(names)))

fig.update_xaxes(showgrid=False)
fig.update_yaxes(showgrid=False)
fig.show()
```
------------------------------------- 32
```python
# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Bidirectional, LSTM
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt

# Load the dataset
# Assuming the dataset is in a CSV file with columns 'Date' and 'Close'
data = pd.read_csv('ETH-USD.csv', parse_dates=['Date'], index_col='Date')

# Preprocess the data
# Extract the 'Close' prices
prices = data['Close'].values
prices = prices.reshape(-1, 1)

# Normalize the prices
scaler = MinMaxScaler(feature_range=(0, 1))
prices_scaled = scaler.fit_transform(prices)

# Create sequences for the LSTM model
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length])
    return np.array(X), np.array(y)

seq_length = 60  # Number of time steps to look back
X, y = create_sequences(prices_scaled, seq_length)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Reshape X to be [samples, time steps, features]
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# Build the model
model = Sequential()
model.add(Bidirectional(LSTM(50, return_sequences=True), input_shape=(seq_length, 1)))
model.add(Dropout(0.2))
model.add(Bidirectional(LSTM(50, return_sequences=False)))
model.add(Dropout(0.2))
model.add(Dense(25))
model.add(Dropout(0.2))
model.add(Dense(1))

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')

# Define early stopping to prevent overfitting
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])

# Evaluate the model
train_predictions = model.predict(X_train)
test_predictions = model.predict(X_test)

train_mse = mean_squared_error(y_train, train_predictions)
test_mse = mean_squared_error(y_test, test_predictions)

train_mae = mean_absolute_error(y_train, train_predictions)
test_mae = mean_absolute_error(y_test, test_predictions)

print(f'Train MSE: {train_mse}, Test MSE: {test_mse}')
print(f'Train MAE: {train_mae}, Test MAE: {test_mae}')

# Plot the training and validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Inverse transform the predictions to get actual prices
train_predictions = scaler.inverse_transform(train_predictions)
test_predictions = scaler.inverse_transform(test_predictions)
y_train = scaler.inverse_transform(y_train)
y_test = scaler.inverse_transform(y_test)

# Plot the actual vs predicted prices
plt.figure(figsize=(14, 7))
plt.plot(data.index[seq_length:len(train_predictions)+seq_length], train_predictions, label='Train Predictions', color='blue')
plt.plot(data.index[len(train_predictions)+seq_length:], test_predictions, label='Test Predictions', color='red')
plt.plot(data.index[seq_length:], prices[seq_length:], label='Actual Prices', color='green')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.show()
```
------------------------------------- 33
```python
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, Input
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
data = pd.read_csv('yelp_reviews.csv')  # Assuming the dataset is named 'yelp_reviews.csv'

# Preprocess the text data
def clean_text(text):
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    text = text.lower()
    return text

data['text'] = data['text'].apply(clean_text)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(data['text'], data['stars'], test_size=0.2, random_state=42)

# Tokenization and padding
max_features = 10000  # Maximum number of words to keep based on word frequency
max_len = 150  # Maximum length of the sequence

tokenizer = Tokenizer(num_words=max_features, oov_token="<OOV>")
tokenizer.fit_on_texts(X_train)

X_train = tokenizer.texts_to_sequences(X_train)
X_test = tokenizer.texts_to_sequences(X_test)

X_train = pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')
X_test = pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')

# Define the model
embedding_dim = 128

inputs = Input(shape=(max_len,))
x = Embedding(input_dim=max_features, output_dim=embedding_dim, input_length=max_len)(inputs)
x = Bidirectional(LSTM(128, return_sequences=True))(x)
x = Bidirectional(LSTM(128, return_sequences=False))(x)
x = Dense(64, activation='relu')(x)
x = Dropout(0.25)(x)
x = Dense(64, activation='relu')(x)
x = Dropout(0.25)(x)
x = Dense(16, activation='relu')(x)
x = Dropout(0.25)(x)
outputs = Dense(5, activation='softmax')(x)  # 5 classes for star ratings 1 to 5

model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Callbacks
checkpoint_cb = ModelCheckpoint("best_model.h5", save_best_only=True)
early_stopping_cb = EarlyStopping(patience=3, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train, epochs=20, batch_size=200, validation_split=0.1, callbacks=[checkpoint_cb, early_stopping_cb])

# Evaluate the model
score, acc = model.evaluate(X_test, y_test)
print('Test Loss =', score)
print('Test Accuracy =', acc)

# Predictions
predictions = model.predict(X_test)
y_pred = np.argmax(predictions, axis=1)

# Confusion Matrix
CM = confusion_matrix(y_test, y_pred)
CM_percent = CM.astype('float') / CM.sum(axis=1)[:, np.newaxis]
sns.heatmap(CM_percent, fmt='g', center=True, cbar=False, annot=True, cmap='Blues')
plt.show()

# Classification Report
ClassificationReport = classification_report(y_test, y_pred)
print('Classification Report is : ', ClassificationReport)
```
------------------------------------- 34
```python
# Install required libraries
pip install tf-models-official
pip install livelossplot
pip install imblearn

# Import necessary libraries
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Bidirectional, Conv1D, GlobalMaxPooling1D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from imblearn.over_sampling import SMOTE
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from livelossplot import PlotLossesKeras

# Load the dataset
def load_data(train_path, test_path):
    train_df = pd.read_csv(train_path)
    test_df = pd.read_csv(test_path)
    return train_df, test_df

# Preprocess the data
def preprocess_data(data, max_features=10000, max_len=100):
    # Drop duplicates and reset index
    data = data.drop_duplicates()
    data.reset_index(drop=True, inplace=True)
    
    # Remove unwanted characters
    remove_characters = ['~', '\xa0', '\xad', '\u200b', '\u200c', '\u200d', '\u200e', '\u2060', '\ueb9a', '\uf03d', '\uf06e', '\ufeff', "\n"]
    new_list_df = []
    for sent in tqdm(data["essay"]):
        for char in remove_characters:
            if char in sent:
                sent = sent.replace(char, "")
        new_list_df.append(sent)
    
    # Tokenize the text
    tokenizer = Tokenizer(num_words=max_features, filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n', split=' ')
    tokenizer.fit_on_texts(new_list_df)
    
    # Convert text to sequences
    sequences = tokenizer.texts_to_sequences(data["essay"])
    sequences = pad_sequences(sequences, maxlen=max_len, padding='post')
    
    # Encode labels
    le = LabelEncoder()
    labels = np.array(le.fit_transform(data["label"]))
    
    return sequences, labels, tokenizer

# Apply SMOTE for class balancing
def apply_smote(X_train, y_train):
    smote = SMOTE(random_state=42)
    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
    return X_train_resampled, y_train_resampled

# Build the model
def build_model(max_features, max_len, embedding_dim=100):
    inputs = Input(shape=(max_len,))
    x = Embedding(input_dim=max_features, output_dim=embedding_dim, input_length=max_len)(inputs)
    x = Bidirectional(LSTM(32, return_sequences=True))(x)
    x = Conv1D(128, 7, padding='valid', activation='relu', strides=3)(x)
    x = GlobalMaxPooling1D()(x)
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.5)(x)
    outputs = Dense(1, activation='sigmoid')(x)
    
    model = Model(inputs, outputs)
    model.compile(optimizer='adam', loss="binary_crossentropy", metrics=["accuracy"])
    return model

# Train the model
def train_model(model, X_train, y_train, X_val, y_val, epochs=10):
    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, callbacks=[PlotLossesKeras(), early_stopping])
    return history

# Evaluate the model
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    y_pred_classes = (y_pred > 0.5).astype(int)
    
    # Classification report
    print(classification_report(y_test, y_pred_classes))
    
    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred_classes)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title('Confusion Matrix')
    plt.show()
    
    # ROC curve
    fpr, tpr, thresholds = roc_curve(y_test, y_pred)
    roc_auc = auc(fpr, tpr)
    
    plt.figure()
    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic')
    plt.legend(loc="lower right")
    plt.show()

# Main function
def main():
    # Load data
    train_df, test_df = load_data('train.csv', 'test.csv')
    
    # Preprocess text
    X_train, y_train, tokenizer = preprocess_data(train_df)
    X_test, y_test, _ = preprocess_data(test_df)
    
    # Apply SMOTE
    X_train_resampled, y_train_resampled = apply_smote(X_train, y_train)
    
    # Build model
    model = build_model(max_features=10000, max_len=100)
    
    # Train model
    history = train_model(model, X_train_resampled, y_train_resampled, X_test, y_test)
    
    # Evaluate model
    evaluate_model(model, X_test, y_test)

if __name__ == "__main__":
    main()
```
------------------------------------- 35
```python
import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, GlobalMaxPooling1D, Conv1D, MaxPooling1D, Input, Layer, MultiHeadAttention, LayerNormalization
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from transformers import BertTokenizer, TFBertModel

# Load the dataset
df = pd.read_csv('malayalam_news_headlines.csv')

# Preprocess the data
X = df['headline'].astype(str)
y = df['category']

# Encode the labels
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)
y_categorical = tf.keras.utils.to_categorical(y_encoded)

# Split the data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y_categorical, test_size=0.2, random_state=42)

# Tokenize the text
tokenizer = Tokenizer(num_words=10000, oov_token="<OOV>")
tokenizer.fit_on_texts(X_train)

X_train_sequences = tokenizer.texts_to_sequences(X_train)
X_val_sequences = tokenizer.texts_to_sequences(X_val)

# Pad sequences to ensure uniform input size
max_length = 100
X_train_padded = pad_sequences(X_train_sequences, maxlen=max_length, padding='post', truncating='post')
X_val_padded = pad_sequences(X_val_sequences, maxlen=max_length, padding='post', truncating='post')

# Define the LSTM model
def build_lstm_model(num_classes):
    model = Sequential([
        Embedding(input_dim=10000, output_dim=128, input_length=max_length),
        LSTM(128, return_sequences=True),
        Dropout(0.2),
        LSTM(64),
        Dense(64, activation='relu'),
        Dropout(0.2),
        Dense(num_classes, activation='softmax')
    ])
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Define the Transformer Encoder Block
class TransformerEncoderBlock(Layer):
    def __init__(self, num_attention_heads, inner_dim, inner_activation, **kwargs):
        super(TransformerEncoderBlock, self).__init__(**kwargs)
        self.num_attention_heads = num_attention_heads
        self.inner_dim = inner_dim
        self.inner_activation = inner_activation
    
    def build(self, input_shape):
        self.attention = MultiHeadAttention(num_heads=self.num_attention_heads, key_dim=input_shape[-1])
        self.dense_1 = Dense(self.inner_dim, activation=self.inner_activation)
        self.dense_2 = Dense(input_shape[-1])
        self.layernorm_1 = LayerNormalization(epsilon=1e-6)
        self.layernorm_2 = LayerNormalization(epsilon=1e-6)
        super(TransformerEncoderBlock, self).build(input_shape)
    
    def call(self, inputs):
        attention_output = self.attention(inputs, inputs)
        out_1 = self.layernorm_1(inputs + attention_output)
        dense_output = self.dense_1(out_1)
        dense_output = self.dense_2(dense_output)
        return self.layernorm_2(out_1 + dense_output)

# Define the Transformer model using BERT
def build_transformer_model(num_classes):
    input_ids = Input(shape=(max_length,), dtype=tf.int32, name="input_ids")
    attention_masks = Input(shape=(max_length,), dtype=tf.int32, name="attention_masks")
    
    bert_model = TFBertModel.from_pretrained('bert-base-multilingual-cased')
    bert_output = bert_model(input_ids, attention_mask=attention_masks)[1]
    
    dense = Dense(64, activation='relu')(bert_output)
    dropout = Dropout(0.2)(dense)
    output = Dense(num_classes, activation='softmax')(dropout)
    
    model = Model(inputs=[input_ids, attention_masks], outputs=output)
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Tokenize the text for BERT
bert_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')

def encode_for_bert(texts, max_length):
    input_ids = []
    attention_masks = []
    for text in texts:
        encoded = bert_tokenizer.encode_plus(
            text,
            add_special_tokens=True,
            max_length=max_length,
            pad_to_max_length=True,
            return_attention_mask=True,
            return_tensors='tf',
        )
        input_ids.append(encoded['input_ids'])
        attention_masks.append(encoded['attention_mask'])
    return np.array(input_ids), np.array(attention_masks)

X_train_input_ids, X_train_attention_masks = encode_for_bert(X_train, max_length)
X_val_input_ids, X_val_attention_masks = encode_for_bert(X_val, max_length)

# Build and train the LSTM model
lstm_model = build_lstm_model(num_classes=y_categorical.shape[1])
lstm_model.summary()

early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7, verbose=1)

lstm_history = lstm_model.fit(
    X_train_padded, y_train,
    validation_data=(X_val_padded, y_val),
    epochs=10,
    batch_size=32,
    callbacks=[early_stopping, reduce_lr]
)

# Build and train the Transformer model
transformer_model = build_transformer_model(num_classes=y_categorical.shape[1])
transformer_model.summary()

transformer_history = transformer_model.fit(
    [X_train_input_ids, X_train_attention_masks], y_train,
    validation_data=([X_val_input_ids, X_val_attention_masks], y_val),
    epochs=10,
    batch_size=32,
    callbacks=[early_stopping, reduce_lr]
)

# Evaluate the models
lstm_loss, lstm_accuracy = lstm_model.evaluate(X_val_padded, y_val, verbose=2)
print(f"LSTM Model - Validation Accuracy: {lstm_accuracy*100:.2f}%")

transformer_loss, transformer_accuracy = transformer_model.evaluate([X_val_input_ids, X_val_attention_masks], y_val, verbose=2)
print(f"Transformer Model - Validation Accuracy: {transformer_accuracy*100:.2f}%")

# Example text to predict category
new_headlines = [
    "വിവിധ വിഷയങ്ങളിൽ പ്രതിക്രിയകൾ",
    "സിനിമയുടെ വിമര്‍ശനം",
]

# Preprocess the new headlines for LSTM
new_headlines_sequences = tokenizer.texts_to_sequences(new_headlines)
new_headlines_padded = pad_sequences(new_headlines_sequences, maxlen=max_length, padding='post')

# Predict using LSTM model
lstm_predictions = lstm_model.predict(new_headlines_padded)
lstm_predicted_classes = np.argmax(lstm_predictions, axis=1)
lstm_predicted_labels = label_encoder.inverse_transform(lstm_predicted_classes)

for headline, label in zip(new_headlines, lstm_predicted_labels):
    print(f"Headline: {headline}\nPredicted Category (LSTM): {label}\n")

# Preprocess the new headlines for Transformer
new_headlines_input_ids, new_headlines_attention_masks = encode_for_bert(new_headlines, max_length)

# Predict using Transformer model
transformer_predictions = transformer_model.predict([new_headlines_input_ids, new_headlines_attention_masks])
transformer_predicted_classes = np.argmax(transformer_predictions, axis=1)
transformer_predicted_labels = label_encoder.inverse_transform(transformer_predicted_classes)

for headline, label in zip(new_headlines, transformer_predicted_labels):
    print(f"Headline: {headline}\nPredicted Category (Transformer): {label}\n")
```
------------------------------------- 36
```python
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Dropout, GlobalMaxPooling1D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from transformers import BertTokenizer, TFBertModel

# Load the dataset
df = pd.read_csv('movie_reviews.csv')

# Preprocess the data
df['sentiment'] = df['sentiment'].map({'Fresh': 1, 'Rotten': 0})
reviews = df['review'].values
labels = df['sentiment'].values

# Tokenize the reviews using BERT tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encoded_reviews = [tokenizer.encode(review, add_special_tokens=True, max_length=128, truncation=True) for review in reviews]

# Pad sequences to the same length
max_len = 128
padded_reviews = pad_sequences(encoded_reviews, maxlen=max_len, padding='post', truncating='post')

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(padded_reviews, labels, test_size=0.2, random_state=42)

# Build the BERT model
def build_bert_model(max_len):
    input_ids = Input(shape=(max_len,), dtype=tf.int32, name="input_ids")
    bert_layer = TFBertModel.from_pretrained('bert-base-uncased')
    bert_output = bert_layer(input_ids)[0]
    pooled_output = GlobalMaxPooling1D()(bert_output)
    dropout = Dropout(0.3)(pooled_output)
    output = Dense(1, activation='sigmoid')(dropout)
    model = Model(inputs=input_ids, outputs=output)
    model.compile(optimizer=Adam(learning_rate=2e-5), loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Create and compile the model
model = build_bert_model(max_len)
model.summary()

# Train the model
history = model.fit(X_train, y_train, batch_size=32, epochs=4, validation_split=0.1)

# Evaluate the model
y_pred = model.predict(X_test)
y_pred = np.int64(y_pred > 0.5)

# Print classification report and confusion matrix
print(classification_report(y_test, y_pred, target_names=['Rotten', 'Fresh']))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))
```
------------------------------------- 37
```python
import pandas as pd
import numpy as np
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, Conv1D, Bidirectional, LSTM, MultiHeadAttention, LayerNormalization, Dense, Dropout, concatenate
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score

# Load the dataset
data = pd.read_csv('sql_injection_dataset.csv')

# Preprocess the data
max_length = 1000
vocab_size = 128  # ASCII characters

def preprocess_query(query):
    return [ord(char) for char in query]

X = np.array([preprocess_query(query) for query in data['query']])
y = np.array(data['label'])

# Pad sequences to ensure uniform length
X = pad_sequences(X, maxlen=max_length, padding='post')

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build the model
def build_model(max_len, vocab_size):
    # Input layer
    text_input = Input(shape=(max_len,), dtype='int32', name='text_input')
    
    # Embedding layer
    text_embedding = Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len)(text_input)
    
    # Convolutional layer for feature extraction
    text_conv = Conv1D(filters=128, kernel_size=3, activation='relu')(text_embedding)
    
    # Bidirectional LSTM layers for sequence processing
    text_lstm = Bidirectional(LSTM(128, return_sequences=True))(text_conv)
    text_lstm = Bidirectional(LSTM(128))(text_lstm)
    
    # Multi-head attention layer for capturing dependencies
    text_attention = MultiHeadAttention(num_heads=4, key_dim=64)(text_lstm, text_lstm)
    
    # Layer normalization
    text_norm = LayerNormalization()(text_attention)
    
    # Dense layers with dropout
    dense1 = Dense(256, activation='relu')(text_norm)
    dropout1 = Dropout(0.5)(dense1)
    dense2 = Dense(128, activation='relu')(dropout1)
    dropout2 = Dropout(0.5)(dense2)
    
    # Output layer with sigmoid activation
    output = Dense(1, activation='sigmoid')(dropout2)
    
    # Create the model
    model = Model(inputs=text_input, outputs=output)
    return model

# Compile and train the model
def train_model(model, X_train, y_train, X_val, y_val, epochs=10, batch_size=64):
    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])
    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size)

# Evaluate the model
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    y_pred = (y_pred > 0.5).astype(int)
    
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    
    print(f"Accuracy: {accuracy}")
    print(f"Precision: {precision}")
    print(f"Recall: {recall}")

# Main function
def main():
    # Build the model
    model = build_model(max_len=max_length, vocab_size=vocab_size)
    
    # Train the model
    train_model(model, X_train, y_train, X_test, y_test)
    
    # Evaluate the model
    evaluate_model(model, X_test, y_test)

if __name__ == "__main__":
    main()
```
------------------------------------- 38
```python
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Dense, Attention, Concatenate, Embedding, TimeDistributed
from sklearn.model_selection import train_test_split

# Download necessary NLTK data
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')

# Load the dataset
data = pd.read_csv('news_articles.csv')

# Preprocessing
data['text'] = data['text'].astype(str)
data['title'] = data['title'].astype(str)

# Remove duplicates and missing values
data = data.drop_duplicates().dropna()

# Split the data into training and testing sets
train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)

# Preprocessing functions
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()
url_pattern = re.compile(r'https?://\S+')

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)
    text = url_pattern.sub('', text)
    tokens = word_tokenize(text)
    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalnum() and token not in stop_words]
    return ' '.join(tokens)

# Apply preprocessing to the training and testing data
train_data['preprocessed_text'] = train_data['text'].apply(preprocess_text)
train_data['preprocessed_title'] = train_data['title'].apply(preprocess_text)

test_data['preprocessed_text'] = test_data['text'].apply(preprocess_text)
test_data['preprocessed_title'] = test_data['title'].apply(preprocess_text)

# Tokenization
tokenizer_text = Tokenizer()
tokenizer_text.fit_on_texts(train_data['preprocessed_text'])
tokenizer_summary = Tokenizer()
tokenizer_summary.fit_on_texts(train_data['preprocessed_title'])

train_text_sequences = tokenizer_text.texts_to_sequences(train_data['preprocessed_text'])
train_title_sequences = tokenizer_summary.texts_to_sequences(train_data['preprocessed_title'])

test_text_sequences = tokenizer_text.texts_to_sequences(test_data['preprocessed_text'])
test_title_sequences = tokenizer_summary.texts_to_sequences(test_data['preprocessed_title'])

# Padding sequences
max_text_length = 500
max_title_length = 50

train_text_padded = pad_sequences(train_text_sequences, maxlen=max_text_length, padding='post')
train_title_padded = pad_sequences(train_title_sequences, maxlen=max_title_length, padding='post')

test_text_padded = pad_sequences(test_text_sequences, maxlen=max_text_length, padding='post')
test_title_padded = pad_sequences(test_title_sequences, maxlen=max_title_length, padding='post')

# Model Building
embedding_dim = 128
lstm_units = 256

# Encoder
encoder_inputs = Input(shape=(max_text_length,))
encoder_embedding = Embedding(input_dim=len(tokenizer_text.word_index) + 1, output_dim=embedding_dim)(encoder_inputs)

encoder_lstm1 = LSTM(lstm_units, return_sequences=True, return_state=True)
encoder_outputs1, state_h1, state_c1 = encoder_lstm1(encoder_embedding)

encoder_lstm2 = LSTM(lstm_units, return_sequences=True, return_state=True)
encoder_outputs2, state_h2, state_c2 = encoder_lstm2(encoder_outputs1)

encoder_lstm3 = LSTM(lstm_units, return_sequences=True, return_state=True)
encoder_outputs3, state_h3, state_c3 = encoder_lstm3(encoder_outputs2)

encoder_states = [state_h3, state_c3]

# Decoder
decoder_inputs = Input(shape=(max_title_length,))
decoder_embedding = Embedding(input_dim=len(tokenizer_summary.word_index) + 1, output_dim=embedding_dim)(decoder_inputs)

decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)
decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)

# Attention Mechanism
attention = Attention()([decoder_outputs, encoder_outputs3])
decoder_concat = Concatenate(axis=-1)([decoder_outputs, attention])

# Output layer
decoder_dense = TimeDistributed(Dense(len(tokenizer_summary.word_index) + 1, activation='softmax'))
decoder_outputs = decoder_dense(decoder_concat)

# Model
model = Model([encoder_inputs, decoder_inputs], decoder_outputs)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Training
model.fit([train_text_padded, train_title_padded[:, :-1]], train_title_padded[:, 1:],
          validation_data=([test_text_padded, test_title_padded[:, :-1]], test_title_padded[:, 1:]),
          epochs=10, batch_size=64)

# Save the model
model.save('text_summarization_model.h5')
```
------------------------------------- 39
```python
import numpy as np
import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW
import torch
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split

# Download necessary NLTK data
nltk.download('stopwords')
nltk.download('punkt')

# Load the dataset
def load_dataset(file_path):
    encodings_to_try = ['utf-8', 'latin1', 'ISO-8859-1', 'utf-16']
    for encoding in encodings_to_try:
        try:
            df = pd.read_csv(file_path, encoding=encoding)
            print(f"Successfully read CSV file using encoding: {encoding}")
            return df
        except UnicodeDecodeError:
            print(f"Failed to read CSV file using encoding: {encoding}")
    raise Exception("Failed to read CSV file with any encoding")

# Preprocessing functions
def clean_text(text):
    """Clean the text by removing punctuation, links, and stopwords."""
    text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation and special characters
    text = re.sub(r'http\S+', '', text)  # Remove URLs
    text = re.sub(r'\d+', '', text)  # Remove numbers
    stop_words = set(stopwords.words('arabic'))
    word_tokens = word_tokenize(text)
    filtered_text = [word for word in word_tokens if word not in stop_words]
    return ' '.join(filtered_text)

def preprocess_text(text):
    """Apply all preprocessing steps to the text."""
    text = clean_text(text)
    return text

# Preprocess the dataset
def preprocess_dataset(dataset):
    """Preprocess the text and summary columns in the dataset."""
    dataset['text'] = dataset['text'].apply(preprocess_text)
    dataset['summary'] = dataset['summary'].apply(preprocess_text)
    return dataset

# Save preprocessed data to CSV
def save_preprocessed_data(dataset, file_path):
    """Save the preprocessed dataset to a CSV file."""
    dataset.to_csv(file_path, index=False)

# Dataset class for PyTorch
class TextSummaryDataset(Dataset):
    def __init__(self, texts, summaries, tokenizer, max_length=512):
        self.texts = texts
        self.summaries = summaries
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = self.texts[idx]
        summary = self.summaries[idx]
        
        # Tokenize the text and summary
        inputs = self.tokenizer.encode_plus(
            text,
            max_length=self.max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        targets = self.tokenizer.encode_plus(
            summary,
            max_length=self.max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        
        return {
            'input_ids': inputs['input_ids'].flatten(),
            'attention_mask': inputs['attention_mask'].flatten(),
            'labels': targets['input_ids'].flatten()
        }

# Fine-tune GPT-2 model
def fine_tune_gpt2(train_dataset, val_dataset, epochs=3, batch_size=8, learning_rate=5e-5):
    """Fine-tune the GPT-2 model for text summarization."""
    # Load pre-trained GPT-2 model and tokenizer
    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
    model = GPT2LMHeadModel.from_pretrained('gpt2')
    
    # Add special tokens for summarization
    tokenizer.add_special_tokens({'pad_token': '[PAD]'})
    model.resize_token_embeddings(len(tokenizer))
    
    # Create DataLoaders
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size)
    
    # Define optimizer and loss function
    optimizer = AdamW(model.parameters(), lr=learning_rate)
    
    # Training loop
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    model.train()
    for epoch in range(epochs):
        for batch in train_loader:
            optimizer.zero_grad()
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            loss = outputs.loss
            loss.backward()
            optimizer.step()
        
        # Validation loop
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for batch in val_loader:
                input_ids = batch['input_ids'].to(device)
                attention_mask = batch['attention_mask'].to(device)
                labels = batch['labels'].to(device)
                
                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
                val_loss += outputs.loss.item()
        
        print(f'Epoch {epoch+1}, Validation Loss: {val_loss/len(val_loader)}')
    
    return model, tokenizer

# Main function
if __name__ == "__main__":
    # Load and preprocess the dataset
    file_path = 'path_to_your_arabic_dataset.csv'
    dataset = load_dataset(file_path)
    preprocessed_dataset = preprocess_dataset(dataset)
    save_preprocessed_data(preprocessed_dataset, 'preprocessed_arabic_text_summaries.csv')
    
    # Split the dataset into training and validation sets
    train_texts, val_texts, train_summaries, val_summaries = train_test_split(
        preprocessed_dataset['text'].tolist(),
        preprocessed_dataset['summary'].tolist(),
        test_size=0.2,
        random_state=42
    )
    
    # Create datasets and tokenizer
    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
    train_dataset = TextSummaryDataset(train_texts, train_summaries, tokenizer)
    val_dataset = TextSummaryDataset(val_texts, val_summaries, tokenizer)
    
    # Fine-tune the GPT-2 model
    fine_tuned_model, fine_tuned_tokenizer = fine_tune_gpt2(train_dataset, val_dataset)
    
    # Save the fine-tuned model and tokenizer
    fine_tuned_model.save_pretrained('fine_tuned_gpt2_arabic_summarization')
    fine_tuned_tokenizer.save_pretrained('fine_tuned_gpt2_arabic_summarization')
```
------------------------------------- 40
```python
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.layers import Dense, LSTM, Embedding, Input, TimeDistributed, Concatenate
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.models import Model
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Hyperparameters
max_text_len = 190
max_summary_len = 80
embedding_dim = 200
latent_dim = 300
batch_size = 128
epochs = 100

# Load and preprocess the dataset
def load_and_preprocess_data(file1, file2):
    df1 = pd.read_csv(file1)
    df2 = pd.read_csv(file2)
    df = pd.concat([df1, df2], ignore_index=True)
    df = df[['text', 'summary']]
    df.dropna(inplace=True)
    df.drop_duplicates(inplace=True)
    df['summary'] = df['summary'].apply(lambda x: '<start> ' + x + ' <end>')
    
    x_tokenizer = Tokenizer()
    x_tokenizer.fit_on_texts(df.text)
    text_sequences = x_tokenizer.texts_to_sequences(df.text)
    text_pad_sequences = pad_sequences(text_sequences, maxlen=max_text_len, padding='post')
    
    y_tokenizer = Tokenizer()
    y_tokenizer.fit_on_texts(df.summary)
    summary_sequences = y_tokenizer.texts_to_sequences(df.summary)
    summary_pad_sequences = pad_sequences(summary_sequences, maxlen=max_summary_len, padding='post')
    
    X_train, X_test, y_train, y_test = train_test_split(text_pad_sequences, summary_pad_sequences, test_size=0.25, shuffle=True, random_state=101)
    
    return X_train, X_test, y_train, y_test, x_tokenizer, y_tokenizer

# Define the Luong Attention mechanism
class LuongAttention(tf.keras.layers.Layer):
    def __init__(self, units):
        super(LuongAttention, self).__init__()
        self.W1 = tf.keras.layers.Dense(units)
        self.W2 = tf.keras.layers.Dense(units)
        self.V = tf.keras.layers.Dense(1)

    def call(self, query, values):
        query_with_time_axis = tf.expand_dims(query, 1)
        values_transposed = tf.transpose(values, perm=[0, 2, 1])
        score = tf.transpose(tf.matmul(query_with_time_axis, values_transposed), perm=[0, 2, 1])
        attention_weights = tf.nn.softmax(score, axis=1)
        context_vector = attention_weights * values
        context_vector = tf.reduce_sum(context_vector, axis=1)
        return context_vector, attention_weights

# Build the encoder-decoder model with attention
def build_model(x_voc, y_voc):
    # Encoder
    encoder_inputs = Input(shape=(max_text_len,))
    enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)
    encoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)
    encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)
    encoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)
    encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)
    encoder_lstm3 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)
    encoder_outputs, state_h, state_c = encoder_lstm3(encoder_output2)

    # Decoder
    decoder_inputs = Input(shape=(max_summary_len,))
    dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)
    dec_emb = dec_emb_layer(decoder_inputs)
    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)
    decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])

    # Attention mechanism
    attention = LuongAttention(latent_dim)
    context_vector, attention_weights = attention(decoder_outputs, encoder_outputs)
    decoder_combined_context = Concatenate(axis=-1)([decoder_outputs, context_vector])

    # Dense layer
    decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))
    decoder_outputs = decoder_dense(decoder_combined_context)

    # Define the model
    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)
    return model

# Train the model
def train_model(model, X_train, X_test, y_train, y_test):
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    
    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)
    mc = ModelCheckpoint('text_summarizer.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)
    
    history = model.fit(
        [X_train, y_train[:, :-1]], 
        y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:, 1:], 
        epochs=epochs, 
        batch_size=batch_size, 
        validation_data=([X_test, y_test[:, :-1]], y_test.reshape(y_test.shape[0], y_test.shape[1], 1)[:, 1:]), 
        callbacks=[es, mc]
    )
    
    return history

# Inference setup
def setup_inference_models(model, x_tokenizer, y_tokenizer):
    encoder_inputs = model.input[0]
    encoder_outputs, state_h_enc, state_c_enc = model.layers[6].output
    encoder_model = Model(encoder_inputs, [encoder_outputs, state_h_enc, state_c_enc])

    decoder_state_input_h = Input(shape=(latent_dim,))
    decoder_state_input_c = Input(shape=(latent_dim,))
    decoder_hidden_state_input = Input(shape=(max_text_len, latent_dim))

    dec_emb_layer = model.layers[3]
    dec_emb2 = dec_emb_layer(model.input[1])
    decoder_lstm = model.layers[4]
    decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])
    attention = model.layers[7]
    context_vector2, attention_weights2 = attention(decoder_outputs2, decoder_hidden_state_input)
    decoder_combined_context2 = Concatenate(axis=-1)([decoder_outputs2, context_vector2])
    decoder_dense = model.layers[8]
    decoder_outputs2 = decoder_dense(decoder_combined_context2)

    decoder_model = Model(
        [model.input[1]] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],
        [decoder_outputs2] + [state_h2, state_c2]
    )
    
    return encoder_model, decoder_model

# Decode sequence function
def decode_sequence(input_seq, encoder_model, decoder_model, y_tokenizer):
    e_out, e_h, e_c = encoder_model.predict(input_seq)
    target_seq = np.zeros((1, 1))
    target_seq[0, 0] = y_tokenizer.word_index['start']
    stop_condition = False
    decoded_sentence = ''
    while not stop_condition:
        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])
        sampled_token_index = np.argmax(output_tokens[0, -1, :])
        sampled_token = y_tokenizer.index_word[sampled_token_index]
        if sampled_token != 'end':
            decoded_sentence += ' ' + sampled_token
        if sampled_token == 'end' or len(decoded_sentence.split()) >= (max_summary_len - 1):
            stop_condition = True
        target_seq = np.zeros((1, 1))
        target_seq[0, 0] = sampled_token_index
        e_h, e_c = h, c
    return decoded_sentence

# Main function
def main():
    file1 = 'file1.csv'
    file2 = 'file2.csv'
    X_train, X_test, y_train, y_test, x_tokenizer, y_tokenizer = load_and_preprocess_data(file1, file2)
    
    x_voc = len(x_tokenizer.word_index) + 1
    y_voc = len(y_tokenizer.word_index) + 1
    
    model = build_model(x_voc, y_voc)
    history = train_model(model, X_train, X_test, y_train, y_test)
    
    plt.plot(history.history['loss'], label='train')
    plt.plot(history.history['val_loss'], label='val')
    plt.legend()
    plt.show()
    
    encoder_model, decoder_model = setup_inference_models(model, x_tokenizer, y_tokenizer)
    
    for i in range(10):
        print("Review:", ' '.join([x_tokenizer.index_word[idx] for idx in X_test[i] if idx != 0]))
        print("Original summary:", ' '.join([y_tokenizer.index_word[idx] for idx in y_test[i] if idx != 0 and idx != y_tokenizer.word_index['start'] and idx != y_tokenizer.word_index['end']]))
        print("Predicted summary:", decode_sequence(X_test[i].reshape(1, max_text_len), encoder_model, decoder_model, y_tokenizer))
        print("\n")

if __name__ == "__main__":
    main()
```
------------------------------------- 41
```python
import tensorflow as tf
import numpy as np
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, Dense, Bidirectional, Attention, Concatenate
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import SparseCategoricalCrossentropy
from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn.model_selection import train_test_split
import re

# Constants
MARK_START = "<sos>"
MARK_END = "<eos>"
VOCAB_SIZE = 10000
EMBED_DIM = 256
HIDDEN_DIM = 512
DROPOUT = 0.2
BATCH_SIZE = 32
EPOCHS = 10
MAX_SEQ_LENGTH = 50
LEARNING_RATE = 0.001

# Preprocessing function
def preprocess_text(text):
    text = text.lower()
    text = re.sub(r"[^a-zA-Z0-9\s]", "", text)
    return text

# Load and preprocess dataset
def load_data(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        lines = file.read().split('\n')
    pairs = [line.split('\t') for line in lines if len(line.split('\t')) == 2]
    french_sentences, english_sentences = zip(*pairs)
    french_sentences = [preprocess_text(sent) for sent in french_sentences]
    english_sentences = [preprocess_text(sent) for sent in english_sentences]
    return french_sentences, english_sentences

# Tokenize and pad sequences
def tokenize_and_pad(sentences, tokenizer, max_len):
    tokenizer.fit_on_texts(sentences)
    sequences = tokenizer.texts_to_sequences(sentences)
    return pad_sequences(sequences, maxlen=max_len, padding='post')

# Load dataset
french_sentences, english_sentences = load_data('path_to_dataset.txt')

# Tokenize sentences
french_tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token="<OOV>")
english_tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token="<OOV>")

french_sequences = tokenize_and_pad(french_sentences, french_tokenizer, MAX_SEQ_LENGTH)
english_sequences = tokenize_and_pad(english_sentences, english_tokenizer, MAX_SEQ_LENGTH)

# Add <sos> and <eos> tokens to target sequences
english_sequences = np.array([[english_tokenizer.word_index[MARK_START]] + seq + [english_tokenizer.word_index[MARK_END]] for seq in english_sequences])

# Split data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(french_sequences, english_sequences, test_size=0.2, random_state=42)

# Model definition
class Seq2SeqAttention(Model):
    def __init__(self, vocab_size, embed_dim, hidden_dim, dropout):
        super(Seq2SeqAttention, self).__init__()
        self.encoder_embedding = Embedding(vocab_size, embed_dim, mask_zero=True)
        self.encoder_lstm = Bidirectional(LSTM(hidden_dim // 2, return_sequences=True, return_state=True))
        self.decoder_embedding = Embedding(vocab_size, embed_dim, mask_zero=True)
        self.decoder_gru = GRU(hidden_dim, dropout=dropout, return_sequences=True, return_state=True)
        self.attention = Attention()
        self.dense = Dense(vocab_size, activation='softmax')

    def call(self, inputs):
        encoder_input, decoder_input = inputs
        encoder_embedded = self.encoder_embedding(encoder_input)
        encoder_outputs, forward_h, forward_c, backward_h, backward_c = self.encoder_lstm(encoder_embedded)
        encoder_states = [Concatenate()([forward_h, backward_h]), Concatenate()([forward_c, backward_c])]
        
        decoder_embedded = self.decoder_embedding(decoder_input)
        decoder_outputs, _ = self.decoder_gru(decoder_embedded, initial_state=encoder_states)
        
        attention_output = self.attention([decoder_outputs, encoder_outputs])
        concat_output = Concatenate()([decoder_outputs, attention_output])
        output = self.dense(concat_output)
        return output

# Instantiate model
model = Seq2SeqAttention(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, DROPOUT)

# Compile model
model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss=SparseCategoricalCrossentropy(), metrics=['accuracy'])

# Checkpoint callback
path_checkpoint = 'checkpoint.keras'
checkpoint = ModelCheckpoint(filepath=path_checkpoint, monitor='val_loss', verbose=1, save_best_only=True, mode='min', save_weights_only=True)

# Train model
model.fit([X_train, y_train[:, :-1]], y_train[:, 1:], batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=([X_val, y_val[:, :-1]], y_val[:, 1:]), callbacks=[checkpoint])

# Save model
model.save('seq2seq_attention_model.h5')

# Translation function
def translate(input_text, true_output_text=None):
    input_tokens = french_tokenizer.texts_to_sequences([input_text])
    input_tokens = pad_sequences(input_tokens, maxlen=MAX_SEQ_LENGTH, padding='post')
    
    max_tokens = MAX_SEQ_LENGTH
    decoder_input_data = np.zeros(shape=(1, max_tokens), dtype=np.int32)
    
    token_int = english_tokenizer.word_index[MARK_START]
    output_text = ''
    count_tokens = 0
    
    while token_int != english_tokenizer.word_index[MARK_END] and count_tokens < max_tokens:
        decoder_input_data[0, count_tokens] = token_int
        prediction = model.predict([input_tokens, decoder_input_data])
        token_onehot = prediction[0, count_tokens, :]
        token_int = np.argmax(token_onehot)
        sampled_word = english_tokenizer.index_word[token_int]
        output_text += ' ' + sampled_word
        count_tokens += 1
    
    print('Input text:')
    print(input_text)
    print()
    
    print('Translated text:')
    print(output_text)
    print()
    
    if true_output_text is not None:
        print('True output text:')
        print(true_output_text)
        print()

# Example usage
translate(input_text=french_sentences[100], true_output_text=english_sentences[100])
```
------------------------------------- 42
```python
import warnings
warnings.filterwarnings('ignore')

import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import seaborn as sns
from tqdm.auto import tqdm 

import re
from nltk.corpus import stopwords 
from collections import Counter 
from string import punctuation 

from sklearn.model_selection import train_test_split 

import tensorflow as tf 
from tensorflow import keras 
from tensorflow.keras.preprocessing.text import Tokenizer 
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Bidirectional, Concatenate, Dropout, TimeDistributed
from tensorflow.keras.losses import SparseCategoricalCrossentropy
from tensorflow.keras.optimizers import Adam

# Load the dataset
df = pd.read_csv('/path/to/turkish_to_english_dataset.csv', nrows=500000)

# Preprocessing functions
def english_preprocessing(data, col): 
    data[col] = data[col].astype(str) 
    data[col] = data[col].apply(lambda x: x.lower())
    data[col] = data[col].apply(lambda x: re.sub("[^A-Za-z\s]", "", x)) 
    data[col] = data[col].apply(lambda x: x.replace("\s+", " "))
    data[col] = data[col].apply(lambda x: " ".join([word for word in x.split()]))
    return data 

def turkish_preprocessing(data, col): 
    data[col] = data[col].astype(str) 
    data[col] = data[col].apply(lambda x: x.lower()) 
    data[col] = data[col].apply(lambda x: re.sub(r'\d', '', x))
    data[col] = data[col].apply(lambda x: re.sub(r'\s+', ' ', x))
    data[col] = data[col].apply(lambda x: re.sub(r"[-()\"#/@;:<>{}`+=~|.!?,।]", "", x))
    data[col] = data[col].apply(lambda x: x.strip()) 
    data[col] = "<sos> " + data[col] + " <eos>" 
    return data

# Apply preprocessing
df = turkish_preprocessing(df, 'tr')
df = english_preprocessing(df, 'en')

# Filter sentences based on length
df["en_len"] = [len(text.split()) for text in df.en]
df['tr_len'] = [len(text.split()) for text in df.tr]

df = df[~(df['en_len'] < 5) & ~(df['en_len'] > 20)]
df = df[~(df['tr_len'] < 5) & ~(df['tr_len'] > 20)]

# Vectorization function
def Vectorization(col, MAXLEN=20): 
    sents = df[col].tolist() 
    
    # Build vocabulary 
    corpus = [word for text in df[col] for word in text.split()] 
    vocab_size = len(Counter(corpus)) 
    
    tokenizer = Tokenizer(num_words=vocab_size, oov_token="<OOV>", 
                          filters='!#$%&()*+,-/:;<=>@«»""[\\]^_`{|}~\t\n')
    tokenizer.fit_on_texts(sents) 
    
    tokenizer.word_index['<pad>'] = 0 
    tokenizer.index_word[0] = '<pad>' 
    
    vocab_to_idx = tokenizer.word_index 
    idx_to_vocab = tokenizer.index_word 
    
    # Text Vectorization 
    seqs = tokenizer.texts_to_sequences(sents) 
    
    pad_seqs = pad_sequences(seqs, maxlen=MAXLEN, padding='post')
    
    return vocab_to_idx, idx_to_vocab, pad_seqs, tokenizer

# Vectorize the data
en_vocab, en_inv_vocab, en_seqs, en_tokenizer = Vectorization('en')
tr_vocab, tr_inv_vocab, tr_seqs, tr_tokenizer = Vectorization('tr')

# Split the data
x_train, x_val, y_train, y_val = train_test_split(en_seqs, tr_seqs, train_size=0.80, random_state=42)

# Create TensorFlow datasets
BATCH_SIZE = 128
BUFFER_SIZE = 1000

train_set = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_set = train_set.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)

val_set = tf.data.Dataset.from_tensor_slices((x_val, y_val))
val_set = val_set.batch(BATCH_SIZE, drop_remainder=True)

# Define parameters
EMBEDDING_DIM = 256
SRC_VOCAB_SIZE = len(en_vocab) + 1
TRG_VOCAB_SIZE = len(tr_vocab) + 1
HIDDEN_DIM = 512
MAXLEN = 20
EPOCHS = 50
LR = 0.001

# Define the Encoder
class Encoder(Model): 
    def __init__(self, vocab_size, embedding_dim, hidden_dim): 
        super(Encoder, self).__init__() 
        
        self.embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)
        self.lstm = Bidirectional(
            LSTM(hidden_dim // 2, return_sequences=True, return_state=True)
        )
        
    def call(self, x): 
        embed = self.embedding(x) 
        
        enc_output, forward_h, forward_c, backward_h, backward_c = self.lstm(embed) 
        
        state_h = Concatenate()([forward_h, backward_h]) 
        state_c = Concatenate()([forward_c, backward_c])
        
        return enc_output, state_h, state_c
    
    def summary(self): 
        x = tf.keras.layers.Input(shape=(None,))
        model = Model(inputs=[x], outputs=self.call(x))
        return model.summary()

encoder = Encoder(SRC_VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM)
encoder.summary()

# Define the Decoder
class Decoder(Model): 
    def __init__(self, vocab_size, embedding_dim, hidden_dim): 
        super(Decoder, self).__init__() 
        self.units = hidden_dim 
        
        self.embedding = Embedding(vocab_size, embedding_dim, mask_zero=True) 
        
        self.lstm = LSTM(hidden_dim, return_sequences=True, return_state=True) 
        
        self.fc = TimeDistributed(Dense(vocab_size, activation='softmax'))
        
    def call(self, x, enc_output, state_h, state_c): 
        embed = self.embedding(x)
        
        dec_output, dec_h, dec_c = self.lstm(embed, initial_state=[state_h, state_c])
        
        output = self.fc(dec_output)
        
        return output, dec_h, dec_c
    
    def summary(self): 
        x = tf.keras.layers.Input(shape=(None,))
        enc_output = tf.keras.layers.Input(shape=(None, self.units))
        state_h = tf.keras.layers.Input(shape=(self.units,))
        state_c = tf.keras.layers.Input(shape=(self.units,))
        model = Model(inputs=[x, enc_output, state_h, state_c], outputs=self.call(x, enc_output, state_h, state_c))
        return model.summary()

decoder = Decoder(TRG_VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM)
decoder.summary()

# Define the optimizer and loss function
optimizer = Adam(learning_rate=LR)
loss_object = SparseCategoricalCrossentropy() 

def criterion(real, pred): 
    mask = tf.math.logical_not(tf.math.equal(real, 0)) 
    loss = loss_object(real, pred) 
    mask = tf.cast(mask, dtype=loss.dtype)
    loss *= mask 
    loss = tf.reduce_mean(loss)
    return loss

# Define training and validation steps
@tf.function 
def train_step(src, trg): 
    loss = 0 
    with tf.GradientTape() as tape: 
        enc_output, state_h, state_c = encoder(src)
        dec_input = tf.expand_dims(trg[:, 0], 1)
        
        for i in range(1, trg.shape[1]): 
            dec_output, state_h, state_c = decoder(dec_input, enc_output, state_h, state_c)
            
            loss += criterion(trg[:, i], dec_output[:, 0, :]) 
            
            dec_input = tf.expand_dims(trg[:, i], 1)
            
    batch_loss = (loss / int(trg.shape[1])) 
    ModelWeights = encoder.trainable_variables + decoder.trainable_variables 
    gradients = tape.gradient(loss, ModelWeights)
    optimizer.apply_gradients(zip(gradients, ModelWeights))
    
    return batch_loss 

@tf.function 
def val_step(src, trg): 
    loss = 0 
    enc_output, state_h, state_c = encoder(src) 
    dec_input = tf.expand_dims(trg[:, 0], 1)
    
    for i in range(1, trg.shape[1]): 
        dec_output, state_h, state_c = decoder(dec_input, enc_output, state_h, state_c)
        
        loss += criterion(trg[:, i], dec_output[:, 0, :])
        
        dec_input = tf.expand_dims(trg[:, i], 1)
        
    batch_loss = (loss / int(trg.shape[1]))
    
    return batch_loss

# Training loop
with tf.device("/GPU:0"): 
    training_losses = []
    val_losses = []
    for epoch in tqdm(range(EPOCHS)): 
        epoch_loss = [] 
        epoch_val_loss = [] 

        for x_train, y_train in train_set: 
            loss = train_step(x_train, y_train)
            epoch_loss.append(loss)

        for x_val, y_val in val_set: 
            val_loss = val_step(x_val, y_val) 
            epoch_val_loss.append(val_loss) 

        training_losses.append(np.mean(epoch_loss))
        val_losses.append(np.mean(epoch_val_loss))
        if (epoch + 1) % 10 == 0: 
            print(f"Epoch: {epoch+1}, Training Loss: {training_losses[-1]}, Validation Loss: {val_losses[-1]}\n")

# Plot training and validation losses
plt.plot(training_losses, label='train') 
plt.plot(val_losses, label='validation') 
plt.title('Training/Validation measure over Epochs') 
plt.xlabel('epoch') 
plt.ylabel('Training/Validation Losses') 
plt.legend() 
plt.show()

# Save model weights
encoder.save_weights('NMT_encoder.h5') 
decoder.save_weights('NMT_decoder.h5')

# Load model weights
encoder.load_weights('NMT_encoder.h5') 
decoder.load_weights('NMT_decoder.h5')

# Prediction function
def predict_sentence(en_input): 
    eng_seq = en_tokenizer.texts_to_sequences([en_input]) 
    en_input = pad_sequences(eng_seq, maxlen=MAXLEN, padding='post') 
    
    hidden_state, next_h, next_c = encoder(en_input) 
    
    curr_token = np.zeros((1, 1)) 
    curr_token[0, 0] = tr_tokenizer.word_index['sos'] 
    
    pred_sent = ''
    
    for i in range(MAXLEN): 
        output, next_h, next_c = decoder(curr_token, hidden_state, next_h, next_c)
        
        next_token = np.argmax(output[:, 0, :], axis=1)[0] 
        next_word = tr_tokenizer.index_word[next_token] 
        
        if next_word == 'eos':
            break
        else:
            pred_sent += ' ' + next_word
            curr_token[0, 0] = next_token
            
    return pred_sent.strip()

# Test the model
test_sample = df.sample(1000)

test_sample = test_sample[~(test_sample['en_len'] < 5) & ~(test_sample['en_len'] > 10)]
test_sample = test_sample[~(test_sample['tr_len'] < 5) & ~(test_sample['tr_len'] > 10)]

x_test = test_sample['en'].tolist() 
y_test = test_sample['tr'].tolist()

for en_sent in x_test[-10:]:
    result = predict_sentence(en_sent)
    print(f"English sentence: {en_sent}")
    print(f"Predicted translation: {result}")
```
------------------------------------- 43
```python
# Libraries
import pathlib
import random
import string
import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers import TextVectorization
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import callbacks

# Load the dataset
eng_file = '/path/to/english_sentences.txt'
fr_file = '/path/to/french_sentences.txt'

with open(eng_file, 'r') as file:
    english_sentences = file.readlines()
with open(fr_file, 'r') as file:
    french_sentences = file.readlines()

english_sentences = [sentence.rstrip('\n').lower() for sentence in english_sentences]
french_sentences = [sentence.rstrip('\n') for sentence in french_sentences]

# Filter out sentences which contains letters other than whats listed below
french_vocabulary = [ ' ', '!', '"', '#', '$', '%', '&', "'", '(', ')', '*', '+', ',', '-', '.', '/',
                      '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', 'ˌ',
                      "à", "â", "ç", "è", "é", "ê", "ë", "î", "ï", "ô", "ù", "û", "ü", "ÿ",
                      "a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k", "l", "m", "n", "o", "p", "q", "r", "s", "t", "u", "v", "w", "x", "y", "z"]

english_vocabulary = [' ', '!', '"', '#', '$', '%', '&', "'", '(', ')', '*', '+', ',', '-', '.', '/',
                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',
                        ':', '<', '=', '>', '?', '@',
                        '[', '\\', ']', '^', '_', '`',
                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',
                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',
                        'y', 'z',
                        '{', '|', '}', '~']

def is_valid_tokens(sentence, vocab):
    for token in list(set(sentence)):
        if token not in vocab:
            return False
    return True

valid_sentence_indicies = []
for index in range(len(english_sentences[:500000])):
    french_sentence, english_sentence = french_sentences[index], english_sentences[index]
    if is_valid_tokens(french_sentence, french_vocabulary) \
      and is_valid_tokens(english_sentence, english_vocabulary):
        valid_sentence_indicies.append(index)

TOTAL_SENTENCES = 200000 # only the first 200000 valid sentences are taken to train the model
x = [english_sentences[i] for i in valid_sentence_indicies[:TOTAL_SENTENCES]]
y = [french_sentences[i] for i in valid_sentence_indicies[:TOTAL_SENTENCES]]

dataset = pd.DataFrame({"English": x, "French": y})
dataset.info()

dataset.sample(5)

dataset.to_csv('/path/to/save/data.csv', index=False)
dataset = pd.read_csv('/path/to/save/data.csv')
dataset.head()

text_pairs = []

# Adding [start] and [end] tokens
for i in range(dataset.shape[0]):
    eng = str(dataset["English"][i])
    fr = "[start] " + str(dataset["French"][i]) + " [end]"
    text_pairs.append((eng, fr))

train_sample_size = len(text_pairs) - int(0.1 * len(text_pairs))
train_pairs = text_pairs[:train_sample_size]
test_pairs = text_pairs[train_sample_size:]

print("Total pairs :", len(text_pairs))
print("Train pairs :", len(train_pairs))
print("Test pairs :", len(test_pairs))

strip_chars = string.punctuation + "|"
strip_chars = strip_chars.replace("[", "")
strip_chars = strip_chars.replace("]", "")
strip_chars = strip_chars.replace('""', "")

vocab_size = 50000
sequence_length = 30
batch_size = 128

def custom_standardization(input_string):
    lowercase = tf.strings.lower(input_string)
    return tf.strings.regex_replace(lowercase, "[%s]" % re.escape(strip_chars), "")

eng_vectorization = TextVectorization(
    max_tokens=vocab_size, output_mode="int", output_sequence_length=sequence_length,
)

fr_vectorization = TextVectorization(
    max_tokens=vocab_size,
    output_mode="int",
    output_sequence_length=sequence_length + 1,
    standardize=custom_standardization,
)

train_eng_texts = [pair[0] for pair in train_pairs]
train_fr_texts = [pair[1] for pair in train_pairs]

# Adapt the TextVectorization layers to the training data
eng_vectorization.adapt(train_eng_texts)
fr_vectorization.adapt(train_fr_texts)

import json

# Get the vocabulary
eng_vocab = eng_vectorization.get_vocabulary()
fr_vocab = fr_vectorization.get_vocabulary()

# Save the vocabulary
with open('/path/to/save/eng_vocab.json', 'w') as f:
    json.dump(eng_vocab, f)
with open('/path/to/save/fr_vocab.json', 'w') as f:
    json.dump(fr_vocab, f)

# Load the vocabulary
with open('/path/to/save/eng_vocab.json', 'r') as f:
    eng_vocab = json.load(f)
with open('/path/to/save/fr_vocab.json', 'r') as f:
    fr_vocab = json.load(f)

# Create a TextVectorization layer with the loaded vocabulary
eng_vectorization = TextVectorization(vocabulary=eng_vocab, output_mode="int", output_sequence_length=sequence_length)
fr_vectorization = TextVectorization(vocabulary=fr_vocab, output_mode="int",
    output_sequence_length=sequence_length + 1,
    standardize=custom_standardization)

def format_dataset(eng, fr):
    eng = eng_vectorization(eng)
    fr = fr_vectorization(fr)
    return ({"encoder_inputs": eng, "decoder_inputs": fr[:, :-1],}, fr[:, 1:])

def make_dataset(pairs):
    eng_texts, fr_texts = zip(*pairs)
    eng_texts = list(eng_texts)
    fr_texts = list(fr_texts)
    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, fr_texts))
    dataset = dataset.batch(batch_size)
    dataset = dataset.map(format_dataset)
    return dataset.shuffle(2048).prefetch(16).cache()

train_ds = make_dataset(train_pairs)
test_ds = make_dataset(test_pairs)

for inputs, targets in train_ds.take(2):
    print(f'inputs["encoder_inputs"].shape: {inputs["encoder_inputs"].shape}')
    print(f'inputs["decoder_inputs"].shape: {inputs["decoder_inputs"].shape}')
    print(f"targets.shape: {targets.shape}")

class TransformerEncoder(layers.Layer):
    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):
        super().__init__(**kwargs)
        self.embed_dim = embed_dim
        self.dense_dim = dense_dim
        self.num_heads = num_heads
        self.attention = layers.MultiHeadAttention(
            num_heads=num_heads, key_dim=embed_dim
        )
        self.dense_proj = keras.Sequential(
            [layers.Dense(dense_dim, activation="relu"), layers.Dense(embed_dim),]
        )
        self.layernorm_1 = layers.LayerNormalization()
        self.layernorm_2 = layers.LayerNormalization()
        self.supports_masking = True

    def call(self, inputs, mask=None):
        if mask is not None:
            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype="int32")
        attention_output = self.attention(
            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask
        )
        proj_input = self.layernorm_1(inputs + attention_output)
        proj_output = self.dense_proj(proj_input)
        return self.layernorm_2(proj_input + proj_output)

class PositionalEmbedding(layers.Layer):
    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):
        super().__init__(**kwargs)
        self.token_embeddings = layers.Embedding(
            input_dim=vocab_size, output_dim=embed_dim
        )
        self.position_embeddings = layers.Embedding(
            input_dim=sequence_length, output_dim=embed_dim
        )
        self.sequence_length = sequence_length
        self.vocab_size = vocab_size
        self.embed_dim = embed_dim

    def call(self, inputs):
        length = tf.shape(inputs)[-1]
        positions = tf.range(start=0, limit=length, delta=1)
        embedded_tokens = self.token_embeddings(inputs)
        embedded_positions = self.position_embeddings(positions)
        embedded = embedded_tokens + embedded_positions
        
        # Compute mask
        mask = tf.not_equal(inputs, 0)
        return embedded, mask

class TransformerDecoder(layers.Layer):
    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):
        super().__init__(**kwargs)
        self.embed_dim = embed_dim
        self.latent_dim = latent_dim
        self.num_heads = num_heads
        self.attention_1 = layers.MultiHeadAttention(
            num_heads=num_heads, key_dim=embed_dim
        )
        self.attention_2 = layers.MultiHeadAttention(
            num_heads=num_heads, key_dim=embed_dim
        )
        self.dense_proj = keras.Sequential(
            [layers.Dense(latent_dim, activation="relu"), layers.Dense(embed_dim),]
        )
        self.layernorm_1 = layers.LayerNormalization()
        self.layernorm_2 = layers.LayerNormalization()
        self.layernorm_3 = layers.LayerNormalization()
        self.supports_masking = True

    def call(self, inputs, encoder_outputs, mask=None):
        causal_mask = self.get_causal_attention_mask(inputs)
        if mask is not None:
            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype="int32")
            padding_mask = tf.minimum(padding_mask, causal_mask)

        attention_output_1 = self.attention_1(
            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask
        )
        out_1 = self.layernorm_1(inputs + attention_output_1)

        attention_output_2  = self.attention_2(
            query=out_1,
            value=encoder_outputs,
            key=encoder_outputs,
            attention_mask=padding_mask,
        )

        out_2 = self.layernorm_2(out_1 + attention_output_2)

        proj_output = self.dense_proj(out_2)
        return self.layernorm_3(out_2 + proj_output)

    def get_causal_attention_mask(self, inputs):
        input_shape = tf.shape(inputs)
        batch_size, sequence_length = input_shape[0], input_shape[1]
        i = tf.range(sequence_length)[:, tf.newaxis]
        j = tf.range(sequence_length)
        mask = tf.cast(i >= j, dtype="int32")
        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))
        mult = tf.concat(
            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],
            axis=0,
        )
        return tf.tile(mask, mult)

embed_dim = 512
latent_dim = 1024
num_heads = 8

encoder_inputs = keras.Input(shape=(None,), dtype="int64", name="encoder_inputs")
x, mask = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)
encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x, mask)
encoder = keras.Model(encoder_inputs, encoder_outputs)

decoder_inputs = keras.Input(shape=(None,), dtype="int64", name="decoder_inputs")
encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name="decoder_state_inputs")
x, mask = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)
x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs, mask)
x = layers.Dropout(0.5)(x)
decoder_outputs = layers.Dense(vocab_size, activation="softmax")(x)
decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)

decoder_outputs = decoder([decoder_inputs, encoder_outputs])
transformer = keras.Model(
    [encoder_inputs, decoder_inputs], decoder_outputs, name="transformer"
)

transformer.summary()

class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):
  def __init__(self, d_model, warmup_steps=4000):
    super().__init__()

    self.d_model = d_model
    self.d_model = tf.cast(self.d_model, tf.float32)

    self.warmup_steps = warmup_steps

  def __call__(self, step):
    step = tf.cast(step, dtype=tf.float32)
    arg1 = tf.math.rsqrt(step)
    arg2 = step * (self.warmup_steps ** -1.5)

    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)

  def get_config(self):
    return {"d_model": self.d_model.numpy(), "warmup_steps": self.warmup_steps}

learning_rate = CustomSchedule(latent_dim)

optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,
                                     epsilon=1e-9)

plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))
plt.ylabel('Learning Rate')
plt.xlabel('Train Step')

# Callbacks
early_stopping = callbacks.EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)

checkpoint_filepath = '/path/to/save/checkpoint.keras'
model_checkpoint_callback = callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    save_weights_only=False,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True)

csv_logger = callbacks.CSVLogger('/path/to/save/training_log.csv', append=True)

backup_callback = callbacks.BackupAndRestore(backup_dir="/path/to/save/backup",
                                             delete_checkpoint=False)

epochs = 30
transformer.compile(
    optimizer=optimizer,
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

history = transformer.fit(train_ds,
                epochs=epochs,
                validation_data=test_ds,
                callbacks=[
                      early_stopping,
                      model_checkpoint_callback,
                      csv_logger,
                      backup_callback]
)

transformer.save('/path/to/save/transformer_model.h5')

import os
def plot_loss_and_accuracy(history, save_dir=None, filename=None):
    # Extract the loss and accuracy values from the history object
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    accuracy = history.history['accuracy']
    val_accuracy = history.history['val_accuracy']

    # Get the number of epochs
    epochs = range(1, len(loss) + 1)

    # Plot training and validation loss
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(epochs, loss, 'bo-', label='Training Loss')
    plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # Plot training and validation accuracy
    plt.subplot(1, 2, 2)
    plt.plot(epochs, accuracy, 'bo-', label='Training Accuracy')
    plt.plot(epochs, val_accuracy, 'ro-', label='Validation Accuracy')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.tight_layout()

    # Save the figure if save_dir and filename are provided
    if save_dir and filename:
        os.makedirs(save_dir, exist_ok=True)
        save_path = os.path.join(save_dir, filename)
        plt.savefig(save_path)
        print(f"Plots saved as '{save_path}'")

    plt.show()

plot_loss_and_accuracy(history, "/path/to/save/plots", "transformer_trainloss.png")

fr_vocab = fr_vectorization.get_vocabulary()
fr_index_lookup = dict(zip(range(len(fr_vocab)), fr_vocab))
max_decoded_sentence_length = 20

def decode_sequence(input_sentence):
    tokenized_input_sentence = eng_vectorization([input_sentence])
    decoded_sentence = "[start]"
    for i in range(max_decoded_sentence_length):
        tokenized_target_sentence = fr_vectorization([decoded_sentence])[:, :-1]
        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])

        sampled_token_index = np.argmax(predictions[0, i, :])
        sampled_token = fr_index_lookup[sampled_token_index]
        decoded_sentence += " " + sampled_token

        if sampled_token == "[end]":
            break
    return decoded_sentence

input_sentence = 'I came late'
output = decode_sequence(input_sentence)
print(output)
------------------------------------- 44
```python
import warnings
warnings.filterwarnings('ignore')

import pandas as pd 
import numpy as np 
from tqdm.auto import tqdm 
import re
from sklearn.model_selection import train_test_split 
import tensorflow as tf 
from tensorflow import keras 
from tensorflow.keras.preprocessing.text import Tokenizer 
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, LayerNormalization, MultiHeadAttention, Add
from tensorflow.keras.losses import SparseCategoricalCrossentropy
from tensorflow.keras.optimizers import Adam

# Load the dataset
df = pd.read_csv('path_to_your_dataset.csv')

# Preprocessing functions
def tamil_preprocessing(data, col):
    data[col] = data[col].astype(str)
    data[col] = data[col].apply(lambda x: x.lower())
    data[col] = data[col].apply(lambda x: re.sub("[^A-Za-z\s]", "", x))
    data[col] = data[col].apply(lambda x: x.replace("\s+", " "))
    data[col] = data[col].apply(lambda x: " ".join([word for word in x.split()]))
    return data

def english_preprocessing(data, col):
    data[col] = data[col].astype(str)
    data[col] = data[col].apply(lambda x: x.lower())
    data[col] = data[col].apply(lambda x: re.sub(r'\d', '', x))
    data[col] = data[col].apply(lambda x: re.sub(r'\s+', ' ', x))
    data[col] = data[col].apply(lambda x: re.sub(r"[-()\"#/@;:<>{}`+=~|.!?,।]", "", x))
    data[col] = data[col].apply(lambda x: x.strip())
    data[col] = "<sos> " + data[col] + " <eos>"
    return data

df = tamil_preprocessing(df, 'tamil')
df = english_preprocessing(df, 'english')

# Calculate sentence lengths
df["en_len"] = [len(text.split()) for text in df.english]
df['ta_len'] = [len(text.split()) for text in df.tamil]

# Filter sentences based on length
df = df[~(df['en_len'] < 5) & ~(df['en_len'] > 20)]
df = df[~(df['ta_len'] < 5) & ~(df['ta_len'] > 20)]

# Vectorization function
def Vectorization(col, MAXLEN=20):
    sents = df[col].tolist()
    tokenizer = Tokenizer(oov_token="<OOV>")
    tokenizer.fit_on_texts(sents)
    seqs = tokenizer.texts_to_sequences(sents)
    pad_seqs = pad_sequences(seqs, maxlen=MAXLEN, padding='post')
    return tokenizer, pad_seqs

en_tokenizer, en_seqs = Vectorization('english')
ta_tokenizer, ta_seqs = Vectorization('tamil')

# Split the dataset
x_train, x_test, y_train, y_test = train_test_split(ta_seqs, en_seqs, train_size=0.95, random_state=42)
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size=0.75, random_state=42)

# Prepare the dataset
BATCH_SIZE = 128
BUFFER_SIZE = 1000

train_set = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_set = train_set.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)

val_set = tf.data.Dataset.from_tensor_slices((x_val, y_val))
val_set = val_set.batch(BATCH_SIZE, drop_remainder=True)

test_set = tf.data.Dataset.from_tensor_slices((x_test, y_test))
test_set = test_set.batch(BATCH_SIZE, drop_remainder=True)

# Define parameters
EMBEDDING_DIM = 256
SRC_VOCAB_SIZE = len(ta_tokenizer.word_index) + 1
TRG_VOCAB_SIZE = len(en_tokenizer.word_index) + 1
HIDDEN_DIM = 512
EPOCHS = 30
NUM_LAYERS = 4
NUM_HEADS = 8
DFF = 2048
DROPOUT_RATE = 0.1
MAX_SEQ_LENGTH = 20

# Custom Learning Rate Schedule
class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):
    def __init__(self, d_model, warmup_steps=4000):
        super(CustomSchedule, self).__init__()
        self.d_model = d_model
        self.d_model = tf.cast(self.d_model, tf.float32)
        self.warmup_steps = warmup_steps

    def __call__(self, step):
        arg1 = tf.math.rsqrt(step)
        arg2 = step * (self.warmup_steps ** -1.5)
        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)

# Positional Encoding Layer
class PositionalEmbedding(tf.keras.layers.Layer):
    def __init__(self, vocab_size, d_model, max_len):
        super(PositionalEmbedding, self).__init__()
        self.d_model = d_model
        self.embedding = Embedding(vocab_size, d_model, mask_zero=True)
        self.pos_encoding = self.positional_encoding(max_len, self.d_model)

    def positional_encoding(self, position, d_model):
        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis],
                                     np.arange(d_model)[np.newaxis, :],
                                     d_model)
        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])
        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])
        pos_encoding = angle_rads[np.newaxis, ...]
        return tf.cast(pos_encoding, dtype=tf.float32)

    def get_angles(self, pos, i, d_model):
        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))
        return pos * angle_rates

    def call(self, inputs):
        length = tf.shape(inputs)[1]
        inputs = self.embedding(inputs)
        inputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))
        inputs += self.pos_encoding[:, :length, :]
        return inputs

# Transformer Encoder Layer
class EncoderLayer(tf.keras.layers.Layer):
    def __init__(self, d_model, num_heads, dff, rate=0.1):
        super(EncoderLayer, self).__init__()
        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)
        self.ffn = tf.keras.Sequential([
            Dense(dff, activation='relu'),
            Dense(d_model)
        ])
        self.layernorm1 = LayerNormalization(epsilon=1e-6)
        self.layernorm2 = LayerNormalization(epsilon=1e-6)
        self.dropout1 = Dropout(rate)
        self.dropout2 = Dropout(rate)

    def call(self, x, training, mask):
        attn_output = self.mha(x, x, x, mask)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(x + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        out2 = self.layernorm2(out1 + ffn_output)
        return out2

# Transformer Decoder Layer
class DecoderLayer(tf.keras.layers.Layer):
    def __init__(self, d_model, num_heads, dff, rate=0.1):
        super(DecoderLayer, self).__init__()
        self.mha1 = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)
        self.mha2 = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)
        self.ffn = tf.keras.Sequential([
            Dense(dff, activation='relu'),
            Dense(d_model)
        ])
        self.layernorm1 = LayerNormalization(epsilon=1e-6)
        self.layernorm2 = LayerNormalization(epsilon=1e-6)
        self.layernorm3 = LayerNormalization(epsilon=1e-6)
        self.dropout1 = Dropout(rate)
        self.dropout2 = Dropout(rate)
        self.dropout3 = Dropout(rate)

    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):
        attn1 = self.mha1(x, x, x, look_ahead_mask)
        attn1 = self.dropout1(attn1, training=training)
        out1 = self.layernorm1(x + attn1)
        attn2 = self.mha2(out1, enc_output, enc_output, padding_mask)
        attn2 = self.dropout2(attn2, training=training)
        out2 = self.layernorm2(out1 + attn2)
        ffn_output = self.ffn(out2)
        ffn_output = self.dropout3(ffn_output, training=training)
        out3 = self.layernorm3(out2 + ffn_output)
        return out3

# Transformer Encoder
class Encoder(tf.keras.layers.Layer):
    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):
        super(Encoder, self).__init__()
        self.d_model = d_model
        self.num_layers = num_layers
        self.embedding = PositionalEmbedding(input_vocab_size, d_model, maximum_position_encoding)
        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]
        self.dropout = Dropout(rate)

    def call(self, x, training, mask):
        x = self.embedding(x)
        x = self.dropout(x, training=training)
        for i in range(self.num_layers):
            x = self.enc_layers[i](x, training, mask)
        return x

# Transformer Decoder
class Decoder(tf.keras.layers.Layer):
    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):
        super(Decoder, self).__init__()
        self.d_model = d_model
        self.num_layers = num_layers
        self.embedding = PositionalEmbedding(target_vocab_size, d_model, maximum_position_encoding)
        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]
        self.dropout = Dropout(rate)

    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):
        x = self.embedding(x)
        x = self.dropout(x, training=training)
        for i in range(self.num_layers):
            x = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)
        return x

# Transformer Model
class Transformer(tf.keras.Model):
    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):
        super(Transformer, self).__init__()
        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)
        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)
        self.final_layer = Dense(target_vocab_size)

    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):
        enc_output = self.encoder(inp, training, enc_padding_mask)
        dec_output = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)
        final_output = self.final_layer(dec_output)
        return final_output

# Create the transformer model
transformer = Transformer(
    num_layers=NUM_LAYERS,
    d_model=EMBEDDING_DIM,
    num_heads=NUM_HEADS,
    dff=DFF,
    input_vocab_size=SRC_VOCAB_SIZE,
    target_vocab_size=TRG_VOCAB_SIZE,
    pe_input=MAX_SEQ_LENGTH,
    pe_target=MAX_SEQ_LENGTH,
    rate=DROPOUT_RATE
)

# Define the optimizer and loss function
learning_rate = CustomSchedule(EMBEDDING_DIM)
optimizer = Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)
loss_object = SparseCategoricalCrossentropy(from_logits=True, reduction='none')

def loss_function(real, pred):
    mask = tf.math.logical_not(tf.math.equal(real, 0))
    loss_ = loss_object(real, pred)
    mask = tf.cast(mask, dtype=loss_.dtype)
    loss_ *= mask
    return tf.reduce_mean(loss_)

# Training and validation steps
@tf.function
def train_step(inp, tar):
    tar_inp = tar[:, :-1]
    tar_real = tar[:, 1:]
    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)
    with tf.GradientTape() as tape:
        predictions = transformer(inp, tar_inp, True, enc_padding_mask, combined_mask, dec_padding_mask)
        loss = loss_function(tar_real, predictions)
    gradients = tape.gradient(loss, transformer.trainable_variables)
    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))
    return loss

@tf.function
def val_step(inp, tar):
    tar_inp = tar[:, :-1]
    tar_real = tar[:, 1:]
    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)
    predictions = transformer(inp, tar_inp, False, enc_padding_mask, combined_mask, dec_padding_mask)
    loss = loss_function(tar_real, predictions)
    return loss

# Training loop
training_losses = []
val_losses = []
for epoch in tqdm(range(EPOCHS)):
    epoch_loss = []
    epoch_val_loss = []
    for (batch, (inp, tar)) in enumerate(train_set):
        loss = train_step(inp, tar)
        epoch_loss.append(loss)
    for (batch, (inp, tar)) in enumerate(val_set):
        val_loss = val_step(inp, tar)
        epoch_val_loss.append(val_loss)
    training_losses.append(np.mean(epoch_loss))
    val_losses.append(np.mean(epoch_val_loss))
    if (epoch + 1) % 10 == 0:
        print(f"Epoch {epoch + 1}, Training Loss: {training_losses[-1]}, Validation Loss: {val_losses[-1]}")

# Save the model
transformer.save_weights('transformer_model_weights.h5')
```
------------------------------------- 45
