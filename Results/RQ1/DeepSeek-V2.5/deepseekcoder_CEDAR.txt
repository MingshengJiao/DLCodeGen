```python
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dense, Flatten, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping

# Constants
IM_SIZE = 224
BATCH_SIZE = 32
EPOCHS = 20

# Data preprocessing function
def preprocess_image(image, label):
    image = tf.cast(image, tf.float32) / 255.0
    return image, label

# Data augmentation and preprocessing
datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Load dataset
dataset_path = '/path/to/your/dataset'
train_generator = datagen.flow_from_directory(
    dataset_path,
    target_size=(IM_SIZE, IM_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='binary',
    subset='training'
)

validation_generator = datagen.flow_from_directory(
    dataset_path,
    target_size=(IM_SIZE, IM_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='binary',
    subset='validation'
)

# Define the CNN model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(IM_SIZE, IM_SIZE, 3)),
    MaxPooling2D((2, 2)),
    BatchNormalization(),
    
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    BatchNormalization(),
    
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    BatchNormalization(),
    
    Flatten(),
    
    Dense(128, activation='relu'),
    Dropout(0.5),
    
    Dense(64, activation='relu'),
    Dropout(0.5),
    
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss=BinaryCrossentropy(), metrics=['accuracy'])

# Early stopping callback
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Train the model
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=EPOCHS,
    callbacks=[early_stopping]
)

# Evaluate the model
test_loss, test_accuracy = model.evaluate(validation_generator)
print(f'Test Accuracy: {test_accuracy * 100:.2f}%')
```
------------------------------------- 0
```python
import os
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D, Dropout, Dense
from tensorflow.keras.models import Model
import tensorflow as tf

# Load the dataset
train_dir = 'path_to_train_directory'
val_dir = 'path_to_validation_directory'
test_dir = 'path_to_test_directory'

# Define image parameters
image_size = 224
batch_size = 32
num_classes = 2  # Fresh and Stale

# Data preprocessing and augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=45,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.25,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(image_size, image_size),
    batch_size=batch_size,
    class_mode='binary'
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(image_size, image_size),
    batch_size=batch_size,
    class_mode='binary'
)

# Build the model
base_model = ResNet50V2(input_shape=(image_size, image_size, 3), weights='imagenet', include_top=False)
for layer in base_model.layers:
    layer.trainable = False

x = base_model.output
x = BatchNormalization()(x)
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(1, activation='sigmoid')(x)

model = Model(inputs=base_model.input, outputs=predictions)

# Compile the model
learning_rate = 1e-4
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    validation_data=val_generator,
    validation_steps=val_generator.samples // batch_size,
    epochs=15
)

# Plot training and validation accuracy
plt.figure(figsize=(7, 5))
plt.plot(history.history['accuracy'], label="Train Accuracy", color="blue", marker="*")
plt.plot(history.history['val_accuracy'], label="Validation Accuracy", color="red", marker="P")
plt.grid(True)
plt.legend()
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.show()

# Plot training and validation loss
plt.figure(figsize=(7, 5))
plt.plot(history.history['loss'], color="green", marker="D")
plt.plot(history.history['val_loss'], color="navy", marker="H")
plt.grid(True)
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train Loss', 'Validation Loss'], loc='upper left')
plt.show()

# Evaluate the model on the test set
test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(image_size, image_size),
    batch_size=batch_size,
    class_mode='binary'
)

test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // batch_size)
print(f'Test Accuracy: {test_accuracy:.4f}')

# Save the model
model.save('fresh_stale_classifier.h5')
```
------------------------------------- 1
```python
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D
from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import categorical_crossentropy
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications import imagenet_utils
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.applications.resnet50 import ResNet50
from sklearn.utils.class_weight import compute_class_weight
from keras.models import Model
from keras.layers import Dense
from sklearn.model_selection import StratifiedKFold
from keras.layers import Flatten
from sklearn.metrics import confusion_matrix
import itertools
import os
import pandas as pd
import shutil
import random
import glob
import matplotlib.pyplot as plt
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
%matplotlib inline

# Define the root directory
root_dir = '/path/to/your/dataset'

# Initialize lists to store data
image_paths = []
subsets = []
targets = []

# Iterate through the train and test directories
for subset in ['train', 'test']:
    subset_path = os.path.join(root_dir, subset)

    # Iterate through each class folder
    for class_folder in os.listdir(subset_path):
        class_path = os.path.join(subset_path, class_folder)

        # Iterate through images in the class folder
        for image_filename in os.listdir(class_path):
            image_path = os.path.join(class_path, image_filename)

            # Append data to lists
            image_paths.append(image_path)
            subsets.append(subset)
            targets.append(class_folder)

# Create DataFrame
df = pd.DataFrame({
    'Image Path': image_paths,
    'Subset': subsets,
    'Target': targets
})

# Display the DataFrame
print(df.head())

# Specify the output CSV file path
output_csv_path = '/path/to/save/dataset.csv'

# Save the DataFrame to a CSV file
df.to_csv(output_csv_path, index=False)

# Print a message indicating the successful conversion
print(f"DataFrame has been successfully saved to {output_csv_path}")

# Filter the DataFrame to get only the "train" subset
train_df = df[df['Subset'] == 'train']
test_df = df[df['Subset'] == 'test']

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], '.2f'),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

def plotImages(images_arr):
    fig, axes = plt.subplots(1, 10, figsize=(20,20))
    axes = axes.flatten()
    for img, ax in zip( images_arr, axes):
        ax.imshow(img)
        ax.axis('off')
    plt.tight_layout()
    plt.show()

TRAIN_PATH = os.path.join(root_dir, 'train')
TEST_PATH = os.path.join(root_dir, 'test')

train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    channel_shift_range=20.,
    horizontal_flip=True,
    preprocessing_function=tf.keras.applications.vgg16.preprocess_input)

valid_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input)

test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input)

classes = ['Very mild Dementia', 'Non Demented', 'Moderate Dementia', 'Mild Dementia']

data_kfold = pd.DataFrame()

accuracy_list = []
precision_list = []
recall_list = []

# k-fold
kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
# Variable for keeping count of split we are executing
j = 0

for train_idx, val_idx in list(kfold.split(train_df['Image Path'], train_df['Target'])):
    x_train_df = df.iloc[train_idx]
    x_valid_df = df.iloc[val_idx]
    j += 1

    train_batches = train_datagen.flow_from_dataframe(dataframe=x_train_df,
                                                     x_col="Image Path", y_col="Target",
                                                     class_mode="categorical",
                                                     classes=classes,
                                                     target_size=(224, 224), batch_size=32, shuffle=True)
    valid_batches = valid_datagen.flow_from_dataframe(dataframe=x_valid_df,
                                                     x_col="Image Path", y_col="Target",
                                                     class_mode="categorical", classes=classes,
                                                     target_size=(224, 224), batch_size=32, shuffle=False)
    test_batches = test_datagen.flow_from_dataframe(dataframe=test_df, classes=classes,
                                                   x_col="Image Path", y_col="Target",
                                                   class_mode=None,
                                                   target_size=(224, 224), shuffle=False)

    imgs, labels = next(train_batches)
    plotImages(imgs)
    print(labels)

    # Load ResNet50 with pre-trained weights, including the top (fully connected) layer
    resnet50_model = ResNet50(weights='imagenet', include_top=True, input_shape=(224, 224, 3))

    # Remove the last dense layer (the output layer of the original ResNet50)
    resnet50_output = resnet50_model.layers[-2].output

    # Add your custom output layer
    custom_output_layer = Dense(4, activation='softmax')(resnet50_output)

    # Create a new model with ResNet50 as the input and your custom output layer
    skin_disease_classifier = Model(inputs=resnet50_model.input, outputs=custom_output_layer)

    class_weights = compute_class_weight('balanced', classes=np.unique(train_batches.classes), y=train_batches.classes)
    class_weight_dict = dict(enumerate(class_weights))

    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
    model_checkpoint = ModelCheckpoint(f'skin_disease_classifier{j}.h5', monitor='val_loss', save_best_only=True)

    skin_disease_classifier.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

    history = skin_disease_classifier.fit(
        x=train_batches,
        validation_data=valid_batches,
        callbacks=[early_stopping, model_checkpoint],
        class_weight=class_weight_dict,
        verbose=1,
        epochs=2,
    )

    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('Model accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend(['Train', 'Validation'], loc='upper left')
    plt.show()

    # Evaluate the model on the validation set
    valid_batches.reset()  # Reset the validation generator
    valid_pred = skin_disease_classifier.predict(valid_batches)
    valid_predicted_class_indices = np.argmax(valid_pred, axis=1)

    # Calculate metrics for the current fold on the validation set
    val_true_labels = valid_batches.classes
    val_accuracy = accuracy_score(val_true_labels, valid_predicted_class_indices)
    val_precision = precision_score(val_true_labels, valid_predicted_class_indices, average='macro')
    val_recall = recall_score(val_true_labels, valid_predicted_class_indices, average='macro')

    # Store metrics for the current fold on the validation set
    accuracy_list.append(val_accuracy)
    precision_list.append(val_precision)
    recall_list.append(val_recall)

    print("Val acc: ", val_accuracy)
    print("Val prec: ", val_precision)
    print("Val rec: ", val_recall)

    # Generate classification report
    report = classification_report(val_true_labels, valid_predicted_class_indices, target_names=list(train_batches.class_indices.keys()), digits=4)

    # Print the classification report
    print(report)
    pred = skin_disease_classifier.predict(test_batches)

    predicted_class_indices = np.argmax(pred, axis=1)

    data_kfold[j] = predicted_class_indices

# After all folds, calculate average and standard deviation of metrics on the validation set

average_val_accuracy = np.mean(accuracy_list)
std_dev_val_accuracy = np.std(accuracy_list)

average_val_precision = np.mean(precision_list)
std_dev_val_precision = np.std(precision_list)

average_val_recall = np.mean(recall_list)
std_dev_val_recall = np.std(recall_list)

# Return the means and standard deviations
mean_and_std_dev = {
    'accuracy_mean': average_val_accuracy,
    'accuracy_std_dev': std_dev_val_accuracy,
    'precision_mean': average_val_precision,
    'precision_std_dev': std_dev_val_precision,
    'recall_mean': average_val_recall,
    'recall_std_dev': std_dev_val_recall
}

print(mean_and_std_dev)

ans = test_df.copy()
# Reset the indices of the 'ans' DataFrame
ans.reset_index(drop=True, inplace=True)

labels = (train_batches.class_indices)
labels2 = dict((v, k) for k, v in labels.items())
import collections
for i in range(len(data_kfold)):
    co = collections.Counter(data_kfold.loc[i])
    co = sorted(co.items(), key=lambda x: x[1], reverse=True)
    ans.Target.loc[i] = labels2[co[0][0]]

# Generate classification report
report = classification_report(test_df['Target'], ans['Target'], target_names=list(train_batches.class_indices.keys()), digits=4)

# Print the classification report
print(report)

plot_confusion_matrix(confusion_matrix(test_df['Target'], ans['Target']), list(train_batches.class_indices.keys()), normalize=True)
```
------------------------------------- 2
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation, Dense, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import to_categorical
import os
import cv2

# Define paths and constants
DATA_DIR = 'path_to_dataset'  # Replace with the path to your dataset
IMG_SIZE = (128, 128)
NUM_CLASSES = 4
BATCH_SIZE = 32
EPOCHS = 50

# Load and preprocess data
def load_data(data_dir, img_size):
    images = []
    labels = []
    class_names = ['Healthy', 'Bunchy top', 'Fusarium wilt', 'Moko']
    for class_name in class_names:
        class_dir = os.path.join(data_dir, class_name)
        for img_name in os.listdir(class_dir):
            img_path = os.path.join(class_dir, img_name)
            img = cv2.imread(img_path, cv2.IMREAD_COLOR)
            img = cv2.resize(img, img_size)
            img = img / 255.0  # Normalize pixel values
            images.append(img)
            labels.append(class_names.index(class_name))
    return np.array(images), np.array(labels)

X, y = load_data(DATA_DIR, IMG_SIZE)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Convert labels to one-hot encoding
y_train = to_categorical(y_train, NUM_CLASSES)
y_test = to_categorical(y_test, NUM_CLASSES)

# Data augmentation
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
datagen.fit(X_train)

# Build the model
def build_model(input_shape, num_classes):
    inputs = Input(shape=input_shape)
    
    # Convolutional layers
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)
    x = BatchNormalization()(x)
    x = MaxPooling2D((2, 2))(x)
    
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D((2, 2))(x)
    
    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    x = BatchNormalization()(x)
    x = MaxPooling2D((2, 2))(x)
    
    # Fully connected layers
    x = Flatten()(x)
    x = Dense(512, activation='relu')(x)
    x = BatchNormalization()(x)
    x = Dense(256, activation='relu')(x)
    x = BatchNormalization()(x)
    
    # Output layer
    outputs = Dense(num_classes, activation='softmax')(x)
    
    model = Model(inputs, outputs)
    return model

input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3)
model = build_model(input_shape, NUM_CLASSES)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)

# Train the model
history = model.fit(
    datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),
    epochs=EPOCHS,
    validation_data=(X_test, y_test),
    callbacks=[early_stopping, model_checkpoint]
)

# Evaluate the model
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f'Test accuracy: {test_acc:.4f}')

# Save the model
model.save('skin_lesion_classifier.h5')
```
------------------------------------- 3
```python
import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns
import os
import cv2
import tensorflow as tf
from tensorflow import keras   
from sklearn.utils import shuffle
from tensorflow.keras.utils import to_categorical
from keras.models import load_model
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Dropout, Input, LSTM, Reshape
from keras.models import Sequential, Model
from keras.layers import Conv2D, GlobalMaxPooling2D
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import datasets, layers, models
from keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Dropout
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score
from keras import regularizers

# Set seed for reproducibility
seed = 42
np.random.seed(seed)
tf.random.set_seed(seed)

# Define paths
train_path = 'path_to_train_directory'
val_path = 'path_to_validation_directory'
test_path = 'path_to_test_directory'

# Image parameters
IMG_SIZE = 224
ColorChannels = 3
batch_size = 32

# Create data generators for training, validation, and testing
data_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = data_datagen.flow_from_directory(
    train_path,
    target_size=(IMG_SIZE, IMG_SIZE),
    color_mode='rgb',
    batch_size=batch_size,
    class_mode='categorical',
    subset='training',
)

validation_generator = data_datagen.flow_from_directory(
    val_path,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=batch_size,
    color_mode='rgb',
    class_mode='categorical',
    subset='validation',
)

test_generator = test_datagen.flow_from_directory(
    test_path,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=batch_size,
    color_mode='rgb',
    class_mode='categorical',
)

# Visualize some training images
plt.figure(figsize=(15, 10))
plt.suptitle("Train Images", fontsize=20)
for i in range(30):
    img, label = train_generator.next()
    plt.subplot(5, 6, i + 1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(img[0])
    plt.xlabel(train_generator.class_indices)
plt.show()

# Define the model architecture
def Inception_model():
    input_tensor = Input(shape=(IMG_SIZE, IMG_SIZE, ColorChannels))
    baseModel = InceptionV3(include_top=False, weights='imagenet', input_tensor=input_tensor)
    
    headModel = baseModel.output
    headModel = Flatten()(headModel)
    headModel = Dense(128, activation="relu")(headModel)
    headModel = BatchNormalization()(headModel)
    headModel = Dropout(0.5)(headModel)
    headModel = Dense(4, activation="softmax")(headModel)  # 4 classes: meningioma, glioma, pituitary, no tumor
    
    model = Model(inputs=baseModel.input, outputs=headModel)

    for layer in baseModel.layers:
        layer.trainable = False

    return model

model = Inception_model()
model.summary()

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Define callbacks
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.6, patience=20, min_lr=0.00005, verbose=1)
checkpoint = ModelCheckpoint("inception_brain_tumor.h5", save_best_only=True)
early_stopping = EarlyStopping(patience=5, restore_best_weights=True)

# Train the model
epochs = 20
history = model.fit(
    train_generator,
    epochs=epochs,
    validation_data=validation_generator,
    callbacks=[early_stopping, checkpoint, reduce_lr]
)

# Evaluate the model
score, acc = model.evaluate(test_generator)
print('Test Loss =', score)
print('Test Accuracy =', acc)

# Visualize predictions on test data
plt.figure(figsize=(16, 25))
class_label = ['meningioma', 'glioma', 'pituitary', 'no tumor']
image, label = test_generator.next()
for i in range(18):
    model_pred = model.predict(np.expand_dims(image[i], axis=0))
    plt.subplot(7, 3, i + 1)
    plt.imshow(image[i])
    plt.title(f"Prediction: {class_label[np.argmax(model_pred)]}\nOriginal: {class_label[np.argmax(label[i])]}")
    plt.axis("off")
plt.show()
```
------------------------------------- 4
```python
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, LeakyReLU, BatchNormalization, PReLU, Add, UpSampling2D, Dense, Flatten, Reshape
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import MeanSquaredError
from sklearn.model_selection import train_test_split
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim

# Define paths
HIGH_RES_PATH = "/path/to/high_res_images"
LOW_RES_PATH = "/path/to/low_res_images"

# Load images
def load_images(path):
    images = []
    for img_name in os.listdir(path):
        img = cv2.imread(os.path.join(path, img_name))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        images.append(img)
    return np.array(images)

high_res_images = load_images(HIGH_RES_PATH)
low_res_images = load_images(LOW_RES_PATH)

# Normalize images
high_res_images = high_res_images / 255.0
low_res_images = low_res_images / 255.0

# Split data
X_train, X_test, y_train, y_test = train_test_split(low_res_images, high_res_images, test_size=0.2, random_state=42)

# Define the generator
def build_generator():
    def residual_block(layer_input):
        d = Conv2D(64, kernel_size=3, strides=1, padding='same')(layer_input)
        d = BatchNormalization(momentum=0.8)(d)
        d = PReLU()(d)
        d = Conv2D(64, kernel_size=3, strides=1, padding='same')(d)
        d = BatchNormalization(momentum=0.8)(d)
        d = Add()([d, layer_input])
        return d

    img_lr = Input(shape=(None, None, 3))
    
    c1 = Conv2D(64, kernel_size=9, strides=1, padding='same')(img_lr)
    c1 = PReLU()(c1)

    r = residual_block(c1)
    for _ in range(16):
        r = residual_block(r)

    c2 = Conv2D(64, kernel_size=3, strides=1, padding='same')(r)
    c2 = BatchNormalization(momentum=0.8)(c2)
    c2 = Add()([c2, c1])

    u1 = UpSampling2D(size=2)(c2)
    u1 = Conv2D(256, kernel_size=3, strides=1, padding='same')(u1)
    u1 = PReLU()(u1)

    u2 = UpSampling2D(size=2)(u1)
    u2 = Conv2D(256, kernel_size=3, strides=1, padding='same')(u2)
    u2 = PReLU()(u2)

    gen_hr = Conv2D(3, kernel_size=9, strides=1, padding='same', activation='tanh')(u2)

    return Model(img_lr, gen_hr)

# Define the discriminator
def build_discriminator():
    def d_block(layer_input, filters, strides=1, bn=True):
        d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)
        d = LeakyReLU(alpha=0.2)(d)
        if bn:
            d = BatchNormalization(momentum=0.8)(d)
        return d

    d0 = Input(shape=(None, None, 3))

    d1 = d_block(d0, 64, bn=False)
    d2 = d_block(d1, 64, strides=2)
    d3 = d_block(d2, 128)
    d4 = d_block(d3, 128, strides=2)
    d5 = d_block(d4, 256)
    d6 = d_block(d5, 256, strides=2)
    d7 = d_block(d6, 512)
    d8 = d_block(d7, 512, strides=2)

    d9 = Dense(1024)(d8)
    d10 = LeakyReLU(alpha=0.2)(d9)
    validity = Dense(1, activation='sigmoid')(d10)

    return Model(d0, validity)

# Define the SRGAN model
def build_srgan(generator, discriminator):
    discriminator.trainable = False
    img_lr = Input(shape=(None, None, 3))
    gen_hr = generator(img_lr)
    validity = discriminator(gen_hr)
    return Model(img_lr, [gen_hr, validity])

# Compile the models
generator = build_generator()
discriminator = build_discriminator()
srgan = build_srgan(generator, discriminator)

discriminator.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5), metrics=['accuracy'])
srgan.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1e-3, 1], optimizer=Adam(learning_rate=0.0002, beta_1=0.5))

# Training loop
def train(epochs, batch_size=1, save_interval=50):
    for epoch in range(epochs):
        # Select a random batch of images
        idx = np.random.randint(0, X_train.shape[0], batch_size)
        imgs_lr = X_train[idx]
        imgs_hr = y_train[idx]

        # Generate a batch of high-resolution images
        gen_hr = generator.predict(imgs_lr)

        # Train the discriminator
        valid = np.ones((batch_size, 16, 16, 1))
        fake = np.zeros((batch_size, 16, 16, 1))

        d_loss_real = discriminator.train_on_batch(imgs_hr, valid)
        d_loss_fake = discriminator.train_on_batch(gen_hr, fake)
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

        # Train the generator
        g_loss = srgan.train_on_batch(imgs_lr, [imgs_hr, valid])

        # Print the progress
        print(f"{epoch} [D loss: {d_loss[0]}, acc: {100 * d_loss[1]}] [G loss: {g_loss[0]}]")

        # Save generated images
        if epoch % save_interval == 0:
            save_imgs(epoch)

def save_imgs(epoch):
    r, c = 2, 2
    imgs_lr = X_test[:r*c]
    imgs_hr = y_test[:r*c]
    gen_hr = generator.predict(imgs_lr)

    gen_hr = 0.5 * gen_hr + 0.5
    imgs_hr = 0.5 * imgs_hr + 0.5
    imgs_lr = 0.5 * imgs_lr + 0.5

    fig, axs = plt.subplots(r, c)
    cnt = 0
    for i in range(r):
        for j in range(c):
            axs[i, j].imshow(imgs_lr[cnt])
            axs[i, j].axis('off')
            cnt += 1
    fig.savefig(f"images/lr_{epoch}.png")
    plt.close()

    fig, axs = plt.subplots(r, c)
    cnt = 0
    for i in range(r):
        for j in range(c):
            axs[i, j].imshow(gen_hr[cnt])
            axs[i, j].axis('off')
            cnt += 1
    fig.savefig(f"images/gen_{epoch}.png")
    plt.close()

    fig, axs = plt.subplots(r, c)
    cnt = 0
    for i in range(r):
        for j in range(c):
            axs[i, j].imshow(imgs_hr[cnt])
            axs[i, j].axis('off')
            cnt += 1
    fig.savefig(f"images/hr_{epoch}.png")
    plt.close()

# Train the SRGAN
train(epochs=30000, batch_size=1, save_interval=500)

# Save the generator model
generator.save("srgan_generator.h5")
```
------------------------------------- 5
```python
import os
import numpy as np
import matplotlib.pyplot as plt
import glob
import random
from PIL import Image
import tensorflow as tf
from tensorflow.keras.layers import *
from tensorflow.keras.models import Model
from tensorflow.keras.losses import mean_squared_error
from tensorflow.keras.optimizers import Adam

# Function to load and preprocess images
def load_image(img_path, size=(256, 256)):
    img = tf.io.read_file(img_path)
    img = tf.io.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, size=size, antialias=True)
    img = img / 255.0
    return img

# Function to split data into training and validation sets
def data_path(noisy_img_path, denoised_img_path):
    train_img = []
    val_img = []

    noisy_img = glob.glob(noisy_img_path + '/*.jpg')
    n = len(noisy_img)
    random.shuffle(noisy_img)
    train_keys = noisy_img[:int(0.9*n)]
    val_keys = noisy_img[int(0.9*n):]
    
    split_dict = {}
    for key in train_keys:
        split_dict[key] = 'train'
    for key in val_keys:
        split_dict[key] = 'val'

    denoised_img = glob.glob(denoised_img_path + '/*.jpg')
    for img in denoised_img:
        img_name = img.split('/')[-1]
        noisy_path = noisy_img_path + '/' + img_name
        if (split_dict[noisy_path] == 'train'):
            train_img.append([img, noisy_path])
        else:
            val_img.append([img, noisy_path])
            
    return train_img, val_img

# Function to create TensorFlow Dataset
def dataloader(train_data, val_data, batch_size):
    train_data_denoised = tf.data.Dataset.from_tensor_slices([img[0] for img in train_data]).map(lambda x: load_image(x))
    train_data_noisy = tf.data.Dataset.from_tensor_slices([img[1] for img in train_data]).map(lambda x: load_image(x))
    train = tf.data.Dataset.zip((train_data_noisy, train_data_denoised)).shuffle(buffer_size=100, reshuffle_each_iteration=True).batch(batch_size)
    
    val_data_denoised = tf.data.Dataset.from_tensor_slices([img[0] for img in val_data]).map(lambda x: load_image(x))
    val_data_noisy = tf.data.Dataset.from_tensor_slices([img[1] for img in val_data]).map(lambda x: load_image(x))
    val = tf.data.Dataset.zip((val_data_noisy, val_data_denoised)).shuffle(buffer_size=100, reshuffle_each_iteration=True).batch(batch_size)
    
    return train, val

# Function to display images
def display_img(model, noisy_img, denoised_img):
    denoised_img_pred = model(noisy_img, training=True)
    plt.figure(figsize=(15, 12))
    
    display_list = [noisy_img[0], denoised_img[0], denoised_img_pred[0]]
    title = ['Noisy Image', 'Ground Truth', 'Denoised Image']
    
    for i in range(3):
        plt.subplot(1, 3, i+1)
        plt.title(title[i])
        plt.imshow(display_list[i])
        plt.axis('off')
        
    plt.show()

# U-Net model for image denoising
def unet_model(input_size=(256, 256, 3)):
    inputs = Input(input_size)
    
    # Encoder
    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)
    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    
    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)
    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    
    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)
    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    
    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)
    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)
    drop4 = Dropout(0.5)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)
    
    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)
    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)
    drop5 = Dropout(0.5)(conv5)
    
    # Decoder
    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(drop5))
    merge6 = concatenate([drop4, up6], axis=3)
    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)
    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)
    
    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv6))
    merge7 = concatenate([conv3, up7], axis=3)
    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)
    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)
    
    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv7))
    merge8 = concatenate([conv2, up8], axis=3)
    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)
    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)
    
    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv8))
    merge9 = concatenate([conv1, up9], axis=3)
    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)
    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)
    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)
    
    conv10 = Conv2D(3, 1, activation='sigmoid')(conv9)
    
    return Model(inputs=inputs, outputs=conv10)

# Training parameters
epochs = 10
batch_size = 8

# Load data
train_data, val_data = data_path(noisy_img_path='../input/noisy_images', denoised_img_path='../input/denoised_images')
train, val = dataloader(train_data, val_data, batch_size)

# Initialize model and optimizer
optimizer = Adam(learning_rate=1e-4)
model = unet_model()

# Training and validation function
def train_model(epochs, train, val, model, optimizer):
    train_loss_tracker = tf.keras.metrics.MeanSquaredError(name="train loss")
    val_loss_tracker = tf.keras.metrics.MeanSquaredError(name="val loss")
    
    for epoch in range(epochs):
        print("\nStart of epoch %d" % (epoch,), end=' ')
        start_time_epoch = time.time()
        
        # Training loop
        for step, (train_batch_noisy, train_batch_denoised) in enumerate(train):
            with tf.GradientTape() as tape:
                train_logits = model(train_batch_noisy, training=True)
                loss = mean_squared_error(train_batch_denoised, train_logits)
            
            grads = tape.gradient(loss, model.trainable_weights)
            optimizer.apply_gradients(zip(grads, model.trainable_weights))
            
            train_loss_tracker.update_state(train_batch_denoised, train_logits)
            if step == 0:
                print('[', end='')
            if step % 64 == 0:
                print('=', end='')
        
        print(']', end='')
        print('  -  ', end='')
        print('Training Loss: %.4f' % (train_loss_tracker.result()), end='')
        
        # Validation loop
        for step, (val_batch_noisy, val_batch_denoised) in enumerate(val):
            val_logits = model(val_batch_noisy, training=False)
            val_loss_tracker.update_state(val_batch_denoised, val_logits)
            
            if step % 32 == 0:
                display_img(model, val_batch_noisy, val_batch_denoised)
        
        print('  -  ', end='')
        print('Validation Loss: %.4f' % (val_loss_tracker.result()), end='')
        print('  -  ', end=' ')
        print("Time taken: %.2fs" % (time.time() - start_time_epoch))
        
        model.save('trained_model')
        train_loss_tracker.reset_states()
        val_loss_tracker.reset_states()

# Train the model
train_model(epochs, train, val, model, optimizer)

# Evaluation function
def evaluate(model, test_img_path):
    test_img = glob.glob(test_img_path + '/*.jpg')
    random.shuffle(test_img)
    
    for img in test_img:
        img = tf.io.read_file(img)
        img = tf.io.decode_jpeg(img, channels=3)
        img = tf.image.resize(img, size=(256, 256), antialias=True)
        img = img / 255.0
        img = tf.expand_dims(img, axis=0)
        
        denoised_img = model(img, training=False)
        
        plt.figure(figsize=(15, 12))
        display_list = [img[0], denoised_img[0]]
        title = ['Noisy Image', 'Denoised Image']
        
        for i in range(2):
            plt.subplot(1, 2, i+1)
            plt.title(title[i])
            plt.imshow(display_list[i])
            plt.axis('off')
        
        plt.show()

# Load the trained model and evaluate
test_model = tf.keras.models.load_model('trained_model', compile=False)
evaluate(test_model, '../input/test_noisy_images')
```
------------------------------------- 6
```python
import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Dropout, LeakyReLU, ReLU, Concatenate, BatchNormalization
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import MeanSquaredError
import matplotlib.pyplot as plt

# Define the image size
IMAGE_SIZE = [256, 256]

# Function to load and preprocess images
def load_image(image_path):
    image = tf.io.read_file(image_path)
    image = tf.image.decode_png(image, channels=3)
    image = tf.image.resize(image, IMAGE_SIZE)
    image = (tf.cast(image, tf.float32) / 127.5) - 1  # Normalize to [-1, 1]
    return image

# Function to load dataset
def load_dataset(hazy_dir, clear_dir):
    hazy_images = sorted([os.path.join(hazy_dir, img) for img in os.listdir(hazy_dir)])
    clear_images = sorted([os.path.join(clear_dir, img) for img in os.listdir(clear_dir)])
    dataset = tf.data.Dataset.from_tensor_slices((hazy_images, clear_images))
    dataset = dataset.map(lambda x, y: (load_image(x), load_image(y)), num_parallel_calls=tf.data.experimental.AUTOTUNE)
    dataset = dataset.shuffle(buffer_size=100).batch(1)
    return dataset

# Define the generator model
def build_generator():
    def conv_block(filters, kernel_size, strides=2, activation=LeakyReLU(0.2)):
        return keras.Sequential([
            Conv2D(filters, kernel_size, strides=strides, padding='same', use_bias=False),
            BatchNormalization(),
            activation
        ])

    def deconv_block(filters, kernel_size, strides=2, activation=ReLU()):
        return keras.Sequential([
            Conv2DTranspose(filters, kernel_size, strides=strides, padding='same', use_bias=False),
            BatchNormalization(),
            activation
        ])

    inputs = Input(shape=[*IMAGE_SIZE, 3])
    x = conv_block(64, 4)(inputs)
    x = conv_block(128, 4)(x)
    x = conv_block(256, 4)(x)
    x = conv_block(512, 4)(x)
    x = conv_block(512, 4)(x)
    x = conv_block(512, 4)(x)
    x = conv_block(512, 4)(x)
    x = conv_block(512, 4)(x)

    x = deconv_block(512, 4)(x)
    x = deconv_block(512, 4)(x)
    x = deconv_block(512, 4)(x)
    x = deconv_block(512, 4)(x)
    x = deconv_block(256, 4)(x)
    x = deconv_block(128, 4)(x)
    x = deconv_block(64, 4)(x)

    outputs = Conv2DTranspose(3, 4, strides=2, padding='same', activation='tanh')(x)

    return Model(inputs, outputs)

# Define the loss function
def dehaze_loss(y_true, y_pred):
    return MeanSquaredError()(y_true, y_pred)

# Load the dataset
train_dataset = load_dataset('/path/to/hazy/images', '/path/to/clear/images')

# Build the generator
generator = build_generator()

# Compile the model
generator.compile(optimizer=Adam(learning_rate=2e-4, beta_1=0.5), loss=dehaze_loss)

# Train the model
generator.fit(train_dataset, epochs=50)

# Function to visualize results
def visualize_results(generator, dataset, num_samples=5):
    for hazy, clear in dataset.take(num_samples):
        generated = generator(hazy, training=False)[0].numpy()
        generated = (generated * 127.5 + 127.5).astype(np.uint8)
        hazy = (hazy[0] * 127.5 + 127.5).numpy().astype(np.uint8)
        clear = (clear[0] * 127.5 + 127.5).numpy().astype(np.uint8)

        plt.figure(figsize=(15, 5))
        plt.subplot(1, 3, 1)
        plt.title('Hazy Image')
        plt.imshow(hazy)
        plt.axis('off')

        plt.subplot(1, 3, 2)
        plt.title('Generated Clear Image')
        plt.imshow(generated)
        plt.axis('off')

        plt.subplot(1, 3, 3)
        plt.title('Clear Image')
        plt.imshow(clear)
        plt.axis('off')

        plt.show()

# Visualize the results
visualize_results(generator, train_dataset)
```
------------------------------------- 7
```python
# Importing Relevant Libraries
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, BatchNormalization, Activation, Concatenate, LeakyReLU
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
import numpy as np
import matplotlib.pyplot as plt

# Define the Generator and Discriminator models
def build_generator(input_shape):
    """Builds a generator model using U-Net architecture."""
    def conv_block(x, filters, kernel_size=4, strides=2, padding='same', use_bn=True):
        x = Conv2D(filters, kernel_size, strides=strides, padding=padding)(x)
        if use_bn:
            x = BatchNormalization()(x)
        x = LeakyReLU(alpha=0.2)(x)
        return x

    def deconv_block(x, skip_input, filters, kernel_size=4, strides=2, padding='same', use_bn=True):
        x = Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding)(x)
        if use_bn:
            x = BatchNormalization()(x)
        x = Activation('relu')(x)
        x = Concatenate()([x, skip_input])
        return x

    inputs = Input(shape=input_shape)
    
    # Encoder
    e1 = conv_block(inputs, 64, use_bn=False)
    e2 = conv_block(e1, 128)
    e3 = conv_block(e2, 256)
    e4 = conv_block(e3, 512)
    e5 = conv_block(e4, 512)
    e6 = conv_block(e5, 512)
    e7 = conv_block(e6, 512)
    
    # Bottleneck
    b = conv_block(e7, 512, strides=1)
    
    # Decoder
    d1 = deconv_block(b, e7, 512)
    d2 = deconv_block(d1, e6, 512)
    d3 = deconv_block(d2, e5, 512)
    d4 = deconv_block(d3, e4, 512)
    d5 = deconv_block(d4, e3, 256)
    d6 = deconv_block(d5, e2, 128)
    d7 = deconv_block(d6, e1, 64)
    
    outputs = Conv2DTranspose(3, kernel_size=4, strides=2, padding='same', activation='tanh')(d7)
    
    return Model(inputs, outputs, name="Generator")

def build_discriminator(input_shape):
    """Builds a discriminator model using PatchGAN architecture."""
    def d_layer(x, filters, kernel_size=4, strides=2, padding='same', use_bn=True):
        x = Conv2D(filters, kernel_size, strides=strides, padding=padding)(x)
        if use_bn:
            x = BatchNormalization()(x)
        x = LeakyReLU(alpha=0.2)(x)
        return x

    inputs = Input(shape=input_shape)
    
    x = d_layer(inputs, 64, use_bn=False)
    x = d_layer(x, 128)
    x = d_layer(x, 256)
    x = d_layer(x, 512, strides=1)
    
    outputs = Conv2D(1, kernel_size=4, strides=1, padding='same')(x)
    
    return Model(inputs, outputs, name="Discriminator")

# Define the CycleGAN model
class CycleGAN:
    def __init__(self, img_shape):
        self.img_shape = img_shape
        self.lambda_cycle = 10.0
        
        # Build and compile the discriminators
        self.d_A = build_discriminator(img_shape)
        self.d_B = build_discriminator(img_shape)
        self.d_A.compile(loss='mse', optimizer=Adam(learning_rate=0.0002, beta_1=0.5), metrics=['accuracy'])
        self.d_B.compile(loss='mse', optimizer=Adam(learning_rate=0.0002, beta_1=0.5), metrics=['accuracy'])
        
        # Build the generators
        self.g_AB = build_generator(img_shape)
        self.g_BA = build_generator(img_shape)
        
        # Input images from both domains
        img_A = Input(shape=img_shape)
        img_B = Input(shape=img_shape)
        
        # Translate images to the other domain
        fake_B = self.g_AB(img_A)
        fake_A = self.g_BA(img_B)
        
        # Translate images back to original domain
        reconstr_A = self.g_BA(fake_B)
        reconstr_B = self.g_AB(fake_A)
        
        # Identity mapping of images
        img_A_id = self.g_BA(img_A)
        img_B_id = self.g_AB(img_B)
        
        # For the combined model we will only train the generators
        self.d_A.trainable = False
        self.d_B.trainable = False
        
        # Discriminators determine validity of translated images
        valid_A = self.d_A(fake_A)
        valid_B = self.d_B(fake_B)
        
        # Combined model trains generators to fool discriminators
        self.combined = Model(inputs=[img_A, img_B], outputs=[valid_A, valid_B, reconstr_A, reconstr_B, img_A_id, img_B_id])
        self.combined.compile(loss=['mse', 'mse', 'mae', 'mae', 'mae', 'mae'],
                              loss_weights=[1, 1, self.lambda_cycle, self.lambda_cycle, self.lambda_cycle, self.lambda_cycle],
                              optimizer=Adam(learning_rate=0.0002, beta_1=0.5))

    def train(self, data_A, data_B, epochs, batch_size=1, sample_interval=50):
        valid = np.ones((batch_size,) + self.d_A.output_shape[1:])
        fake = np.zeros((batch_size,) + self.d_A.output_shape[1:])
        
        for epoch in range(epochs):
            for batch_i, (imgs_A, imgs_B) in enumerate(zip(data_A, data_B)):
                # Translate images to opposite domain
                fake_B = self.g_AB.predict(imgs_A)
                fake_A = self.g_BA.predict(imgs_B)
                
                # Train discriminators
                dA_loss_real = self.d_A.train_on_batch(imgs_A, valid)
                dA_loss_fake = self.d_A.train_on_batch(fake_A, fake)
                dA_loss = 0.5 * np.add(dA_loss_real, dA_loss_fake)
                
                dB_loss_real = self.d_B.train_on_batch(imgs_B, valid)
                dB_loss_fake = self.d_B.train_on_batch(fake_B, fake)
                dB_loss = 0.5 * np.add(dB_loss_real, dB_loss_fake)
                
                # Total discriminator loss
                d_loss = 0.5 * np.add(dA_loss, dB_loss)
                
                # Train generators
                g_loss = self.combined.train_on_batch([imgs_A, imgs_B], [valid, valid, imgs_A, imgs_B, imgs_A, imgs_B])
                
                # Plot the progress
                if batch_i % sample_interval == 0:
                    print(f"Epoch {epoch}/{epochs} Batch {batch_i}/{len(data_A)} [D loss: {d_loss[0]}, acc: {100*d_loss[1]}] [G loss: {g_loss[0]}]")
                    self.sample_images(epoch, batch_i)

    def sample_images(self, epoch, batch_i):
        r, c = 2, 3
        imgs_A = next(iter(data_A))
        imgs_B = next(iter(data_B))
        
        fake_B = self.g_AB.predict(imgs_A)
        fake_A = self.g_BA.predict(imgs_B)
        
        gen_imgs = np.concatenate([imgs_A, fake_B, imgs_B, fake_A])
        gen_imgs = 0.5 * gen_imgs + 0.5
        
        titles = ['Original', 'Translated', 'Reconstructed']
        fig, axs = plt.subplots(r, c)
        cnt = 0
        for i in range(r):
            for j in range(c):
                axs[i, j].imshow(gen_imgs[cnt])
                axs[i, j].set_title(titles[j])
                axs[i, j].axis('off')
                cnt += 1
        fig.savefig(f"images/{epoch}_{batch_i}.png")
        plt.close()

# Load and preprocess the dataset
def load_dataset(tfrecord_path):
    def parse_tfrecord(example_proto):
        feature_description = {
            'image': tf.io.FixedLenFeature([], tf.string),
            'label': tf.io.FixedLenFeature([], tf.int64),
        }
        example = tf.io.parse_single_example(example_proto, feature_description)
        image = tf.image.decode_jpeg(example['image'], channels=3)
        image = tf.image.resize(image, [256, 256])
        image = (image - 127.5) / 127.5  # Normalize to [-1, 1]
        return image

    dataset = tf.data.TFRecordDataset(tfrecord_path)
    dataset = dataset.map(parse_tfrecord)
    dataset = dataset.shuffle(buffer_size=1000).batch(1)
    return dataset

# Load the datasets
data_A = load_dataset('path_to_monet_tfrecords')
data_B = load_dataset('path_to_photos_tfrecords')

# Initialize and train the CycleGAN model
cycle_gan = CycleGAN(img_shape=(256, 256, 3))
cycle_gan.train(data_A, data_B, epochs=200, batch_size=1, sample_interval=200)
```
------------------------------------- 8
```python
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

# Define the U-Net architecture
def build_unet(input_shape):
    inputs = Input(input_shape)

    # Encoder
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)
    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)
    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)

    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)
    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)
    drop4 = Dropout(0.5)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)

    # Bridge
    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)
    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)
    drop5 = Dropout(0.5)(conv5)

    # Decoder
    up6 = Conv2D(512, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop5))
    merge6 = concatenate([drop4, up6], axis=3)
    conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)
    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)

    up7 = Conv2D(256, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv6))
    merge7 = concatenate([conv3, up7], axis=3)
    conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)
    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)

    up8 = Conv2D(128, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv7))
    merge8 = concatenate([conv2, up8], axis=3)
    conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)
    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)

    up9 = Conv2D(64, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv8))
    merge9 = concatenate([conv1, up9], axis=3)
    conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)
    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)

    # Output layer
    outputs = Conv2D(2, 1, activation='sigmoid')(conv9)

    model = Model(inputs=inputs, outputs=outputs)
    return model

# Load and preprocess the dataset
class DataLoader:
    def __init__(self, dataset):
        self.dataset = dataset

    def load_data(self, batch_size=1, is_testing=False):
        data_type = "train" if not is_testing else "test"
        images = self.dataset[data_type]
        indices = np.random.choice(len(images), batch_size)
        batch_images = images[indices]
        return batch_images[:, :, :, :20], batch_images[:, :, :, 20:]

# Example usage
# Assuming dataset is a numpy array with shape (25000, 64, 64, 22)
dataset = np.random.rand(25000, 64, 64, 22)
data_loader = DataLoader(dataset)

# Build the U-Net model
input_shape = (64, 64, 20)
unet = build_unet(input_shape)
unet.compile(optimizer=Adam(learning_rate=1e-4), loss='mean_squared_error')

# Train the model
train_input, train_target = data_loader.load_data(batch_size=32, is_testing=False)
val_input, val_target = data_loader.load_data(batch_size=32, is_testing=True)
history = unet.fit(train_input, train_target, validation_data=(val_input, val_target), epochs=50, batch_size=32)

# Plot the training and validation loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Save the model
unet.save('unet_model.h5')

# Example of using the model to predict
test_input, _ = data_loader.load_data(batch_size=1, is_testing=True)
predicted_output = unet.predict(test_input)

# Display the input and predicted output
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(test_input[0, :, :, 0], cmap='gray')
plt.title('Input Image')
plt.subplot(1, 2, 2)
plt.imshow(predicted_output[0, :, :, 0], cmap='gray')
plt.title('Predicted Output')
plt.show()
```
------------------------------------- 9
```python
import numpy as np
import pandas as pd
import os
import json
import tensorflow as tf
from tensorflow.keras.layers import LSTM, Bidirectional, Dropout, Embedding, Dense, Input, Conv2D, MaxPooling2D, Flatten
from tensorflow.keras.models import Model
from tqdm.notebook import tqdm
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings("ignore")

# Load the dataset
def load_flickr8k_data(image_dir, caption_file):
    # Load captions
    with open(caption_file, 'r') as f:
        captions = f.readlines()
    
    # Create a dictionary to store image paths and their corresponding captions
    data = {}
    for line in captions:
        parts = line.strip().split('\t')
        image_id = parts[0].split('#')[0]
        caption = parts[1]
        if image_id not in data:
            data[image_id] = []
        data[image_id].append(caption)
    
    # Create a list of tuples (image_path, caption)
    image_captions = []
    for image_id, captions in data.items():
        image_path = os.path.join(image_dir, image_id)
        for caption in captions:
            image_captions.append((image_path, caption))
    
    return image_captions

# Preprocess images
def preprocess_image(image_path, target_size=(224, 224)):
    img = tf.keras.preprocessing.image.load_img(image_path, target_size=target_size)
    img = tf.keras.preprocessing.image.img_to_array(img)
    img = tf.keras.applications.vgg16.preprocess_input(img)
    return img

# Preprocess captions
def preprocess_caption(caption, max_length):
    caption = caption.lower()
    caption = caption.replace('.', '').replace(',', '').replace('!', '').replace('?', '').replace('"', '')
    caption = caption.split()
    caption = ['<start>'] + caption + ['<end>']
    if len(caption) > max_length:
        caption = caption[:max_length]
    else:
        caption += ['<pad>'] * (max_length - len(caption))
    return caption

# Create vocabulary
def create_vocabulary(captions):
    word_counts = {}
    for _, caption in captions:
        for word in caption.split():
            if word not in word_counts:
                word_counts[word] = 0
            word_counts[word] += 1
    vocabulary = ['<pad>', '<start>', '<end>', '<unk>'] + [word for word in word_counts if word_counts[word] > 1]
    word_to_index = {word: idx for idx, word in enumerate(vocabulary)}
    index_to_word = {idx: word for idx, word in enumerate(vocabulary)}
    return word_to_index, index_to_word

# Data generator
def data_generator(image_captions, word_to_index, max_length, batch_size):
    while True:
        np.random.shuffle(image_captions)
        for start in range(0, len(image_captions), batch_size):
            batch_images = []
            batch_captions = []
            for image_path, caption in image_captions[start:start + batch_size]:
                img = preprocess_image(image_path)
                cap = preprocess_caption(caption, max_length)
                cap = [word_to_index[word] if word in word_to_index else word_to_index['<unk>'] for word in cap]
                batch_images.append(img)
                batch_captions.append(cap)
            yield np.array(batch_images), np.array(batch_captions)

# Load and preprocess data
image_dir = 'path_to_flickr8k_images'
caption_file = 'path_to_flickr8k_captions.txt'
image_captions = load_flickr8k_data(image_dir, caption_file)
word_to_index, index_to_word = create_vocabulary(image_captions)

# Split data into training and validation sets
train_captions, val_captions = train_test_split(image_captions, test_size=0.2, random_state=42)

# Model parameters
max_length = 40
vocab_size = len(word_to_index)
embedding_dim = 256
units = 512
batch_size = 32

# Encoder (CNN)
encoder_inputs = Input(shape=(224, 224, 3))
x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoder_inputs)
x = MaxPooling2D((2, 2), padding='same')(x)
x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)
x = MaxPooling2D((2, 2), padding='same')(x)
x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)
x = MaxPooling2D((2, 2), padding='same')(x)
x = Flatten()(x)
encoder_outputs = Dense(units, activation='relu')(x)

# Decoder (LSTM)
decoder_inputs = Input(shape=(max_length,))
embedding = Embedding(vocab_size, embedding_dim)(decoder_inputs)
lstm_out, state_h, state_c = LSTM(units, return_sequences=True, return_state=True)(embedding, initial_state=[encoder_outputs, encoder_outputs])
decoder_outputs = Dense(vocab_size, activation='softmax')(lstm_out)

# Model
model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_outputs)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.summary()

# Training
train_generator = data_generator(train_captions, word_to_index, max_length, batch_size)
val_generator = data_generator(val_captions, word_to_index, max_length, batch_size)

epochs = 10
steps_per_epoch = len(train_captions) // batch_size
validation_steps = len(val_captions) // batch_size

model.fit(train_generator, epochs=epochs, steps_per_epoch=steps_per_epoch, validation_data=val_generator, validation_steps=validation_steps)

# Inference
def generate_caption(image_path, model, word_to_index, index_to_word, max_length):
    image = preprocess_image(image_path)
    image = np.expand_dims(image, axis=0)
    initial_state = model.layers[6].predict(image)
    caption = ['<start>']
    for _ in range(max_length):
        sequence = [word_to_index[word] for word in caption]
        sequence = np.array(sequence)
        sequence = np.expand_dims(sequence, axis=0)
        preds = model.predict([image, sequence], verbose=0)
        pred_word_index = np.argmax(preds[0, -1, :])
        pred_word = index_to_word[pred_word_index]
        if pred_word == '<end>':
            break
        caption.append(pred_word)
    return ' '.join(caption[1:])

# Example usage
image_path = 'path_to_test_image.jpg'
caption = generate_caption(image_path, model, word_to_index, index_to_word, max_length)
print(caption)
```
------------------------------------- 10
```python
import numpy as np
import pandas as pd
import os
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Dropout, Concatenate, Reshape
from tensorflow.keras.callbacks import EarlyStopping

# Load the dataset
train_df = pd.read_csv("path_to_train_dataset.csv")
test_df = pd.read_csv("path_to_test_dataset.csv")

# Tokenize the text data
tokenizer = Tokenizer(filters="")
tokenizer.fit_on_texts(train_df["phrases"].values)
voc_size = len(tokenizer.word_index) + 1
seq_max = 512
batch_size = 64

# Custom Data Generator
class CustomDataGenerator(tf.keras.utils.Sequence):
    def __init__(self, df, batch_size, tokenizer, vocab_size, max_length, shuffle=True):
        self.df = df.copy()
        self.batch_size = batch_size
        self.tokenizer = tokenizer
        self.vocab_size = vocab_size
        self.max_length = max_length
        self.shuffle = shuffle
        self.n = len(self.df)

    def on_epoch_end(self):
        if self.shuffle:
            self.df = self.df.sample(frac=1).reset_index(drop=True)

    def __len__(self):
        return self.n // self.batch_size

    def __getitem__(self, index):
        batch = self.df.iloc[index * self.batch_size:(index + 1) * self.batch_size, :]
        X1, X2, y = self.__get_data(batch)
        return (X1, X2), y

    def __get_data(self, batch):
        X1, X2, y = list(), list(), list()

        keypoints = batch['keypoints'].tolist()
        phrases = batch['phrases'].tolist()

        for keypoint, phrase in zip(keypoints, phrases):
            keypoint = np.array(eval(keypoint))  # Convert string representation of list to actual list
            seq = self.tokenizer.texts_to_sequences([phrase])[0]

            for i in range(1, len(seq)):
                in_seq, out_seq = seq[:i], seq[i]
                in_seq = pad_sequences([in_seq], maxlen=self.max_length)[0]
                out_seq = tf.keras.utils.to_categorical([out_seq], num_classes=self.vocab_size)[0]
                X1.append(keypoint)
                X2.append(in_seq)
                y.append(out_seq)

        X1, X2, y = np.array(X1), np.array(X2), np.array(y)
        return X1, X2, y

# Initialize Data Generators
train_generator = CustomDataGenerator(df=train_df, batch_size=batch_size, tokenizer=tokenizer, vocab_size=voc_size, max_length=seq_max)
test_generator = CustomDataGenerator(df=test_df, batch_size=batch_size, tokenizer=tokenizer, vocab_size=voc_size, max_length=seq_max)

# Model Architecture
input1 = Input(shape=(21, 2))  # Assuming 21 keypoints with 2 coordinates each
input2 = Input(shape=(seq_max,))

keypoint_features = LSTM(256, dropout=0.1)(input1)
sentence_features = Embedding(voc_size, 256, mask_zero=False)(input2)
sentence_features = LSTM(256, dropout=0.1)(sentence_features)

merged = Concatenate()([keypoint_features, sentence_features])
merged = Dense(256, activation='relu')(merged)
merged = Dropout(0.5)(merged)
output = Dense(voc_size, activation='softmax')(merged)

model = Model(inputs=[input1, input2], outputs=output)
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Model Training
model.fit(train_generator, epochs=10, validation_data=test_generator, callbacks=[EarlyStopping(monitor='val_loss', patience=3)])

# Save the model
model.save("asl_fingerspelling_model.h5")

# Function to predict phrases from keypoints
def predict_phrase(model, keypoints, tokenizer, max_length):
    keypoints = np.array([keypoints])
    in_text = 'sos'
    for i in range(max_length):
        sequence = tokenizer.texts_to_sequences([in_text])[0]
        sequence = pad_sequences([sequence], maxlen=max_length)
        y_pred = model.predict([keypoints, sequence])
        y_pred = np.argmax(y_pred)
        word = tokenizer.index_word[y_pred]
        if word is None or word == 'eos':
            break
        in_text += " " + word
    return in_text

# Example usage
example_keypoints = train_df.iloc[0]['keypoints']
predicted_phrase = predict_phrase(model, eval(example_keypoints), tokenizer, seq_max)
print("Predicted Phrase:", predicted_phrase)
```
------------------------------------- 11
```python
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Dense, Lambda, Bidirectional, LSTM, Embedding, Concatenate
import tensorflow.keras.backend as K
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import ModelCheckpoint
import matplotlib.pyplot as plt

# Define the character set for captions
char_list = 'abcdefghijklmnopqrstuvwxyz0123456789 '

# Load and preprocess the dataset
def load_data(image_paths, captions, max_caption_length):
    images = []
    tokenizer = Tokenizer(char_level=True)
    tokenizer.fit_on_texts(captions)
    sequences = tokenizer.texts_to_sequences(captions)
    padded_sequences = pad_sequences(sequences, maxlen=max_caption_length, padding='post')
    for path in image_paths:
        img = load_img(path, target_size=(224, 224), color_mode='rgb')
        img = img_to_array(img)
        img = img / 255.0
        images.append(img)
    return np.array(images), np.array(padded_sequences), tokenizer

# Define the model architecture
def build_model(vocab_size, max_caption_length):
    # Image feature extraction
    image_input = Input(shape=(224, 224, 3))
    conv_1 = Conv2D(64, (3, 3), activation='relu', padding='same')(image_input)
    batch_norm_1 = BatchNormalization()(conv_1)
    pool_1 = MaxPooling2D(pool_size=(2, 2), strides=2)(batch_norm_1)
    conv_2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool_1)
    batch_norm_2 = BatchNormalization()(conv_2)
    pool_2 = MaxPooling2D(pool_size=(2, 2), strides=2)(batch_norm_2)
    conv_3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool_2)
    conv_4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv_3)
    pool_4 = MaxPooling2D(pool_size=(2, 1))(conv_4)
    conv_5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool_4)
    batch_norm_5 = BatchNormalization()(conv_5)
    conv_6 = Conv2D(512, (3, 3), activation='relu', padding='same')(batch_norm_5)
    batch_norm_6 = BatchNormalization()(conv_6)
    pool_6 = MaxPooling2D(pool_size=(2, 1))(batch_norm_6)
    conv_7 = Conv2D(512, (2, 2), activation='relu')(pool_6)
    squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)
    
    # Text sequence input
    caption_input = Input(shape=(max_caption_length,))
    embedding = Embedding(vocab_size, 256, input_length=max_caption_length)(caption_input)
    
    # Concatenate image features and text sequences
    merged = Concatenate()([squeezed, embedding])
    
    # LSTM layers
    blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(merged)
    blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(blstm_1)
    
    # Output layer
    outputs = Dense(vocab_size, activation='softmax')(blstm_2)
    
    # Define the model
    model = Model(inputs=[image_input, caption_input], outputs=outputs)
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

# Load the dataset
image_paths = ['path_to_train_images/image1.jpg', 'path_to_train_images/image2.jpg', ...]
captions = ['caption for image1', 'caption for image2', ...]
max_caption_length = 20
images, sequences, tokenizer = load_data(image_paths, captions, max_caption_length)
vocab_size = len(tokenizer.word_index) + 1

# Prepare the labels
labels = to_categorical(sequences, num_classes=vocab_size)

# Build the model
model = build_model(vocab_size, max_caption_length)

# Define callbacks
checkpoint = ModelCheckpoint('model_weights.h5', monitor='val_loss', save_best_only=True, mode='min')

# Train the model
model.fit([images, sequences], labels, batch_size=32, epochs=10, validation_split=0.2, callbacks=[checkpoint])

# Save the model
model.save('full_model.h5')

# Load the model for inference
loaded_model = tf.keras.models.load_model('full_model.h5')

# Inference on a new image
def predict_caption(image_path, model, tokenizer, max_caption_length):
    img = load_img(image_path, target_size=(224, 224), color_mode='rgb')
    img = img_to_array(img)
    img = img / 255.0
    img = np.expand_dims(img, axis=0)
    
    # Start token
    start_token = tokenizer.texts_to_sequences(['start'])[0]
    start_token = pad_sequences([start_token], maxlen=max_caption_length, padding='post')
    
    # Predict the caption
    for i in range(max_caption_length):
        preds = model.predict([img, start_token])
        pred_word_index = np.argmax(preds[0, i, :])
        start_token[0, i+1] = pred_word_index
    
    # Convert the sequence to text
    caption_sequence = start_token[0]
    caption_text = tokenizer.sequences_to_texts([caption_sequence])[0]
    return caption_text

# Example usage
image_path = 'path_to_test_image/test_image.jpg'
predicted_caption = predict_caption(image_path, loaded_model, tokenizer, max_caption_length)
print("Predicted Caption:", predicted_caption)
```
------------------------------------- 12
```python
import os
import pickle
import numpy as np
from tqdm import tqdm
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.utils import to_categorical, plot_model
from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add

# Define directories
BASE_DIR = '/path/to/license_plate_images'
WORKING_DIR = '/path/to/working_directory'

# Load VGG16 model and restructure it
vgg_model = VGG16(weights='imagenet')
vgg_model = Model(inputs=vgg_model.inputs, outputs=vgg_model.layers[-2].output)

# Extract features from license plate images
features = {}
directory = os.path.join(BASE_DIR, 'Images')

for img_name in tqdm(os.listdir(directory)):
    img_path = os.path.join(directory, img_name)
    image = load_img(img_path, target_size=(224, 224))
    image = img_to_array(image)
    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))
    image = preprocess_input(image)
    feature = vgg_model.predict(image, verbose=0)
    image_id = img_name.split('.')[0]
    features[image_id] = feature

# Save features to a pickle file
pickle.dump(features, open(os.path.join(WORKING_DIR, 'features.pkl'), 'wb'))

# Load features from pickle
with open(os.path.join(WORKING_DIR, 'features.pkl'), 'rb') as f:
    features = pickle.load(f)

# Load captions
with open(os.path.join(BASE_DIR, 'captions.txt'), 'r') as f:
    captions_doc = f.read()

# Create mapping of image to captions
mapping = {}
for line in tqdm(captions_doc.split('\n')):
    tokens = line.split(',')
    if len(line) < 2:
        continue
    image_id, caption = tokens[0], tokens[1]
    image_id = image_id.split('.')[0]
    if image_id not in mapping:
        mapping[image_id] = []
    mapping[image_id].append(caption)

# Clean captions
def clean(mapping):
    for key, captions in mapping.items():
        for i in range(len(captions)):
            caption = captions[i].lower()
            caption = caption.replace('[^a-z]', ' ')
            caption = caption.replace('\s+', ' ')
            caption = 'startseq ' + " ".join([word for word in caption.split() if len(word) > 1]) + ' endseq'
            captions[i] = caption

clean(mapping)

# Tokenize captions
all_captions = []
for key in mapping:
    for caption in mapping[key]:
        all_captions.append(caption)

tokenizer = Tokenizer()
tokenizer.fit_on_texts(all_captions)
vocab_size = len(tokenizer.word_index) + 1

# Determine max length of captions
max_length = max(len(caption.split()) for caption in all_captions)

# Split data into training and testing
image_ids = list(mapping.keys())
split = int(len(image_ids) * 0.80)
train = image_ids[:split]
test = image_ids[split:]

# Data generator
def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size):
    X1, X2, y = list(), list(), list()
    n = 0
    while 1:
        for key in data_keys:
            n += 1
            captions = mapping[key]
            for caption in captions:
                seq = tokenizer.texts_to_sequences([caption])[0]
                for i in range(1, len(seq)):
                    in_seq, out_seq = seq[:i], seq[i]
                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]
                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]
                    X1.append(features[key][0])
                    X2.append(in_seq)
                    y.append(out_seq)
            if n == batch_size:
                X1, X2, y = np.array(X1), np.array(X2), np.array(y)
                yield [X1, X2], y
                X1, X2, y = list(), list(), list()
                n = 0

# Define the model
inputs1 = Input(shape=(4096,))
fe1 = Dropout(0.4)(inputs1)
fe2 = Dense(256, activation='relu')(fe1)
inputs2 = Input(shape=(max_length,))
se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)
se2 = Dropout(0.4)(se1)
se3 = LSTM(256)(se2)
decoder1 = add([fe2, se3])
decoder2 = Dense(256, activation='relu')(decoder1)
outputs = Dense(vocab_size, activation='softmax')(decoder2)
model = Model(inputs=[inputs1, inputs2], outputs=outputs)
model.compile(loss='categorical_crossentropy', optimizer='adam')

# Train the model
epochs = 50
batch_size = 32
steps = len(train) // batch_size

for i in range(epochs):
    generator = data_generator(train, mapping, features, tokenizer, max_length, vocab_size, batch_size)
    model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)

# Save the model
model.save(os.path.join(WORKING_DIR, 'license_plate_recognition_model.h5'))

# Function to convert index to word
def idx_to_word(integer, tokenizer):
    for word, index in tokenizer.word_index.items():
        if index == integer:
            return word
    return None

# Function to predict caption
def predict_caption(model, image, tokenizer, max_length):
    in_text = 'startseq'
    for i in range(max_length):
        sequence = tokenizer.texts_to_sequences([in_text])[0]
        sequence = pad_sequences([sequence], max_length)
        yhat = model.predict([image, sequence], verbose=0)
        yhat = np.argmax(yhat)
        word = idx_to_word(yhat, tokenizer)
        if word is None:
            break
        in_text += " " + word
        if word == 'endseq':
            break
    return in_text

# Evaluate the model
actual, predicted = list(), list()
for key in tqdm(test):
    captions = mapping[key]
    y_pred = predict_caption(model, features[key], tokenizer, max_length)
    actual_captions = [caption.split() for caption in captions]
    y_pred = y_pred.split()
    actual.append(actual_captions)
    predicted.append(y_pred)

# Calculate BLEU score
from nltk.translate.bleu_score import corpus_bleu
print("BLEU-1: %f" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))
print("BLEU-2: %f" % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))

# Function to generate caption for a given image
from PIL import Image
import matplotlib.pyplot as plt
def generate_caption(image_name):
    image_id = image_name.split('.')[0]
    img_path = os.path.join(BASE_DIR, "Images", image_name)
    image = Image.open(img_path)
    captions = mapping[image_id]
    print('---------------------Actual---------------------')
    for caption in captions:
        print(caption)
    y_pred = predict_caption(model, features[image_id], tokenizer, max_length)
    print('--------------------Predicted--------------------')
    print(y_pred)
    plt.imshow(image)
    plt.show()

# Example usage
generate_caption("example_license_plate_image.jpg")
```
------------------------------------- 13
```python
import os
import pickle
import numpy as np
from tqdm import tqdm
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.utils import to_categorical, plot_model
from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add
from tensorflow.keras.optimizers import Adam
import re
from PIL import Image
import matplotlib.pyplot as plt
from tensorflow.keras.callbacks import ModelCheckpoint

# Define directories
BASE_DIR = '/path/to/dataset'
WORKING_DIR = '/path/to/working/directory'

# Load VGG16 model and restructure it
vgg_model = VGG16()
vgg_model = Model(inputs=vgg_model.inputs, outputs=vgg_model.layers[-2].output)

# Function to extract features from images
def extract_features(directory):
    features = {}
    for img_name in tqdm(os.listdir(directory)):
        img_path = os.path.join(directory, img_name)
        image = load_img(img_path, target_size=(224, 224))
        image = img_to_array(image)
        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))
        image = preprocess_input(image)
        feature = vgg_model.predict(image, verbose=0)
        image_id = img_name.split('.')[0]
        features[image_id] = feature
    return features

# Extract features from the dataset
image_directory = os.path.join(BASE_DIR, 'Images')
features = extract_features(image_directory)

# Save features to a pickle file
pickle.dump(features, open(os.path.join(WORKING_DIR, 'features.pkl'), 'wb'))

# Load features from the pickle file
with open(os.path.join(WORKING_DIR, 'features.pkl'), 'rb') as f:
    features = pickle.load(f)

# Load captions
with open(os.path.join(BASE_DIR, 'captions.txt'), 'r') as f:
    next(f)
    captions_doc = f.read()

# Create mapping of image to captions
mapping = {}
for line in tqdm(captions_doc.split('\n')):
    tokens = line.split(',')
    if len(line) < 2:
        continue
    image_id, caption = tokens[0], tokens[1:]
    image_id = image_id.split('.')[0]
    caption = " ".join(caption)
    if image_id not in mapping:
        mapping[image_id] = []
    mapping[image_id].append(caption)

# Clean and preprocess text
def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^a-zA-Z]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    text = 'startseq ' + text + ' endseq'
    return text

def clean(mapping):
    for key, captions in mapping.items():
        for i in range(len(captions)):
            captions[i] = clean_text(captions[i])

clean(mapping)

# Tokenize the text
all_captions = []
for key in mapping:
    for caption in mapping[key]:
        all_captions.append(caption)

tokenizer = Tokenizer()
tokenizer.fit_on_texts(all_captions)
vocab_size = len(tokenizer.word_index) + 1

# Get maximum length of the caption available
max_length = max(len(caption.split()) for caption in all_captions)

# Split data into training and testing sets
image_ids = list(mapping.keys())
split = int(len(image_ids) * 0.80)
train = image_ids[:split]
test = image_ids[split:]

# Data generator
def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size):
    X1, X2, y = list(), list(), list()
    n = 0
    while 1:
        for key in data_keys:
            n += 1
            captions = mapping[key]
            for caption in captions:
                seq = tokenizer.texts_to_sequences([caption])[0]
                for i in range(1, len(seq)):
                    in_seq, out_seq = seq[:i], seq[i]
                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]
                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]
                    X1.append(features[key][0])
                    X2.append(in_seq)
                    y.append(out_seq)
            if n == batch_size:
                X1, X2, y = np.array(X1), np.array(X2), np.array(y)
                yield [X1, X2], y
                X1, X2, y = list(), list(), list()
                n = 0

# Encoder model
inputs1 = Input(shape=(4096,))
fe1 = Dropout(0.4)(inputs1)
fe2 = Dense(256, activation='relu')(fe1)

# Sequence feature layers
inputs2 = Input(shape=(max_length,))
se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)
se2 = Dropout(0.4)(se1)
se3 = LSTM(256)(se2)

# Decoder model
decoder1 = add([fe2, se3])
decoder2 = Dense(256, activation='relu')(decoder1)
outputs = Dense(vocab_size, activation='softmax')(decoder2)

model = Model(inputs=[inputs1, inputs2], outputs=outputs)
model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])

# Plot the model
plot_model(model, show_shapes=True)

# Train the model
epochs = 30
batch_size = 64
steps = len(train) // batch_size
checkpoint_filepath = os.path.join(WORKING_DIR, 'Image_model.h5')
model_checkpoint = ModelCheckpoint(checkpoint_filepath, save_best_only=True, save_weights_only=True)

history = model.fit(
    data_generator(train, mapping, features, tokenizer, max_length, vocab_size, batch_size),
    epochs=epochs,
    steps_per_epoch=steps,
    verbose=1,
    callbacks=[model_checkpoint]
)

# Save the model
model.save(os.path.join(WORKING_DIR, 'Image_model.h5'))

# Load the best weights
model.load_weights(checkpoint_filepath)

# Function to convert index to word
def idx_to_word(integer, tokenizer):
    for word, index in tokenizer.word_index.items():
        if index == integer:
            return word
    return None

# Function to generate caption for an image
def predict_caption(model, image, tokenizer, max_length):
    in_text = 'startseq'
    for i in range(max_length):
        sequence = tokenizer.texts_to_sequences([in_text])[0]
        sequence = pad_sequences([sequence], max_length)
        yhat = model.predict([image, sequence], verbose=0)
        yhat = np.argmax(yhat)
        word = idx_to_word(yhat, tokenizer)
        if word is None:
            break
        in_text += " " + word
        if word == 'endseq':
            break
    return in_text

# Function to generate caption for a given image path
def generate_caption(image_path):
    image = load_img(image_path, target_size=(224, 224))
    image = img_to_array(image)
    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))
    image = preprocess_input(image)
    feature = vgg_model.predict(image, verbose=0)
    predicted_caption = predict_caption(model, feature, tokenizer, max_length)
    img = Image.open(image_path)
    plt.imshow(img)
    plt.title('Predicted Caption: ' + predicted_caption)
    plt.show()

# Example usage:
generate_caption("/path/to/test/image.jpg")
```
------------------------------------- 14
```python
import numpy as np
import pandas as pd
import os
import glob as gb
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, Concatenate, BatchNormalization, Activation
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler
from sklearn.model_selection import train_test_split
import nibabel as nib

# Check if a GPU is available
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))

# Load and preprocess the dataset
def load_nifti_data(path):
    img = nib.load(path).get_fdata()
    return img

def preprocess_nifti(path, target_shape=(128, 128, 64)):
    img = load_nifti_data(path)
    img = tf.image.resize(img, target_shape)
    img = tf.convert_to_tensor(img, dtype=tf.float32)
    return img

base_path = '/path/to/your/dataset/'
image_files = gb.glob(base_path + 'images/*')
label_files = gb.glob(base_path + 'labels/*')

images = np.array([preprocess_nifti(i) for i in image_files])
labels = np.array([preprocess_nifti(i) for i in label_files])

# Split the dataset into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)

# Define the 3D U-Net model
def create_3d_unet(input_shape=(128, 128, 64, 4)):
    inputs = Input(input_shape)
    
    # Encoder
    conv1 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(inputs)
    conv1 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(conv1)
    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)

    conv2 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(pool1)
    conv2 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(conv2)
    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)

    conv3 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(pool2)
    conv3 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(conv3)
    pool3 = MaxPooling3D(pool_size=(2, 2, 2))(conv3)

    conv4 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(pool3)
    conv4 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(conv4)

    # Decoder
    up5 = UpSampling3D(size=(2, 2, 2))(conv4)
    up5 = Concatenate()([up5, conv3])
    conv5 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(up5)
    conv5 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(conv5)

    up6 = UpSampling3D(size=(2, 2, 2))(conv5)
    up6 = Concatenate()([up6, conv2])
    conv6 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(up6)
    conv6 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(conv6)

    up7 = UpSampling3D(size=(2, 2, 2))(conv6)
    up7 = Concatenate()([up7, conv1])
    conv7 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(up7)
    conv7 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(conv7)

    outputs = Conv3D(4, (1, 1, 1), activation='softmax')(conv7)

    model = Model(inputs=[inputs], outputs=[outputs])
    return model

# Compile the model
model = create_3d_unet()
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Define callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)
model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)
lr_scheduler = LearningRateScheduler(lambda epoch, lr: lr * 0.9 if epoch % 10 == 0 else lr, verbose=1)

# Train the model
model.fit(x_train, y_train, batch_size=2, epochs=50, validation_data=(x_test, y_test), callbacks=[early_stopping, model_checkpoint, lr_scheduler])

# Evaluate the model
loss, accuracy = model.evaluate(x_test, y_test)
print(f'Test Loss: {loss}')
print(f'Test Accuracy: {accuracy}')
```
------------------------------------- 15
```python
# Install necessary libraries
!pip install keras==2.10
!pip install segmentation-models==1.0.1

import os
import glob
import cv2
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import tifffile
from PIL import Image
import albumentations as A
from tqdm import tqdm
from sklearn.model_selection import train_test_split

import segmentation_models as sm
from segmentation_models import Unet
from segmentation_models import get_preprocessing
from segmentation_models import metrics
from segmentation_models.metrics import iou_score
from segmentation_models import set_framework
from tensorflow.keras.layers import Conv2DTranspose, Dropout, Conv2D
from tensorflow.keras import regularizers
from keras.models import Model
from segmentation_models.utils import set_trainable
from segmentation_models import losses

sm.set_framework('tf.keras')

# Load dataset function
def load_dataset(root_dir):
    data_list = []
    label_mapping = {
        'Cercospora': 0,
        'Coffee Rust': 1,
        'Phoma': 2
    }

    for folder in ["Images", "Leaf Masks", "Biotic Stress Masks"]:
        image_folder = os.path.join(root_dir, folder)
        leaf_folder = os.path.join(root_dir, "Leaf Masks")
        stress_folder = os.path.join(root_dir, "Biotic Stress Masks")

        for image_class in os.listdir(image_folder):
            class_images = glob.glob(os.path.join(image_folder, image_class, "*.jpg"))
            for img_path in class_images:
                img_name = os.path.basename(img_path).split(".")[0]

                leaf_mask_name = img_name.replace(" ", "_") + "_leaf.ome.tiff"
                leaf_mask_path = os.path.join(leaf_folder, image_class, leaf_mask_name)

                if image_class == 'Coffee Rust':
                    stress_mask_name = img_name.replace(" ", "_") + "_rust.ome.tiff"
                else:
                    stress_mask_name = img_name.replace(" ", "_") + "_" + image_class.lower() + ".ome.tiff"
                stress_mask_path = os.path.join(stress_folder, image_class, stress_mask_name)

                data_list.append((img_path, leaf_mask_path, stress_mask_path, image_class, label_mapping[image_class]))

    return data_list, label_mapping

# Load train and test datasets
train_data, train_label_mapping = load_dataset("/kaggle/input/segmentation-v6/Segmentation Coffee Dataset/Train")
test_data, test_label_mapping = load_dataset("/kaggle/input/segmentation-v6/Segmentation Coffee Dataset/Test")

train_df = pd.DataFrame(train_data, columns=['ImagePath', 'LeafMaskPath', 'BioticStressMaskPath', 'ClassName', 'Label'])
test_df = pd.DataFrame(test_data, columns=['ImagePath', 'LeafMaskPath', 'BioticStressMaskPath', 'ClassName', 'Label'])

# Augmentation function
def augment_image_and_mask(image, mask):
    augmentations = A.Compose([
        A.Resize(height=256, width=512, p=1.0),
        A.HorizontalFlip(p=0.5),
        A.Rotate(limit=30, p=0.3),
        A.VerticalFlip(p=0.3),
    ])

    mask = mask.astype(np.uint8)

    augmented = augmentations(image=image, mask=mask)
    augmented_image = augmented['image']
    augmented_mask = augmented['mask']
    return augmented_image, augmented_mask

# Read TIFF mask function
def read_tiff_mask(mask_path):
    return tifffile.imread(mask_path)

# Load and augment training data
train_images = []
train_leaf_masks = []
train_label = []

for index, row in tqdm(train_df.iterrows(), total=len(train_df)):
    img_path = row['ImagePath']
    leaf_mask_path = row['LeafMaskPath']

    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    leaf_mask = read_tiff_mask(leaf_mask_path)

    for _ in range(3):
        augmented_image, augmented_leaf_mask = augment_image_and_mask(img, leaf_mask)

        train_images.append(augmented_image)
        train_leaf_masks.append(np.where(augmented_leaf_mask==0, 0, 1))
        train_label.append(row['Label'])

norm_train_images = np.array(train_images)
norm_train_leaf_masks = np.array(train_leaf_masks)
norm_train_label = np.array(train_label)

# Load and augment test data
test_images = []
test_leaf_masks = []
test_label = []

for index, row in tqdm(test_df.iterrows(), total=len(test_df)):
    img_path = row['ImagePath']
    leaf_mask_path = row['LeafMaskPath']

    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    leaf_mask = read_tiff_mask(leaf_mask_path)

    for _ in range(3):
        augmented_image, augmented_leaf_mask = augment_image_and_mask(img, leaf_mask)

        test_images.append(augmented_image)
        test_leaf_masks.append(np.where(augmented_leaf_mask==0, 0, 1))
        test_label.append(row['Label'])

norm_test_images = np.array(test_images)
norm_test_leaf_masks = np.array(test_leaf_masks)
norm_test_label = np.array(test_label)

# Scale images
def scale_image(data):
    return (data - np.min(data)) / (np.max(data) - np.min(data))

norm_train_images = np.array([scale_image(i) for i in norm_train_images])
norm_test_images = np.array([scale_image(i) for i in norm_test_images])

# Visualize samples
num_samples_to_visualize = 3

for i in range(num_samples_to_visualize):
    img = norm_train_images[i]
    leaf_mask = norm_train_leaf_masks[i]

    fig, axs = plt.subplots(1, 2, figsize=(8, 5))

    axs[0].imshow(img)
    axs[0].set_title('Image')

    axs[1].imshow(leaf_mask)
    axs[1].set_title('Leaf Mask')

    plt.show()

# Split data into training and validation sets
x_train, x_val, y_train, y_val = norm_train_images, norm_test_images, norm_train_leaf_masks, norm_test_leaf_masks

input_shape = (256, 512, 3)
y_train = y_train.astype(np.float32)
y_val = y_val.astype(np.float32)

# Define model
BACKBONE = 'resnet34'
preprocess_input = sm.get_preprocessing(BACKBONE)
x_train_preprocessed = preprocess_input(x_train)
x_val_preprocessed = preprocess_input(x_val)

model = sm.Unet(BACKBONE, input_shape=input_shape, encoder_weights='imagenet')

for layer in model.layers:
    if isinstance(layer, Conv2D):
        layer.kernel_regularizer = regularizers.l2(1e-4)
    if isinstance(layer, Dropout):
        layer.rate = 0.5

num_classes = 1
output = Conv2DTranspose(num_classes, (1, 1), activation='sigmoid')(model.output)

DiceLoss = losses.DiceLoss()

model = Model(inputs=model.input, outputs=output)
model.compile(optimizer='adam', loss=DiceLoss, metrics=['binary_accuracy', metrics.FScore(), iou_score])

# Train model
history = model.fit(
    x=x_train_preprocessed,
    y=y_train,
    batch_size=16,
    epochs=40,
    validation_data=(x_val_preprocessed, y_val),
)

# Save results
results_df = pd.DataFrame(history.history)
results_df.to_csv('resnet50.csv', index=False)

# Plot metrics
loss = history.history['loss']
val_loss = history.history['val_loss']
binary_accuracy = history.history['binary_accuracy']
val_binary_accuracy = history.history['val_binary_accuracy']
fscore = history.history['f1-score']
val_fscore = history.history['val_f1-score']
iou_score = history.history['iou_score']
val_iou_score = history.history['val_iou_score']

epochs = range(1, len(loss) + 1)

plt.figure(figsize=(8, 5))
plt.plot(epochs, loss, 'r', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.figure(figsize=(8, 5))
plt.plot(epochs, binary_accuracy, 'r', label='Binary Accuracy')
plt.plot(epochs, val_binary_accuracy, 'b', label='Validation Binary Accuracy')
plt.title('Binary Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.figure(figsize=(8, 5))
plt.plot(epochs, fscore, 'r', label='F1-score')
plt.plot(epochs, val_fscore, 'b', label='Validation F1-score')
plt.title('F1-score')
plt.xlabel('Epochs')
plt.ylabel('F1-score')
plt.legend()

plt.figure(figsize=(8, 5))
plt.plot(epochs, iou_score, 'r', label='IoU-score')
plt.plot(epochs, val_iou_score, 'b', label='Validation IoU-score')
plt.title('IoU-score')
plt.xlabel('Epochs')
plt.ylabel('IoU-score')
plt.legend()

plt.tight_layout()
plt.show()

# Save model
model.save('resnet50.h5')

# Load saved model
saved_model = keras.models.load_model('/kaggle/working/resnet50.h5', compile=False)

# Preprocess function
def preprocess(image_array):
    image = cv2.resize(image_array, (512, 256))
    normalized_image = image / 255.0
    return np.expand_dims(normalized_image, axis=0)

# Prediction function
def predict(image, threshold=0.7):
    preprocessed_image = preprocess(image)
    prediction = saved_model.predict(preprocessed_image)
    pred_image = np.squeeze(prediction > threshold)
    return pred_image

# Test prediction
image_path = '/kaggle/input/sample/Try/Rust(516).jpg'
image = cv2.imread(image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

predicted_image = predict(image)

plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(image)
plt.title('Original Image')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.imshow(predicted_image)
plt.title('Predicted Mask')
plt.axis('off')

plt.tight_layout()
plt.show()
```
------------------------------------- 16
```python
import os
import numpy as np
import json
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow.keras.layers as tfl
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from PIL import Image, ImageDraw
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# Set random seed for reproducibility
tf.random.set_seed(221)

# Constants
INPUT_SIZE = (1920, 1080)
IMG_SIZE = 512  # image size for the network
N = 512  # Number of images

# Paths
path = ''
image_path = os.path.join(path, '/kaggle/input/plant-disease-segmentation/images/')
mask_path = os.path.join(path, '/kaggle/input/plant-disease-segmentation/annotations/')

# Load annotations
with open('/kaggle/input/plant-disease-segmentation/annotations/instances_default.json') as f:
    annotations = json.load(f)

# Create a dictionary mapping image IDs to filenames
image_id_dict = {image['id']: image['file_name'] for image in annotations['images']}

# Load and resize images
images = np.zeros((N, IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
for img_id, img_filename in image_id_dict.items():
    img = Image.open(os.path.join(image_path, img_filename))
    img = img.resize((IMG_SIZE, IMG_SIZE))
    images[img_id - 1] = img

# Show first 9 images
fig = plt.figure(figsize=(12, 6))
for i in range(9):
    plt.subplot(3, 3, i+1)
    plt.imshow(images[i]/255)
    plt.axis('off')
fig.tight_layout()

# Load and resize masks
masks = np.zeros((N, IMG_SIZE, IMG_SIZE), dtype=bool)
for annotation in annotations['annotations']:
    img_id = annotation['image_id']
    mask = Image.new('1', INPUT_SIZE)
    mask_draw = ImageDraw.Draw(mask, '1')
    segmentation = annotation['segmentation'][0]
    mask_draw.polygon(segmentation, fill=1)
    bool_array = np.array(mask.resize((IMG_SIZE, IMG_SIZE))) > 0
    masks[img_id - 1] = masks[img_id - 1] | bool_array

masks = masks.reshape(N, IMG_SIZE, IMG_SIZE, 1)  # add channel dimension

# Show masks applied on top of the images
fig = plt.figure(figsize=(12, 6))
for i in range(9):
    plt.subplot(3, 3, i+1)
    plt.imshow(images[i]/255)
    plt.imshow(masks[i], alpha=0.5)
    plt.axis('off')
fig.tight_layout()

# Split data into training and testing sets
images_train, images_test, masks_train, masks_test = train_test_split(images, masks, test_size=0.1, random_state=42)
print(f"Train images shape: {images_train.shape}, Train masks shape: {masks_train.shape}")
print(f"Test images shape: {images_test.shape}, Test masks shape: {masks_test.shape}")

# Jaccard Index (IoU) metric
def jaccard_index(y_true, y_pred):
    y_true = tf.keras.backend.flatten(y_true)
    y_pred = tf.keras.backend.flatten(y_pred)
    intersection = tf.keras.backend.sum(y_true * y_pred)
    union = tf.keras.backend.sum(y_true) + tf.keras.backend.sum(y_pred) - intersection
    return (intersection + 1e-7) / (union + 1e-7)

# Convolution block for U-Net
def conv_block(inputs, n_filters, maxpooling=True):
    x = tfl.Conv2D(filters=n_filters, kernel_size=3, padding='same')(inputs)
    x = tfl.BatchNormalization()(x)
    x = tfl.Activation('relu')(x)
    x = tfl.Conv2D(filters=n_filters, kernel_size=3, padding='same')(x)
    x = tfl.BatchNormalization()(x)
    skip = tfl.Activation('relu')(x)
    if maxpooling:
        out = tfl.MaxPool2D(pool_size=(2, 2), strides=(2, 2))(skip)
    else:
        out = skip
    return out, skip

# Upsampling block for U-Net
def upsampling_block(expansive_input, contractive_input, n_filters):
    up = tfl.Conv2DTranspose(n_filters, kernel_size=2, strides=2, padding='same')(expansive_input)
    input = tfl.concatenate([up, contractive_input], axis=3)
    out, _ = conv_block(input, n_filters, False)
    return out

# U-Net model
def unet_model(input_size=(512, 512, 3), n_filters=64):
    inputs = tfl.Input(input_size)
    cblock1 = conv_block(inputs, n_filters)
    cblock2 = conv_block(cblock1[0], n_filters*2)
    cblock3 = conv_block(cblock2[0], n_filters*4)
    cblock4 = conv_block(cblock3[0], n_filters*8)
    cblock5 = conv_block(cblock4[0], n_filters*16, maxpooling=False)

    ublock6 = upsampling_block(cblock5[0], cblock4[1], n_filters*8)
    ublock7 = upsampling_block(ublock6, cblock3[1], n_filters*4)
    ublock8 = upsampling_block(ublock7, cblock2[1], n_filters*2)
    ublock9 = upsampling_block(ublock8, cblock1[1], n_filters)

    out = tfl.Conv2D(1, 1, padding='same', activation='sigmoid')(ublock9)
    model = tf.keras.Model(inputs=inputs, outputs=out)
    return model

# Create and compile the model
unet = unet_model()
unet.compile(optimizer=tf.keras.optimizers.Adam(),
             loss=tf.keras.losses.BinaryCrossentropy(),
             metrics=[jaccard_index, 'accuracy'])

# Train the model
unet.fit(images_train, masks_train, epochs=10, batch_size=4, validation_split=0.2)

# Evaluate the model
unet.evaluate(images_test, masks_test, batch_size=4)

# Predict masks
predicted_mask = unet.predict(images_test, batch_size=4)
predicted_mask2 = (predicted_mask > 0.5).astype(np.uint8)

# Display predicted masks
fig, ax = plt.subplots(5, 3, figsize=(12, 10))
for i in range(5):
    ax[i, 0].imshow(images_test[i])
    ax[i, 0].axis('off')
    ax[i, 1].imshow(masks_test[i])
    ax[i, 1].axis('off')
    ax[i, 2].imshow(predicted_mask2[i])
    ax[i, 2].axis('off')

ax[0, 0].set_title('Original image')
ax[0, 1].set_title('True mask')
ax[0, 2].set_title('Predicted mask')
fig.tight_layout()

# Classification report
cr = classification_report(masks_test.flatten(), predicted_mask2.flatten())
print(cr)
```
------------------------------------- 17
```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
import json
import os

# Load the dataset
def load_dataset(image_dir, mask_json):
    images = []
    masks = []
    with open(mask_json, 'r') as f:
        mask_data = json.load(f)
    
    for img_name, mask_info in mask_data.items():
        img_path = os.path.join(image_dir, img_name)
        img = tf.keras.preprocessing.image.load_img(img_path, target_size=(512, 512))
        img = tf.keras.preprocessing.image.img_to_array(img)
        images.append(img)
        
        mask = np.zeros((512, 512, 1), dtype=np.float32)
        for obj in mask_info:
            mask[obj['y']:obj['y']+obj['height'], obj['x']:obj['x']+obj['width'], 0] = 1.0
        masks.append(mask)
    
    return np.array(images), np.array(masks)

# Define the U-Net model
def build_unet(input_shape):
    inputs = keras.Input(shape=input_shape)
    
    # Encoder
    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)
    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)
    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)
    
    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)
    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)
    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)
    
    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)
    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)
    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)
    
    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(pool3)
    conv4 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv4)
    drop4 = layers.Dropout(0.5)(conv4)
    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(drop4)
    
    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(pool4)
    conv5 = layers.Conv2D(1024, 3, activation='relu', padding='same')(conv5)
    drop5 = layers.Dropout(0.5)(conv5)
    
    # Decoder
    up6 = layers.Conv2D(512, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(drop5))
    merge6 = layers.concatenate([drop4, up6], axis=3)
    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(merge6)
    conv6 = layers.Conv2D(512, 3, activation='relu', padding='same')(conv6)
    
    up7 = layers.Conv2D(256, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv6))
    merge7 = layers.concatenate([conv3, up7], axis=3)
    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(merge7)
    conv7 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv7)
    
    up8 = layers.Conv2D(128, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv7))
    merge8 = layers.concatenate([conv2, up8], axis=3)
    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(merge8)
    conv8 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv8)
    
    up9 = layers.Conv2D(64, 2, activation='relu', padding='same')(layers.UpSampling2D(size=(2, 2))(conv8))
    merge9 = layers.concatenate([conv1, up9], axis=3)
    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(merge9)
    conv9 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv9)
    
    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv9)
    
    model = keras.Model(inputs=inputs, outputs=outputs)
    return model

# Load and preprocess the dataset
image_dir = 'path_to_images'
mask_json = 'path_to_masks.json'
X_train, y_train = load_dataset(image_dir, mask_json)

# Normalize the images
X_train = X_train / 255.0

# Build the U-Net model
model = build_unet(input_shape=(512, 512, 3))
model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
model.fit(X_train, y_train, batch_size=4, epochs=50, validation_split=0.2, callbacks=[early_stopping])

# Save the model
model.save('semantic_segmentation_model.h5')
```
------------------------------------- 18
```python
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import nibabel as nib
import cv2
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger
from sklearn.model_selection import train_test_split

# Constants
IMG_SIZE = 128
VOLUME_SLICES = 100
VOLUME_START_AT = 22
SEGMENT_CLASSES = {
    0: 'NOT tumor',
    1: 'NECROTIC/CORE',
    2: 'EDEMA',
    3: 'ENHANCING'
}

# Path to the dataset
TRAIN_DATASET_PATH = './BraTS2021_Training_Data/'

# Function to load and preprocess data
def load_data(ids, dataset_path):
    X = np.zeros((len(ids) * VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))
    y = np.zeros((len(ids) * VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 4))
    
    for i, case_id in enumerate(ids):
        case_path = os.path.join(dataset_path, case_id)
        
        flair = nib.load(os.path.join(case_path, f'{case_id}_flair.nii.gz')).get_fdata()
        t1ce = nib.load(os.path.join(case_path, f'{case_id}_t1ce.nii.gz')).get_fdata()
        seg = nib.load(os.path.join(case_path, f'{case_id}_seg.nii.gz')).get_fdata()
        
        for j in range(VOLUME_SLICES):
            X[i * VOLUME_SLICES + j, :, :, 0] = cv2.resize(flair[:, :, j + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))
            X[i * VOLUME_SLICES + j, :, :, 1] = cv2.resize(t1ce[:, :, j + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))
            y_resized = cv2.resize(seg[:, :, j + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)
            y[i * VOLUME_SLICES + j, :, :, :] = tf.one_hot(y_resized.astype(int), depth=4)
    
    return X / np.max(X), y

# Function to build the U-Net model
def build_unet(input_shape):
    inputs = Input(input_shape)
    
    conv1 = Conv2D(32, 3, activation='relu', padding='same')(inputs)
    conv1 = Conv2D(32, 3, activation='relu', padding='same')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    
    conv2 = Conv2D(64, 3, activation='relu', padding='same')(pool1)
    conv2 = Conv2D(64, 3, activation='relu', padding='same')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    
    conv3 = Conv2D(128, 3, activation='relu', padding='same')(pool2)
    conv3 = Conv2D(128, 3, activation='relu', padding='same')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    
    conv4 = Conv2D(256, 3, activation='relu', padding='same')(pool3)
    conv4 = Conv2D(256, 3, activation='relu', padding='same')(conv4)
    drop4 = Dropout(0.5)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)
    
    conv5 = Conv2D(512, 3, activation='relu', padding='same')(pool4)
    conv5 = Conv2D(512, 3, activation='relu', padding='same')(conv5)
    drop5 = Dropout(0.5)(conv5)
    
    up6 = Conv2D(256, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(drop5))
    merge6 = concatenate([drop4, up6], axis=3)
    conv6 = Conv2D(256, 3, activation='relu', padding='same')(merge6)
    conv6 = Conv2D(256, 3, activation='relu', padding='same')(conv6)
    
    up7 = Conv2D(128, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv6))
    merge7 = concatenate([conv3, up7], axis=3)
    conv7 = Conv2D(128, 3, activation='relu', padding='same')(merge7)
    conv7 = Conv2D(128, 3, activation='relu', padding='same')(conv7)
    
    up8 = Conv2D(64, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv7))
    merge8 = concatenate([conv2, up8], axis=3)
    conv8 = Conv2D(64, 3, activation='relu', padding='same')(merge8)
    conv8 = Conv2D(64, 3, activation='relu', padding='same')(conv8)
    
    up9 = Conv2D(32, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv8))
    merge9 = concatenate([conv1, up9], axis=3)
    conv9 = Conv2D(32, 3, activation='relu', padding='same')(merge9)
    conv9 = Conv2D(32, 3, activation='relu', padding='same')(conv9)
    
    conv10 = Conv2D(4, 1, activation='softmax')(conv9)
    
    model = Model(inputs=inputs, outputs=conv10)
    return model

# Custom Dice Coefficient for multi-class segmentation
def dice_coef(y_true, y_pred, smooth=1.0):
    y_true_f = tf.reshape(y_true, [-1])
    y_pred_f = tf.reshape(y_pred, [-1])
    intersection = tf.reduce_sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)

# Load and split data
all_ids = [f for f in os.listdir(TRAIN_DATASET_PATH) if os.path.isdir(os.path.join(TRAIN_DATASET_PATH, f))]
train_ids, test_ids = train_test_split(all_ids, test_size=0.2)
train_ids, val_ids = train_test_split(train_ids, test_size=0.15)

X_train, y_train = load_data(train_ids, TRAIN_DATASET_PATH)
X_val, y_val = load_data(val_ids, TRAIN_DATASET_PATH)
X_test, y_test = load_data(test_ids, TRAIN_DATASET_PATH)

# Build and compile the model
input_shape = (IMG_SIZE, IMG_SIZE, 2)
model = build_unet(input_shape)
model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=[dice_coef])

# Callbacks
checkpoint = ModelCheckpoint('unet_glioma_segmentation.h5', monitor='val_loss', save_best_only=True)
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
csv_logger = CSVLogger('training_log.csv')

# Train the model
history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=8, callbacks=[checkpoint, early_stop, csv_logger])

# Evaluate the model
test_loss, test_dice = model.evaluate(X_test, y_test)
print(f'Test Loss: {test_loss}, Test Dice Coefficient: {test_dice}')

# Plot training history
history_df = pd.DataFrame(history.history)
history_df[['loss', 'val_loss']].plot()
history_df[['dice_coef', 'val_dice_coef']].plot()
plt.show()
```
------------------------------------- 19
```python
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate, LeakyReLU, BatchNormalization
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import LearningRateScheduler
from tensorflow.keras.applications import ResNet50, VGG16
import numpy as np
import cv2
import random
import csv
import os
import matplotlib.pyplot as plt

# Constants
HEIGHT = 96
WIDTH = 96
CHANNELS = 3
INIT_LR = 0.001
EPOCHS = 50
TRAIN_PATH = "./data/train.csv"
TEST_PATH = "./data/test.csv"

# Check for GPU availability
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
    raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

# Helper functions
def downsampling_block(input_tensor, n_filters):
    x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same')(input_tensor)
    x = LeakyReLU(alpha=0.2)(x)
    x = BatchNormalization()(x)
    x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same')(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = BatchNormalization()(x)
    return x

def upsampling_block(input_tensor, n_filters, name, concat_with):
    x = UpSampling2D((2, 2), interpolation='bilinear', name=name)(input_tensor)
    x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same', name=name + "_convA")(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = concatenate([x, concat_with], axis=3)
    x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same', name=name + "_convB")(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = BatchNormalization()(x)
    x = Conv2D(filters=n_filters, kernel_size=(3, 3), padding='same', name=name + "_convC")(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = BatchNormalization()(x)
    return x

def build_resnet_model(height, width, channels):
    i = Input(shape=(height, width, channels))
    resnet50 = ResNet50(include_top=False, weights="imagenet", input_tensor=i)
    conv1 = resnet50.get_layer("conv1_relu").output
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    conv2 = resnet50.get_layer("conv2_block3_out").output
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    conv3 = resnet50.get_layer("conv3_block4_out").output
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    conv4 = resnet50.get_layer("conv4_block6_out").output
    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)
    conv5 = resnet50.get_layer("conv5_block3_out").output
    conv5 = LeakyReLU(alpha=0.2)(conv5)
    conv6 = upsampling_block(conv5, 256, "up1", concat_with=conv4)
    conv7 = upsampling_block(conv6, 128, "up2", concat_with=conv3)
    conv8 = upsampling_block(conv7, 64, "up3", concat_with=conv2)
    conv9 = upsampling_block(conv8, 32, "up4", concat_with=conv1)
    o = Conv2D(filters=1, kernel_size=3, strides=(1, 1), activation='sigmoid', padding='same', name='conv10')(conv9)
    model = Model(inputs=i, outputs=o)
    return model

def build_vgg_model(height, width, channels):
    i = Input(shape=(height, width, channels))
    vgg16 = VGG16(include_top=False, weights="imagenet", input_tensor=i)
    conv1 = vgg16.get_layer("block1_conv2").output
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    conv2 = vgg16.get_layer("block2_conv2").output
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    conv3 = vgg16.get_layer("block3_conv3").output
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    conv4 = vgg16.get_layer("block4_conv3").output
    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)
    conv5 = vgg16.get_layer("block5_conv3").output
    conv5 = LeakyReLU(alpha=0.2)(conv5)
    conv6 = upsampling_block(conv5, 256, "up1", concat_with=conv4)
    conv7 = upsampling_block(conv6, 128, "up2", concat_with=conv3)
    conv8 = upsampling_block(conv7, 64, "up3", concat_with=conv2)
    conv9 = upsampling_block(conv8, 32, "up4", concat_with=conv1)
    o = Conv2D(filters=1, kernel_size=3, strides=(1, 1), activation='sigmoid', padding='same', name='conv10')(conv9)
    model = Model(inputs=i, outputs=o)
    return model

def load_data(csv_file_path):
    with open(csv_file_path, 'r') as f:
        csv_reader = csv.reader(f, delimiter=',')
        return [(row[0], np.array([float(x) for x in row[1:]])) for row in csv_reader if len(row) > 0]

def train_val_split(data, val_size):
    random.shuffle(data)
    len_data = len(data)
    i = int(len_data * (1.0 - val_size))
    train = data[0:i]
    val = data[i:len_data]
    return train, val

def preprocess_image(img_path):
    image = cv2.imread(img_path)
    image = cv2.resize(image, (HEIGHT, WIDTH))
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image = image.astype("float32") / 255.0
    return image

def preprocess_keypoints(keypoints):
    keypoints = keypoints.reshape(-1, 2)
    keypoints = keypoints / np.array([WIDTH, HEIGHT])
    return keypoints

class DataGenerator(tf.keras.utils.Sequence):
    def __init__(self, list_IDs, labels, batch_size=16, dim=(HEIGHT, WIDTH), n_channels=CHANNELS, shuffle=True):
        self.dim = dim
        self.batch_size = batch_size
        self.labels = labels
        self.list_IDs = list_IDs
        self.n_channels = n_channels
        self.shuffle = shuffle
        self.on_epoch_end()

    def __len__(self):
        return int(np.floor(len(self.list_IDs) / self.batch_size))

    def __getitem__(self, index):
        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]
        list_IDs_temp = [self.list_IDs[k] for k in indexes]
        X, y = self.__data_generation(list_IDs_temp)
        return X, y

    def on_epoch_end(self):
        self.indexes = np.arange(len(self.list_IDs))
        if self.shuffle == True:
            np.random.shuffle(self.indexes)

    def __data_generation(self, list_IDs_temp):
        X = np.empty((self.batch_size, *self.dim, self.n_channels))
        y = np.empty((self.batch_size, 68, 2))
        for i, ID in enumerate(list_IDs_temp):
            X[i,] = preprocess_image(ID)
            y[i,] = preprocess_keypoints(self.labels[ID])
        return X, y

def poly_decay(epoch):
    maxEpochs = EPOCHS
    baseLR = INIT_LR
    power = 1.0
    alpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power
    return alpha

# Load and preprocess data
data = load_data(TRAIN_PATH)
train_data, val_data = train_val_split(data, 0.2)
train_paths = [x for x, y in train_data]
val_paths = [x for x, y in val_data]
train_labels = {x: y for x, y in train_data}
val_labels = {x: y for x, y in val_data}

# Create data generators
train_generator = DataGenerator(list_IDs=train_paths, labels=train_labels, batch_size=16, dim=(HEIGHT, WIDTH), n_channels=CHANNELS, shuffle=True)
val_generator = DataGenerator(list_IDs=val_paths, labels=val_labels, batch_size=16, dim=(HEIGHT, WIDTH), n_channels=CHANNELS, shuffle=True)

# Build models
resnet_model = build_resnet_model(HEIGHT, WIDTH, CHANNELS)
vgg_model = build_vgg_model(HEIGHT, WIDTH, CHANNELS)

# Compile models
opt = Adam(lr=INIT_LR, amsgrad=True)
callbacks = [LearningRateScheduler(poly_decay)]
resnet_model.compile(optimizer=opt, loss='mean_squared_error', metrics=['accuracy'])
vgg_model.compile(optimizer=opt, loss='mean_squared_error', metrics=['accuracy'])

# Train models
resnet_history = resnet_model.fit(train_generator, validation_data=val_generator, epochs=EPOCHS, callbacks=callbacks)
vgg_history = vgg_model.fit(train_generator, validation_data=val_generator, epochs=EPOCHS, callbacks=callbacks)

# Save models
resnet_model.save("resnet_keypoints_model.h5")
vgg_model.save("vgg_keypoints_model.h5")

# Plot training history
plt.style.use('ggplot')
plt.figure()
plt.plot(resnet_history.history['loss'], label='ResNet Train Loss')
plt.plot(resnet_history.history['val_loss'], label='ResNet Val Loss')
plt.plot(vgg_history.history['loss'], label='VGG Train Loss')
plt.plot(vgg_history.history['val_loss'], label='VGG Val Loss')
plt.title('Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Evaluate models on test data
test_data = load_data(TEST_PATH)
test_paths = [x for x, y in test_data]
test_labels = {x: y for x, y in test_data}
test_generator = DataGenerator(list_IDs=test_paths, labels=test_labels, batch_size=16, dim=(HEIGHT, WIDTH), n_channels=CHANNELS, shuffle=False)
resnet_results = resnet_model.evaluate(test_generator)
vgg_results = vgg_model.evaluate(test_generator)
print(f"ResNet Model Test Loss: {resnet_results[0]}, Test Accuracy: {resnet_results[1]}")
print(f"VGG Model Test Loss: {vgg_results[0]}, Test Accuracy: {vgg_results[1]}")
```
------------------------------------- 20
```python
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, UpSampling2D, Concatenate
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
import pandas as pd
import numpy as np
import os
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import load_img, img_to_array

# Load the dataset paths from CSV files
def load_data_paths(csv_path):
    df = pd.read_csv(csv_path)
    return df['image_path'].values, df['depth_path'].values

train_image_paths, train_depth_paths = load_data_paths('train.csv')
test_image_paths, test_depth_paths = load_data_paths('test.csv')

# Load images and depth maps
def load_data(image_paths, depth_paths, target_size=(256, 256)):
    images = []
    depths = []
    for img_path, depth_path in zip(image_paths, depth_paths):
        img = load_img(img_path, target_size=target_size)
        depth = load_img(depth_path, target_size=target_size, color_mode="grayscale")
        img = img_to_array(img) / 255.0
        depth = img_to_array(depth) / 255.0
        images.append(img)
        depths.append(depth)
    return np.array(images), np.array(depths)

train_images, train_depths = load_data(train_image_paths, train_depth_paths)
test_images, test_depths = load_data(test_image_paths, test_depth_paths)

# Split training data into training and validation sets
train_images, val_images, train_depths, val_depths = train_test_split(train_images, train_depths, test_size=0.2, random_state=42)

# Define the ResNet-based U-Net model
def resnet_block(inputs, filters, kernel_size=3, strides=1, activation='relu'):
    x = Conv2D(filters, kernel_size, strides=strides, padding='same')(inputs)
    x = BatchNormalization()(x)
    x = Activation(activation)(x)
    x = Conv2D(filters, kernel_size, padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation(activation)(x)
    return x

def build_resnet_unet(input_shape):
    inputs = Input(input_shape)
    
    # Encoder
    conv1 = resnet_block(inputs, 64)
    pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)
    
    conv2 = resnet_block(pool1, 128)
    pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)
    
    conv3 = resnet_block(pool2, 256)
    pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)
    
    conv4 = resnet_block(pool3, 512)
    pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv4)
    
    # Bridge
    conv5 = resnet_block(pool4, 1024)
    
    # Decoder
    up6 = UpSampling2D(size=(2, 2))(conv5)
    up6 = Conv2D(512, 2, padding='same')(up6)
    merge6 = Concatenate()([conv4, up6])
    conv6 = resnet_block(merge6, 512)
    
    up7 = UpSampling2D(size=(2, 2))(conv6)
    up7 = Conv2D(256, 2, padding='same')(up7)
    merge7 = Concatenate()([conv3, up7])
    conv7 = resnet_block(merge7, 256)
    
    up8 = UpSampling2D(size=(2, 2))(conv7)
    up8 = Conv2D(128, 2, padding='same')(up8)
    merge8 = Concatenate()([conv2, up8])
    conv8 = resnet_block(merge8, 128)
    
    up9 = UpSampling2D(size=(2, 2))(conv8)
    up9 = Conv2D(64, 2, padding='same')(up9)
    merge9 = Concatenate()([conv1, up9])
    conv9 = resnet_block(merge9, 64)
    
    # Output layer
    outputs = Conv2D(1, 1, activation='sigmoid')(conv9)
    
    model = Model(inputs, outputs)
    return model

# Build the model
model = build_resnet_unet(input_shape=(256, 256, 3))

# Compile the model
model.compile(optimizer=Adam(learning_rate=1e-4), loss='mean_squared_error', metrics=['mae'])

# Callbacks
checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')
early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)

# Train the model
history = model.fit(
    train_images, train_depths,
    validation_data=(val_images, val_depths),
    epochs=50,
    batch_size=8,
    callbacks=[checkpoint, early_stopping, reduce_lr]
)

# Evaluate the model
test_loss, test_mae = model.evaluate(test_images, test_depths)
print(f'Test Loss: {test_loss}, Test MAE: {test_mae}')

# Predict and visualize results
def visualize_results(model, test_images, test_depths, num_samples=5):
    for i in range(num_samples):
        pred_depth = model.predict(np.expand_dims(test_images[i], axis=0))
        pred_depth = pred_depth.squeeze()
        plt.figure(figsize=(15, 5))
        plt.subplot(1, 3, 1)
        plt.title('Input Image')
        plt.imshow(test_images[i])
        plt.subplot(1, 3, 2)
        plt.title('Ground Truth Depth')
        plt.imshow(test_depths[i].squeeze(), cmap='gray')
        plt.subplot(1, 3, 3)
        plt.title('Predicted Depth')
        plt.imshow(pred_depth, cmap='gray')
        plt.show()

visualize_results(model, test_images, test_depths)
```
------------------------------------- 21
```python
import os
import numpy as np
import h5py
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split

# Load the dataset
def load_data(data_dir):
    images = []
    density_maps = []
    for filename in os.listdir(data_dir):
        if filename.endswith('.h5'):
            with h5py.File(os.path.join(data_dir, filename), 'r') as hf:
                images.append(hf['image'][:])
                density_maps.append(hf['density'][:])
    return np.array(images), np.array(density_maps)

# Preprocess the data
def preprocess(images, density_maps):
    images = images / 255.0  # Normalize images
    density_maps = density_maps / np.max(density_maps)  # Normalize density maps
    return images, density_maps

# Define the model architecture
def create_model(input_shape):
    inputs = Input(shape=input_shape)
    
    # Encoder
    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    
    # Bottleneck
    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)
    
    # Decoder
    up5 = UpSampling2D(size=(2, 2))(conv4)
    conv5 = Conv2D(256, 3, activation='relu', padding='same')(up5)
    up6 = UpSampling2D(size=(2, 2))(conv5)
    conv6 = Conv2D(128, 3, activation='relu', padding='same')(up6)
    up7 = UpSampling2D(size=(2, 2))(conv6)
    conv7 = Conv2D(64, 3, activation='relu', padding='same')(up7)
    
    # Output layer
    outputs = Conv2D(1, 1, activation='linear')(conv7)
    
    model = Model(inputs=inputs, outputs=outputs)
    return model

# Load and preprocess the data
data_dir = '/path/to/ShanghaiTech/part_B/train_data'
images, density_maps = load_data(data_dir)
images, density_maps = preprocess(images, density_maps)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(images, density_maps, test_size=0.2, random_state=42)

# Create and compile the model
model = create_model(input_shape=(images.shape[1], images.shape[2], images.shape[3]))
model.compile(optimizer=Adam(), loss='mse', metrics=['mae'])

# Train the model
model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2)

# Evaluate the model
loss, mae = model.evaluate(X_test, y_test)
print(f'Test Loss: {loss}')
print(f'Test MAE: {mae}')

# Predict density maps for test images
predictions = model.predict(X_test)

# Example: Display a predicted density map
import matplotlib.pyplot as plt
plt.imshow(predictions[0, :, :, 0], cmap='jet')
plt.colorbar()
plt.show()
```
------------------------------------- 22
```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess
from tensorflow.keras.applications.stopnet import StopNet
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import numpy as np
import matplotlib.pyplot as plt

# Configuration class
class Config:
    img_size = (224, 224, 3)
    batch_size = 32
    epochs = 10
    validation_split = 0.15
    random_state = 42

config = Config()

# Function to parse TFRecord
def parse_tfrecord(example_proto):
    feature_description = {
        'image': tf.io.FixedLenFeature([], tf.string),
        'label': tf.io.FixedLenFeature([], tf.int64),
    }
    example = tf.io.parse_single_example(example_proto, feature_description)
    image = tf.image.decode_jpeg(example['image'], channels=3)
    image = tf.image.resize(image, [config.img_size[0], config.img_size[1]])
    image = efficientnet_preprocess(image)
    label = tf.one_hot(example['label'], depth=2)  # Assuming binary classification
    return image, label

# Load and preprocess dataset
def load_dataset(filenames):
    dataset = tf.data.TFRecordDataset(filenames)
    dataset = dataset.map(parse_tfrecord, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    dataset = dataset.shuffle(buffer_size=1024).batch(config.batch_size).prefetch(tf.data.experimental.AUTOTUNE)
    return dataset

train_filenames = ['path/to/train.tfrecord']
val_filenames = ['path/to/val.tfrecord']

train_dataset = load_dataset(train_filenames)
val_dataset = load_dataset(val_filenames)

# Model definition
def create_model():
    # EfficientNetB0 as the base model
    efficientnet = EfficientNetB0(include_top=False, weights='imagenet', input_shape=config.img_size)
    efficientnet.trainable = False

    # StopNet as the additional feature extractor
    stopnet = StopNet(include_top=False, weights=None, input_shape=config.img_size)
    stopnet.trainable = False

    model = Sequential([
        efficientnet,
        Flatten(),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(64, activation='relu'),
        Dropout(0.5),
        Dense(2, activation='softmax')  # Assuming binary classification
    ])

    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

model = create_model()

# Callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')

# Training
history = model.fit(
    train_dataset,
    epochs=config.epochs,
    validation_data=val_dataset,
    callbacks=[early_stopping, checkpoint]
)

# Evaluation
test_filenames = ['path/to/test.tfrecord']
test_dataset = load_dataset(test_filenames)
test_loss, test_accuracy = model.evaluate(test_dataset)
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")

# Visualization
def visualize_predictions(dataset, model):
    for images, labels in dataset.take(1):
        predictions = model.predict(images)
        for i in range(len(images)):
            plt.imshow(images[i].numpy().astype("uint8"))
            plt.title(f"True: {np.argmax(labels[i])}, Pred: {np.argmax(predictions[i])}")
            plt.show()

visualize_predictions(test_dataset, model)
```
------------------------------------- 23
```python
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, regularizers
from sklearn.model_selection import train_test_split, StratifiedKFold

# Load your dataset
# Assuming X is your feature matrix and y is your target labels
# X = np.load('path_to_your_features.npy')
# y = np.load('path_to_your_labels.npy')

# Example data loading (replace with your actual data loading code)
X = np.random.rand(1000, 10)  # 1000 instances, 10 features
y = np.random.randint(0, 2, 1000)  # Binary labels (0 or 1)

# Convert labels to categorical
num_classes = 2
y = tf.keras.utils.to_categorical(y, num_classes)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

def create_model(input_shape):
    model = models.Sequential()

    # Bi-directional LSTM layer
    model.add(layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=input_shape))
    model.add(layers.Dropout(0.5))

    # Another Bi-directional LSTM layer
    model.add(layers.Bidirectional(layers.LSTM(64)))
    model.add(layers.Dropout(0.5))

    # Fully connected layer
    model.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))
    model.add(layers.Dropout(0.5))

    # Output layer
    model.add(layers.Dense(num_classes, activation='softmax'))

    return model

# Define the input shape
input_shape = (X_train.shape[1], 1)  # Assuming 1D features

# Create the model
model = create_model(input_shape)

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Set the number of folds for cross-validation
num_folds = 5
skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)

# Initialize lists to store training and validation accuracies
train_accuracies = []
val_accuracies = []

# Iterate through folds
for fold_index, (train_index, val_index) in enumerate(skf.split(X_train, np.argmax(y_train, axis=1))):
    print(f"Training fold {fold_index + 1}/{num_folds}")

    # Split the data into training and validation sets
    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]
    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]

    # Reshape data for LSTM input (samples, timesteps, features)
    X_train_fold = np.expand_dims(X_train_fold, axis=2)
    X_val_fold = np.expand_dims(X_val_fold, axis=2)

    # Train the model
    history = model.fit(X_train_fold, y_train_fold, batch_size=64, epochs=50, validation_data=(X_val_fold, y_val_fold), verbose=1)

    # Evaluate and store training accuracy
    train_loss, train_acc = model.evaluate(X_train_fold, y_train_fold, verbose=0)
    train_accuracies.append(train_acc)

    # Evaluate and store validation accuracy
    val_loss, val_acc = model.evaluate(X_val_fold, y_val_fold, verbose=0)
    val_accuracies.append(val_acc)

    # Save the model for each fold
    model.save(f"model_fold_{fold_index+1}.h5")

# Print average training and validation accuracies
print(f"\nAverage Training Accuracy: {np.mean(train_accuracies):.4f}")
print(f"Average Validation Accuracy: {np.mean(val_accuracies):.4f}")

# Evaluate the model on the test set
X_test = np.expand_dims(X_test, axis=2)
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
print(f"Test Accuracy: {test_acc:.4f}")

# Summary of the model
model.summary()
```
------------------------------------- 24
```python
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np

# Assuming X is your 2D audio feature array and y is your one-hot encoded labels
# X.shape = (num_samples, 40, 249, 1)
# y.shape = (num_samples, 10)

# Preprocess the data
scaler = StandardScaler()
X = scaler.fit_transform(X.reshape(X.shape[0], -1)).reshape(X.shape)

# Split the data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Build the CNN model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(40, 249, 1)),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    
    Conv2D(64, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    
    Conv2D(128, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D((2, 2)),
    
    Flatten(),
    
    Dense(256, activation='relu'),
    Dropout(0.5),
    
    Dense(128, activation='relu'),
    Dropout(0.5),
    
    Dense(10, activation='softmax')
])

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Define callbacks
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train,
                    epochs=50,
                    batch_size=32,
                    validation_data=(X_val, y_val),
                    callbacks=[reduce_lr, early_stopping])

# Evaluate the model
val_loss, val_acc = model.evaluate(X_val, y_val)
print(f'Validation Loss: {val_loss}')
print(f'Validation Accuracy: {val_acc}')
```
------------------------------------- 25
```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LeakyReLU
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

# Load the dataset
TRAIN = 'path_to_training_data.csv'
TEST = 'path_to_testing_data.csv'

df = pd.read_csv(TRAIN)
test = pd.read_csv(TEST)

# Define features and target
features = df.columns.drop(['fault_category_1', 'fault_category_2', 'fault_category_3', 'fault_category_4', 'fault_category_5', 'fault_category_6', 'fault_category_7'])
target = ['fault_category_1', 'fault_category_2', 'fault_category_3', 'fault_category_4', 'fault_category_5', 'fault_category_6', 'fault_category_7']

# Preprocessing
numerical_cols = df[features].select_dtypes(include=['int64', 'float64']).columns
categorical_cols = df[features].select_dtypes(include=['object']).columns

numerical_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

# Split the data
X = df[features]
y = df[target]
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)

# Preprocess the data
X_train = preprocessor.fit_transform(X_train)
X_valid = preprocessor.transform(X_valid)

# Define the model
model = Sequential()
model.add(Dense(units=128, activation='relu', input_dim=X_train.shape[1]))
model.add(Dense(units=64, activation=LeakyReLU(alpha=0.1)))
model.add(Dropout(0.5))
model.add(Dense(units=32, activation='relu'))
model.add(Dense(units=len(target), activation='sigmoid'))  # Multi-label classification

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

# Early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_valid, y_valid), callbacks=[early_stopping])

# Evaluate the model
loss, accuracy = model.evaluate(X_valid, y_valid)
print(f'Validation Loss: {loss}')
print(f'Validation Accuracy: {accuracy}')

# Make predictions on the test set
test_preprocessed = preprocessor.transform(test[features])
predictions = model.predict(test_preprocessed)

# Convert predictions to binary labels
predicted_labels = (predictions > 0.5).astype(int)

# Save predictions to a CSV file
submission_df = pd.DataFrame(predicted_labels, columns=target)
submission_df.to_csv('fault_predictions.csv', index=False)
```
------------------------------------- 26
```python
import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
import keras_tuner as kt

# Load the dataset
df = pd.read_csv("/kaggle/input/patient-health-records/Dataset.csv")

# Display basic information about the dataset
df.head()
df.info()
df.shape
df.isnull().sum()
df.columns
df.describe()

# Drop columns with unique values that are not useful for prediction
columns_to_drop = ['encounter_id', 'patient_id', 'hospital_id', 'hospital_admit_source', 'icu_admit_source', 'icu_stay_type', 'icu_id', 'readmission_status']
df = df.drop(columns=columns_to_drop, axis=1)

# Function to identify columns with more than 50% missing values
def missing_col(df):
    missing_df = pd.DataFrame(df.isnull().sum() / df.shape[0], columns=["Missing"])
    return missing_df[missing_df["Missing"] >= 0.50]

# Drop columns with more than 50% missing values
missing_val_col = list(missing_col(df).index)
df = df.drop(columns=missing_val_col)

# Ensure no rows with missing values in 'bmi', 'weight', 'height'
df = df[df[['bmi', 'weight', 'height']].isnull().sum(axis=1) == 0]

# Impute missing values with the most frequent value
imputer = SimpleImputer(strategy='most_frequent')
df.iloc[:, :] = imputer.fit_transform(df)

# One-hot encode categorical columns
cat_col = df.select_dtypes(include=object).columns.to_list()
df_encoded = pd.get_dummies(df, columns=cat_col, drop_first=False, prefix='isIN', prefix_sep='_')
df_encoded = df_encoded.applymap(lambda x: 1 if x == True else (0 if x == False else x))

# Prepare features and target variable
X = df_encoded.drop("DiagPeriodL90D", axis=1)
y = df_encoded['DiagPeriodL90D']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=45)

# Normalize the features
scaler = MinMaxScaler()
X_train_std = scaler.fit_transform(X_train)
X_test_std = scaler.transform(X_test)

# Convert normalized data back to DataFrame
X_train_new = pd.DataFrame(X_train_std, columns=X_train.columns)
X_test_new = pd.DataFrame(X_test_std, columns=X_test.columns)

# Define the model architecture
model = Sequential()
model.add(Dense(64, input_shape=(X_train_new.shape[-1],), activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(16, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
metrics = [
    keras.metrics.Precision(name="precision"),
    keras.metrics.Recall(name="recall"),
    keras.metrics.AUC(curve='ROC')
]
model.compile(optimizer=keras.optimizers.Adam(0.01),
              loss='binary_crossentropy',
              metrics=metrics)

# Train the model
epochs = 25
batch_size = 32
history = model.fit(X_train_new.values, y_train, validation_data=(X_test_new.values, y_test), epochs=epochs, batch_size=batch_size)

# Plot training and validation metrics
acc = history.history['auc']
val_acc = history.history['val_auc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(16, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training AUC Score')
plt.plot(epochs_range, val_acc, label='Validation AUC Score')
plt.legend(loc='lower right')
plt.title('Training and Validation AUC Score')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

# Hyperparameter tuning with Keras Tuner
def model_builder(hp):
    model = keras.Sequential()
    model.add(keras.layers.Flatten(input_shape=[X_train_new.shape[-1]]))
    
    # Tune the number of units in the first Dense layer
    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)
    model.add(keras.layers.Dense(units=hp_units, activation='relu'))
    model.add(keras.layers.Dense(units=hp_units, activation='relu'))
    model.add(keras.layers.Dense(1, activation='sigmoid'))

    # Tune the learning rate for the optimizer
    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])

    metrics = [
        keras.metrics.Precision(name="precision"),
        keras.metrics.Recall(name="recall"),
        keras.metrics.AUC(curve='ROC')
    ]

    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),
                  loss=keras.losses.BinaryCrossentropy(),
                  metrics=metrics)

    return model

tuner = kt.RandomSearch(
    model_builder,
    objective='val_loss',
    max_trials=5
)

# Early stopping to prevent overfitting
stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_recall', patience=5)

tuner.search(X_train_new.values, y_train, epochs=25, validation_data=(X_test_new.values, y_test), callbacks=[stop_early])

# Get the optimal hyperparameters
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]

print(f"""
The hyperparameter search is complete. The optimal number of units in the first densely-connected
layer is {best_hps.get('units')} and the optimal learning rate for the optimizer
is {best_hps.get('learning_rate')}.
""")

# Build the final model with the best hyperparameters
model = Sequential()
model.add(Dense(best_hps.get('units'), input_dim=X_train_new.shape[-1], activation='relu'))
model.add(Dense(best_hps.get('units'), activation='relu'))
model.add(Dense(1, activation='sigmoid'))

metrics = [
    keras.metrics.Precision(name="precision"),
    keras.metrics.Recall(name="recall"),
    keras.metrics.AUC(curve='ROC')
]

model.compile(optimizer=keras.optimizers.Adam(best_hps.get('learning_rate')),
              loss='binary_crossentropy',
              metrics=metrics)

# Train the final model
epochs = 15
batch_size = 32
history = model.fit(X_train_new.values, y_train, validation_data=(X_test_new.values, y_test), epochs=epochs, batch_size=batch_size)

# Plot final training and validation metrics
acc = history.history['auc']
val_acc = history.history['val_auc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(15, 6))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training AUC Score')
plt.plot(epochs_range, val_acc, label='Validation AUC Score')
plt.legend(loc='lower right')
plt.title('Training and Validation AUC Score')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()
```
------------------------------------- 27
```python
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

# Load the dataset
df = pd.read_csv('patient_survival_data.csv')

# Display the first few rows of the dataset
print("First few rows of the dataset:")
print(df.head())

# Display the dimensions of the dataset
print("\nDimensions of the dataset:")
print(df.shape)

# Display basic statistics for numerical columns in the dataset
print("\nSummary statistics for numerical columns in the dataset:")
print(df.describe())

# Display information about the dataset
print("\nInformation about the dataset:")
print(df.info())

# Check for null values
print("\nChecking for null values...")
null_values = df.isnull().sum()
null_columns = null_values[null_values > 0]
if not null_columns.empty:
    print('Columns with null values:')
    print(null_columns)
else:
    print('No null values found in the dataset.')

# Impute null values in numerical columns with the mean
imputer = SimpleImputer(strategy='mean')
df[df.select_dtypes(include=['float64', 'int64']).columns] = imputer.fit_transform(df.select_dtypes(include=['float64', 'int64']))

# Encode categorical features
label_encoder = LabelEncoder()
for col in df.select_dtypes(include=['object']).columns:
    df[col] = label_encoder.fit_transform(df[col])

# Split the dataset into features (X) and target (y)
X = df.drop('Survival_Status', axis=1)
y = df['Survival_Status']

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the dataset into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Build the deep learning model
model = Sequential()
model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Set early stopping
early_stopping = EarlyStopping(patience=10, monitor='val_loss')

# Train the model
history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32, callbacks=[early_stopping])

# Evaluate the model
y_pred_probs = model.predict(X_val)
y_pred = (y_pred_probs > 0.5).astype(int)

# Calculate ROC curve and AUC
fpr, tpr, thresholds = roc_curve(y_val, y_pred_probs)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Generate confusion matrix
conf_matrix = confusion_matrix(y_val, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=True)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.xticks([0.5, 1.5], ['Not Survived', 'Survived'])
plt.yticks([0.5, 1.5], ['Not Survived', 'Survived'])
plt.show()

# Calculate metrics
accuracy = accuracy_score(y_val, y_pred)
precision = precision_score(y_val, y_pred)
recall = recall_score(y_val, y_pred)
f1 = f1_score(y_val, y_pred)

# Print metrics
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)
```
------------------------------------- 28
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam, RMSprop
from tensorflow.keras import backend as K
from scikeras.wrappers import KerasRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error

# Load the dataset
train_path = r"/kaggle/input/predictiva-dl-time-series-forecasting/train.csv"
test_path = r"/kaggle/input/predictiva-dl-time-series-forecasting/test.csv"
train_data = pd.read_csv(train_path)
test_data = pd.read_csv(test_path)

# Explore data before cleaning
def explore_data(data):
    """
    Display basic information about the dataset.
    """
    print("Data Overview:")
    print(data.head())
    print("\nData Info:")
    print(data.info())
    print("\nSummary Statistics:")
    print(data.describe())

explore_data(train_data)

# Handle missing values
train_data.dropna(inplace=True)

# Encode categorical variables
label_encoders = {}
categorical_columns = ['zip_code', 'race', 'payer_type', 'diagnosis_codes']
for col in categorical_columns:
    le = LabelEncoder()
    train_data[col] = le.fit_transform(train_data[col])
    label_encoders[col] = le

# Split the data into features and target
X = train_data.drop(columns=['DiagPeriodL90D'])
y = train_data['DiagPeriodL90D']

# Split the data into training, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

# Reshape data for LSTM
X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])
X_val_reshaped = X_val_scaled.reshape(X_val_scaled.shape[0], 1, X_val_scaled.shape[1])
X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])

# Define a function to create the LSTM model
def create_lstm_model(units=50, dropout_rate=0.2, optimizer='adam', loss='mean_squared_error'):
    model = Sequential()
    model.add(LSTM(units=units, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))
    model.add(Dropout(dropout_rate))
    model.add(Dense(units=1))
    model.compile(optimizer=optimizer, loss=loss)
    return model

# Create KerasRegressor for use in GridSearchCV
lstm_regressor = KerasRegressor(build_fn=create_lstm_model, verbose=0)

# Define hyperparameters grid including optimizers and loss functions
param_grid = {
    'units': [50, 100],
    'dropout_rate': [0.0, 0.2, 0.4],
    'optimizer': ['adam', 'rmsprop'],
    'loss': ['mean_squared_error', 'mean_absolute_error']
}

# Perform GridSearchCV
grid_search = GridSearchCV(estimator=lstm_regressor, param_grid=param_grid, cv=3)
grid_result = grid_search.fit(X_train_reshaped, y_train)

# Print best results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("Mean MSE: %f, Standard Deviation: %f with: %r" % (mean, stdev, param))

# Train the best model
best_lstm_model = create_lstm_model(**grid_result.best_params_)
history = best_lstm_model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, verbose=1, validation_data=(X_val_reshaped, y_val))

# Evaluate the model on test data
loss = best_lstm_model.evaluate(X_test_reshaped, y_test)
print("Loss on test data:", loss)

# Plot training loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Make predictions on the test set
y_test_pred = best_lstm_model.predict(X_test_reshaped)

# Plot the predicted vs actual values
plt.figure(figsize=(12, 6))
plt.plot(y_test.values, label='Actual Data', marker='o')
plt.plot(y_test_pred, label='Predicted Data', marker='o')
plt.xlabel('Sample Index')
plt.ylabel('Diagnosis Period (L90D)')
plt.title('LSTM Model - Predicted vs Actual on Test Data')
plt.legend()
plt.show()

# Prepare the test data for prediction
test_data_encoded = test_data.copy()
for col in categorical_columns:
    test_data_encoded[col] = label_encoders[col].transform(test_data_encoded[col])

X_test_final = test_data_encoded.drop(columns=['DiagPeriodL90D'])
X_test_final_scaled = scaler.transform(X_test_final)
X_test_final_reshaped = X_test_final_scaled.reshape(X_test_final_scaled.shape[0], 1, X_test_final_scaled.shape[1])

# Make predictions on the final test set
y_test_final_pred = best_lstm_model.predict(X_test_final_reshaped)

# Create submission DataFrame
submission = pd.DataFrame({
    'id': test_data['id'],
    'DiagPeriodL90D': y_test_final_pred.flatten()
})

# Save the submission file
submission.to_csv('submission.csv', index=False)
```
------------------------------------- 29
```python
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Lambda
from tensorflow.keras.models import Sequential
from tensorflow.keras.losses import Huber
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import LearningRateScheduler
from tensorflow.keras.metrics import mean_absolute_error
from statsmodels.tsa.statespace.sarimax import SARIMAX

# Directory containing input files
DIR_IN = "/kaggle/input/sales-data/"
# Working directory (the only writable place in a Kaggle's work)
DIR_WORK = "/kaggle/working/"
# Full path to the input file
FILE_IN = os.path.join(DIR_IN, "sales_data.csv")
# Date used to split the training and the test part
SPLIT_DATE = "2023-01-01"
# Size of the window applied to the time series
WINDOW_SIZE = 10
# Batch size for model training and prediction
BATCH_SIZE = 32
# Buffer size used to shuffle the training set, should be bigger than the dataset's size
SHUFFLE_BUFFER = 3000

# Load the dataset
df = pd.read_csv(FILE_IN, sep=",")
df.head()

# Preprocess the data
df['Date'] = pd.to_datetime(df['Date'])
df.set_index('Date', inplace=True)
df = df.resample('D').asfreq()
df = df.ffill()

# Split the data into training and test sets
df_train = df[df.index < SPLIT_DATE]
df_test = df[df.index >= SPLIT_DATE]

time_test = df_test.index  # just used for plotting results at the end

X_train = df_train['Number_of_Products_Sold'].values  # convert to Numpy array
X_test = df_test['Number_of_Products_Sold'].values  # convert to Numpy array

print(f"X_train shape = {X_train.shape}; X_test shape = {X_test.shape}")
print(f"Some X_train data: {X_train[:10]}")

# Utility function to plot a series
def plot_series(x, y, start=0, end=None, title=None, xlabel=None, ylabel=None):
    """
    Utility function to plot a series
    
    Args:
        x (1d Numpy array): values for the x-axis
        y (tuple of Numpy arrays or 1d Numpy array): values for the y-axis
        start (int): start index
        end (int): end index
        title (str): title of the plot
        xlabel (str): label for the x-axis
        ylabel (str): label for the y-axis
    """
    plt.figure(figsize=(10, 6))
    if type(y) is tuple:
        for val_set in y:
            plt.plot(x[start: end], val_set[start: end])
    else:
        plt.plot(x[start: end], y[start: end])
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.grid(True)    
    plt.show()

# Function to create windowed dataset for training
def window_train(series, window_size, batch_size, shuffle_buffer):
    """
    Convert the train series to Tensorflow Dataset
    
    Args:
        series (1d Numpy array): input time series data
        window_size (int): size of the sliding window
        batch_size (int): number of elements in each batch
        shuffle_buffer (int): buffer size used for shuffling
        
    Returns:
        A Tensorflow Dataset where each batch's element is a tuple ([v-N, ..., v-1], [v])
        where v, v-1, ..., v-N are values at time t, t-1, ..., t-N, respectively.
    """
    dataset = tf.data.Dataset.from_tensor_slices(series)
    dataset = dataset.window(window_size + 1, shift=1, stride=1, drop_remainder=True)
    dataset = dataset.flat_map(lambda w: w.batch(window_size + 1))
    dataset = dataset.map(lambda w: (w[:-1], w[-1]))
    dataset = dataset.shuffle(shuffle_buffer)
    dataset = dataset.batch(batch_size).prefetch(1)
    return dataset

# Function to create windowed dataset for testing
def window_test(series, window_size, batch_size):
    """
    Convert the test series to Tensorflow Dataset
    """
    dataset = tf.data.Dataset.from_tensor_slices(series)
    dataset = dataset.window(window_size, shift=1, stride=1, drop_remainder=True)
    dataset = dataset.flat_map(lambda w: w.batch(window_size))
    dataset = dataset.batch(batch_size).prefetch(1)
    return dataset

# Create the train and test datasets
ds_train = window_train(X_train, WINDOW_SIZE, BATCH_SIZE, SHUFFLE_BUFFER)
ds_test = window_test(np.concatenate((X_train[-WINDOW_SIZE:], X_test[:-1])), WINDOW_SIZE, BATCH_SIZE)

# LSTM Model
tf.keras.backend.clear_session()

model = Sequential([
    Lambda(lambda x: tf.expand_dims(x, axis=-1), input_shape=[WINDOW_SIZE]),
    Bidirectional(LSTM(32, return_sequences=True)),
    Bidirectional(LSTM(32)),
    Dense(1),
    Lambda(lambda x: x * 100.0)
])

# Save the initial weights
init_weights = model.get_weights()

model.summary()

# Learning rate scheduler
lr_schd = LearningRateScheduler(lambda epoch: 1e-8 * 10**(epoch / 20))

model.compile(loss=Huber(), optimizer=Adam())

# Train the model
hist = model.fit(ds_train, epochs=100, callbacks=[lr_schd])

# Plot learning rate vs loss
lr_arr = 1e-8 * (10 ** (np.arange(100) / 20))
plt.figure(figsize=(10, 6))
plt.grid(True)
plt.semilogx(lr_arr, hist.history['loss'])
plt.tick_params('both', length=10, width=1, which='both')
plt.axis([1e-8, 1e-3, 0, 100])

# Reset model weights and compile with optimal learning rate
model.set_weights(init_weights)
model.compile(loss=Huber(), optimizer=Adam(learning_rate=1e-4), metrics=['mae'])

# Train the model again with optimal learning rate
hist = model.fit(ds_train, epochs=300)

# Plot MAE and Loss
hist_mae = hist.history['mae']
hist_loss = hist.history['loss']
plot_series(range(len(hist_loss)), (hist_mae, hist_loss), title="MAE & Loss", xlabel="Epochs")

# Make predictions using LSTM model
forecasts_lstm = model.predict(ds_test)
forecasts_lstm = forecasts_lstm.squeeze()  # remove the single axis

# SARIMAX Model
model_sarimax = SARIMAX(X_train, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))
results_sarimax = model_sarimax.fit(disp=False)
forecasts_sarimax = results_sarimax.get_forecast(steps=len(X_test)).predicted_mean

# Plot actual vs predicted values
plot_series(time_test, (X_test, forecasts_lstm, forecasts_sarimax), title="Actual vs Predicted Sales", xlabel="Date", ylabel="Number of Products Sold")

# Calculate MAE for LSTM and SARIMAX
mae_lstm = mean_absolute_error(X_test, forecasts_lstm).numpy()
mae_sarimax = mean_absolute_error(X_test, forecasts_sarimax).numpy()
mean = np.mean(X_test)

print(f"LSTM MAE = {mae_lstm:.2f}")
print(f"SARIMAX MAE = {mae_sarimax:.2f}")
print(f"LSTM MAE / mean = {(mae_lstm/mean * 100):.2f} %")
print(f"SARIMAX MAE / mean = {(mae_sarimax/mean * 100):.2f} %")
```
------------------------------------- 30
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

# Load the dataset
data = pd.read_csv('fruit_prices.csv')

# Filter the dataset for 'Potato Red'
potato_data = data[data['Commodity'] == 'Potato Red']

# Sort by date
potato_data['Date'] = pd.to_datetime(potato_data['Date'])
potato_data.sort_values('Date', inplace=True)

# Prepare the data
prices = potato_data['Average'].values.reshape(-1, 1)

# Normalize the data
scaler = MinMaxScaler(feature_range=(0, 1))
prices_scaled = scaler.fit_transform(prices)

# Create sequences for LSTM
def create_sequences(data, seq_length):
    X = []
    y = []
    for i in range(len(data) - seq_length):
        X.append(data[i:i + seq_length])
        y.append(data[i + seq_length])
    return np.array(X), np.array(y)

seq_length = 50  # Number of time steps to look back
X, y = create_sequences(prices_scaled, seq_length)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

# Build the LSTM model
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(units=25))
model.add(Dense(units=1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
early_stop = EarlyStopping(monitor='val_loss', patience=10)
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stop])

# Plot training & validation loss values
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.show()

# Make predictions
train_predict = model.predict(X_train)
test_predict = model.predict(X_test)

# Inverse transform the predictions and actual values
train_predict = scaler.inverse_transform(train_predict)
y_train_actual = scaler.inverse_transform(y_train)
test_predict = scaler.inverse_transform(test_predict)
y_test_actual = scaler.inverse_transform(y_test)

# Plot the results
plt.figure(figsize=(16, 8))
plt.plot(potato_data['Date'][seq_length:len(train_predict) + seq_length], y_train_actual, label='Train Actual')
plt.plot(potato_data['Date'][seq_length:len(train_predict) + seq_length], train_predict, label='Train Predicted')
plt.plot(potato_data['Date'][len(train_predict) + seq_length:], y_test_actual, label='Test Actual')
plt.plot(potato_data['Date'][len(train_predict) + seq_length:], test_predict, label='Test Predicted')
plt.xlabel('Date')
plt.ylabel('Price')
plt.title('Potato Red Price Prediction')
plt.legend()
plt.show()

# Calculate RMSE
from sklearn.metrics import mean_squared_error
train_rmse = np.sqrt(mean_squared_error(y_train_actual, train_predict))
test_rmse = np.sqrt(mean_squared_error(y_test_actual, test_predict))
print(f'Train RMSE: {train_rmse}')
print(f'Test RMSE: {test_rmse}')
```
------------------------------------- 31
```python
import os
import yfinance as yf
import pandas as pd
import numpy as np
import math
import datetime as dt
from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, GRU, LeakyReLU
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from itertools import cycle

# Function to preprocess date strings
def remove(x):
    x = str(x)
    res = x.split(" ")[0]
    return res

# Fetch and preprocess data
df = yf.Ticker("ETH-USD").history(period="max")
df.index = pd.to_datetime(df.index)
df.index = df.index.to_series().apply(lambda x: remove(x))
df.reset_index(inplace=True)

# Visualize the data
fig = px.line(df, x=df.Date, y=df.Close, labels={'date':'Date','close':'Close Stock'})
fig.update_traces(marker_line_width=2, opacity=1, marker_line_color='orange')
fig.update_layout(title_text='ETH close price 2017-2024', plot_bgcolor='white', font_size=15, font_color='black')
fig.update_xaxes(showgrid=False)
fig.update_yaxes(showgrid=False)
fig.show()

# Prepare the dataset
data = df.loc[(df['Date'] > '2021-01-01') & (df['Date'] < '2024-02-06')]
close_stock = data.filter(['Date', 'Close'])
data = data.filter(['Close'])
closedf = data.values

# Scale the data
scaler = MinMaxScaler(feature_range=(0, 1))
closedf_scale = scaler.fit_transform(np.array(closedf).reshape(-1, 1))

# Split the data into training and testing sets
training_size = int(len(closedf_scale) * 0.80)
test_size = len(closedf) - training_size
train_data, test_data = closedf_scale[0:training_size, :], closedf_scale[training_size:len(closedf_scale), :1]

# Function to create dataset for LSTM
def create_dataset(dataset, time_step=1):
    dataX, dataY = [], []
    for i in range(len(dataset) - time_step - 1):
        a = dataset[i:(i + time_step), 0]
        dataX.append(a)
        dataY.append(dataset[i + time_step, 0])
    return np.array(dataX), np.array(dataY)

time_step = 60
X_train, y_train = create_dataset(train_data, time_step)
X_test, y_test = create_dataset(test_data, time_step)

# Reshape input to be [samples, time steps, features]
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# Build GAN model
def build_generator(input_shape):
    model = Sequential()
    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))
    model.add(Dropout(0.2))
    model.add(LSTM(50, return_sequences=False))
    model.add(Dropout(0.2))
    model.add(Dense(25))
    model.add(LeakyReLU(alpha=0.01))
    model.add(Dense(1))
    return model

def build_discriminator(input_shape):
    model = Sequential()
    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))
    model.add(Dropout(0.2))
    model.add(LSTM(50, return_sequences=False))
    model.add(Dropout(0.2))
    model.add(Dense(25))
    model.add(LeakyReLU(alpha=0.01))
    model.add(Dense(1, activation='sigmoid'))
    return model

def build_gan(generator, discriminator):
    discriminator.trainable = False
    model = Sequential()
    model.add(generator)
    model.add(discriminator)
    return model

# Compile models
input_shape = (X_train.shape[1], 1)
generator = build_generator(input_shape)
discriminator = build_discriminator(input_shape)
discriminator.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy', metrics=['accuracy'])
gan = build_gan(generator, discriminator)
gan.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')

# Training the GAN
epochs = 100
batch_size = 32
half_batch = int(batch_size / 2)

for epoch in range(epochs):
    idx = np.random.randint(0, X_train.shape[0], half_batch)
    real_samples = X_train[idx]
    noise = np.random.normal(0, 1, (half_batch, time_step, 1))
    generated_samples = generator.predict(noise)

    X = np.concatenate([real_samples, generated_samples])
    y_dis = np.zeros(batch_size)
    y_dis[:half_batch] = 0.9

    discriminator.trainable = True
    d_loss = discriminator.train_on_batch(X, y_dis)

    noise = np.random.normal(0, 1, (batch_size, time_step, 1))
    y_gen = np.ones(batch_size)
    discriminator.trainable = False
    g_loss = gan.train_on_batch(noise, y_gen)

    print(f"Epoch {epoch+1}/{epochs}, Discriminator Loss: {d_loss[0]}, Generator Loss: {g_loss}")

# Generate predictions
train_predict = generator.predict(X_train)
test_predict = generator.predict(X_test)

# Inverse transform predictions
train_predict_inverse = scaler.inverse_transform(train_predict)
test_predict_inverse = scaler.inverse_transform(test_predict)
original_ytrain = scaler.inverse_transform(y_train.reshape(-1, 1))
original_ytest = scaler.inverse_transform(y_test.reshape(-1, 1))

# Evaluation metrics
print("Train data RMSE: ", math.sqrt(mean_squared_error(original_ytrain, train_predict_inverse)))
print("Train data MAE: ", mean_absolute_error(original_ytrain, train_predict_inverse))
print("Train data R2: ", r2_score(original_ytrain, train_predict_inverse))
print("Train data explained variance regression score:", explained_variance_score(original_ytrain, train_predict_inverse))
print("-------------------------------------------------------------------------------------")
print("Test data RMSE: ", math.sqrt(mean_squared_error(original_ytest, test_predict_inverse)))
print("Test data MAE: ", mean_absolute_error(original_ytest, test_predict_inverse))
print("Test data R2: ", r2_score(original_ytest, test_predict_inverse))
print("Test data explained variance regression score:", explained_variance_score(original_ytest, test_predict_inverse))

# Plotting predictions
look_back = 60
testPredictPlot = np.empty_like(closedf)
testPredictPlot[:, :] = np.nan
testPredictPlot[len(train_predict) + (look_back * 2) + 1:len(closedf) - 1, :] = test_predict_inverse

names = cycle(['Original close price', 'Test predicted close price'])

plotdf = pd.DataFrame({'date': close_stock['Date'],
                       'original_close': close_stock['Close'],
                       'test_predicted_close': testPredictPlot.reshape(1, -1)[0].tolist()})

fig = px.line(plotdf, x=plotdf['date'], y=[plotdf['original_close'], plotdf['test_predicted_close']],
              labels={'value': 'Close price', 'date': 'Date'})
fig.update_layout(title_text='Comparison between original close price vs predicted close price',
                  plot_bgcolor='white', font_size=15, font_color='black', legend_title_text='Close Price')
fig.for_each_trace(lambda t: t.update(name=next(names)))

fig.update_xaxes(showgrid=False)
fig.update_yaxes(showgrid=False)
fig.show()
```
------------------------------------- 32
```python
# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt

# Load the dataset
# Assuming the dataset is in a CSV file with columns 'Date' and 'Close'
data = pd.read_csv('ETH-USD.csv', parse_dates=['Date'], index_col='Date')

# Preprocess the data
# Extract the 'Close' prices
prices = data['Close'].values

# Normalize the prices
scaler = StandardScaler()
prices_scaled = scaler.fit_transform(prices.reshape(-1, 1))

# Create sequences for the LSTM model
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(len(data) - seq_length):
        X.append(data[i:i+seq_length])
        y.append(data[i+seq_length])
    return np.array(X), np.array(y)

seq_length = 30  # Number of time steps to look back
X, y = create_sequences(prices_scaled, seq_length)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build the model
model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(seq_length, 1)))
model.add(Dropout(0.4))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.4))
model.add(Dense(32, activation='relu'))
model.add(Dense(1, activation='linear'))

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')

# Define early stopping to prevent overfitting
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])

# Evaluate the model
train_predictions = model.predict(X_train)
test_predictions = model.predict(X_test)

train_mse = mean_squared_error(y_train, train_predictions)
test_mse = mean_squared_error(y_test, test_predictions)

train_mae = mean_absolute_error(y_train, train_predictions)
test_mae = mean_absolute_error(y_test, test_predictions)

print(f'Train MSE: {train_mse}, Test MSE: {test_mse}')
print(f'Train MAE: {train_mae}, Test MAE: {test_mae}')

# Plot the training and validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Inverse transform the predictions to get actual prices
train_predictions = scaler.inverse_transform(train_predictions)
test_predictions = scaler.inverse_transform(test_predictions)
y_train = scaler.inverse_transform(y_train)
y_test = scaler.inverse_transform(y_test)

# Plot the actual vs predicted prices
plt.figure(figsize=(14, 7))
plt.plot(data.index[seq_length:len(train_predictions)+seq_length], train_predictions, label='Train Predictions', color='blue')
plt.plot(data.index[len(train_predictions)+seq_length:], test_predictions, label='Test Predictions', color='red')
plt.plot(data.index[seq_length:], prices[seq_length:], label='Actual Prices', color='green')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.show()
```
------------------------------------- 33
```python
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import TextVectorization, Embedding, Bidirectional, LSTM, Dense, Dropout
from tensorflow.keras import Model, Input
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
data = pd.read_csv('yelp_reviews.csv')  # Assuming the dataset is named 'yelp_reviews.csv'

# Preprocess the text data
def clean_text(text):
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    text = text.lower()
    return text

data['text'] = data['text'].apply(clean_text)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(data['text'], data['stars'], test_size=0.2, random_state=42)

# Tokenization and padding
max_features = 10000  # Maximum number of words to keep based on word frequency
max_len = 150  # Maximum length of the sequence

tokenizer = Tokenizer(num_words=max_features)
tokenizer.fit_on_texts(X_train)

X_train = tokenizer.texts_to_sequences(X_train)
X_test = tokenizer.texts_to_sequences(X_test)

X_train = pad_sequences(X_train, maxlen=max_len)
X_test = pad_sequences(X_test, maxlen=max_len)

# Define the model
embedding_dim = 128

inputs = Input(shape=(max_len,))
x = Embedding(input_dim=max_features, output_dim=embedding_dim)(inputs)
x = Bidirectional(LSTM(64, return_sequences=True))(x)
x = Bidirectional(LSTM(64))(x)
x = Dense(64, activation='relu')(x)
x = Dropout(0.5)(x)
outputs = Dense(5, activation='softmax')(x)  # 5 classes for star ratings 1 to 5

model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Callbacks
checkpoint_cb = ModelCheckpoint("best_model.h5", save_best_only=True)
early_stopping_cb = EarlyStopping(patience=3, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train, epochs=10, validation_split=0.1, callbacks=[checkpoint_cb, early_stopping_cb])

# Evaluate the model
score, acc = model.evaluate(X_test, y_test)
print('Test Loss =', score)
print('Test Accuracy =', acc)

# Predictions
predictions = model.predict(X_test)
y_pred = np.argmax(predictions, axis=1)

# Confusion Matrix
CM = confusion_matrix(y_test, y_pred)
CM_percent = CM.astype('float') / CM.sum(axis=1)[:, np.newaxis]
sns.heatmap(CM_percent, fmt='g', center=True, cbar=False, annot=True, cmap='Blues')
plt.show()

# Classification Report
ClassificationReport = classification_report(y_test, y_pred)
print('Classification Report is : ', ClassificationReport)
```
------------------------------------- 34
```python
# Install required libraries
pip install tf-models-official
pip install livelossplot

# Import necessary libraries
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Bidirectional
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.preprocessing import LabelEncoder
import pandas as pd
import numpy as np
from tqdm import tqdm
from livelossplot import PlotLossesKeras

# Load the dataset
data_train = pd.read_csv("path_to_train_dataset.csv")
data_test = pd.read_csv("path_to_test_dataset.csv")

# Preprocess the data
def preprocess_data(data):
    # Drop duplicates and reset index
    data = data.drop_duplicates()
    data.reset_index(drop=True, inplace=True)
    
    # Remove unwanted characters
    remove_characters = ['~', '\xa0', '\xad', '\u200b', '\u200c', '\u200d', '\u200e', '\u2060', '\ueb9a', '\uf03d', '\uf06e', '\ufeff', "\n"]
    new_list_df = []
    for sent in tqdm(data["essay"]):
        for char in remove_characters:
            if char in sent:
                sent = sent.replace(char, "")
        new_list_df.append(sent)
    
    # Tokenize the text
    tokenizer = Tokenizer(num_words=20000, filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n', split=' ')
    tokenizer.fit_on_texts(new_list_df)
    
    # Convert text to sequences
    sequences = tokenizer.texts_to_sequences(data["essay"])
    sequences = pad_sequences(sequences, maxlen=64, padding='post')
    
    # Encode labels
    le = LabelEncoder()
    labels = np.array(le.fit_transform(data["label"]))
    
    return sequences, labels

# Preprocess training and test data
train_sequences, train_labels = preprocess_data(data_train)
test_sequences, test_labels = preprocess_data(data_test)

# Build the model
def build_model():
    latent_dim = 500

    # Encoder
    encoder_inputs = Input(shape=(64,))
    enc_emb = Embedding(20000, latent_dim, trainable=True)(encoder_inputs)

    # LSTM layers
    encoder_lstm1 = LSTM(latent_dim, return_sequences=True)(enc_emb)
    encoder_lstm2 = LSTM(latent_dim, return_sequences=True)(encoder_lstm1)
    encoder_lstm3 = LSTM(latent_dim//2, return_sequences=False)(encoder_lstm2)

    # Dense layer
    decoder_dense = Dense(1, activation="sigmoid")(encoder_lstm3)

    # Define the model
    model = Model(inputs=encoder_inputs, outputs=decoder_dense)
    return model

# Compile and train the model
model = build_model()
model.compile(optimizer='adam', loss="binary_crossentropy", metrics=["accuracy"])

early_stopping = EarlyStopping(monitor='val_loss', patience=5)
model.fit(x=train_sequences, y=train_labels, validation_data=(test_sequences, test_labels),
          epochs=100, callbacks=[PlotLossesKeras(), early_stopping])

# Save the model
model.save("ai_text_detection_model.hdf5")
```
------------------------------------- 35
```python
import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, GlobalMaxPooling1D, Conv1D, MaxPooling1D
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from transformers import BertTokenizer, TFBertModel

# Load the dataset
# Assuming the dataset is in a CSV file with columns 'headline' and 'category'
df = pd.read_csv('malayalam_news_headlines.csv')

# Preprocess the data
X = df['headline'].astype(str)
y = df['category']

# Encode the labels
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)
y_categorical = tf.keras.utils.to_categorical(y_encoded)

# Split the data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y_categorical, test_size=0.2, random_state=42)

# Tokenize the text
tokenizer = Tokenizer(num_words=10000, oov_token="<OOV>")
tokenizer.fit_on_texts(X_train)

X_train_sequences = tokenizer.texts_to_sequences(X_train)
X_val_sequences = tokenizer.texts_to_sequences(X_val)

# Pad sequences to ensure uniform input size
max_length = 100  # Adjust based on your dataset
X_train_padded = pad_sequences(X_train_sequences, maxlen=max_length, padding='post', truncating='post')
X_val_padded = pad_sequences(X_val_sequences, maxlen=max_length, padding='post', truncating='post')

# Define the LSTM model
def build_lstm_model(num_classes):
    model = Sequential([
        Embedding(input_dim=10000, output_dim=128, input_length=max_length),
        LSTM(128, return_sequences=True),
        Dropout(0.2),
        LSTM(64),
        Dense(64, activation='relu'),
        Dropout(0.2),
        Dense(num_classes, activation='softmax')
    ])
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Define the Transformer model using BERT
def build_transformer_model(num_classes):
    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name="input_ids")
    attention_masks = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name="attention_masks")
    
    bert_model = TFBertModel.from_pretrained('bert-base-multilingual-cased')
    bert_output = bert_model(input_ids, attention_mask=attention_masks)[1]
    
    dense = Dense(64, activation='relu')(bert_output)
    dropout = Dropout(0.2)(dense)
    output = Dense(num_classes, activation='softmax')(dropout)
    
    model = tf.keras.models.Model(inputs=[input_ids, attention_masks], outputs=output)
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Tokenize the text for BERT
bert_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')

def encode_for_bert(texts, max_length):
    input_ids = []
    attention_masks = []
    for text in texts:
        encoded = bert_tokenizer.encode_plus(
            text,
            add_special_tokens=True,
            max_length=max_length,
            pad_to_max_length=True,
            return_attention_mask=True,
            return_tensors='tf',
        )
        input_ids.append(encoded['input_ids'])
        attention_masks.append(encoded['attention_mask'])
    return np.array(input_ids), np.array(attention_masks)

X_train_input_ids, X_train_attention_masks = encode_for_bert(X_train, max_length)
X_val_input_ids, X_val_attention_masks = encode_for_bert(X_val, max_length)

# Build and train the LSTM model
lstm_model = build_lstm_model(num_classes=y_categorical.shape[1])
lstm_model.summary()

early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-7, verbose=1)

lstm_history = lstm_model.fit(
    X_train_padded, y_train,
    validation_data=(X_val_padded, y_val),
    epochs=10,
    batch_size=32,
    callbacks=[early_stopping, reduce_lr]
)

# Build and train the Transformer model
transformer_model = build_transformer_model(num_classes=y_categorical.shape[1])
transformer_model.summary()

transformer_history = transformer_model.fit(
    [X_train_input_ids, X_train_attention_masks], y_train,
    validation_data=([X_val_input_ids, X_val_attention_masks], y_val),
    epochs=10,
    batch_size=32,
    callbacks=[early_stopping, reduce_lr]
)

# Evaluate the models
lstm_loss, lstm_accuracy = lstm_model.evaluate(X_val_padded, y_val, verbose=2)
print(f"LSTM Model - Validation Accuracy: {lstm_accuracy*100:.2f}%")

transformer_loss, transformer_accuracy = transformer_model.evaluate([X_val_input_ids, X_val_attention_masks], y_val, verbose=2)
print(f"Transformer Model - Validation Accuracy: {transformer_accuracy*100:.2f}%")

# Example text to predict category
new_headlines = [
    "  ",
    " ",
]

# Preprocess the new headlines for LSTM
new_headlines_sequences = tokenizer.texts_to_sequences(new_headlines)
new_headlines_padded = pad_sequences(new_headlines_sequences, maxlen=max_length, padding='post')

# Predict using LSTM model
lstm_predictions = lstm_model.predict(new_headlines_padded)
lstm_predicted_classes = np.argmax(lstm_predictions, axis=1)
lstm_predicted_labels = label_encoder.inverse_transform(lstm_predicted_classes)

for headline, label in zip(new_headlines, lstm_predicted_labels):
    print(f"Headline: {headline}\nPredicted Category (LSTM): {label}\n")

# Preprocess the new headlines for Transformer
new_headlines_input_ids, new_headlines_attention_masks = encode_for_bert(new_headlines, max_length)

# Predict using Transformer model
transformer_predictions = transformer_model.predict([new_headlines_input_ids, new_headlines_attention_masks])
transformer_predicted_classes = np.argmax(transformer_predictions, axis=1)
transformer_predicted_labels = label_encoder.inverse_transform(transformer_predicted_classes)

for headline, label in zip(new_headlines, transformer_predicted_labels):
    print(f"Headline: {headline}\nPredicted Category (Transformer): {label}\n")
```
------------------------------------- 36
```python
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Dropout, GlobalMaxPooling1D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from transformers import BertTokenizer, TFBertModel

# Load the dataset
df = pd.read_csv('movie_reviews.csv')

# Preprocess the data
reviews = df['review'].values
labels = df['sentiment'].map({'Fresh': 1, 'Rotten': 0}).values

# Tokenize the reviews using BERT tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encoded_reviews = [tokenizer.encode(review, add_special_tokens=True) for review in reviews]

# Pad sequences to the same length
max_len = 128
padded_reviews = pad_sequences(encoded_reviews, maxlen=max_len, padding='post', truncating='post')

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(padded_reviews, labels, test_size=0.2, random_state=42)

# Build the BERT model
def build_bert_model(max_len):
    # Input layer for token ids
    input_ids = Input(shape=(max_len,), dtype=tf.int32, name="input_ids")
    
    # BERT layer
    bert_layer = TFBertModel.from_pretrained('bert-base-uncased')
    bert_output = bert_layer(input_ids)[0]
    
    # Pooling layer to get a fixed-size vector
    pooled_output = GlobalMaxPooling1D()(bert_output)
    
    # Dropout for regularization
    dropout = Dropout(0.3)(pooled_output)
    
    # Output layer with sigmoid activation for binary classification
    output = Dense(1, activation='sigmoid')(dropout)
    
    # Compile the model
    model = Model(inputs=input_ids, outputs=output)
    model.compile(optimizer=Adam(learning_rate=2e-5), loss='binary_crossentropy', metrics=['accuracy'])
    
    return model

# Create and compile the model
model = build_bert_model(max_len)
model.summary()

# Train the model
history = model.fit(X_train, y_train, batch_size=32, epochs=3, validation_split=0.1)

# Evaluate the model
y_pred = model.predict(X_test)
y_pred = np.int64(y_pred > 0.5)

# Print classification report and confusion matrix
print(classification_report(y_test, y_pred, target_names=['Rotten', 'Fresh']))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))
```
------------------------------------- 37
```python
import pandas as pd
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Embedding, Dropout, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score

# Load the dataset
# Assuming the dataset is in a CSV file with columns 'query' and 'label'
# 'query' contains the SQL queries and 'label' contains 0 for normal queries and 1 for SQL injection attacks
data = pd.read_csv('sql_injection_dataset.csv')

# Preprocess the data
# Convert queries to character and symbol indices
max_length = 1000
vocab_size = 128  # ASCII characters

def preprocess_query(query):
    return [ord(char) for char in query]

X = np.array([preprocess_query(query) for query in data['query']])
y = np.array(data['label'])

# Pad sequences to ensure uniform length
X = pad_sequences(X, maxlen=max_length, padding='post')

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build the model
model = Sequential()
model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_length))
model.add(Bidirectional(LSTM(128, return_sequences=True)))
model.add(Bidirectional(LSTM(128)))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))

# Evaluate the model
y_pred = model.predict(X_test)
y_pred = (y_pred > 0.5).astype(int)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
```
------------------------------------- 38
```python
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Dense, Attention, Concatenate
from sklearn.model_selection import train_test_split

# Download necessary NLTK data
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')

# Load the dataset
data = pd.read_csv('news_articles.csv')

# Preprocessing
data['text'] = data['text'].astype(str)
data['title'] = data['title'].astype(str)

# Split the data into training and testing sets
train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)

# Preprocessing functions
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()
url_pattern = re.compile(r'https?://\S+')

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text)
    text = url_pattern.sub('', text)
    tokens = word_tokenize(text)
    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalnum() and token not in stop_words]
    return ' '.join(tokens)

# Apply preprocessing to the training and testing data
train_data['preprocessed_text'] = train_data['text'].apply(preprocess_text)
train_data['preprocessed_title'] = train_data['title'].apply(preprocess_text)

test_data['preprocessed_text'] = test_data['text'].apply(preprocess_text)
test_data['preprocessed_title'] = test_data['title'].apply(preprocess_text)

# Tokenization
tokenizer = Tokenizer()
tokenizer.fit_on_texts(train_data['preprocessed_text'] + train_data['preprocessed_title'])

train_text_sequences = tokenizer.texts_to_sequences(train_data['preprocessed_text'])
train_title_sequences = tokenizer.texts_to_sequences(train_data['preprocessed_title'])

test_text_sequences = tokenizer.texts_to_sequences(test_data['preprocessed_text'])
test_title_sequences = tokenizer.texts_to_sequences(test_data['preprocessed_title'])

# Padding sequences
max_text_length = 500
max_title_length = 50

train_text_padded = pad_sequences(train_text_sequences, maxlen=max_text_length, padding='post')
train_title_padded = pad_sequences(train_title_sequences, maxlen=max_title_length, padding='post')

test_text_padded = pad_sequences(test_text_sequences, maxlen=max_text_length, padding='post')
test_title_padded = pad_sequences(test_title_sequences, maxlen=max_title_length, padding='post')

# Model Building
embedding_dim = 128
lstm_units = 128

# Encoder
encoder_inputs = Input(shape=(max_text_length,))
encoder_embedding = tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim)(encoder_inputs)
encoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)
encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)
encoder_states = [state_h, state_c]

# Decoder
decoder_inputs = Input(shape=(max_title_length,))
decoder_embedding = tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim)(decoder_inputs)
decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)
decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)

# Attention Mechanism
attention = Attention()([decoder_outputs, encoder_outputs])
decoder_concat = Concatenate(axis=-1)([decoder_outputs, attention])

# Output layer
decoder_dense = Dense(len(tokenizer.word_index) + 1, activation='softmax')
decoder_outputs = decoder_dense(decoder_concat)

# Model
model = Model([encoder_inputs, decoder_inputs], decoder_outputs)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Training
model.fit([train_text_padded, train_title_padded[:, :-1]], train_title_padded[:, 1:],
          validation_data=([test_text_padded, test_title_padded[:, :-1]], test_title_padded[:, 1:]),
          epochs=10, batch_size=64)

# Save the model
model.save('text_summarization_model.h5')
```
------------------------------------- 39
```python
import numpy as np
import pandas as pd
import re
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, TimeDistributed
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import warnings
import nltk
from nltk.corpus import stopwords
from tqdm import tqdm

# Download necessary NLTK data
nltk.download('stopwords')

# Suppress warnings
warnings.filterwarnings("ignore")

# Load the dataset
def load_dataset(file_path):
    encodings_to_try = ['utf-8', 'latin1', 'ISO-8859-1', 'utf-16']
    for encoding in encodings_to_try:
        try:
            df = pd.read_csv(file_path, encoding=encoding)
            print(f"Successfully read CSV file using encoding: {encoding}")
            return df
        except UnicodeDecodeError:
            print(f"Failed to read CSV file using encoding: {encoding}")
    raise Exception("Failed to read CSV file with any encoding")

# Preprocess text data
def text_cleaner(text):
    arabic_stopwords = set(stopwords.words('arabic'))
    cleaned_text = []
    for sentence in text:
        sentence = re.sub(r'\W', ' ', str(sentence))  # Remove non-word characters
        sentence = re.sub(r'\s+', ' ', sentence)  # Remove extra spaces
        sentence = ' '.join([word for word in sentence.split() if word not in arabic_stopwords])  # Remove stopwords
        cleaned_text.append(sentence)
    return cleaned_text

# Load and preprocess data
file_path = 'path_to_your_arabic_dataset.csv'
data = load_dataset(file_path)
data['text'] = text_cleaner(data['text'])
data['summary'] = text_cleaner(data['summary'])

# Tokenization and padding
max_text_len = 100
max_summary_len = 15

x_tokenizer = Tokenizer()
x_tokenizer.fit_on_texts(data['text'])
x_train_seq = x_tokenizer.texts_to_sequences(data['text'])
xtrain = pad_sequences(x_train_seq, maxlen=max_text_len, padding='post')

y_tokenizer = Tokenizer()
y_tokenizer.fit_on_texts(data['summary'])
y_train_seq = y_tokenizer.texts_to_sequences(data['summary'])
ytrain = pad_sequences(y_train_seq, maxlen=max_summary_len, padding='post')

# Model architecture
latent_dim = 300
embedding_dim = 200

encoder_inputs = Input(shape=(max_text_len,))
enc_emb = Embedding(input_dim=len(x_tokenizer.word_index) + 1, output_dim=embedding_dim, trainable=True)(encoder_inputs)
encoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.2, recurrent_dropout=0.2)
encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)

decoder_inputs = Input(shape=(None,))
dec_emb_layer = Embedding(input_dim=len(y_tokenizer.word_index) + 1, output_dim=embedding_dim, trainable=True)
dec_emb = dec_emb_layer(decoder_inputs)
decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.2, recurrent_dropout=0.2)
decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])
decoder_dense = TimeDistributed(Dense(len(y_tokenizer.word_index) + 1, activation='softmax'))
decoder_outputs = decoder_dense(decoder_outputs)

model = Model([encoder_inputs, decoder_inputs], decoder_outputs)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')

# Callbacks
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)
mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)

# Training
history = model.fit([xtrain, ytrain[:, :-1]], ytrain.reshape(ytrain.shape[0], ytrain.shape[1], 1)[:, 1:],
                    epochs=50, callbacks=[es, mc], batch_size=128, validation_split=0.1)

# Inference setup
encoder_model = Model(encoder_inputs, [encoder_outputs, state_h, state_c])

decoder_state_input_h = Input(shape=(latent_dim,))
decoder_state_input_c = Input(shape=(latent_dim,))
decoder_hidden_state_input = Input(shape=(max_text_len, latent_dim))

dec_emb2 = dec_emb_layer(decoder_inputs)
decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])
decoder_outputs2 = decoder_dense(decoder_outputs2)

decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],
                      [decoder_outputs2] + [state_h2, state_c2])

# Decoding function
def decode_sequence(input_seq):
    e_out, e_h, e_c = encoder_model.predict(input_seq)
    target_seq = np.zeros((1, 1))
    target_seq[0, 0] = y_tokenizer.word_index['sostok']

    stop_condition = False
    decoded_sentence = ''
    while not stop_condition:
        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])
        sampled_token_index = np.argmax(output_tokens[0, -1, :])
        sampled_token = y_tokenizer.index_word[sampled_token_index]

        if sampled_token != 'eostok':
            decoded_sentence += ' ' + sampled_token

        if sampled_token == 'eostok' or len(decoded_sentence.split()) >= (max_summary_len - 1):
            stop_condition = True

        target_seq = np.zeros((1, 1))
        target_seq[0, 0] = sampled_token_index
        e_h, e_c = h, c

    return decoded_sentence

# Example usage
for i in range(5):
    print("Review:", data['text'][i])
    print("Original summary:", data['summary'][i])
    print("Predicted summary:", decode_sequence(xtrain[i].reshape(1, max_text_len)))
    print("\n")

# Save model and tokenizers
model.save('text_summarization_model.h5')

import pickle
with open('x_tokenizer.pkl', 'wb') as handle:
    pickle.dump(x_tokenizer, handle)
with open('y_tokenizer.pkl', 'wb') as handle:
    pickle.dump(y_tokenizer, handle)
```
------------------------------------- 40
```python
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.layers import Dense, LSTM, Embedding, Input, TimeDistributed, Concatenate
from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint
from tensorflow.keras.models import Model, load_model, Sequential
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns

# Load and preprocess the dataset
df1 = pd.read_csv('file1.csv')
df2 = pd.read_csv('file2.csv')
df = pd.concat([df1, df2], ignore_index=True)
df = df[['text', 'summary']]
df.dropna(inplace=True)
df.drop_duplicates(inplace=True)
df['summary'] = df['summary'].apply(lambda x: '<start> ' + x + ' <end>')

# Tokenization and padding
max_text_len = 190
max_summary_len = 80

x_tokenizer = Tokenizer()
x_tokenizer.fit_on_texts(df.text)
text_sequences = x_tokenizer.texts_to_sequences(df.text)
text_pad_sequences = pad_sequences(text_sequences, maxlen=max_text_len, padding='post')

y_tokenizer = Tokenizer()
y_tokenizer.fit_on_texts(df.summary)
summary_sequences = y_tokenizer.texts_to_sequences(df.summary)
summary_pad_sequences = pad_sequences(summary_sequences, maxlen=max_summary_len, padding='post')

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(text_pad_sequences, summary_pad_sequences, test_size=0.25, shuffle=True, random_state=101)

# Define the Luong Attention mechanism
class LuongAttention(tf.keras.layers.Layer):
    def __init__(self, units):
        super(LuongAttention, self).__init__()
        self.W1 = tf.keras.layers.Dense(units)
        self.W2 = tf.keras.layers.Dense(units)
        self.V = tf.keras.layers.Dense(1)

    def call(self, query, values):
        query_with_time_axis = tf.expand_dims(query, 1)
        values_transposed = tf.transpose(values, perm=[0, 2, 1])
        score = tf.transpose(tf.matmul(query_with_time_axis, values_transposed), perm=[0, 2, 1])
        attention_weights = tf.nn.softmax(score, axis=1)
        context_vector = attention_weights * values
        context_vector = tf.reduce_sum(context_vector, axis=1)
        return context_vector, attention_weights

# Define the model architecture
latent_dim = 300
embedding_dim = 200

# Encoder
encoder_inputs = Input(shape=(max_text_len,))
enc_emb = Embedding(len(x_tokenizer.word_index) + 1, embedding_dim, trainable=True)(encoder_inputs)
encoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)
encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)
encoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)
encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)
encoder_lstm3 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)
encoder_outputs, state_h, state_c = encoder_lstm3(encoder_output2)

# Decoder
decoder_inputs = Input(shape=(max_summary_len,))
dec_emb_layer = Embedding(len(y_tokenizer.word_index) + 1, embedding_dim, trainable=True)
dec_emb = dec_emb_layer(decoder_inputs)
decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)
decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])

# Attention mechanism
attention = LuongAttention(latent_dim)
context_vector, attention_weights = attention(decoder_outputs, encoder_outputs)
decoder_combined_context = Concatenate(axis=-1)([decoder_outputs, context_vector])

# Dense layer
decoder_dense = TimeDistributed(Dense(len(y_tokenizer.word_index) + 1, activation='softmax'))
decoder_outputs = decoder_dense(decoder_combined_context)

# Define the model
model = Model([encoder_inputs, decoder_inputs], decoder_outputs)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Callbacks
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)
mc = ModelCheckpoint('text_summarizer.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)

# Train the model
history = model.fit(
    [X_train, y_train[:, :-1]], 
    y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:, 1:], 
    epochs=100, 
    batch_size=128, 
    validation_data=([X_test, y_test[:, :-1]], y_test.reshape(y_test.shape[0], y_test.shape[1], 1)[:, 1:]), 
    callbacks=[es, mc]
)

# Plot training history
plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='val')
plt.legend()
plt.show()

# Inference setup
encoder_model = Model(encoder_inputs, [encoder_outputs, state_h, state_c])

decoder_state_input_h = Input(shape=(latent_dim,))
decoder_state_input_c = Input(shape=(latent_dim,))
decoder_hidden_state_input = Input(shape=(max_text_len, latent_dim))

dec_emb2 = dec_emb_layer(decoder_inputs)
decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])
context_vector2, attention_weights2 = attention(decoder_outputs2, decoder_hidden_state_input)
decoder_combined_context2 = Concatenate(axis=-1)([decoder_outputs2, context_vector2])
decoder_outputs2 = decoder_dense(decoder_combined_context2)

decoder_model = Model(
    [decoder_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],
    [decoder_outputs2] + [state_h2, state_c2]
)

# Decode sequence function
def decode_sequence(input_seq):
    e_out, e_h, e_c = encoder_model.predict(input_seq)
    target_seq = np.zeros((1, 1))
    target_seq[0, 0] = y_tokenizer.word_index['start']
    stop_condition = False
    decoded_sentence = ''
    while not stop_condition:
        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])
        sampled_token_index = np.argmax(output_tokens[0, -1, :])
        sampled_token = y_tokenizer.index_word[sampled_token_index]
        if sampled_token != 'end':
            decoded_sentence += ' ' + sampled_token
        if sampled_token == 'end' or len(decoded_sentence.split()) >= (max_summary_len - 1):
            stop_condition = True
        target_seq = np.zeros((1, 1))
        target_seq[0, 0] = sampled_token_index
        e_h, e_c = h, c
    return decoded_sentence

# Test the model
for i in range(10):
    print("Review:", ' '.join([x_tokenizer.index_word[idx] for idx in X_test[i] if idx != 0]))
    print("Original summary:", ' '.join([y_tokenizer.index_word[idx] for idx in y_test[i] if idx != 0 and idx != y_tokenizer.word_index['start'] and idx != y_tokenizer.word_index['end']]))
    print("Predicted summary:", decode_sequence(X_test[i].reshape(1, max_text_len)))
    print("\n")
```
------------------------------------- 41
```python
import tensorflow as tf
import numpy as np

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, LSTM, GRU, Embedding, Attention
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.utils import pad_sequences

# Constants
MARK_START = "startseq "
MARK_END = " endseq"

# Load and preprocess the dataset
data_src = []
data_dest = []

for line in open('path_to_dataset.txt', encoding='UTF-8'):
    en_text, fr_text = line.rstrip().split('\t')
    fr_text = MARK_START + fr_text + MARK_END
    data_src.append(en_text)
    data_dest.append(fr_text)

# Tokenization and preprocessing functions
def tokenize_texts(texts, num_words=None):
    tokenizer = Tokenizer(num_words=num_words)
    tokenizer.fit_on_texts(texts)
    return tokenizer

def reverse_tokens(tokens):
    return [list(reversed(x)) for x in tokens]

def pad_tokens(tokens, maxlen, padding, truncating):
    return pad_sequences(tokens, maxlen=maxlen, padding=padding, truncating=truncating)

def calculate_max_tokens(num_tokens):
    return int(np.mean(num_tokens) + 2 * np.std(num_tokens))

def tokenize_and_preprocess(texts, padding, reverse=False, num_words=None):
    tokenizer = tokenize_texts(texts, num_words=num_words)
    index_to_word = dict(zip(tokenizer.word_index.values(), tokenizer.word_index.keys()))
    
    tokens = tokenizer.texts_to_sequences(texts)

    if reverse:
        tokens = reverse_tokens(tokens)
        truncating = "pre"
    else:
        truncating = "post"

    num_tokens = [len(x) for x in tokens]
    max_tokens = calculate_max_tokens(num_tokens)

    tokens_padded = pad_tokens(tokens, maxlen=max_tokens, padding=padding, truncating=truncating)

    return {
        'tokenizer': tokenizer,
        'index_to_word': index_to_word,
        'tokens': tokens,
        'max_tokens': max_tokens,
        'tokens_padded': tokens_padded,
    }

# Tokenize and preprocess the data
tokenizer_src = tokenize_and_preprocess(texts=data_src, padding="pre", reverse=True, num_words=None)
tokenizer_dest = tokenize_and_preprocess(texts=data_dest, padding="post", reverse=False, num_words=None)

tokens_src = tokenizer_src["tokens_padded"]
tokens_dest = tokenizer_dest["tokens_padded"]

# Prepare the data for the model
encoder_input_data = tokens_src
decoder_input_data = tokens_dest[:, :-1]
decoder_output_data = tokens_dest[:, 1:]

# Model parameters
num_encoder_words = len(tokenizer_src['tokenizer'].word_index)
num_decoder_words = len(tokenizer_dest['tokenizer'].word_index)
embedding_size = 100
state_size = 256
dropout_rate = 0.2

# Encoder model
encoder_input = Input(shape=(None,), name='encoder_input')
encoder_embedding = Embedding(input_dim=num_encoder_words, output_dim=embedding_size, name='encoder_embedding')
encoder_lstm1 = LSTM(state_size, dropout=dropout_rate, return_sequences=True, name='encoder_lstm1')
encoder_lstm2 = LSTM(state_size, dropout=dropout_rate, return_sequences=True, name='encoder_lstm2')
encoder_lstm3 = LSTM(state_size, dropout=dropout_rate, return_sequences=False, name='encoder_lstm3')

def connect_encoder():
    net = encoder_input
    net = encoder_embedding(net)
    net = encoder_lstm1(net)
    net = encoder_lstm2(net)
    net = encoder_lstm3(net)
    encoder_output = net
    return encoder_output

encoder_output = connect_encoder()

# Decoder model with attention
decoder_initial_state = Input(shape=(state_size,), name='decoder_initial_state')
decoder_input = Input(shape=(None,), name='decoder_input')
decoder_embedding = Embedding(input_dim=num_decoder_words, output_dim=embedding_size, name='decoder_embedding')
decoder_lstm1 = LSTM(state_size, dropout=dropout_rate, return_sequences=True, name='decoder_lstm1')
decoder_lstm2 = LSTM(state_size, dropout=dropout_rate, return_sequences=True, name='decoder_lstm2')
decoder_lstm3 = LSTM(state_size, dropout=dropout_rate, return_sequences=True, name='decoder_lstm3')
decoder_dense = Dense(num_decoder_words, activation='softmax', name='decoder_output')

attention = Attention()([decoder_lstm3.output, encoder_lstm2.output])
decoder_concat = tf.keras.layers.Concatenate()([decoder_lstm3.output, attention])
decoder_output = decoder_dense(decoder_concat)

def connect_decoder(initial_state):
    net = decoder_input
    net = decoder_embedding(net)
    net = decoder_lstm1(net, initial_state=[initial_state, initial_state])
    net = decoder_lstm2(net, initial_state=[initial_state, initial_state])
    net = decoder_lstm3(net, initial_state=[initial_state, initial_state])
    return decoder_output

decoder_output = connect_decoder(initial_state=encoder_output)

# Compile the model
model_train = Model(inputs=[encoder_input, decoder_input], outputs=[decoder_output])
optimizer = RMSprop(lr=0.001)
model_train.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy')

# Checkpoint callback
path_checkpoint = 'checkpoint.keras'
checkpoint = ModelCheckpoint(filepath=path_checkpoint, monitor='val_loss', verbose=1, save_best_only=True, mode='min', save_weights_only=True)

# Train the model
x_data = {'encoder_input': encoder_input_data, 'decoder_input': decoder_input_data}
y_data = {'decoder_output': decoder_output_data}

model_train.fit(x=x_data, y=y_data, batch_size=512, epochs=20, callbacks=[checkpoint])

# Save the model weights
model_train.save_weights("model_weights.keras")

# Translation function
def translate(input_text, true_output_text=None):
    input_tokens = tokenizer_src['tokenizer'].texts_to_sequences([input_text])
    input_tokens = pad_sequences(input_tokens, maxlen=tokenizer_src['max_tokens'], padding='pre')
    initial_state = model_train.predict(input_tokens)
    max_tokens = tokenizer_dest['max_tokens']
    
    decoder_input_data = np.zeros(shape=(1, max_tokens), dtype=np.int32)
    
    token_int = tokenizer_dest['tokenizer'].word_index[MARK_START.strip()]
    output_text = ''
    count_tokens = 0
    
    while token_int != tokenizer_dest['tokenizer'].word_index[MARK_END.strip()] and count_tokens < max_tokens:
        decoder_input_data[0, count_tokens] = token_int
        x_data = {'decoder_initial_state': initial_state, 'decoder_input': decoder_input_data}
        
        decoder_output = model_train.predict(x_data)
        token_onehot = decoder_output[0, count_tokens, :]

        token_int = np.argmax(token_onehot)
        sampled_word = tokenizer_dest['index_to_word'][token_int]
        output_text += ' ' + sampled_word
        count_tokens += 1
        
    print('Input text:')
    print(input_text)
    print()
    
    print('Translated text:')
    print(output_text)
    print()
    
    if true_output_text is not None:
        print('True output text:')
        print(true_output_text)
        print()

# Example usage
translate(input_text=data_src[100], true_output_text=data_dest[100])
```
------------------------------------- 42
```python
import warnings
warnings.filterwarnings('ignore')

import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import seaborn as sns
from tqdm.auto import tqdm 

import re
from nltk.corpus import stopwords 
from collections import Counter 
from string import punctuation 

from sklearn.model_selection import train_test_split 

import tensorflow as tf 
from tensorflow import keras 
from tensorflow.keras.preprocessing.text import Tokenizer 
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Bidirectional, Dense, LSTM, Embedding, Concatenate, Dropout, TimeDistributed
from tensorflow.keras.losses import SparseCategoricalCrossentropy
from tensorflow.keras.optimizers import Adam

# Load the dataset
df = pd.read_csv('/path/to/turkish_to_english_dataset.csv', nrows=500000)

# Preprocessing functions
def english_preprocessing(data, col): 
    data[col] = data[col].astype(str) 
    data[col] = data[col].apply(lambda x: x.lower())
    data[col] = data[col].apply(lambda x: re.sub("[^A-Za-z\s]", "", x)) 
    data[col] = data[col].apply(lambda x: x.replace("\s+", " "))
    data[col] = data[col].apply(lambda x: " ".join([word for word in x.split()]))
    return data 

def turkish_preprocessing(data, col): 
    data[col] = data[col].astype(str) 
    data[col] = data[col].apply(lambda x: x.lower()) 
    data[col] = data[col].apply(lambda x: re.sub(r'\d', '', x))
    data[col] = data[col].apply(lambda x: re.sub(r'\s+', ' ', x))
    data[col] = data[col].apply(lambda x: re.sub(r"[-()\"#/@;:<>{}`+=~|.!?,]", "", x))
    data[col] = data[col].apply(lambda x: x.strip()) 
    data[col] = "<sos> " + data[col] + " <eos>" 
    return data

# Apply preprocessing
df = turkish_preprocessing(df, 'tr')
df = english_preprocessing(df, 'en')

# Filter sentences based on length
df["en_len"] = [len(text.split()) for text in df.en]
df['tr_len'] = [len(text.split()) for text in df.tr]

df = df[~(df['en_len'] < 5) & ~(df['en_len'] > 20)]
df = df[~(df['tr_len'] < 5) & ~(df['tr_len'] > 20)]

# Vectorization function
def Vectorization(col, MAXLEN=20): 
    sents = df[col].tolist() 
    
    # Build vocabulary 
    corpus = [word for text in df[col] for word in text.split()] 
    vocab_size = len(Counter(corpus)) 
    
    tokenizer = Tokenizer(num_words=vocab_size, oov_token="<OOV>", 
                          filters='!#$%&()*+,-/:;<=>@""[\\]^_`{|}~\t\n')
    tokenizer.fit_on_texts(sents) 
    
    tokenizer.word_index['<pad>'] = 0 
    tokenizer.index_word[0] = '<pad>' 
    
    vocab_to_idx = tokenizer.word_index 
    idx_to_vocab = tokenizer.index_word 
    
    # Text Vectorization 
    seqs = tokenizer.texts_to_sequences(sents) 
    
    pad_seqs = pad_sequences(seqs, maxlen=MAXLEN, padding='post')
    
    return vocab_to_idx, idx_to_vocab, pad_seqs, tokenizer

# Vectorize the data
en_vocab, en_inv_vocab, en_seqs, en_tokenizer = Vectorization('en')
tr_vocab, tr_inv_vocab, tr_seqs, tr_tokenizer = Vectorization('tr')

# Split the data
x_train, x_val, y_train, y_val = train_test_split(en_seqs, tr_seqs, train_size=0.80, random_state=42)

# Create TensorFlow datasets
BATCH_SIZE = 128
BUFFER_SIZE = 1000

train_set = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_set = train_set.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)

val_set = tf.data.Dataset.from_tensor_slices((x_val, y_val))
val_set = val_set.batch(BATCH_SIZE, drop_remainder=True)

# Define parameters
EMBEDDING_DIM = 256
SRC_VOCAB_SIZE = len(en_vocab) + 1
TRG_VOCAB_SIZE = len(tr_vocab) + 1
HIDDEN_DIM = 512
MAXLEN = 20
EPOCHS = 50
LR = 0.001

# Define the Attention mechanism
class Attention(Model): 
    def __init__(self, hidden_dim): 
        super(Attention, self).__init__() 
        
        self.W1 = Dense(hidden_dim) 
        self.W2 = Dense(hidden_dim) 
        self.V = Dense(1)
        
    def call(self, s_hidden, h_hidden): 
        s_hidden = tf.expand_dims(s_hidden, axis=1) 
        
        score = tf.nn.tanh(self.W1(s_hidden) + self.W2(h_hidden))
        
        attention_weights = tf.nn.softmax(self.V(score), axis=1)
        
        context_vector = attention_weights * h_hidden 
        
        context_vector = tf.reduce_sum(context_vector, axis=1)
        
        context_vector = tf.expand_dims(context_vector, axis=1)
        
        return context_vector, attention_weights 

# Define the Encoder
class Encoder(Model): 
    def __init__(self, vocab_size, embedding_dim, hidden_dim): 
        super(Encoder, self).__init__() 
        
        self.embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)
        self.lstm = Bidirectional(
            LSTM(hidden_dim // 2, return_sequences=True, return_state=True)
        )
        
    def call(self, x): 
        embed = self.embedding(x) 
        
        enc_output, forward_h, forward_c, backward_h, backward_c = self.lstm(embed) 
        
        state_h = Concatenate()([forward_h, backward_h]) 
        state_c = Concatenate()([forward_c, backward_c])
        
        return enc_output, state_h, state_c
    
    def summary(self): 
        x = tf.keras.layers.Input(shape=(None,))
        model = Model(inputs=[x], outputs=self.call(x))
        return model.summary()

encoder = Encoder(SRC_VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM)
encoder.summary()

# Define the Decoder
class Decoder(Model): 
    def __init__(self, vocab_size, embedding_dim, hidden_dim): 
        super(Decoder, self).__init__() 
        self.units = hidden_dim 
        
        self.embedding = Embedding(vocab_size, embedding_dim, mask_zero=True) 
        
        self.lstm = LSTM(hidden_dim, return_sequences=True, return_state=True) 
        
        self.attention = Attention(hidden_dim) 
        
        self.fc = TimeDistributed(Dense(vocab_size, activation='softmax'))
        
    def call(self, x, enc_output, state_h, state_c): 
        embed = self.embedding(x)
        
        context_vector, attention_weights = self.attention(state_h, enc_output) 
        
        context_vector = Concatenate(axis=-1)([context_vector, embed]) 
        
        dec_output, dec_h, dec_c = self.lstm(context_vector, initial_state=[state_h, state_c])
        
        output = self.fc(dec_output)
        
        return output, dec_h, dec_c, attention_weights
    
    def summary(self): 
        x = tf.keras.layers.Input(shape=(None,))
        enc_output = tf.keras.layers.Input(shape=(None, self.units))
        state_h = tf.keras.layers.Input(shape=(self.units,))
        state_c = tf.keras.layers.Input(shape=(self.units,))
        model = Model(inputs=[x, enc_output, state_h, state_c], outputs=self.call(x, enc_output, state_h, state_c))
        return model.summary()

decoder = Decoder(TRG_VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM)
decoder.summary()

# Define the optimizer and loss function
optimizer = Adam(learning_rate=LR)
loss_object = SparseCategoricalCrossentropy() 

def criterion(real, pred): 
    mask = tf.math.logical_not(tf.math.equal(real, 0)) 
    loss = loss_object(real, pred) 
    mask = tf.cast(mask, dtype=loss.dtype)
    loss *= mask 
    loss = tf.reduce_mean(loss)
    return loss

# Define training and validation steps
@tf.function 
def train_step(src, trg): 
    loss = 0 
    with tf.GradientTape() as tape: 
        enc_output, state_h, state_c = encoder(src)
        dec_input = tf.expand_dims(trg[:, 0], 1)
        
        for i in range(1, trg.shape[1]): 
            dec_output, state_h, state_c, _ = decoder(dec_input, enc_output, state_h, state_c)
            
            loss += criterion(trg[:, i], dec_output[:, 0, :]) 
            
            dec_input = tf.expand_dims(trg[:, i], 1)
            
    batch_loss = (loss / int(trg.shape[1])) 
    ModelWeights = encoder.trainable_variables + decoder.trainable_variables 
    gradients = tape.gradient(loss, ModelWeights)
    optimizer.apply_gradients(zip(gradients, ModelWeights))
    
    return batch_loss 

@tf.function 
def val_step(src, trg): 
    loss = 0 
    enc_output, state_h, state_c = encoder(src) 
    dec_input = tf.expand_dims(trg[:, 0], 1)
    
    for i in range(1, trg.shape[1]): 
        dec_output, state_h, state_c, _ = decoder(dec_input, enc_output, state_h, state_c)
        
        loss += criterion(trg[:, i], dec_output[:, 0, :])
        
        dec_input = tf.expand_dims(trg[:, i], 1)
        
    batch_loss = (loss / int(trg.shape[1]))
    
    return batch_loss

# Training loop
with tf.device("/GPU:0"): 
    training_losses = []
    val_losses = []
    for epoch in tqdm(range(EPOCHS)): 
        epoch_loss = [] 
        epoch_val_loss = [] 

        for x_train, y_train in train_set: 
            loss = train_step(x_train, y_train)
            epoch_loss.append(loss)

        for x_val, y_val in val_set: 
            val_loss = val_step(x_val, y_val) 
            epoch_val_loss.append(val_loss) 

        training_losses.append(np.mean(epoch_loss))
        val_losses.append(np.mean(epoch_val_loss))
        if (epoch + 1) % 10 == 0: 
            print(f"Epoch: {epoch+1}, Training Loss: {training_losses[-1]}, Validation Loss: {val_losses[-1]}\n")

# Plot training and validation losses
plt.plot(training_losses, label='train') 
plt.plot(val_losses, label='validation') 
plt.title('Training/Validation measure over Epochs') 
plt.xlabel('epoch') 
plt.ylabel('Training/Validation Losses') 
plt.legend() 
plt.show()

# Save model weights
encoder.save_weights('NMT_encoder.h5') 
decoder.save_weights('NMT_decoder.h5')

# Load model weights
encoder.load_weights('NMT_encoder.h5') 
decoder.load_weights('NMT_decoder.h5')

# Prediction function
def predict_sentence(en_input): 
    eng_seq = en_tokenizer.texts_to_sequences([en_input]) 
    en_input = pad_sequences(eng_seq, maxlen=MAXLEN, padding='post') 
    
    hidden_state, next_h, next_c = encoder(en_input) 
    
    attn_plot = [] 
    
    curr_token = np.zeros((1, 1)) 
    curr_token[0, 0] = tr_tokenizer.word_index['sos'] 
    
    pred_sent = ''
    
    for i in range(MAXLEN): 
        output, next_h, next_c, attn_w = decoder(curr_token, hidden_state, next_h, next_c)
        
        attn_plot.append(attn_w.numpy().reshape(-1, )) 
        next_token = np.argmax(output[:, 0, :], axis=1)[0] 
        next_word = tr_tokenizer.index_word[next_token] 
        
        if next_word == 'eos':
            break
        else:
            pred_sent += ' ' + next_word
            curr_token[0, 0] = next_token
            
    return pred_sent.strip(), np.array(attn_plot)

# Test the model
test_sample = df.sample(1000)

test_sample = test_sample[~(test_sample['en_len'] < 5) & ~(test_sample['en_len'] > 10)]
test_sample = test_sample[~(test_sample['tr_len'] < 5) & ~(test_sample['tr_len'] > 10)]

x_test = test_sample['en'].tolist() 
y_test = test_sample['tr'].tolist()

def plot_attention(attention, sent, pred_sent): 
    plt.figure(figsize=(9, 6))
    plt.rcParams['font.size'] = 7
    g = sns.heatmap(attention, annot=True, fmt='.2f')
    g.set_xticklabels(sent)
    g.set_yticklabels(pred_sent)
    plt.show()

for en_sent in x_test[-10:]:
    result, attention_plot = predict_sentence(en_sent)
    print(f"English sentence: {en_sent}")
    print(f"Predicted translation: {result}")
    attention_plot = attention_plot[:len(result.split()), :len(en_sent.split())]
    plot_attention(attention_plot, en_sent.split(), result.split())
```
------------------------------------- 43
```python
# Libraries
import pathlib
import random
import string
import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers import TextVectorization
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import callbacks

# Load the dataset
eng_file = '/path/to/english_sentences.txt'
fr_file = '/path/to/french_sentences.txt'

with open(eng_file, 'r') as file:
    english_sentences = file.readlines()
with open(fr_file, 'r') as file:
    french_sentences = file.readlines()

english_sentences = [sentence.rstrip('\n').lower() for sentence in english_sentences]
french_sentences = [sentence.rstrip('\n') for sentence in french_sentences]

# Filter out sentences which contains letters other than whats listed below
french_vocabulary = [ ' ', '!', '"', '#', '$', '%', '&', "'", '(', ')', '*', '+', ',', '-', '.', '/',
                      '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', '',
                      "", "", "", "", "", "", "", "", "", "", "", "", "", "",
                      "a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k", "l", "m", "n", "o", "p", "q", "r", "s", "t", "u", "v", "w", "x", "y", "z"]

english_vocabulary = [' ', '!', '"', '#', '$', '%', '&', "'", '(', ')', '*', '+', ',', '-', '.', '/',
                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',
                        ':', '<', '=', '>', '?', '@',
                        '[', '\\', ']', '^', '_', '`',
                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',
                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',
                        'y', 'z',
                        '{', '|', '}', '~']

def is_valid_tokens(sentence, vocab):
    for token in list(set(sentence)):
        if token not in vocab:
            return False
    return True

valid_sentence_indicies = []
for index in range(len(english_sentences[:500000])):
    french_sentence, english_sentence = french_sentences[index], english_sentences[index]
    if is_valid_tokens(french_sentence, french_vocabulary) \
      and is_valid_tokens(english_sentence, english_vocabulary):
        valid_sentence_indicies.append(index)

TOTAL_SENTENCES = 200000 # only the first 200000 valid sentences are taken to train the model
x = [english_sentences[i] for i in valid_sentence_indicies[:TOTAL_SENTENCES]]
y = [french_sentences[i] for i in valid_sentence_indicies[:TOTAL_SENTENCES]]

dataset = pd.DataFrame({"English": x, "French": y})
dataset.info()

dataset.sample(5)

dataset.to_csv('/path/to/save/data.csv', index=False)
dataset = pd.read_csv('/path/to/save/data.csv')
dataset.head()

text_pairs = []

# Adding [start] and [end] tokens
for i in range(dataset.shape[0]):
    eng = str(dataset["English"][i])
    fr = "[start] " + str(dataset["French"][i]) + " [end]"
    text_pairs.append((eng, fr))

train_sample_size = len(text_pairs) - int(0.1 * len(text_pairs))
train_pairs = text_pairs[:train_sample_size]
test_pairs = text_pairs[train_sample_size:]

print("Total pairs :", len(text_pairs))
print("Train pairs :", len(train_pairs))
print("Test pairs :", len(test_pairs))

strip_chars = string.punctuation + "|"
strip_chars = strip_chars.replace("[", "")
strip_chars = strip_chars.replace("]", "")
strip_chars = strip_chars.replace('""', "")

vocab_size = 50000
sequence_length = 30
batch_size = 128

def custom_standardization(input_string):
    lowercase = tf.strings.lower(input_string)
    return tf.strings.regex_replace(lowercase, "[%s]" % re.escape(strip_chars), "")

eng_vectorization = TextVectorization(
    max_tokens=vocab_size, output_mode="int", output_sequence_length=sequence_length,
)

fr_vectorization = TextVectorization(
    max_tokens=vocab_size,
    output_mode="int",
    output_sequence_length=sequence_length + 1,
    standardize=custom_standardization,
)

train_eng_texts = [pair[0] for pair in train_pairs]
train_fr_texts = [pair[1] for pair in train_pairs]

# Adapt the TextVectorization layers to the training data
eng_vectorization.adapt(train_eng_texts)
fr_vectorization.adapt(train_fr_texts)

import json

# Get the vocabulary
eng_vocab = eng_vectorization.get_vocabulary()
fr_vocab = fr_vectorization.get_vocabulary()

# Save the vocabulary
with open('/path/to/save/eng_vocab.json', 'w') as f:
    json.dump(eng_vocab, f)
with open('/path/to/save/fr_vocab.json', 'w') as f:
    json.dump(fr_vocab, f)

# Load the vocabulary
with open('/path/to/save/eng_vocab.json', 'r') as f:
    eng_vocab = json.load(f)
with open('/path/to/save/fr_vocab.json', 'r') as f:
    fr_vocab = json.load(f)

# Create a TextVectorization layer with the loaded vocabulary
eng_vectorization = TextVectorization(vocabulary=eng_vocab, output_mode="int", output_sequence_length=sequence_length)
fr_vectorization = TextVectorization(vocabulary=fr_vocab, output_mode="int",
    output_sequence_length=sequence_length + 1,
    standardize=custom_standardization)

def format_dataset(eng, fr):
    eng = eng_vectorization(eng)
    fr = fr_vectorization(fr)
    return ({"encoder_inputs": eng, "decoder_inputs": fr[:, :-1],}, fr[:, 1:])

def make_dataset(pairs):
    eng_texts, fr_texts = zip(*pairs)
    eng_texts = list(eng_texts)
    fr_texts = list(fr_texts)
    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, fr_texts))
    dataset = dataset.batch(batch_size)
    dataset = dataset.map(format_dataset)
    return dataset.shuffle(2048).prefetch(16).cache()

train_ds = make_dataset(train_pairs)
test_ds = make_dataset(test_pairs)

for inputs, targets in train_ds.take(2):
    print(f'inputs["encoder_inputs"].shape: {inputs["encoder_inputs"].shape}')
    print(f'inputs["decoder_inputs"].shape: {inputs["decoder_inputs"].shape}')
    print(f"targets.shape: {targets.shape}")

class TransformerEncoder(layers.Layer):
    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):
        super().__init__(**kwargs)
        self.embed_dim = embed_dim
        self.dense_dim = dense_dim
        self.num_heads = num_heads
        self.attention = layers.MultiHeadAttention(
            num_heads=num_heads, key_dim=embed_dim
        )
        self.dense_proj = keras.Sequential(
            [layers.Dense(dense_dim, activation="relu"), layers.Dense(embed_dim),]
        )
        self.layernorm_1 = layers.LayerNormalization()
        self.layernorm_2 = layers.LayerNormalization()
        self.supports_masking = True

    def call(self, inputs, mask=None):
        if mask is not None:
            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype="int32")
        attention_output = self.attention(
            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask
        )
        proj_input = self.layernorm_1(inputs + attention_output)
        proj_output = self.dense_proj(proj_input)
        return self.layernorm_2(proj_input + proj_output)

class PositionalEmbedding(layers.Layer):
    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):
        super().__init__(**kwargs)
        self.token_embeddings = layers.Embedding(
            input_dim=vocab_size, output_dim=embed_dim
        )
        self.position_embeddings = layers.Embedding(
            input_dim=sequence_length, output_dim=embed_dim
        )
        self.sequence_length = sequence_length
        self.vocab_size = vocab_size
        self.embed_dim = embed_dim

    def call(self, inputs):
        length = tf.shape(inputs)[-1]
        positions = tf.range(start=0, limit=length, delta=1)
        embedded_tokens = self.token_embeddings(inputs)
        embedded_positions = self.position_embeddings(positions)
        embedded = embedded_tokens + embedded_positions
        
        # Compute mask
        mask = tf.not_equal(inputs, 0)
        return embedded, mask

class TransformerDecoder(layers.Layer):
    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):
        super().__init__(**kwargs)
        self.embed_dim = embed_dim
        self.latent_dim = latent_dim
        self.num_heads = num_heads
        self.attention_1 = layers.MultiHeadAttention(
            num_heads=num_heads, key_dim=embed_dim
        )
        self.attention_2 = layers.MultiHeadAttention(
            num_heads=num_heads, key_dim=embed_dim
        )
        self.dense_proj = keras.Sequential(
            [layers.Dense(latent_dim, activation="relu"), layers.Dense(embed_dim),]
        )
        self.layernorm_1 = layers.LayerNormalization()
        self.layernorm_2 = layers.LayerNormalization()
        self.layernorm_3 = layers.LayerNormalization()
        self.supports_masking = True

    def call(self, inputs, encoder_outputs, mask=None):
        causal_mask = self.get_causal_attention_mask(inputs)
        if mask is not None:
            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype="int32")
            padding_mask = tf.minimum(padding_mask, causal_mask)

        attention_output_1 = self.attention_1(
            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask
        )
        out_1 = self.layernorm_1(inputs + attention_output_1)

        attention_output_2  = self.attention_2(
            query=out_1,
            value=encoder_outputs,
            key=encoder_outputs,
            attention_mask=padding_mask,
        )

        out_2 = self.layernorm_2(out_1 + attention_output_2)

        proj_output = self.dense_proj(out_2)
        return self.layernorm_3(out_2 + proj_output)

    def get_causal_attention_mask(self, inputs):
        input_shape = tf.shape(inputs)
        batch_size, sequence_length = input_shape[0], input_shape[1]
        i = tf.range(sequence_length)[:, tf.newaxis]
        j = tf.range(sequence_length)
        mask = tf.cast(i >= j, dtype="int32")
        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))
        mult = tf.concat(
            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],
            axis=0,
        )
        return tf.tile(mask, mult)

embed_dim = 512
latent_dim = 1024
num_heads = 8

encoder_inputs = keras.Input(shape=(None,), dtype="int64", name="encoder_inputs")
x, mask = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)
encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x, mask)
encoder = keras.Model(encoder_inputs, encoder_outputs)

decoder_inputs = keras.Input(shape=(None,), dtype="int64", name="decoder_inputs")
encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name="decoder_state_inputs")
x, mask = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)
x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs, mask)
x = layers.Dropout(0.5)(x)
decoder_outputs = layers.Dense(vocab_size, activation="softmax")(x)
decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)

decoder_outputs = decoder([decoder_inputs, encoder_outputs])
transformer = keras.Model(
    [encoder_inputs, decoder_inputs], decoder_outputs, name="transformer"
)

transformer.summary()

class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):
  def __init__(self, d_model, warmup_steps=4000):
    super().__init__()

    self.d_model = d_model
    self.d_model = tf.cast(self.d_model, tf.float32)

    self.warmup_steps = warmup_steps

  def __call__(self, step):
    step = tf.cast(step, dtype=tf.float32)
    arg1 = tf.math.rsqrt(step)
    arg2 = step * (self.warmup_steps ** -1.5)

    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)

  def get_config(self):
    return {"d_model": self.d_model.numpy(), "warmup_steps": self.warmup_steps}

learning_rate = CustomSchedule(latent_dim)

optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,
                                     epsilon=1e-9)

plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))
plt.ylabel('Learning Rate')
plt.xlabel('Train Step')

# Callbacks
early_stopping = callbacks.EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)

checkpoint_filepath = '/path/to/save/checkpoint.keras'
model_checkpoint_callback = callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    save_weights_only=False,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True)

csv_logger = callbacks.CSVLogger('/path/to/save/training_log.csv', append=True)

backup_callback = callbacks.BackupAndRestore(backup_dir="/path/to/save/backup",
                                             delete_checkpoint=False)

epochs = 30
transformer.compile(
    optimizer=optimizer,
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

history = transformer.fit(train_ds,
                epochs=epochs,
                validation_data=test_ds,
                callbacks=[
                      early_stopping,
                      model_checkpoint_callback,
                      csv_logger,
                      backup_callback]
)

transformer.save('/path/to/save/transformer_model.h5')

import os
def plot_loss_and_accuracy(history, save_dir=None, filename=None):
    # Extract the loss and accuracy values from the history object
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    accuracy = history.history['accuracy']
    val_accuracy = history.history['val_accuracy']

    # Get the number of epochs
    epochs = range(1, len(loss) + 1)

    # Plot training and validation loss
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(epochs, loss, 'bo-', label='Training Loss')
    plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # Plot training and validation accuracy
    plt.subplot(1, 2, 2)
    plt.plot(epochs, accuracy, 'bo-', label='Training Accuracy')
    plt.plot(epochs, val_accuracy, 'ro-', label='Validation Accuracy')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.tight_layout()

    # Save the figure if save_dir and filename are provided
    if save_dir and filename:
        os.makedirs(save_dir, exist_ok=True)
        save_path = os.path.join(save_dir, filename)
        plt.savefig(save_path)
        print(f"Plots saved as '{save_path}'")

    plt.show()

plot_loss_and_accuracy(history, "/path/to/save/plots", "transformer_trainloss.png")

fr_vocab = fr_vectorization.get_vocabulary()
fr_index_lookup = dict(zip(range(len(fr_vocab)), fr_vocab))
max_decoded_sentence_length = 20

def decode_sequence(input_sentence):
    tokenized_input_sentence = eng_vectorization([input_sentence])
    decoded_sentence = "[start]"
    for i in range(max_decoded_sentence_length):
        tokenized_target_sentence = fr_vectorization([decoded_sentence])[:, :-1]
        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])

        sampled_token_index = np.argmax(predictions[0, i, :])
        sampled_token = fr_index_lookup[sampled_token_index]
        decoded_sentence += " " + sampled_token

        if sampled_token == "[end]":
            break
    return decoded_sentence

input_sentence = 'I came late'
output = decode_sequence(input_sentence)
print(output)
------------------------------------- 44
```python
import warnings
warnings.filterwarnings('ignore')

import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import plotly.express as px
from tqdm.auto import tqdm 

import re
from nltk.corpus import stopwords 
from collections import Counter 
from string import punctuation 

from sklearn.model_selection import train_test_split 

import tensorflow as tf 
from tensorflow import keras 
from tensorflow.keras.preprocessing.text import Tokenizer 
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Concatenate, Dropout, TimeDistributed, LayerNormalization, MultiHeadAttention, Add
from tensorflow.keras.losses import SparseCategoricalCrossentropy
from tensorflow.keras.optimizers import Adam

# Load the dataset
df = pd.read_csv('path_to_your_dataset.csv')

# Preprocessing functions
def tamil_preprocessing(data, col):
    data[col] = data[col].astype(str)
    data[col] = data[col].apply(lambda x: x.lower())
    data[col] = data[col].apply(lambda x: re.sub("[^A-Za-z\s]", "", x))
    data[col] = data[col].apply(lambda x: x.replace("\s+", " "))
    data[col] = data[col].apply(lambda x: " ".join([word for word in x.split()]))
    return data

def english_preprocessing(data, col):
    data[col] = data[col].astype(str)
    data[col] = data[col].apply(lambda x: x.lower())
    data[col] = data[col].apply(lambda x: re.sub(r'\d', '', x))
    data[col] = data[col].apply(lambda x: re.sub(r'\s+', ' ', x))
    data[col] = data[col].apply(lambda x: re.sub(r"[-()\"#/@;:<>{}`+=~|.!?,]", "", x))
    data[col] = data[col].apply(lambda x: x.strip())
    data[col] = "<sos> " + data[col] + " <eos>"
    return data

df = tamil_preprocessing(df, 'tamil')
df = english_preprocessing(df, 'english')

# Calculate sentence lengths
df["en_len"] = [len(text.split()) for text in df.english]
df['ta_len'] = [len(text.split()) for text in df.tamil]

# Filter sentences based on length
df = df[~(df['en_len'] < 5) & ~(df['en_len'] > 20)]
df = df[~(df['ta_len'] < 5) & ~(df['ta_len'] > 20)]

# Vectorization function
def Vectorization(col, MAXLEN=20):
    sents = df[col].tolist()
    corpus = [word for text in df[col] for word in text.split()]
    vocab_size = len(Counter(corpus))
    tokenizer = Tokenizer(num_words=vocab_size, oov_token="<OOV>", filters='!#$%&()*+,-/:;<=>@""[\\]^_`{|}~\t\n')
    tokenizer.fit_on_texts(sents)
    tokenizer.word_index['<pad>'] = 0
    tokenizer.index_word[0] = '<pad>'
    vocab_to_idx = tokenizer.word_index
    idx_to_vocab = tokenizer.index_word
    seqs = tokenizer.texts_to_sequences(sents)
    pad_seqs = pad_sequences(seqs, maxlen=MAXLEN, padding='post')
    return vocab_to_idx, idx_to_vocab, pad_seqs

en_vocab, en_inv_vocab, en_seqs = Vectorization('english')
ta_vocab, ta_inv_vocab, ta_seqs = Vectorization('tamil')

# Split the dataset
x_train, x_test, y_train, y_test = train_test_split(ta_seqs, en_seqs, train_size=0.95, random_state=42)
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size=0.75, random_state=42)

# Prepare the dataset
BATCH_SIZE = 128
BUFFER_SIZE = 1000

train_set = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_set = train_set.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)

val_set = tf.data.Dataset.from_tensor_slices((x_val, y_val))
val_set = val_set.batch(BATCH_SIZE, drop_remainder=True)

test_set = tf.data.Dataset.from_tensor_slices((x_test, y_test))
test_set = test_set.batch(BATCH_SIZE, drop_remainder=True)

# Define parameters
EMBEDDING_DIM = 256
SRC_VOCAB_SIZE = len(ta_vocab) + 1
TRG_VOCAB_SIZE = len(en_vocab) + 1
HIDDEN_DIM = 512
EPOCHS = 100
LR = 0.001
NUM_LAYERS = 4
NUM_HEADS = 8
DFF = 2048
DROPOUT_RATE = 0.1

# Transformer Encoder Layer
class EncoderLayer(tf.keras.layers.Layer):
    def __init__(self, d_model, num_heads, dff, rate=0.1):
        super(EncoderLayer, self).__init__()
        self.mha = MultiHeadAttention(d_model, num_heads)
        self.ffn = self.point_wise_feed_forward_network(d_model, dff)
        self.layernorm1 = LayerNormalization(epsilon=1e-6)
        self.layernorm2 = LayerNormalization(epsilon=1e-6)
        self.dropout1 = Dropout(rate)
        self.dropout2 = Dropout(rate)

    def call(self, x, training, mask):
        attn_output, _ = self.mha(x, x, x, mask)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(x + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        out2 = self.layernorm2(out1 + ffn_output)
        return out2

    def point_wise_feed_forward_network(self, d_model, dff):
        return tf.keras.Sequential([
            Dense(dff, activation='relu'),
            Dense(d_model)
        ])

# Transformer Decoder Layer
class DecoderLayer(tf.keras.layers.Layer):
    def __init__(self, d_model, num_heads, dff, rate=0.1):
        super(DecoderLayer, self).__init__()
        self.mha1 = MultiHeadAttention(d_model, num_heads)
        self.mha2 = MultiHeadAttention(d_model, num_heads)
        self.ffn = self.point_wise_feed_forward_network(d_model, dff)
        self.layernorm1 = LayerNormalization(epsilon=1e-6)
        self.layernorm2 = LayerNormalization(epsilon=1e-6)
        self.layernorm3 = LayerNormalization(epsilon=1e-6)
        self.dropout1 = Dropout(rate)
        self.dropout2 = Dropout(rate)
        self.dropout3 = Dropout(rate)

    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):
        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)
        attn1 = self.dropout1(attn1, training=training)
        out1 = self.layernorm1(x + attn1)
        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)
        attn2 = self.dropout2(attn2, training=training)
        out2 = self.layernorm2(out1 + attn2)
        ffn_output = self.ffn(out2)
        ffn_output = self.dropout3(ffn_output, training=training)
        out3 = self.layernorm3(out2 + ffn_output)
        return out3, attn_weights_block1, attn_weights_block2

    def point_wise_feed_forward_network(self, d_model, dff):
        return tf.keras.Sequential([
            Dense(dff, activation='relu'),
            Dense(d_model)
        ])

# Transformer Encoder
class Encoder(tf.keras.layers.Layer):
    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):
        super(Encoder, self).__init__()
        self.d_model = d_model
        self.num_layers = num_layers
        self.embedding = Embedding(input_vocab_size, d_model)
        self.pos_encoding = self.positional_encoding(maximum_position_encoding, self.d_model)
        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]
        self.dropout = Dropout(rate)

    def call(self, x, training, mask):
        seq_len = tf.shape(x)[1]
        x = self.embedding(x)
        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))
        x += self.pos_encoding[:, :seq_len, :]
        x = self.dropout(x, training=training)
        for i in range(self.num_layers):
            x = self.enc_layers[i](x, training, mask)
        return x

    def positional_encoding(self, position, d_model):
        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)
        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])
        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])
        pos_encoding = angle_rads[np.newaxis, ...]
        return tf.cast(pos_encoding, dtype=tf.float32)

    def get_angles(self, pos, i, d_model):
        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))
        return pos * angle_rates

# Transformer Decoder
class Decoder(tf.keras.layers.Layer):
    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):
        super(Decoder, self).__init__()
        self.d_model = d_model
        self.num_layers = num_layers
        self.embedding = Embedding(target_vocab_size, d_model)
        self.pos_encoding = self.positional_encoding(maximum_position_encoding, d_model)
        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]
        self.dropout = Dropout(rate)

    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):
        seq_len = tf.shape(x)[1]
        attention_weights = {}
        x = self.embedding(x)
        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))
        x += self.pos_encoding[:, :seq_len, :]
        x = self.dropout(x, training=training)
        for i in range(self.num_layers):
            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)
            attention_weights[f'decoder_layer{i+1}_block1'] = block1
            attention_weights[f'decoder_layer{i+1}_block2'] = block2
        return x, attention_weights

    def positional_encoding(self, position, d_model):
        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)
        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])
        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])
        pos_encoding = angle_rads[np.newaxis, ...]
        return tf.cast(pos_encoding, dtype=tf.float32)

    def get_angles(self, pos, i, d_model):
        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))
        return pos * angle_rates

# Transformer Model
class Transformer(tf.keras.Model):
    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):
        super(Transformer, self).__init__()
        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)
        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)
        self.final_layer = Dense(target_vocab_size)

    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):
        enc_output = self.encoder(inp, training, enc_padding_mask)
        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)
        final_output = self.final_layer(dec_output)
        return final_output, attention_weights

# Create the transformer model
transformer = Transformer(
    num_layers=NUM_LAYERS,
    d_model=EMBEDDING_DIM,
    num_heads=NUM_HEADS,
    dff=DFF,
    input_vocab_size=SRC_VOCAB_SIZE,
    target_vocab_size=TRG_VOCAB_SIZE,
    pe_input=1000,
    pe_target=1000,
    rate=DROPOUT_RATE
)

# Define the optimizer and loss function
optimizer = Adam(learning_rate=LR, beta_1=0.9, beta_2=0.98, epsilon=1e-9)
loss_object = SparseCategoricalCrossentropy(from_logits=True, reduction='none')

def loss_function(real, pred):
    mask = tf.math.logical_not(tf.math.equal(real, 0))
    loss_ = loss_object(real, pred)
    mask = tf.cast(mask, dtype=loss_.dtype)
    loss_ *= mask
    return tf.reduce_mean(loss_)

# Training and validation steps
@tf.function
def train_step(inp, tar):
    tar_inp = tar[:, :-1]
    tar_real = tar[:, 1:]
    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)
    with tf.GradientTape() as tape:
        predictions, _ = transformer(inp, tar_inp, True, enc_padding_mask, combined_mask, dec_padding_mask)
        loss = loss_function(tar_real, predictions)
    gradients = tape.gradient(loss, transformer.trainable_variables)
    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))
    return loss

@tf.function
def val_step(inp, tar):
    tar_inp = tar[:, :-1]
    tar_real = tar[:, 1:]
    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)
    predictions, _ = transformer(inp, tar_inp, False, enc_padding_mask, combined_mask, dec_padding_mask)
    loss = loss_function(tar_real, predictions)
    return loss

# Training loop
training_losses = []
val_losses = []
for epoch in tqdm(range(EPOCHS)):
    epoch_loss = []
    epoch_val_loss = []
    for (batch, (inp, tar)) in enumerate(train_set):
        loss = train_step(inp, tar)
        epoch_loss.append(loss)
    for (batch, (inp, tar)) in enumerate(val_set):
        val_loss = val_step(inp, tar)
        epoch_val_loss.append(val_loss)
    training_losses.append(np.mean(epoch_loss))
    val_losses.append(np.mean(epoch_val_loss))
    if (epoch + 1) % 10 == 0:
        print(f"Epoch {epoch + 1}, Training Loss: {training_losses[-1]}, Validation Loss: {val_losses[-1]}")

# Save the model
transformer.save_weights('transformer_model_weights.h5')
```
------------------------------------- 45
