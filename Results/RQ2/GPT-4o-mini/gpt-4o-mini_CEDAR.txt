```python
import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dense, Flatten, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Constants
IM_SIZE = 224
BATCH_SIZE = 32
TRAIN_RATIO = 0.8
VAL_RATIO = 0.1
TEST_RATIO = 0.1

# Function to preprocess images
def preprocess_image(image, label):
    # Rescaling pixel values to the range [0, 1]
    image = tf.cast(image, tf.float32) / 255.0
    return image, label

# Load datasets
def load_data(path):
    dataset = tf.keras.utils.image_dataset_from_directory(
        path,
        shuffle=True,
        batch_size=BATCH_SIZE,
        image_size=(IM_SIZE, IM_SIZE),
        label_mode='binary'  # Binary classification
    )
    return dataset

# Load violence and non-violence datasets
violence_data = load_data('/path/to/violence/dataset')
non_violence_data = load_data('/path/to/non-violence/dataset')

# Combine datasets
combined_dataset = violence_data.concatenate(non_violence_data).shuffle(buffer_size=1000)

# Split datasets into train, validation, and test sets
def split_dataset(dataset, train_ratio, val_ratio, test_ratio):
    dataset_size = len(dataset)
    train_size = int(train_ratio * dataset_size)
    val_size = int(val_ratio * dataset_size)
    
    train_dataset = dataset.take(train_size)
    val_dataset = dataset.skip(train_size).take(val_size)
    test_dataset = dataset.skip(train_size + val_size)
    
    return train_dataset, val_dataset, test_dataset

train_dataset, val_dataset, test_dataset = split_dataset(combined_dataset, TRAIN_RATIO, VAL_RATIO, TEST_RATIO)

# Preprocess datasets
train_dataset = train_dataset.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
val_dataset = val_dataset.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
test_dataset = test_dataset.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

# Build the CNN model
def build_model():
    model = Sequential()
    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IM_SIZE, IM_SIZE, 3)))
    model.add(MaxPooling2D((2, 2)))
    model.add(BatchNormalization())
    
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2, 2)))
    model.add(BatchNormalization())
    
    model.add(Conv2D(128, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2, 2)))
    model.add(BatchNormalization())
    
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification
    
    return model

# Compile the model
model = build_model()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
history = model.fit(train_dataset, validation_data=val_dataset, epochs=20, callbacks=[early_stopping])

# Evaluate the model
test_loss, test_accuracy = model.evaluate(test_dataset)
print(f'Test accuracy: {test_accuracy:.4f}')

# Plot training history
def plot_history(history):
    plt.figure(figsize=(12, 4))
    
    # Plot accuracy
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    
    # Plot loss
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    
    plt.show()

# Call the plot function
plot_history(history)
``` 

Make sure to replace `'/path/to/violence/dataset'` and `'/path/to/non-violence/dataset'` with the actual paths to your datasets. This code will load the images, preprocess them, build a CNN model, train it, and evaluate its performance on a test set.
------------------------------------- 0
```python
import os
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D, Dropout, Dense
from tensorflow.keras.models import Model
import tensorflow as tf

# Set parameters
image_size = 200
batch_size = 32
num_classes = 2  # Fresh and Stale

# Load dataset
# Assuming the dataset is structured with images in 'train' directory and a CSV file with labels
df = pd.read_csv('/path/to/your/dataset/labels.csv')  # Update with your CSV path
train_dir = '/path/to/your/dataset/train/'  # Update with your images directory

# Display dataset info
df.info()
print(df.head())

# Visualize class distribution
plt.figure(figsize=(10, 5))
sns.countplot(x='label', data=df)  # Assuming 'label' column contains 'Fresh' and 'Stale'
plt.title('Class Distribution')
plt.show()

# Prepare image data
train_data = np.zeros((len(df), image_size, image_size, 3), dtype="float32")

for i, img_id in enumerate(df["image_file"]):
    img_path = os.path.join(train_dir, img_id)
    img = cv2.resize(cv2.imread(img_path), (image_size, image_size))
    train_data[i] = img / 255.0  # Normalize the image data

# Encode labels
encoder = LabelEncoder()
label_data = encoder.fit_transform(df["label"].values)  # Assuming 'label' column contains 'Fresh' and 'Stale'

# Split the dataset
x_train, x_test, y_train, y_test = train_test_split(train_data, label_data, test_size=0.2, random_state=42)

# Data augmentation
train_datagen = ImageDataGenerator(rotation_range=45,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.25,
                                   horizontal_flip=True,
                                   fill_mode='nearest')

train_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)

test_datagen = ImageDataGenerator()
test_generator = test_datagen.flow(x_test, y_test, batch_size=batch_size)

# Build the model
base_model = ResNet50V2(input_shape=(image_size, image_size, 3), weights='imagenet', include_top=False)
for layer in base_model.layers:
    layer.trainable = False  # Freeze the base model

x = base_model.output
x = BatchNormalization()(x)
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
x = Dense(256, activation='relu')(x)
prediction = Dense(num_classes, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=prediction)

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.summary()

# Train the model
history = model.fit(train_generator, steps_per_epoch=len(x_train) // batch_size, epochs=15,
                    validation_data=test_generator, validation_steps=len(x_test) // batch_size)

# Plot training history
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.show()

# Evaluate the model
predictions = model.predict(x_test)
predicted_classes = np.argmax(predictions, axis=1)

# Confusion matrix and classification report
from sklearn.metrics import confusion_matrix, classification_report

conf_matrix = confusion_matrix(y_test, predicted_classes)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.title('Confusion Matrix')
plt.show()

print(classification_report(y_test, predicted_classes, target_names=encoder.classes_))

# Save the model
model.save('fresh_stale_classifier.h5')
```
------------------------------------- 1
```python
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D
from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.applications import ResNet50
from sklearn.utils.class_weight import compute_class_weight
from sklearn.model_selection import StratifiedKFold
import pandas as pd
import os
import matplotlib.pyplot as plt
import itertools

# Define the root directory for the dataset
root_dir = '/path/to/your/dataset'  # Update this path

# Initialize lists to store data
image_paths = []
subsets = []
targets = []

# Load the dataset
for subset in ['train', 'test']:
    subset_path = os.path.join(root_dir, subset)

    for class_folder in os.listdir(subset_path):
        class_path = os.path.join(subset_path, class_folder)

        for image_filename in os.listdir(class_path):
            image_path = os.path.join(class_path, image_filename)

            image_paths.append(image_path)
            subsets.append(subset)
            targets.append(class_folder)

# Create DataFrame
df = pd.DataFrame({
    'Image Path': image_paths,
    'Subset': subsets,
    'Target': targets
})

# Filter the DataFrame to get only the "train" and "test" subsets
train_df = df[df['Subset'] == 'train']
test_df = df[df['Subset'] == 'test']

# Data augmentation for training
train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    preprocessing_function=tf.keras.applications.resnet50.preprocess_input
)

valid_datagen = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.resnet50.preprocess_input
)

test_datagen = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.resnet50.preprocess_input
)

# Define classes
classes = ['Very mild Dementia', 'Non Demented', 'Moderate Dementia', 'Mild Dementia']

# K-Fold Cross Validation
kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
accuracy_list = []
precision_list = []
recall_list = []

# K-Fold Loop
for train_idx, val_idx in kfold.split(train_df['Image Path'], train_df['Target']):
    x_train_df = train_df.iloc[train_idx]
    x_valid_df = train_df.iloc[val_idx]

    train_batches = train_datagen.flow_from_dataframe(
        dataframe=x_train_df,
        x_col="Image Path", y_col="Target",
        class_mode="categorical",
        classes=classes,
        target_size=(224, 224), batch_size=32, shuffle=True
    )

    valid_batches = valid_datagen.flow_from_dataframe(
        dataframe=x_valid_df,
        x_col="Image Path", y_col="Target",
        class_mode="categorical",
        classes=classes,
        target_size=(224, 224), batch_size=32, shuffle=False
    )

    # Load ResNet50 model
    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    x = Flatten()(base_model.output)
    x = Dense(256, activation='relu')(x)
    predictions = Dense(len(classes), activation='softmax')(x)

    model = Model(inputs=base_model.input, outputs=predictions)

    # Compile the model
    model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

    # Class weights
    class_weights = compute_class_weight('balanced', classes=np.unique(train_batches.classes), y=train_batches.classes)
    class_weight_dict = dict(enumerate(class_weights))

    # Callbacks
    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
    model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)

    # Train the model
    history = model.fit(
        train_batches,
        validation_data=valid_batches,
        callbacks=[early_stopping, model_checkpoint],
        class_weight=class_weight_dict,
        epochs=20,
        verbose=1
    )

    # Evaluate the model
    valid_batches.reset()
    valid_pred = model.predict(valid_batches)
    valid_predicted_class_indices = np.argmax(valid_pred, axis=1)

    # Calculate metrics
    val_true_labels = valid_batches.classes
    val_accuracy = accuracy_score(val_true_labels, valid_predicted_class_indices)
    val_precision = precision_score(val_true_labels, valid_predicted_class_indices, average='macro')
    val_recall = recall_score(val_true_labels, valid_predicted_class_indices, average='macro')

    accuracy_list.append(val_accuracy)
    precision_list.append(val_precision)
    recall_list.append(val_recall)

    print(f"Validation Accuracy: {val_accuracy}, Precision: {val_precision}, Recall: {val_recall}")

# Average metrics
average_val_accuracy = np.mean(accuracy_list)
average_val_precision = np.mean(precision_list)
average_val_recall = np.mean(recall_list)

print(f"Average Validation Accuracy: {average_val_accuracy}")
print(f"Average Validation Precision: {average_val_precision}")
print(f"Average Validation Recall: {average_val_recall}")

# Testing the model
test_batches = test_datagen.flow_from_dataframe(
    dataframe=test_df,
    x_col="Image Path", y_col="Target",
    class_mode=None,
    target_size=(224, 224), batch_size=32, shuffle=False
)

predictions = model.predict(test_batches)
predicted_class_indices = np.argmax(predictions, axis=1)

# Generate classification report
report = classification_report(test_df['Target'], predicted_class_indices, target_names=classes, digits=4)
print(report)

# Plot confusion matrix
def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)
    plt.colorbar()
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(test_df['Target'], predicted_class_indices)
plt.figure()
plot_confusion_matrix(cm, classes)
plt.show()
```
------------------------------------- 2
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation, Flatten, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras import optimizers
import os
import cv2

# Define constants
IMAGE_SIZE = (240, 240)
NUM_CLASSES = 4
BATCH_SIZE = 32
EPOCHS = 50
DATASET_PATH = 'path_to_your_dataset'  # Update this to your dataset path

# Load dataset
def load_data(dataset_path):
    images = []
    labels = []
    label_map = {'Healthy': 0, 'Bunchy top': 1, 'Fusarium wilt': 2, 'Moko': 3}
    
    for label in os.listdir(dataset_path):
        if label in label_map:
            for img_file in os.listdir(os.path.join(dataset_path, label)):
                img_path = os.path.join(dataset_path, label, img_file)
                img = cv2.imread(img_path)
                img = cv2.resize(img, IMAGE_SIZE)
                images.append(img)
                labels.append(label_map[label])
    
    return np.array(images), np.array(labels)

# Preprocess data
def preprocess_data(images, labels):
    images = images.astype('float32') / 255.0  # Normalize images
    labels = tf.keras.utils.to_categorical(labels, NUM_CLASSES)  # One-hot encode labels
    return images, labels

# Build the CNN model
def build_model(input_shape):
    inputs = Input(shape=input_shape)
    
    # Convolutional Block 1
    x = Conv2D(32, (3, 3), padding='same')(inputs)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)
    
    # Convolutional Block 2
    x = Conv2D(64, (3, 3), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)
    
    # Convolutional Block 3
    x = Conv2D(128, (3, 3), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)
    
    # Flatten and Dense layers
    x = Flatten()(x)
    x = Dense(256, activation='relu')(x)
    outputs = Dense(NUM_CLASSES, activation='softmax')(x)
    
    model = Model(inputs, outputs)
    return model

# Load and preprocess data
images, labels = load_data(DATASET_PATH)
X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size=0.15, random_state=42)
X_train, Y_train = preprocess_data(X_train, Y_train)
X_test, Y_test = preprocess_data(X_test, Y_test)

# Build and compile the model
model = build_model((IMAGE_SIZE[0], IMAGE_SIZE[1], 3))
model.compile(optimizer=optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

# Define callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('skin_lesion_model.h5', save_best_only=True)

# Train the model
history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.2, callbacks=[early_stopping, model_checkpoint])

# Evaluate the model
test_loss, test_accuracy = model.evaluate(X_test, Y_test)
print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')

# Plot training history
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()
```
------------------------------------- 3
```python
import numpy as np
import matplotlib.pyplot as plt
import os
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report, confusion_matrix

# Set random seed for reproducibility
seed = 42
np.random.seed(seed)
tf.random.set_seed(seed)

# Define paths for the dataset
base_dir = '/path/to/dataset'  # Change this to your dataset path
train_dir = os.path.join(base_dir, 'train')
val_dir = os.path.join(base_dir, 'validation')
test_dir = os.path.join(base_dir, 'test')

# Image parameters
IMG_SIZE = 224
BATCH_SIZE = 32

# Data augmentation and preprocessing
data_gen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_generator = data_gen.flow_from_directory(
    train_dir,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training'
)

validation_generator = data_gen.flow_from_directory(
    val_dir,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation'
)

test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

# Define the model architecture
def create_model():
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(4, activation='softmax')  # 4 classes: meningioma, glioma, pituitary, no tumor
    ])
    return model

# Create and compile the model
model = create_model()
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Model summary
model.summary()

# Callbacks
early_stopping = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)
checkpoint = keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)

# Train the model
history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=20,
    callbacks=[early_stopping, checkpoint]
)

# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(test_generator)
print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')

# Predictions and evaluation
test_generator.reset()
predictions = model.predict(test_generator)
predicted_classes = np.argmax(predictions, axis=1)
true_classes = test_generator.classes
class_labels = list(test_generator.class_indices.keys())

# Classification report
print(classification_report(true_classes, predicted_classes, target_names=class_labels))

# Confusion matrix
conf_matrix = confusion_matrix(true_classes, predicted_classes)
plt.figure(figsize=(10, 8))
plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(class_labels))
plt.xticks(tick_marks, class_labels, rotation=45)
plt.yticks(tick_marks, class_labels)
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()
```
------------------------------------- 4
```python
# Required Libraries
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, Dropout, concatenate
from sklearn.model_selection import train_test_split
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim

# Dataset Path
inputs = "/kaggle/input/dnd-nam-noise-data/Noisy_Dataset"

def load_images_from_folder(folder):
    images = []
    for filename in os.listdir(folder):
        img = cv2.imread(os.path.join(folder, filename))
        if img is not None:
            images.append(img)
    return images

def calculate_psnr_ssim(original, predicted):
    psnr_values = []
    ssim_values = []
    
    for orig, pred in zip(original, predicted):
        psnr_value = psnr(orig, pred)
        ssim_value = ssim(orig, pred, channel_axis=-1)
        psnr_values.append(psnr_value)
        ssim_values.append(ssim_value)

    return np.mean(psnr_values), np.mean(ssim_values)

def build_srgan_model(input_shape):
    # Generator Model
    input_layer = Input(shape=input_shape)

    # Convolutional Layers
    conv1 = Conv2D(64, (9, 9), padding='same', activation='relu')(input_layer)
    conv2 = Conv2D(64, (3, 3), padding='same', activation='relu')(conv1)
    conv3 = Conv2D(64, (3, 3), padding='same', activation='relu')(conv2)

    # Upsampling Layers
    upsample1 = Conv2DTranspose(64, (3, 3), strides=2, padding='same')(conv3)
    upsample2 = Conv2DTranspose(64, (3, 3), strides=2, padding='same')(upsample1)

    # Output Layer
    output_layer = Conv2D(3, (9, 9), padding='same', activation='sigmoid')(upsample2)

    return Model(inputs=input_layer, outputs=output_layer)

# Load Dataset
low_res_images = load_images_from_folder(os.path.join(inputs, 'Low_Resolution'))
high_res_images = load_images_from_folder(os.path.join(inputs, 'High_Resolution'))

# Preprocess Images
low_res_images = np.array([img / 255.0 for img in low_res_images])
high_res_images = np.array([img / 255.0 for img in high_res_images])

# Split Dataset
X_train, X_test, y_train, y_test = train_test_split(low_res_images, high_res_images, test_size=0.2, random_state=42)

# Build and Compile Model
input_shape = (None, None, 3)  # Variable input size
model = build_srgan_model(input_shape)
model.compile(optimizer='adam', loss='mean_squared_error')

# Train Model
model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_test, y_test))

# Save Model
model.save("/kaggle/working/srgan_model.h5")

# Predictions
predictions = model.predict(X_test)

# Evaluate Results
psnr_results = []
ssim_results = []

for original, predicted in zip(y_test, predictions):
    psnr_value, ssim_value = calculate_psnr_ssim([original], [predicted])
    psnr_results.append(psnr_value)
    ssim_results.append(ssim_value)

# Display Results
max_index = np.argmax(ssim_results)
min_index = np.argmin(ssim_results)

def display_results(original, predicted, index):
    plt.figure(figsize=(15, 5))
    
    plt.subplot(1, 3, 1)
    plt.imshow(original[index])
    plt.title('Original High-Resolution Image')
    
    plt.subplot(1, 3, 2)
    plt.imshow(predicted[index])
    plt.title('Predicted High-Resolution Image')
    
    plt.subplot(1, 3, 3)
    plt.imshow(X_test[index])
    plt.title('Low-Resolution Input Image')
    
    plt.show()

# Display best and worst results
display_results(y_test, predictions, max_index)
display_results(y_test, predictions, min_index)
```
------------------------------------- 5
```python
import os
import numpy as np
import matplotlib.pyplot as plt
import glob
import random
from PIL import Image
import tensorflow as tf
from tensorflow.keras.layers import *
from tensorflow.keras.models import Model
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.optimizers import Adam
import pywt  # For wavelet transformation

# Function to load and preprocess images
def load_image(img_path):
    img = tf.io.read_file(img_path)
    img = tf.io.decode_jpeg(img, channels=3)
    img = tf.image.resize(img, size=(384, 384), antialias=True)
    img = img / 255.0
    return img

# Function to apply Gaussian smoothing
def gaussian_smoothing(image, sigma=1):
    return tf.image.per_image_standardization(image)

# Function to apply wavelet transformation
def wavelet_transform(image):
    coeffs = pywt.wavedec2(image.numpy(), 'haar', level=2)
    return pywt.waverec2(coeffs, 'haar')

# Function to prepare the dataset
def data_path(orig_img_path, noisy_img_path):
    train_img = []
    val_img = []

    orig_img = glob.glob(orig_img_path + '/*.png')
    n = len(orig_img)
    random.shuffle(orig_img)
    train_keys = orig_img[:int(0.9*n)]
    val_keys = orig_img[int(0.9*n):]

    split_dict = {}
    for key in train_keys:
        split_dict[key] = 'train'
    for key in val_keys:
        split_dict[key] = 'val'

    noisy_img = glob.glob(noisy_img_path + '/*.png')
    for img in noisy_img:
        img_name = img.split('/')[-1]
        orig_path = orig_img_path + '/' + img_name.split('_')[0] + '.png'
        if (split_dict[orig_path] == 'train'):
            train_img.append([img, orig_path])
        else:
            val_img.append([img, orig_path])

    return train_img, val_img

# Function to create a data loader
def dataloader(train_data, val_data, batch_size):
    train_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in train_data]).map(lambda x: load_image(x))
    train_data_noisy = tf.data.Dataset.from_tensor_slices([img[0] for img in train_data]).map(lambda x: load_image(x))
    train = tf.data.Dataset.zip((train_data_noisy, train_data_orig)).shuffle(buffer_size=100).batch(batch_size)

    val_data_orig = tf.data.Dataset.from_tensor_slices([img[1] for img in val_data]).map(lambda x: load_image(x))
    val_data_noisy = tf.data.Dataset.from_tensor_slices([img[0] for img in val_data]).map(lambda x: load_image(x))
    val = tf.data.Dataset.zip((val_data_noisy, val_data_orig)).shuffle(buffer_size=100).batch(batch_size)

    return train, val

# U-Net model definition
def unet_model():
    inputs = tf.keras.Input(shape=[384, 384, 3])

    # Encoding path
    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)
    p1 = MaxPooling2D((2, 2))(c1)

    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)
    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)
    p2 = MaxPooling2D((2, 2))(c2)

    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)
    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)
    p3 = MaxPooling2D((2, 2))(c3)

    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)
    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)
    p4 = MaxPooling2D((2, 2))(c4)

    # Bottleneck
    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)
    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)

    # Decoding path
    u6 = UpSampling2D((2, 2))(c5)
    u6 = concatenate([u6, c4])
    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)
    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)

    u7 = UpSampling2D((2, 2))(c6)
    u7 = concatenate([u7, c3])
    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)
    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)

    u8 = UpSampling2D((2, 2))(c7)
    u8 = concatenate([u8, c2])
    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)
    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)

    u9 = UpSampling2D((2, 2))(c8)
    u9 = concatenate([u9, c1])
    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)
    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)

    outputs = Conv2D(3, (1, 1), activation='sigmoid')(c9)

    return Model(inputs=[inputs], outputs=[outputs])

# Hyperparameters
epochs = 10
batch_size = 16
learning_rate = 1e-4

# Load dataset
train_data, val_data = data_path(orig_img_path='path/to/denoised/images', noisy_img_path='path/to/noisy/images')
train, val = dataloader(train_data, val_data, batch_size)

# Initialize model, optimizer, and loss function
model = unet_model()
optimizer = Adam(learning_rate=learning_rate)
loss_fn = MeanSquaredError()

# Training and validation function
def train_model(epochs, train, val, model, optimizer, loss_fn):
    for epoch in range(epochs):
        print(f"\nEpoch {epoch + 1}/{epochs}")
        
        # Training loop
        for step, (noisy_batch, orig_batch) in enumerate(train):
            with tf.GradientTape() as tape:
                preds = model(noisy_batch, training=True)
                loss = loss_fn(orig_batch, preds)

            grads = tape.gradient(loss, model.trainable_weights)
            optimizer.apply_gradients(zip(grads, model.trainable_weights))

            if step % 10 == 0:
                print(f"Step {step}, Loss: {loss.numpy():.4f}")

        # Validation loop
        val_loss = 0
        for val_noisy_batch, val_orig_batch in val:
            val_preds = model(val_noisy_batch, training=False)
            val_loss += loss_fn(val_orig_batch, val_preds).numpy()
        
        val_loss /= len(val)
        print(f"Validation Loss: {val_loss:.4f}")

# Train the model
train_model(epochs, train, val, model, optimizer, loss_fn)

# Save the model
model.save('unet_denoising_model.h5')

# Function to evaluate the model on new images
def evaluate_model(model, test_img_path):
    test_images = glob.glob(test_img_path + '/*.jpg')
    random.shuffle(test_images)

    for img_path in test_images:
        img = load_image(img_path)
        img = tf.expand_dims(img, axis=0)  # Add batch dimension

        denoised_img = model(img, training=False)
        plt.figure(figsize=(10, 5))
        plt.subplot(1, 2, 1)
        plt.title('Noisy Image')
        plt.imshow(img[0])
        plt.axis('off')

        plt.subplot(1, 2, 2)
        plt.title('Denoised Image')
        plt.imshow(denoised_img[0])
        plt.axis('off')
        plt.show()

# Evaluate the model on test images
evaluate_model(model, 'path/to/test/images')
```
------------------------------------- 6
```python
import numpy as np
import os
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Dropout, LeakyReLU, ReLU, ZeroPadding2D, GroupNormalization, Concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.losses import MeanAbsoluteError
from tensorflow.keras.optimizers import Adam

# Set image size
IMAGE_SIZE = [256, 256]

def decode_img(image):
    """Decode and preprocess the image."""
    image = tf.image.decode_png(image, channels=3)  # Decode PNG images
    image = (tf.cast(image, tf.float32) / 255.0) * 2 - 1  # Normalize to [-1, 1]
    image = tf.reshape(image, shape=[*IMAGE_SIZE, 3])  # Reshape to desired size
    return image

def read_image_pair(example):
    """Extract hazy and clear images from the TFRecord."""
    tfrec_format = {
        'hazy_image': tf.io.FixedLenFeature([], tf.string),
        'clear_image': tf.io.FixedLenFeature([], tf.string)
    }
    example = tf.io.parse_single_example(example, tfrec_format)
    hazy_image = decode_img(example['hazy_image'])
    clear_image = decode_img(example['clear_image'])
    return hazy_image, clear_image

def load_data(files):
    """Load dataset from TFRecord files."""
    data = tf.data.TFRecordDataset(files)
    data = data.map(read_image_pair)  # Map the parsing function
    return data

# Load your dataset files here
hazy_files = tf.io.gfile.glob('/path/to/hazy/images/*.tfrecord')  # Update with your path
clear_files = tf.io.gfile.glob('/path/to/clear/images/*.tfrecord')  # Update with your path

hazy_data = load_data(hazy_files).batch(1)
clear_data = load_data(clear_files).batch(1)

def downsample(filters, size):
    """Downsample the input."""
    initializer = tf.random_normal_initializer(0, 0.02)
    model = keras.Sequential()
    model.add(Conv2D(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))
    model.add(GroupNormalization(groups=-1))
    model.add(LeakyReLU())
    return model

def upsample(filters, size):
    """Upsample the input."""
    initializer = tf.random_normal_initializer(0, 0.02)
    model = keras.Sequential()
    model.add(Conv2DTranspose(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))
    model.add(GroupNormalization(groups=-1))
    model.add(ReLU())
    return model

def build_generator():
    """Build the generator model."""
    down_stack = [
        downsample(64, 4),
        downsample(128, 4),
        downsample(256, 4),
        downsample(512, 4),
        downsample(512, 4),
        downsample(512, 4),
        downsample(512, 4),
        downsample(512, 4),
    ]

    up_stack = [
        upsample(512, 4),
        upsample(512, 4),
        upsample(512, 4),
        upsample(512, 4),
        upsample(256, 4),
        upsample(128, 4),
        upsample(64, 4),
    ]

    last_layer = Conv2DTranspose(3, 4, strides=2, padding='same', kernel_initializer='he_normal', activation='tanh')

    inputs = Input(shape=[256, 256, 3])
    x = inputs

    skips = []
    for down in down_stack:
        x = down(x)
        skips.append(x)

    skips = reversed(skips[:-1])

    for up, skip in zip(up_stack, skips):
        x = up(x)
        x = Concatenate()([x, skip])

    x = last_layer(x)
    return Model(inputs, x)

# Build the generator model
generator = build_generator()

def generator_loss(real, generated):
    """Calculate generator loss."""
    return MeanAbsoluteError()(real, generated)

# Compile the model
generator_optimizer = Adam(learning_rate=2e-4, beta_1=0.5)

# Training loop
@tf.function
def train_step(hazy_image, clear_image):
    """Perform a single training step."""
    with tf.GradientTape() as tape:
        generated_image = generator(hazy_image, training=True)
        loss = generator_loss(clear_image, generated_image)

    gradients = tape.gradient(loss, generator.trainable_variables)
    generator_optimizer.apply_gradients(zip(gradients, generator.trainable_variables))
    return loss

# Training the model
EPOCHS = 50
for epoch in range(EPOCHS):
    for hazy_image, clear_image in tf.data.Dataset.zip((hazy_data, clear_data)):
        loss = train_step(hazy_image, clear_image)
    print(f'Epoch {epoch + 1}/{EPOCHS}, Loss: {loss.numpy()}')

# Save the model
generator.save('image_dehazing_generator.h5')

# Example of generating a dehazed image
sample_hazy = next(iter(hazy_data))
predicted_clear = generator(sample_hazy, training=False)

# Display the results
plt.subplot(1, 2, 1)
plt.title('Hazy Image')
plt.imshow((sample_hazy[0] + 1) / 2)  # Rescale to [0, 1]

plt.subplot(1, 2, 2)
plt.title('Dehazed Image')
plt.imshow((predicted_clear[0] + 1) / 2)  # Rescale to [0, 1]

plt.show()
```
------------------------------------- 7
```python
# Importing Relevant Libraries
import tensorflow as tf
from tensorflow.keras import layers, Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import numpy as np

# Define the CycleGAN model
class CycleGAN:
    def __init__(self, img_shape):
        self.img_shape = img_shape
        self.generator_g = self.build_generator()  # Generator G: Photos to Monet
        self.generator_f = self.build_generator()  # Generator F: Monet to Photos
        self.discriminator_x = self.build_discriminator()  # Discriminator for Photos
        self.discriminator_y = self.build_discriminator()  # Discriminator for Monet

    def build_generator(self):
        # Define a simple U-Net architecture for the generator
        inputs = layers.Input(shape=self.img_shape)
        # Encoder
        encoder_conv1 = layers.Conv2D(64, (7, 7), padding='same')(inputs)
        encoder_conv1 = layers.BatchNormalization()(encoder_conv1)
        encoder_conv1 = layers.Activation('relu')(encoder_conv1)

        encoder_conv2 = layers.Conv2D(128, (3, 3), strides=2, padding='same')(encoder_conv1)
        encoder_conv2 = layers.BatchNormalization()(encoder_conv2)
        encoder_conv2 = layers.Activation('relu')(encoder_conv2)

        # Bottleneck
        bottleneck = layers.Conv2D(256, (3, 3), padding='same')(encoder_conv2)
        bottleneck = layers.BatchNormalization()(bottleneck)
        bottleneck = layers.Activation('relu')(bottleneck)

        # Decoder
        decoder_conv1 = layers.Conv2DTranspose(128, (3, 3), strides=2, padding='same')(bottleneck)
        decoder_conv1 = layers.BatchNormalization()(decoder_conv1)
        decoder_conv1 = layers.Activation('relu')(decoder_conv1)

        outputs = layers.Conv2D(3, (7, 7), padding='same', activation='tanh')(decoder_conv1)

        return Model(inputs, outputs)

    def build_discriminator(self):
        # Define a simple CNN architecture for the discriminator
        inputs = layers.Input(shape=self.img_shape)
        x = layers.Conv2D(64, (4, 4), strides=2, padding='same')(inputs)
        x = layers.LeakyReLU(alpha=0.2)(x)

        x = layers.Conv2D(128, (4, 4), strides=2, padding='same')(x)
        x = layers.BatchNormalization()(x)
        x = layers.LeakyReLU(alpha=0.2)(x)

        x = layers.Conv2D(256, (4, 4), strides=2, padding='same')(x)
        x = layers.BatchNormalization()(x)
        x = layers.LeakyReLU(alpha=0.2)(x)

        x = layers.Conv2D(512, (4, 4), strides=2, padding='same')(x)
        x = layers.BatchNormalization()(x)
        x = layers.LeakyReLU(alpha=0.2)(x)

        outputs = layers.Conv2D(1, (4, 4), padding='same')(x)

        return Model(inputs, outputs)

    def compile_models(self):
        # Compile the models
        self.generator_g.compile(loss='mae', optimizer=Adam(2e-4, beta_1=0.5))
        self.generator_f.compile(loss='mae', optimizer=Adam(2e-4, beta_1=0.5))
        self.discriminator_x.compile(loss='mse', optimizer=Adam(2e-4, beta_1=0.5))
        self.discriminator_y.compile(loss='mse', optimizer=Adam(2e-4, beta_1=0.5))

# Load your dataset from TFRecords
def load_dataset(tfrecords_path):
    raw_dataset = tf.data.TFRecordDataset(tfrecords_path)
    # Define a parsing function
    def _parse_function(proto):
        # Define your feature description
        feature_description = {
            'image': tf.io.FixedLenFeature([], tf.string),
        }
        parsed_features = tf.io.parse_single_example(proto, feature_description)
        image = tf.io.decode_raw(parsed_features['image'], tf.uint8)
        image = tf.reshape(image, [64, 64, 3])  # Adjust based on your image size
        return image

    dataset = raw_dataset.map(_parse_function)
    return dataset

# Training function
def train_cycle_gan(dataset_x, dataset_y, epochs=100, batch_size=1):
    cycle_gan = CycleGAN(img_shape=(64, 64, 3))
    cycle_gan.compile_models()

    # Prepare datasets
    dataset_x = dataset_x.batch(batch_size)
    dataset_y = dataset_y.batch(batch_size)

    for epoch in range(epochs):
        for real_x, real_y in zip(dataset_x, dataset_y):
            # Implement the training logic here
            # Train generators and discriminators
            pass  # Placeholder for training logic

        print(f'Epoch {epoch + 1}/{epochs} completed.')

# Load datasets
dataset_photos = load_dataset('path_to_photos.tfrecords')
dataset_monet = load_dataset('path_to_monet.tfrecords')

# Start training
train_cycle_gan(dataset_photos, dataset_monet)
```
------------------------------------- 8
```python
import numpy as np
import matplotlib.pyplot as plt
import os
from glob import glob
from PIL import Image
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

class DataLoader():
    def __init__(self, dataset_path, img_shape=(64, 64, 2)):
        self.dataset_path = dataset_path
        self.img_shape = img_shape

    def load_data(self, batch_size=1, is_testing=False):
        # Load images from the dataset
        data_type = "test" if is_testing else "train"
        image_paths = glob(os.path.join(self.dataset_path, data_type, '*.npy'))
        
        # Randomly select a batch of images
        batch_images = np.random.choice(image_paths, size=batch_size)

        imgs = []
        for img_path in batch_images:
            img = np.load(img_path)
            imgs.append(img)

        # Convert list to numpy array and normalize
        imgs = np.array(imgs).astype(float)
        imgs /= 255.0  # Normalize to [0, 1]
        
        return imgs

def build_unet(input_shape):
    inputs = Input(shape=input_shape)

    # Encoder
    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)
    p1 = MaxPooling2D((2, 2))(c1)

    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)
    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)
    p2 = MaxPooling2D((2, 2))(c2)

    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)
    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)
    p3 = MaxPooling2D((2, 2))(c3)

    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)
    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)
    p4 = MaxPooling2D((2, 2))(c4)

    # Bottleneck
    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)
    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)

    # Decoder
    u6 = UpSampling2D((2, 2))(c5)
    u6 = concatenate([u6, c4])
    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)
    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)

    u7 = UpSampling2D((2, 2))(c6)
    u7 = concatenate([u7, c3])
    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)
    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)

    u8 = UpSampling2D((2, 2))(c7)
    u8 = concatenate([u8, c2])
    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)
    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)

    u9 = UpSampling2D((2, 2))(c8)
    u9 = concatenate([u9, c1])
    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)
    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)

    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)

    model = Model(inputs=[inputs], outputs=[outputs])
    return model

# Example usage
dataset_loader = DataLoader(dataset_path='path/to/dataset', img_shape=(64, 64, 2))
imgs = dataset_loader.load_data(batch_size=2, is_testing=False)
print("Loaded images shape:", imgs.shape)

# Build U-Net model
unet_model = build_unet(input_shape=(64, 64, 2))
unet_model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])

# Train the model (assuming imgs contains both input and target images)
# For demonstration, we will use imgs as both input and target
history = unet_model.fit(imgs, imgs, batch_size=2, epochs=10, validation_split=0.2)

# Save the model weights
unet_model.save_weights("unet_weights_final.h5")

# Plot training history
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()
```
------------------------------------- 9
```python
import numpy as np  # linear algebra
import pandas as pd  # data processing
import os
import json
import tensorflow as tf
from tensorflow.keras.layers import LSTM, Bidirectional, Dropout, Embedding, Dense, Input, Conv2D, Flatten
from tensorflow.keras.models import Model
from sklearn.model_selection import train_test_split
from tqdm import tqdm
import warnings
warnings.filterwarnings("ignore")

# Load the dataset
# Assuming the images are in a directory and captions are in a CSV file
image_dir = "/path/to/flickr8k/images/"
captions_file = "/path/to/flickr8k/captions.txt"

# Load captions
captions_df = pd.read_csv(captions_file, delimiter='\t', names=['image', 'caption'])

# Preprocess captions
captions_df['caption'] = captions_df['caption'].str.lower().str.replace('[^a-zA-Z0-9 ]', '', regex=True)

# Split the dataset into training and testing sets
train_df, test_df = train_test_split(captions_df, test_size=0.2, random_state=42)

# Create a vocabulary from the captions
all_captions = ' '.join(captions_df['caption']).split()
vocab = set(all_captions)
vocab_size = len(vocab) + 1  # +1 for padding
word_to_index = {word: i + 1 for i, word in enumerate(vocab)}  # Start indexing from 1
index_to_word = {i: word for word, i in word_to_index.items()}

# Parameters
max_caption_length = 20  # Maximum length of captions
image_size = (224, 224)  # Resize images to this size

# Image preprocessing function
def preprocess_image(image_path):
    img = tf.keras.preprocessing.image.load_img(image_path, target_size=image_size)
    img = tf.keras.preprocessing.image.img_to_array(img)
    img = img / 255.0  # Normalize to [0, 1]
    return img

# Data generator
def data_generator(dataframe, batch_size):
    while True:
        for start in range(0, len(dataframe), batch_size):
            end = min(start + batch_size, len(dataframe))
            batch_data = dataframe[start:end]
            images = []
            captions = []
            for _, row in batch_data.iterrows():
                img_path = os.path.join(image_dir, row['image'])
                img = preprocess_image(img_path)
                images.append(img)
                caption = row['caption'].split()
                caption_indices = [word_to_index[word] for word in caption if word in word_to_index]
                caption_indices = caption_indices[:max_caption_length] + [0] * (max_caption_length - len(caption_indices))  # Padding
                captions.append(caption_indices)
            yield np.array(images), np.array(captions)

# Create datasets
batch_size = 32
train_gen = data_generator(train_df, batch_size)
test_gen = data_generator(test_df, batch_size)

# Define the model
# Image feature extractor
image_input = Input(shape=(image_size[0], image_size[1], 3))
x = Conv2D(32, (3, 3), activation='relu')(image_input)
x = Conv2D(64, (3, 3), activation='relu')(x)
x = Flatten()(x)
image_features = Dense(256, activation='relu')(x)

# Caption generator
caption_input = Input(shape=(max_caption_length,))
y = Embedding(input_dim=vocab_size, output_dim=256)(caption_input)
y = LSTM(256)(y)

# Combine image features and caption features
combined = tf.keras.layers.Add()([image_features, y])
output = Dense(vocab_size, activation='softmax')(combined)

# Create the model
model = Model(inputs=[image_input, caption_input], outputs=output)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Model summary
model.summary()

# Training the model
epochs = 10
steps_per_epoch = len(train_df) // batch_size
validation_steps = len(test_df) // batch_size

model.fit(train_gen, steps_per_epoch=steps_per_epoch, epochs=epochs, validation_data=test_gen, validation_steps=validation_steps)

# Function to generate captions for a given image
def generate_caption(image_path):
    img = preprocess_image(image_path)
    img = np.expand_dims(img, axis=0)  # Add batch dimension
    caption = []
    for _ in range(max_caption_length):
        # Predict the next word
        pred = model.predict([img, np.array(caption).reshape(1, -1)])
        next_word_index = np.argmax(pred)
        if next_word_index == 0:  # Padding
            break
        caption.append(next_word_index)
    return ' '.join([index_to_word[i] for i in caption if i in index_to_word])

# Example usage
# caption = generate_caption('/path/to/some/image.jpg')
# print(caption)
```
------------------------------------- 10
```python
import numpy as np
import pandas as pd
import os
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, LSTM, Dropout, Bidirectional, Flatten, Embedding, concatenate
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping

# Load dataset
train_df = pd.read_csv("path_to_your_dataset/train.csv")
test_df = pd.read_csv("path_to_your_dataset/test.csv")

# Preprocess text data
def preprocess_text(text):
    text = str(text).lower().strip()
    return "sos " + text + " eos"

train_df['phrases'] = train_df['phrases'].apply(preprocess_text)
test_df['phrases'] = test_df['phrases'].apply(preprocess_text)

# Tokenization
tokenizer = Tokenizer(filters="")
tokenizer.fit_on_texts(train_df['phrases'].values)
vocab_size = len(tokenizer.word_index) + 1
max_length = 50  # Adjust based on your dataset

# Custom Data Generator
class CustomDataGenerator(tf.keras.utils.Sequence):
    def __init__(self, df, batch_size, tokenizer, max_length, shuffle=True):
        self.df = df.copy()
        self.batch_size = batch_size
        self.tokenizer = tokenizer
        self.max_length = max_length
        self.shuffle = shuffle
        self.n = len(self.df)

    def on_epoch_end(self):
        if self.shuffle:
            self.df = self.df.sample(frac=1).reset_index(drop=True)

    def __len__(self):
        return self.n // self.batch_size

    def __getitem__(self, index):
        batch = self.df.iloc[index * self.batch_size:(index + 1) * self.batch_size]
        X, y = self.__get_data(batch)
        return X, y

    def __get_data(self, batch):
        X, y = [], []
        for _, row in batch.iterrows():
            keypoints = np.array(row['keypoints'])  # Assuming keypoints are stored in a suitable format
            phrase = row['phrases']
            seq = self.tokenizer.texts_to_sequences([phrase])[0]
            for i in range(1, len(seq)):
                in_seq, out_seq = seq[:i], seq[i]
                in_seq = pad_sequences([in_seq], maxlen=self.max_length)[0]
                out_seq = to_categorical([out_seq], num_classes=self.vocab_size)[0]
                X.append(keypoints)
                y.append(out_seq)
        return np.array(X), np.array(y)

# Create data generators
train_generator = CustomDataGenerator(train_df, batch_size=32, tokenizer=tokenizer, max_length=max_length)
test_generator = CustomDataGenerator(test_df, batch_size=32, tokenizer=tokenizer, max_length=max_length)

# Define the model
input_shape = (train_generator[0][0].shape[1],)  # Shape of keypoints
input_layer = Input(shape=input_shape)
x = Dense(128, activation='relu')(input_layer)
x = Dropout(0.5)(x)
x = Bidirectional(LSTM(128, return_sequences=False))(x)
output_layer = Dense(vocab_size, activation='softmax')(x)

model = Model(inputs=input_layer, outputs=output_layer)
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Model summary
model.summary()

# Train the model
model.fit(train_generator, epochs=10, validation_data=test_generator, 
          callbacks=[EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)])

# Save the model
model.save("asl_fingerspelling_model.h5")

# Function to predict phrases from keypoints
def predict_phrase(model, keypoints, tokenizer, max_length):
    keypoints = np.array(keypoints).reshape(1, -1)  # Reshape for model input
    in_text = 'sos'
    for _ in range(max_length):
        sequence = tokenizer.texts_to_sequences([in_text])[0]
        sequence = pad_sequences([sequence], maxlen=max_length)
        y_pred = model.predict(keypoints)
        y_pred_index = np.argmax(y_pred)
        word = tokenizer.index_word.get(y_pred_index, None)
        if word is None or word == 'eos':
            break
        in_text += " " + word
    return in_text

# Example usage
# keypoints = [...]  # Replace with actual keypoint data
# predicted_phrase = predict_phrase(model, keypoints, tokenizer, max_length)
# print(predicted_phrase)
```
------------------------------------- 11
```python
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Dense, Lambda, Bidirectional, LSTM, Embedding, TimeDistributed
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
import os

# Constants
IMAGE_HEIGHT = 128
IMAGE_WIDTH = 128
NUM_CLASSES = 1000  # Adjust based on your dataset
MAX_CAPTION_LENGTH = 20  # Maximum length of captions
EMBEDDING_DIM = 256  # Dimension for embedding layer

# Function to load and preprocess images
def load_and_preprocess_image(image_path):
    img = load_img(image_path, target_size=(IMAGE_HEIGHT, IMAGE_WIDTH))
    img = img_to_array(img) / 255.0  # Normalize to [0, 1]
    return img

# Function to load dataset
def load_dataset(image_dir, captions_file):
    images = []
    captions = []
    
    with open(captions_file, 'r') as file:
        for line in file:
            image_name, caption = line.strip().split('\t')  # Assuming tab-separated
            image_path = os.path.join(image_dir, image_name)
            images.append(load_and_preprocess_image(image_path))
            captions.append(caption)
    
    return np.array(images), captions

# Function to tokenize captions
def tokenize_captions(captions):
    tokenizer = Tokenizer()
    tokenizer.fit_on_texts(captions)
    sequences = tokenizer.texts_to_sequences(captions)
    padded_sequences = pad_sequences(sequences, maxlen=MAX_CAPTION_LENGTH, padding='post')
    return padded_sequences, tokenizer

# Load dataset
image_dir = 'path/to/satellite/images'  # Update with your image directory
captions_file = 'path/to/captions.txt'  # Update with your captions file
images, captions = load_dataset(image_dir, captions_file)

# Tokenize captions
padded_sequences, tokenizer = tokenize_captions(captions)
vocab_size = len(tokenizer.word_index) + 1  # Add 1 for padding

# Define the model architecture
def create_model():
    # Image feature extraction model
    image_input = Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))
    conv_1 = Conv2D(64, (3, 3), activation='relu', padding='same')(image_input)
    batch_norm_1 = BatchNormalization()(conv_1)
    pool_1 = MaxPooling2D(pool_size=(2, 2))(batch_norm_1)
    
    conv_2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool_1)
    batch_norm_2 = BatchNormalization()(conv_2)
    pool_2 = MaxPooling2D(pool_size=(2, 2))(batch_norm_2)
    
    conv_3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool_2)
    pool_3 = MaxPooling2D(pool_size=(2, 2))(conv_3)
    
    # Flatten and prepare for LSTM
    flatten = Lambda(lambda x: tf.keras.backend.squeeze(x, axis=1))(pool_3)
    
    # Text input for captions
    caption_input = Input(shape=(MAX_CAPTION_LENGTH,))
    embedding = Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, mask_zero=True)(caption_input)
    
    # Combine image features and caption embeddings
    combined = tf.keras.layers.Concatenate()([flatten, embedding])
    
    # LSTM layers
    lstm_out = Bidirectional(LSTM(256, return_sequences=True))(combined)
    outputs = TimeDistributed(Dense(vocab_size, activation='softmax'))(lstm_out)
    
    model = Model(inputs=[image_input, caption_input], outputs=outputs)
    return model

# Create and compile the model
model = create_model()
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Prepare target data for training
target_data = to_categorical(padded_sequences, num_classes=vocab_size)

# Train the model
model.fit([images, padded_sequences], target_data, epochs=10, batch_size=32)

# Save the model
model.save('satellite_captioning_model.h5')

# Load the model for inference
loaded_model = tf.keras.models.load_model('satellite_captioning_model.h5')

# Function to generate captions for new images
def generate_caption(image_path, tokenizer, model):
    img = load_and_preprocess_image(image_path)
    img = np.expand_dims(img, axis=0)  # Add batch dimension
    
    # Start with the start token
    caption = [tokenizer.word_index['<start>']]
    
    for _ in range(MAX_CAPTION_LENGTH):
        padded_caption = pad_sequences([caption], maxlen=MAX_CAPTION_LENGTH, padding='post')
        prediction = model.predict([img, padded_caption])
        predicted_word_index = np.argmax(prediction[0, -1, :])
        
        # Break if the end token is predicted
        if predicted_word_index == tokenizer.word_index['<end>']:
            break
        
        caption.append(predicted_word_index)
    
    # Convert indices to words
    caption_text = ' '.join([tokenizer.index_word[i] for i in caption if i in tokenizer.index_word])
    return caption_text

# Example usage
test_image_path = 'path/to/test/image.jpg'  # Update with your test image path
predicted_caption = generate_caption(test_image_path, tokenizer, loaded_model)
print("Predicted Caption:", predicted_caption)
```
------------------------------------- 12
```python
import os
import numpy as np
import pickle
from tqdm import tqdm
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add
from tensorflow.keras.applications import VGG16
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split

# Constants
BASE_DIR = '/path/to/license_plate_images'  # Update with your dataset path
IMAGE_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 50

# Load VGG16 model for feature extraction
def load_vgg16_model():
    model = VGG16(weights='imagenet')
    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)
    return model

# Extract features from images
def extract_features(directory, model):
    features = {}
    for img_name in tqdm(os.listdir(directory)):
        img_path = os.path.join(directory, img_name)
        image = load_img(img_path, target_size=IMAGE_SIZE, color_mode='grayscale')
        image = img_to_array(image)
        image = np.expand_dims(image, axis=0)
        feature = model.predict(image, verbose=0)
        image_id = img_name.split('.')[0]
        features[image_id] = feature
    return features

# Load and preprocess captions
def load_captions(captions_file):
    with open(captions_file, 'r') as f:
        captions_doc = f.read()
    mapping = {}
    for line in captions_doc.split('\n'):
        tokens = line.split(',')
        if len(tokens) < 2:
            continue
        image_id = tokens[0].split('.')[0]
        caption = " ".join(tokens[1:])
        if image_id not in mapping:
            mapping[image_id] = []
        mapping[image_id].append(caption)
    return mapping

# Clean and preprocess captions
def clean_captions(mapping):
    for key, captions in mapping.items():
        for i in range(len(captions)):
            caption = captions[i].lower()
            caption = ''.join(e for e in caption if e.isalnum() or e.isspace())
            caption = 'startseq ' + caption + ' endseq'
            captions[i] = caption

# Create data generator
def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size):
    while True:
        for key in data_keys:
            captions = mapping[key]
            for caption in captions:
                seq = tokenizer.texts_to_sequences([caption])[0]
                for i in range(1, len(seq)):
                    in_seq, out_seq = seq[:i], seq[i]
                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]
                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]
                    yield [features[key][0], in_seq], out_seq

# Build the model
def build_model(vocab_size, max_length):
    # Image feature layers
    inputs1 = Input(shape=(4096,))
    fe1 = Dropout(0.4)(inputs1)
    fe2 = Dense(256, activation='relu')(fe1)

    # Sequence feature layers
    inputs2 = Input(shape=(max_length,))
    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)
    se2 = Dropout(0.4)(se1)
    se3 = LSTM(256)(se2)

    # Decoder model
    decoder1 = add([fe2, se3])
    decoder2 = Dense(256, activation='relu')(decoder1)
    outputs = Dense(vocab_size, activation='softmax')(decoder2)

    model = Model(inputs=[inputs1, inputs2], outputs=outputs)
    model.compile(loss='categorical_crossentropy', optimizer=Adam())
    return model

# Predict caption for an image
def predict_caption(model, image, tokenizer, max_length):
    in_text = 'startseq'
    for _ in range(max_length):
        sequence = tokenizer.texts_to_sequences([in_text])[0]
        sequence = pad_sequences([sequence], maxlen=max_length)
        yhat = model.predict([image, sequence], verbose=0)
        yhat = np.argmax(yhat)
        word = idx_to_word(yhat, tokenizer)
        if word is None:
            break
        in_text += " " + word
        if word == 'endseq':
            break
    return in_text

# Convert index to word
def idx_to_word(integer, tokenizer):
    for word, index in tokenizer.word_index.items():
        if index == integer:
            return word
    return None

# Main execution
if __name__ == "__main__":
    # Load VGG16 model
    vgg_model = load_vgg16_model()

    # Extract features
    features = extract_features(os.path.join(BASE_DIR, 'Images'), vgg_model)

    # Load captions
    mapping = load_captions(os.path.join(BASE_DIR, 'captions.txt'))

    # Clean captions
    clean_captions(mapping)

    # Prepare tokenizer
    all_captions = [caption for captions in mapping.values() for caption in captions]
    tokenizer = Tokenizer()
    tokenizer.fit_on_texts(all_captions)
    vocab_size = len(tokenizer.word_index) + 1
    max_length = max(len(caption.split()) for caption in all_captions)

    # Split data into training and testing
    image_ids = list(mapping.keys())
    train, test = train_test_split(image_ids, test_size=0.2, random_state=42)

    # Create data generator
    train_generator = data_generator(train, mapping, features, tokenizer, max_length, vocab_size, BATCH_SIZE)

    # Build and train the model
    model = build_model(vocab_size, max_length)
    steps = len(train) // BATCH_SIZE
    model.fit(train_generator, epochs=EPOCHS, steps_per_epoch=steps, verbose=1)

    # Save the model
    model.save('license_plate_recognition_model.h5')

    # Example prediction
    sample_image_id = 'sample_image_id'  # Replace with an actual image ID
    predicted_caption = predict_caption(model, features[sample_image_id], tokenizer, max_length)
    print(f'Predicted Caption: {predicted_caption}')
```
------------------------------------- 13
```python
import os
import pickle
import numpy as np
from tqdm.notebook import tqdm
from tensorflow.keras.layers import add, Input, Dense, LSTM, Embedding, Dropout
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.utils import to_categorical, plot_model
from tensorflow.keras.optimizers import Adam
import re
from PIL import Image
import matplotlib.pyplot as plt
from tensorflow.keras.callbacks import ModelCheckpoint

# Define directories
BASE_DIR = '/kaggle/input/flickr8k'
WORKING_DIR = '/kaggle/working'

# Load VGG16 model for feature extraction
def load_vgg_model():
    model = VGG16()
    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)
    return model

# Extract features from images
def extract_features(directory, model):
    features = {}
    for img_name in tqdm(os.listdir(directory)):
        img_path = os.path.join(directory, img_name)
        image = load_img(img_path, target_size=(224, 224))
        image = img_to_array(image)
        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))
        image = preprocess_input(image)
        feature = model.predict(image, verbose=0)
        image_id = img_name.split('.')[0]
        features[image_id] = feature
    return features

# Load captions and create mapping
def load_captions(captions_file):
    with open(captions_file, 'r') as f:
        next(f)  # Skip header
        captions_doc = f.read()
    
    mapping = {}
    for line in tqdm(captions_doc.split('\n')):
        tokens = line.split(',')
        if len(tokens) < 2:
            continue
        image_id = tokens[0].split('.')[0]
        caption = " ".join(tokens[1:])
        if image_id not in mapping:
            mapping[image_id] = []
        mapping[image_id].append(caption)
    return mapping

# Clean and preprocess text
def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^a-zA-Z]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return 'startseq ' + text + ' endseq'

def preprocess_captions(mapping):
    for key, captions in mapping.items():
        mapping[key] = [clean_text(caption) for caption in captions]

# Tokenize captions
def tokenize_captions(all_captions):
    tokenizer = Tokenizer()
    tokenizer.fit_on_texts(all_captions)
    return tokenizer

# Create data generator
def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size):
    while True:
        X1, X2, y = list(), list(), list()
        for key in data_keys:
            captions = mapping[key]
            for caption in captions:
                seq = tokenizer.texts_to_sequences([caption])[0]
                for i in range(1, len(seq)):
                    in_seq, out_seq = seq[:i], seq[i]
                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]
                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]
                    X1.append(features[key][0])
                    X2.append(in_seq)
                    y.append(out_seq)
                    if len(X1) == batch_size:
                        yield [np.array(X1), np.array(X2)], np.array(y)
                        X1, X2, y = list(), list(), list()

# Build the model
def build_model(vocab_size, max_length):
    inputs1 = Input(shape=(4096,))
    fe1 = Dropout(0.4)(inputs1)
    fe2 = Dense(256, activation='relu')(fe1)

    inputs2 = Input(shape=(max_length,))
    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)
    se2 = Dropout(0.4)(se1)
    se3 = LSTM(256)(se2)

    decoder1 = add([fe2, se3])
    decoder2 = Dense(256, activation='relu')(decoder1)
    outputs = Dense(vocab_size, activation='softmax')(decoder2)

    model = Model(inputs=[inputs1, inputs2], outputs=outputs)
    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])
    return model

# Predict caption for an image
def idx_to_word(integer, tokenizer):
    for word, index in tokenizer.word_index.items():
        if index == integer:
            return word
    return None

def predict_caption(model, image, tokenizer, max_length):
    in_text = 'startseq'
    for _ in range(max_length):
        sequence = tokenizer.texts_to_sequences([in_text])[0]
        sequence = pad_sequences([sequence], maxlen=max_length)
        yhat = model.predict([image, sequence], verbose=0)
        yhat = np.argmax(yhat)
        word = idx_to_word(yhat, tokenizer)
        if word is None:
            break
        in_text += " " + word
        if word == 'endseq':
            break
    return in_text

# Main execution
if __name__ == "__main__":
    # Load model and extract features
    vgg_model = load_vgg_model()
    features = extract_features(os.path.join(BASE_DIR, 'Images'), vgg_model)

    # Load and preprocess captions
    mapping = load_captions(os.path.join(BASE_DIR, 'captions.txt'))
    preprocess_captions(mapping)

    # Prepare data for training
    all_captions = [caption for captions in mapping.values() for caption in captions]
    tokenizer = tokenize_captions(all_captions)
    vocab_size = len(tokenizer.word_index) + 1
    max_length = max(len(caption.split()) for caption in all_captions)

    # Split data into training and testing
    image_ids = list(mapping.keys())
    split = int(len(image_ids) * 0.80)
    train = image_ids[:split]
    test = image_ids[split:]

    # Create and train the model
    model = build_model(vocab_size, max_length)
    steps = len(train) // 64
    model_checkpoint = ModelCheckpoint(os.path.join(WORKING_DIR, 'Image_model.h5'), save_best_only=True, save_weights_only=True)

    history = model.fit(data_generator(train, mapping, features, tokenizer, max_length, vocab_size, 64),
                        epochs=30,
                        steps_per_epoch=steps,
                        verbose=1,
                        callbacks=[model_checkpoint])

    # Save the model
    model.save(os.path.join(WORKING_DIR, 'Image_model.h5'))

    # Load the best weights
    model.load_weights(os.path.join(WORKING_DIR, 'Image_model.h5'))

    # Generate caption for a given image
    def generate_caption(image_name):
        image_id = image_name.split('.')[0]
        img_path = os.path.join(BASE_DIR, "Images", image_name)
        image = Image.open(img_path)
        feature = features[image_id]
        predicted_caption = predict_caption(model, feature, tokenizer, max_length)
        print(f'Predicted Caption for {image_name}: {predicted_caption}')
        plt.imshow(image)
        plt.axis('off')
        plt.show()

    # Example usage
    generate_caption("1001773457_577c3a7d70.jpg")
```
------------------------------------- 14
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import glob as gb
import os
import nibabel as nib
import tensorflow as tf
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, BatchNormalization, Activation, Concatenate
from tensorflow.keras.models import Model
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler

# Check if a GPU is available
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))
print("TensorFlow Version: ", tf.__version__)

# Define paths for the dataset
base_path = '/path/to/dataset/'
image_files = gb.glob(base_path + 'images/*.nii.gz')
label_files = gb.glob(base_path + 'labels/*.nii.gz')

def load_nifti_image(path):
    """Load a NIfTI image and return it as a numpy array."""
    img = nib.load(path)
    return img.get_fdata()

def preprocess_image(image):
    """Preprocess the image by normalizing and resizing."""
    image = image / np.max(image)  # Normalize
    return tf.convert_to_tensor(image, dtype=tf.float32)

def preprocess_label(label):
    """Preprocess the label by normalizing and resizing."""
    label = label.astype(np.uint8)  # Ensure label is in uint8 format
    return tf.convert_to_tensor(label, dtype=tf.float32)

# Load and preprocess images and labels
images = np.array([preprocess_image(load_nifti_image(i)) for i in image_files])
labels = np.array([preprocess_label(load_nifti_image(i)) for i in label_files])

# Split the dataset into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)

def unet_model(input_shape):
    """Build a 3D U-Net model."""
    inputs = Input(shape=input_shape)

    # Encoder
    c1 = Conv3D(32, (3, 3, 3), padding='same')(inputs)
    c1 = BatchNormalization()(c1)
    c1 = Activation('relu')(c1)
    p1 = MaxPooling3D((2, 2, 2))(c1)

    c2 = Conv3D(64, (3, 3, 3), padding='same')(p1)
    c2 = BatchNormalization()(c2)
    c2 = Activation('relu')(c2)
    p2 = MaxPooling3D((2, 2, 2))(c2)

    c3 = Conv3D(128, (3, 3, 3), padding='same')(p2)
    c3 = BatchNormalization()(c3)
    c3 = Activation('relu')(c3)
    p3 = MaxPooling3D((2, 2, 2))(c3)

    c4 = Conv3D(256, (3, 3, 3), padding='same')(p3)
    c4 = BatchNormalization()(c4)
    c4 = Activation('relu')(c4)
    p4 = MaxPooling3D((2, 2, 2))(c4)

    # Bottleneck
    c5 = Conv3D(512, (3, 3, 3), padding='same')(p4)
    c5 = BatchNormalization()(c5)
    c5 = Activation('relu')(c5)

    # Decoder
    u6 = UpSampling3D((2, 2, 2))(c5)
    u6 = Concatenate()([u6, c4])
    c6 = Conv3D(256, (3, 3, 3), padding='same')(u6)
    c6 = BatchNormalization()(c6)
    c6 = Activation('relu')(c6)

    u7 = UpSampling3D((2, 2, 2))(c6)
    u7 = Concatenate()([u7, c3])
    c7 = Conv3D(128, (3, 3, 3), padding='same')(u7)
    c7 = BatchNormalization()(c7)
    c7 = Activation('relu')(c7)

    u8 = UpSampling3D((2, 2, 2))(c7)
    u8 = Concatenate()([u8, c2])
    c8 = Conv3D(64, (3, 3, 3), padding='same')(u8)
    c8 = BatchNormalization()(c8)
    c8 = Activation('relu')(c8)

    u9 = UpSampling3D((2, 2, 2))(c8)
    u9 = Concatenate()([u9, c1])
    c9 = Conv3D(32, (3, 3, 3), padding='same')(u9)
    c9 = BatchNormalization()(c9)
    c9 = Activation('relu')(c9)

    outputs = Conv3D(4, (1, 1, 1), activation='softmax')(c9)  # 4 classes for segmentation

    model = Model(inputs=[inputs], outputs=[outputs])
    return model

# Create and compile the model
input_shape = (128, 128, 128, 4)  # Adjust based on your input dimensions
model = unet_model(input_shape)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Define callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)
model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min')

# Train the model
history = model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=2, epochs=50, callbacks=[early_stopping, model_checkpoint])

# Plot training history
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()
```
------------------------------------- 15
```python
!pip install keras==2.10
import tensorflow as tf
from tensorflow import keras

keras.__version__

!pip install segmentation-models==1.0.1

import os
import glob
import cv2  
import numpy as np  
import matplotlib.pyplot as plt
import pandas as pd
import tifffile
from PIL import Image
import albumentations as A
from tqdm import tqdm
from sklearn.model_selection import train_test_split

import segmentation_models as sm
from segmentation_models import Unet
from segmentation_models import get_preprocessing
from segmentation_models import metrics
from segmentation_models.metrics import iou_score
from segmentation_models import set_framework
from tensorflow.keras.layers import Conv2DTranspose, Dropout, Conv2D
from tensorflow.keras import regularizers
from keras.models import Model
from segmentation_models.utils import set_trainable
from segmentation_models import losses

sm.set_framework('tf.keras')

def load_dataset(root_dir):
    data_list = []
    label_mapping = {
        'Cercospora': 0,
        'Coffee Rust': 1,
        'Phoma': 2
    }

    for image_class in os.listdir(os.path.join(root_dir, "Images")):
        class_images = glob.glob(os.path.join(root_dir, "Images", image_class, "*.jpg"))
        for img_path in class_images:
            img_name = os.path.basename(img_path).split(".")[0]
            leaf_mask_path = os.path.join(root_dir, "Leaf Masks", image_class, img_name + "_leaf.ome.tiff")
            stress_mask_path = os.path.join(root_dir, "Biotic Stress Masks", image_class, img_name + "_" + image_class.lower() + ".ome.tiff")
            data_list.append((img_path, leaf_mask_path, stress_mask_path, image_class, label_mapping[image_class]))

    return data_list, label_mapping

train_data, train_label_mapping = load_dataset("/kaggle/input/segmentation-v6/Segmentation Coffee Dataset/Train")
test_data, test_label_mapping = load_dataset("/kaggle/input/segmentation-v6/Segmentation Coffee Dataset/Test")

train_df = pd.DataFrame(train_data, columns=['ImagePath', 'LeafMaskPath', 'BioticStressMaskPath', 'ClassName', 'Label'])
test_df = pd.DataFrame(test_data, columns=['ImagePath', 'LeafMaskPath', 'BioticStressMaskPath', 'ClassName', 'Label'])

def augment_image_and_mask(image, mask):
    augmentations = A.Compose([
        A.Resize(height=256, width=512, p=1.0),
        A.HorizontalFlip(p=0.5),
        A.Rotate(limit=30, p=0.3),
        A.VerticalFlip(p=0.3),
    ])
    mask = mask.astype(np.uint8)
    augmented = augmentations(image=image, mask=mask)
    return augmented['image'], augmented['mask']

def read_tiff_mask(mask_path):
    return tifffile.imread(mask_path)

def prepare_data(df):
    images, masks, labels = [], [], []
    for index, row in tqdm(df.iterrows(), total=len(df)):
        img = cv2.imread(row['ImagePath'])
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        mask = read_tiff_mask(row['LeafMaskPath'])
        for _ in range(3):  # Augment each image 3 times
            augmented_image, augmented_mask = augment_image_and_mask(img, mask)
            images.append(augmented_image)
            masks.append(np.where(augmented_mask == 0, 0, 1))  # Binarize mask
            labels.append(row['Label'])
    return np.array(images), np.array(masks), np.array(labels)

norm_train_images, norm_train_leaf_masks, norm_train_label = prepare_data(train_df)
norm_test_images, norm_test_leaf_masks, norm_test_label = prepare_data(test_df)

def scale_image(data):
    return (data - np.min(data)) / (np.max(data) - np.min(data))

norm_train_images = np.array([scale_image(i) for i in norm_train_images])
norm_test_images = np.array([scale_image(i) for i in norm_test_images])

input_shape = (256, 512, 3)
y_train = norm_train_leaf_masks.astype(np.float32)
y_val = norm_test_leaf_masks.astype(np.float32)

BACKBONE = 'resnet34'
preprocess_input = sm.get_preprocessing(BACKBONE)
x_train_preprocessed = preprocess_input(norm_train_images)
x_val_preprocessed = preprocess_input(norm_test_images)

model = sm.Unet(BACKBONE, input_shape=input_shape, encoder_weights='imagenet')

for layer in model.layers:
    if isinstance(layer, Conv2D):
        layer.kernel_regularizer = regularizers.l2(1e-4)
    if isinstance(layer, Dropout):
        layer.rate = 0.5  

output = Conv2DTranspose(1, (1, 1), activation='sigmoid')(model.output)
model = Model(inputs=model.input, outputs=output)
model.compile(optimizer='adam', loss=losses.DiceLoss(), metrics=['binary_accuracy', metrics.FScore(), iou_score])

history = model.fit(
    x=x_train_preprocessed,
    y=y_train,
    batch_size=16,
    epochs=40,
    validation_data=(x_val_preprocessed, y_val),
)

results_df = pd.DataFrame(history.history)
results_df.to_csv('segmentation_results.csv', index=False)

# Plotting metrics
def plot_metrics(history):
    metrics = ['loss', 'binary_accuracy', 'iou_score']
    for metric in metrics:
        plt.figure(figsize=(8, 5))
        plt.plot(history.history[metric], label='Train ' + metric)
        plt.plot(history.history['val_' + metric], label='Validation ' + metric)
        plt.title(metric)
        plt.xlabel('Epochs')
        plt.ylabel(metric)
        plt.legend()
        plt.show()

plot_metrics(history)

model.save('blood_vessel_segmentation_model.h5')

def preprocess(image_array):
    image = cv2.resize(image_array, (512, 256))
    normalized_image = image / 255.0
    return np.expand_dims(normalized_image, axis=0)

def predict(image, threshold=0.5):
    preprocessed_image = preprocess(image)
    prediction = model.predict(preprocessed_image)
    return np.squeeze(prediction > threshold)

# Example prediction
image_path = '/kaggle/input/sample/Try/Rust(516).jpg'
image = cv2.imread(image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

predicted_image = predict(image)

plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(image)
plt.title('Original Image')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.imshow(predicted_image)
plt.title('Predicted Mask')
plt.axis('off')

plt.tight_layout()
plt.show()
```
------------------------------------- 16
```python
import os
import numpy as np
import json
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow.keras.layers as tfl
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from PIL import Image, ImageDraw
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# Set random seed for reproducibility
tf.random.set_seed(221)

# Constants
INPUT_SIZE = (1920, 1080)
IMG_SIZE = 512  # Image size for the network
N = 512  # Number of images
path = ''  # Set your dataset path here
image_path = os.path.join(path, '/path/to/images/')
mask_path = os.path.join(path, '/path/to/masks/')

# Load annotations
with open('/path/to/annotations.json') as f:
    annotations = json.load(f)

# Create a dictionary to map image IDs to filenames
image_id_dict = {image['id']: image['file_name'] for image in annotations['images']}

# Load and preprocess images
images = np.zeros((N, IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
for img_id, img_filename in image_id_dict.items():
    img = Image.open(os.path.join(image_path, img_filename))
    img = img.resize((IMG_SIZE, IMG_SIZE))
    images[img_id - 1] = img

# Display first 9 images
fig = plt.figure(figsize=(12, 6))
for i in range(9):
    plt.subplot(3, 3, i + 1)
    plt.imshow(images[i] / 255)
    plt.axis('off')
fig.tight_layout()

# Create masks
masks = np.zeros((N, IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)  # 3 channels for multi-class masks
for annotation in annotations['annotations']:
    img_id = annotation['image_id']
    mask = Image.new('1', INPUT_SIZE)
    mask_draw = ImageDraw.Draw(mask, '1')
    segmentation = annotation['segmentation'][0]
    mask_draw.polygon(segmentation, fill=1)
    mask = mask.resize((IMG_SIZE, IMG_SIZE))
    masks[img_id - 1] = np.array(mask).reshape(IMG_SIZE, IMG_SIZE, 1)

# Split dataset into training and testing sets
images_train, images_test, masks_train, masks_test = train_test_split(images, masks, test_size=0.1, random_state=42)

# Define Jaccard index for evaluation
def jaccard_index(y_true, y_pred):
    y_true = tf.keras.backend.flatten(y_true)
    y_pred = tf.keras.backend.flatten(y_pred)
    intersection = tf.keras.backend.sum(y_true * y_pred)
    union = tf.keras.backend.sum(y_true) + tf.keras.backend.sum(y_pred) - intersection
    return (intersection + 1e-7) / (union + 1e-7)

# Define convolution block for U-Net
def conv_block(inputs, n_filters, maxpooling=True):
    x = tfl.Conv2D(filters=n_filters, kernel_size=3, padding='same')(inputs)
    x = tfl.BatchNormalization()(x)
    x = tfl.Activation('relu')(x)
    x = tfl.Conv2D(filters=n_filters, kernel_size=3, padding='same')(x)
    x = tfl.BatchNormalization()(x)
    skip = tfl.Activation('relu')(x)
    if maxpooling:
        out = tfl.MaxPool2D(pool_size=(2, 2), strides=(2, 2))(skip)
    else:
        out = skip
    return out, skip

# Define upsampling block for U-Net
def upsampling_block(expansive_input, contractive_input, n_filters):
    up = tfl.Conv2DTranspose(n_filters, kernel_size=2, strides=2, padding='same')(expansive_input)
    input = tfl.concatenate([up, contractive_input], axis=3)
    out, _ = conv_block(input, n_filters, False)
    return out

# Define U-Net model
def unet_model(input_size=(512, 512, 3), n_filters=64):
    inputs = tfl.Input(input_size)
    cblock1 = conv_block(inputs, n_filters)
    cblock2 = conv_block(cblock1[0], n_filters * 2)
    cblock3 = conv_block(cblock2[0], n_filters * 4)
    cblock4 = conv_block(cblock3[0], n_filters * 8)
    cblock5 = conv_block(cblock4[0], n_filters * 16, maxpooling=False)
    ublock6 = upsampling_block(cblock5[0], cblock4[1], n_filters * 8)
    ublock7 = upsampling_block(ublock6, cblock3[1], n_filters * 4)
    ublock8 = upsampling_block(ublock7, cblock2[1], n_filters * 2)
    ublock9 = upsampling_block(ublock8, cblock1[1], n_filters)
    out = tfl.Conv2D(3, 1, padding='same', activation='softmax')(ublock9)  # 3 classes for multi-class segmentation
    model = tf.keras.Model(inputs=inputs, outputs=out)
    return model

# Instantiate and compile the model
unet = unet_model()
unet.compile(optimizer=tf.keras.optimizers.Adam(),
             loss='sparse_categorical_crossentropy',
             metrics=[jaccard_index, 'accuracy'])

# Train the model
unet.fit(images_train, masks_train, epochs=10, batch_size=4, validation_split=0.2)

# Evaluate the model
unet.evaluate(images_test, masks_test, batch_size=4)

# Predict masks for test images
predicted_mask = unet.predict(images_test, batch_size=4)
predicted_mask_classes = np.argmax(predicted_mask, axis=-1)  # Get class with highest probability

# Display original images, true masks, and predicted masks
fig, ax = plt.subplots(5, 3, figsize=(12, 10))
for i in range(5):
    ax[i, 0].imshow(images_test[i])
    ax[i, 0].axis('off')
    ax[i, 1].imshow(masks_test[i])
    ax[i, 1].axis('off')
    ax[i, 2].imshow(predicted_mask_classes[i])
    ax[i, 2].axis('off')

ax[0, 0].set_title('Original image')
ax[0, 1].set_title('True mask')
ax[0, 2].set_title('Predicted mask')
fig.tight_layout()

# Print classification report
cr = classification_report(masks_test.flatten(), predicted_mask_classes.flatten())
print(cr)
```
------------------------------------- 17
```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
import json
import cv2
import os

# Load dataset from JSON file
def load_dataset(json_file):
    with open(json_file, 'r') as f:
        data = json.load(f)
    
    images = []
    masks = []
    
    for item in data:
        img_path = item['image_path']
        mask_path = item['mask_path']
        
        # Load and resize image
        img = cv2.imread(img_path)
        img = cv2.resize(img, (512, 512))
        images.append(img)
        
        # Load and resize mask
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        mask = cv2.resize(mask, (512, 512))
        masks.append(mask)
    
    return np.array(images), np.array(masks)

# U-Net model definition
def unet_model(input_shape):
    inputs = layers.Input(shape=input_shape)
    
    # Encoder
    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)
    p1 = layers.MaxPooling2D((2, 2))(c1)

    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)
    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)
    p2 = layers.MaxPooling2D((2, 2))(c2)

    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)
    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)
    p3 = layers.MaxPooling2D((2, 2))(c3)

    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)
    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)
    p4 = layers.MaxPooling2D((2, 2))(c4)

    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)
    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)

    # Decoder
    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)
    u6 = layers.concatenate([u6, c4])
    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)
    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)

    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)
    u7 = layers.concatenate([u7, c3])
    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)
    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)

    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)
    u8 = layers.concatenate([u8, c2])
    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)
    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)

    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)
    u9 = layers.concatenate([u9, c1])
    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)
    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)

    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)

    model = keras.Model(inputs=[inputs], outputs=[outputs])
    return model

# Main function to execute the training
def main(json_file):
    # Load dataset
    images, masks = load_dataset(json_file)
    
    # Normalize images
    images = images.astype('float32') / 255.0
    masks = masks.astype('float32') / 255.0  # Assuming masks are binary

    # Split dataset into training and validation
    split_index = int(0.8 * len(images))
    X_train, X_val = images[:split_index], images[split_index:]
    y_train, y_val = masks[:split_index], masks[split_index:]

    # Create U-Net model
    model = unet_model(input_shape=(512, 512, 3))
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    # Train the model
    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=16)

    # Save the model
    model.save('football_player_segmentation_model.h5')

# Run the main function with the path to your JSON file
if __name__ == "__main__":
    json_file_path = 'path/to/your/dataset.json'  # Update this path
    main(json_file_path)
```
------------------------------------- 18
```python
import os
import numpy as np
import nibabel as nib
import cv2
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Constants
IMG_SIZE = 128
VOLUME_SLICES = 100
VOLUME_START_AT = 22
TRAIN_DATASET_PATH = './BraTS2021_Training_Data/'

# Define segmentation classes
SEGMENT_CLASSES = {
    0: 'NOT tumor',
    1: 'NECROTIC/CORE',
    2: 'EDEMA',
    3: 'ENHANCING'
}

# Function to load NIfTI images
def load_nifti_image(file_path):
    return nib.load(file_path).get_fdata()

# Function to preprocess images and masks
def preprocess_data(case_path):
    flair = load_nifti_image(os.path.join(case_path, f'{case_path.split("/")[-1]}_flair.nii.gz'))
    t1ce = load_nifti_image(os.path.join(case_path, f'{case_path.split("/")[-1]}_t1ce.nii.gz'))
    seg = load_nifti_image(os.path.join(case_path, f'{case_path.split("/")[-1]}_seg.nii.gz'))
    
    X = np.zeros((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))
    Y = np.zeros((VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 4))

    for j in range(VOLUME_SLICES):
        X[j, :, :, 0] = cv2.resize(flair[:, :, j + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))
        X[j, :, :, 1] = cv2.resize(t1ce[:, :, j + VOLUME_START_AT], (IMG_SIZE, IMG_SIZE))
        mask = seg[:, :, j + VOLUME_START_AT]
        mask[mask == 4] = 3  # Convert 4 to 3 for consistency
        Y[j] = tf.one_hot(mask, depth=4)
    
    return X, Y

# Data generator class
class DataGenerator(tf.keras.utils.Sequence):
    def __init__(self, list_IDs, batch_size=1, shuffle=True):
        self.list_IDs = list_IDs
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.on_epoch_end()

    def __len__(self):
        return int(np.floor(len(self.list_IDs) / self.batch_size))

    def __getitem__(self, index):
        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]
        Batch_ids = [self.list_IDs[k] for k in indexes]
        X, y = self.__data_generation(Batch_ids)
        return X, y

    def on_epoch_end(self):
        self.indexes = np.arange(len(self.list_IDs))
        if self.shuffle:
            np.random.shuffle(self.indexes)

    def __data_generation(self, Batch_ids):
        X = np.zeros((self.batch_size, VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 2))
        Y = np.zeros((self.batch_size, VOLUME_SLICES, IMG_SIZE, IMG_SIZE, 4))
        
        for i, case in enumerate(Batch_ids):
            X[i], Y[i] = preprocess_data(case)
        
        return X / np.max(X), Y

# Build U-Net model
def build_unet(input_shape):
    inputs = Input(input_shape)
    conv1 = Conv2D(32, 3, activation='relu', padding='same')(inputs)
    conv1 = Conv2D(32, 3, activation='relu', padding='same')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

    conv2 = Conv2D(64, 3, activation='relu', padding='same')(pool1)
    conv2 = Conv2D(64, 3, activation='relu', padding='same')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    conv3 = Conv2D(128, 3, activation='relu', padding='same')(pool2)
    conv3 = Conv2D(128, 3, activation='relu', padding='same')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)

    conv4 = Conv2D(256, 3, activation='relu', padding='same')(pool3)
    conv4 = Conv2D(256, 3, activation='relu', padding='same')(conv4)
    drop4 = Dropout(0.5)(conv4)

    up5 = UpSampling2D(size=(2, 2))(drop4)
    merge5 = concatenate([conv3, up5], axis=3)
    conv5 = Conv2D(128, 3, activation='relu', padding='same')(merge5)
    conv5 = Conv2D(128, 3, activation='relu', padding='same')(conv5)

    up6 = UpSampling2D(size=(2, 2))(conv5)
    merge6 = concatenate([conv2, up6], axis=3)
    conv6 = Conv2D(64, 3, activation='relu', padding='same')(merge6)
    conv6 = Conv2D(64, 3, activation='relu', padding='same')(conv6)

    up7 = UpSampling2D(size=(2, 2))(conv6)
    merge7 = concatenate([conv1, up7], axis=3)
    conv7 = Conv2D(32, 3, activation='relu', padding='same')(merge7)
    conv7 = Conv2D(32, 3, activation='relu', padding='same')(conv7)

    outputs = Conv2D(4, (1, 1), activation='softmax')(conv7)

    return Model(inputs=inputs, outputs=outputs)

# Load dataset
train_and_val_directories = [f.path for f in os.scandir(TRAIN_DATASET_PATH) if f.is_dir()]
train_ids, val_ids = train_test_split(train_and_val_directories, test_size=0.2)

# Create data generators
training_generator = DataGenerator(train_ids)
valid_generator = DataGenerator(val_ids)

# Build and compile model
model = build_unet((IMG_SIZE, IMG_SIZE, 2))
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Callbacks
checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)
early_stop = EarlyStopping(monitor='val_loss', patience=5)
csv_logger = CSVLogger('training.log')

# Train model
model.fit(training_generator, validation_data=valid_generator, epochs=50, callbacks=[checkpoint, early_stop, csv_logger])

# Save the model
model.save("final_model.h5")

# Function to visualize predictions
def visualize_predictions(case_path):
    X, Y = preprocess_data(case_path)
    predictions = model.predict(X)
    
    for i in range(VOLUME_SLICES):
        plt.figure(figsize=(12, 6))
        plt.subplot(1, 3, 1)
        plt.imshow(X[i, :, :, 0], cmap='gray')
        plt.title('Flair Image')
        
        plt.subplot(1, 3, 2)
        plt.imshow(np.argmax(predictions[i], axis=-1), cmap='jet', alpha=0.5)
        plt.title('Predicted Segmentation')
        
        plt.subplot(1, 3, 3)
        plt.imshow(np.argmax(Y[i], axis=-1), cmap='jet', alpha=0.5)
        plt.title('Ground Truth Segmentation')
        
        plt.show()

# Visualize predictions for a specific case
visualize_predictions(train_ids[0])
```
------------------------------------- 19
```python
import tensorflow as tf
import numpy as np
import pandas as pd
import cv2
import random
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, LeakyReLU, BatchNormalization
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import LearningRateScheduler
from tensorflow.keras.utils import Sequence

# Constants
HEIGHT = 96
WIDTH = 96
INIT_LR = 0.0001
EPOCHS = 15
TRAIN_PATH = "./data/facial_keypoints_train.csv"
TEST_PATH = "./data/facial_keypoints_test.csv"

# Function to build a simple CNN model for facial keypoints detection
def build_model(height, width, depth):
    inputs = Input(shape=(height, width, depth))

    # Encoder
    x = Conv2D(32, (3, 3), padding='same')(inputs)
    x = LeakyReLU(alpha=0.2)(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)

    x = Conv2D(64, (3, 3), padding='same')(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)

    x = Conv2D(128, (3, 3), padding='same')(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)

    # Bottleneck
    x = Conv2D(256, (3, 3), padding='same')(x)
    x = LeakyReLU(alpha=0.2)(x)

    # Decoder
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(128, (3, 3), padding='same')(x)
    x = LeakyReLU(alpha=0.2)(x)

    x = UpSampling2D((2, 2))(x)
    x = Conv2D(64, (3, 3), padding='same')(x)
    x = LeakyReLU(alpha=0.2)(x)

    x = UpSampling2D((2, 2))(x)
    x = Conv2D(32, (3, 3), padding='same')(x)
    x = LeakyReLU(alpha=0.2)(x)

    # Output layer
    outputs = Conv2D(30, (3, 3), padding='same', activation='sigmoid')(x)  # 30 keypoints (x, y) pairs

    model = Model(inputs, outputs)
    return model

# Data generator for loading images and keypoints
class DataGenerator(Sequence):
    def __init__(self, image_paths, keypoints, batch_size=32, dim=(HEIGHT, WIDTH), n_channels=3, shuffle=True):
        self.image_paths = image_paths
        self.keypoints = keypoints
        self.batch_size = batch_size
        self.dim = dim
        self.n_channels = n_channels
        self.shuffle = shuffle
        self.on_epoch_end()

    def __len__(self):
        return int(np.floor(len(self.image_paths) / self.batch_size))

    def __getitem__(self, index):
        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]
        batch_image_paths = [self.image_paths[k] for k in indexes]
        return self.__data_generation(batch_image_paths)

    def on_epoch_end(self):
        self.indexes = np.arange(len(self.image_paths))
        if self.shuffle:
            np.random.shuffle(self.indexes)

    def __data_generation(self, batch_image_paths):
        X = np.empty((self.batch_size, *self.dim, self.n_channels))
        y = np.empty((self.batch_size, 30))  # 30 keypoints

        for i, img_path in enumerate(batch_image_paths):
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = cv2.resize(img, (WIDTH, HEIGHT))
            img = img / 255.0  # Normalize
            X[i,] = img

            # Load keypoints
            keypoints = self.keypoints[img_path]
            y[i,] = keypoints

        return X, y

# Load dataset
def load_data(train_path):
    data = pd.read_csv(train_path)
    image_paths = data['image_path'].values
    keypoints = data.iloc[:, 1:].values  # Assuming keypoints are in the remaining columns
    keypoints_dict = {image_paths[i]: keypoints[i] for i in range(len(image_paths))}
    return image_paths, keypoints_dict

# Load training data
train_image_paths, train_keypoints = load_data(TRAIN_PATH)
train_generator = DataGenerator(train_image_paths, train_keypoints)

# Load validation data
val_image_paths, val_keypoints = load_data(TEST_PATH)
val_generator = DataGenerator(val_image_paths, val_keypoints)

# Build and compile the model
model = build_model(HEIGHT, WIDTH, 3)
model.compile(optimizer=Adam(lr=INIT_LR), loss='mean_squared_error')

# Learning rate scheduler
def poly_decay(epoch):
    maxEpochs = EPOCHS
    baseLR = INIT_LR
    power = 1.0
    alpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power
    return alpha

callbacks = [LearningRateScheduler(poly_decay)]

# Train the model
history = model.fit(train_generator, validation_data=val_generator, epochs=EPOCHS, callbacks=callbacks)

# Plot training history
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.show()

# Save the model
model.save("facial_keypoints_detector.h5")
```
------------------------------------- 20
```python
import tensorflow as tf
import tensorflow_addons as tfa
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.initializers import RandomNormal
from tensorflow.keras.optimizers import *
from tensorflow.keras.models import Model
from tensorflow.keras.layers import *
from tensorflow.keras.callbacks import *
from tensorflow.keras import backend as K
import numpy as np
import pandas as pd
import os
import glob
import cv2
import matplotlib.pyplot as plt

# Set mixed precision policy
policy = tf.keras.mixed_precision.Policy('mixed_float16')
tf.keras.mixed_precision.set_policy(policy)

# Function to load RGB images and depth maps from CSV files
def load_data(csv_file):
    df = pd.read_csv(csv_file)
    images = df['image_path'].values
    depths = df['depth_path'].values
    return images, depths

# Function to load images
def load_img(path):
    image = tf.io.read_file(path)
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.convert_image_dtype(image, tf.float32)
    return image

# Function to load depth maps
def load_depth(path):
    depth = cv2.imread(path, cv2.IMREAD_UNCHANGED)
    depth = depth.astype(np.float32) / 255.0  # Normalize depth
    return np.expand_dims(depth, axis=-1)

# U-Net architecture with ResNet as encoder
def build_unet(input_shape):
    inputs = Input(shape=input_shape)
    
    # Encoder
    base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)
    skip_connections = [base_model.get_layer(layer).output for layer in ['conv1_relu', 'conv2_block3_out', 'conv3_block4_out', 'conv4_block6_out']]
    
    # Bottleneck
    x = base_model.output
    x = Conv2D(512, (3, 3), padding='same')(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    
    # Decoder
    for i in range(len(skip_connections)-1, -1, -1):
        x = Conv2DTranspose(256 // (2 ** i), (2, 2), strides=(2, 2), padding='same')(x)
        x = Concatenate()([x, skip_connections[i]])
        x = Conv2D(256 // (2 ** i), (3, 3), padding='same')(x)
        x = BatchNormalization()(x)
        x = Activation('relu')(x)

    outputs = Conv2D(1, (1, 1), activation='sigmoid')(x)
    
    model = Model(inputs, outputs)
    return model

# Load dataset
train_images, train_depths = load_data('train_data.csv')
val_images, val_depths = load_data('val_data.csv')

# Prepare datasets
train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_depths))
val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_depths))

def preprocess(image_path, depth_path):
    image = load_img(image_path)
    depth = load_depth(depth_path)
    return image, depth

train_dataset = train_dataset.map(preprocess).batch(8).prefetch(tf.data.experimental.AUTOTUNE)
val_dataset = val_dataset.map(preprocess).batch(8).prefetch(tf.data.experimental.AUTOTUNE)

# Build and compile model
model = build_unet((None, None, 3))
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])

# Train the model
model.fit(train_dataset, validation_data=val_dataset, epochs=50)

# Evaluate the model
loss, mae = model.evaluate(val_dataset)
print(f'Validation Loss: {loss}, Validation MAE: {mae}')

# Function to visualize predictions
def visualize_predictions(model, dataset):
    for image, depth in dataset.take(1):
        pred = model.predict(image)
        plt.figure(figsize=(12, 6))
        plt.subplot(1, 3, 1)
        plt.title('Input Image')
        plt.imshow(image[0].numpy())
        plt.axis('off')
        
        plt.subplot(1, 3, 2)
        plt.title('Ground Truth Depth')
        plt.imshow(depth[0].numpy().squeeze(), cmap='gray')
        plt.axis('off')
        
        plt.subplot(1, 3, 3)
        plt.title('Predicted Depth')
        plt.imshow(pred[0].squeeze(), cmap='gray')
        plt.axis('off')
        
        plt.show()

# Visualize predictions
visualize_predictions(model, val_dataset)
```
------------------------------------- 21
```python
import numpy as np
import h5py
import os
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, Concatenate
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Set parameters
image_height, image_width, num_channels = 256, 256, 3  # Adjust as per dataset
epochs = 50
batch_size = 16

# Function to load the dataset from HDF5 files
def load_data(hdf5_path):
    with h5py.File(hdf5_path, 'r') as f:
        images = np.array(f['images'])
        density_maps = np.array(f['density_maps'])
    return images, density_maps

# Load the dataset
hdf5_file_path = '/path/to/shanghaitech_part_B.h5'  # Update with your HDF5 file path
X, y = load_data(hdf5_file_path)

# Normalize images
X = X.astype('float32') / 255.0

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the model architecture
def build_model():
    input_layer = Input(shape=(image_height, image_width, num_channels))

    # Encoder
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)

    # Decoder
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)

    # Output layer
    output_layer = Conv2D(1, (1, 1), activation='linear', padding='same')(x)

    model = Model(inputs=input_layer, outputs=output_layer)
    return model

# Build and compile the model
model = build_model()
model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])

# Train the model
model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)

# Evaluate the model
loss, mae = model.evaluate(X_test, y_test)
print(f'Test Loss: {loss}')
print(f'Test MAE: {mae}')

# Predict on test set
predictions = model.predict(X_test)

# Visualize some predictions
def visualize_predictions(X, y, preds, num_images=5):
    plt.figure(figsize=(15, 10))
    for i in range(num_images):
        plt.subplot(3, num_images, i + 1)
        plt.imshow(X[i])
        plt.title('Input Image')
        plt.axis('off')

        plt.subplot(3, num_images, i + 1 + num_images)
        plt.imshow(y[i].reshape(image_height, image_width), cmap='jet')
        plt.title('Ground Truth Density Map')
        plt.axis('off')

        plt.subplot(3, num_images, i + 1 + 2 * num_images)
        plt.imshow(preds[i].reshape(image_height, image_width), cmap='jet')
        plt.title('Predicted Density Map')
        plt.axis('off')
    plt.tight_layout()
    plt.show()

# Visualize predictions
visualize_predictions(X_test, y_test, predictions)
```
------------------------------------- 22
```python
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split

# Configuration class to hold parameters
class Config:
    size = 224  # Image size for EfficientNet
    img_size = (size, size, 3)
    test_size = 0.15
    random_state = 42
    batch_size = 32
    epochs = 10

config = Config()

# Function to parse TFRecord files
def parse_tfrecord(example):
    feature_description = {
        'image': tf.io.FixedLenFeature([], tf.string),
        'label': tf.io.FixedLenFeature([], tf.int64),
    }
    return tf.io.parse_single_example(example, feature_description)

# Function to preprocess images
def preprocess_image(image):
    image = tf.io.decode_jpeg(image, channels=3)
    image = tf.image.resize(image, [config.size, config.size])
    image = image / 255.0  # Normalize to [0, 1]
    return image

# Load TFRecord dataset
def load_dataset(tfrecord_file):
    raw_dataset = tf.data.TFRecordDataset(tfrecord_file)
    parsed_dataset = raw_dataset.map(parse_tfrecord)
    images = []
    labels = []
    for parsed_record in parsed_dataset:
        images.append(preprocess_image(parsed_record['image']))
        labels.append(parsed_record['label'])
    return np.array(images), np.array(labels)

# Load your dataset
X, y = load_dataset('path/to/your/dataset.tfrecord')

# Split the dataset into training, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=config.test_size, random_state=config.random_state)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=config.random_state)

# Function to create the combined model using EfficientNet and StopNet
def create_model(num_classes):
    # Load EfficientNet as the base model
    efficientnet_base = tf.keras.applications.EfficientNetB0(include_top=False, input_shape=config.img_size, weights='imagenet')
    efficientnet_base.trainable = False  # Freeze the base model

    # Create StopNet-like architecture
    stopnet_input = layers.Input(shape=config.img_size)
    x = efficientnet_base(stopnet_input)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(128, activation='relu')(x)
    x = layers.Dropout(0.5)(x)
    x = layers.Dense(64, activation='relu')(x)
    output = layers.Dense(num_classes)(x)

    model = models.Model(inputs=stopnet_input, outputs=output)
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

# Create and train the model
model = create_model(len(np.unique(y_train)))
model.summary()

# Train the model
history = model.fit(
    X_train, 
    y_train, 
    batch_size=config.batch_size,
    epochs=config.epochs, 
    validation_data=(X_val, y_val),
    verbose=1
)

# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print("Test results \n Loss:", test_loss, '\n Accuracy:', test_accuracy)

# Function to visualize predictions
def visualize_predictions(X, y_true, y_pred, index):
    plt.figure(figsize=(6, 3))
    plt.subplot(1, 2, 1)
    plt.imshow(X[index])
    plt.title(f'True Label: {y_true[index]}')
    plt.axis('off')

    plt.subplot(1, 2, 2)
    plt.imshow(X[index])
    plt.title(f'Predicted: {y_pred[index]}')
    plt.axis('off')
    plt.show()

# Make predictions
y_pred = np.argmax(model.predict(X_test), axis=1)

# Visualize a sample prediction
visualize_predictions(X_test, y_test, y_pred, index=0)
```
------------------------------------- 23
```python
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split, StratifiedKFold

# Suppress warnings
import warnings
warnings.filterwarnings("ignore")

# Load your dataset
# Assuming the dataset is in numpy format
X = np.load('/path/to/your/network_traffic_data.npy')  # Replace with your dataset path
y = np.load('/path/to/your/labels.npy')  # Replace with your labels path

# Preprocess the labels (assuming binary classification: 0 for normal, 1 for DoS)
y = keras.utils.to_categorical(y, num_classes=2)

# Define the input shape based on your dataset
input_shape = (X.shape[1], X.shape[2], 1)  # Adjust according to your data shape

def create_bi_lstm_model(input_shape):
    """
    Create a Bi-directional LSTM model for classification.
    
    Args:
    input_shape (tuple): Shape of the input data.

    Returns:
    model: Compiled Keras model.
    """
    model = models.Sequential()
    
    # Add a Bi-directional LSTM layer
    model.add(layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=input_shape))
    model.add(layers.Dropout(0.5))
    
    # Add another LSTM layer
    model.add(layers.Bidirectional(layers.LSTM(32)))
    model.add(layers.Dropout(0.5))
    
    # Fully connected layer
    model.add(layers.Dense(32, activation='relu'))
    model.add(layers.Dropout(0.5))
    
    # Output layer
    model.add(layers.Dense(2, activation='softmax'))  # Change to 1 for binary classification with sigmoid

    return model

# Set the number of folds for cross-validation
num_folds = 5
skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)

# Initialize lists to store training and validation accuracies
train_accuracies = []
val_accuracies = []

# Iterate through folds
for fold_index, (train_index, val_index) in enumerate(skf.split(X, np.argmax(y, axis=1))):
    print(f"Training fold {fold_index + 1}/{num_folds}")

    # Split the data into training and validation sets
    X_train, X_val = X[train_index], X[val_index]
    y_train, y_val = y[train_index], y[val_index]

    # Reshape data for LSTM input
    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))
    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], X_val.shape[2], 1))

    # Create the model
    model = create_bi_lstm_model(input_shape)

    # Compile the model
    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')

    # Train the model
    history = model.fit(X_train,
                        y_train,
                        batch_size=64,
                        epochs=60,
                        validation_data=(X_val, y_val),
                        verbose=1)

    # Evaluate and store training accuracy
    train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)
    train_accuracies.append(train_acc)

    # Evaluate and store validation accuracy
    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)
    val_accuracies.append(val_acc)
    
    # Save the model for this fold
    model.save(f"bi_lstm_model_fold_{fold_index + 1}.h5")

# Print average training and validation accuracies
print(f"\nAverage Training Accuracy: {np.mean(train_accuracies):.4f}")
print(f"Average Validation Accuracy: {np.mean(val_accuracies):.4f}")

# Display model summary
model.summary()
```
------------------------------------- 24
```python
# Import necessary libraries
import os
import random as rn
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Set random seeds for reproducibility
os.environ['PYTHONHASHSEED'] = '0'
tf.random.set_seed(1)
np.random.seed(1)
rn.seed(1)

# Load your dataset
# Assuming 'X' is your feature array and 'y' is your one-hot encoded labels
# Replace this with your actual data loading mechanism
# X.shape should be (num_samples, 40, 249, 1)
# y.shape should be (num_samples, 10)
X = np.random.rand(1000, 40, 249, 1)  # Example data
y = to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)  # Example labels

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize the data
scaler = StandardScaler()
X_train = X_train.reshape(-1, 40 * 249)  # Flatten for scaling
X_test = X_test.reshape(-1, 40 * 249)
X_train = scaler.fit_transform(X_train).reshape(-1, 40, 249, 1)
X_test = scaler.transform(X_test).reshape(-1, 40, 249, 1)

# Define the CNN model
def create_model():
    model = Sequential()
    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(40, 249, 1)))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(BatchNormalization())
    
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(BatchNormalization())
    
    model.add(Conv2D(128, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(BatchNormalization())
    
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(10, activation='softmax'))  # 10 classes for output
    
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

# Create the model
model = create_model()

# Print model summary
model.summary()

# Train the model
history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2)

# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')

# Save the model
model.save('audio_classification_model.h5')
```

------------------------------------- 25
```python
import json
import datetime
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LeakyReLU
from tensorflow.keras.callbacks import EarlyStopping

# Constants for file paths
TEST = '/kaggle/input/widsdatathon2024-challenge1/test.csv'
TRAIN = '/kaggle/input/widsdatathon2024-challenge1/training.csv'

# Load datasets
df = pd.read_csv(TRAIN, index_col='patient_id')
test = pd.read_csv(TEST, index_col='patient_id')

# Define features and target
features = [
    'payer_type', 'patient_zip3', 'patient_age',
    'breast_cancer_diagnosis_code', 'metastatic_cancer_diagnosis_code',
    'patient_race', 'bmi', 'metastatic_first_novel_treatment',
    'Ozone', 'PM25', 'N02'
]
target = ['fault_1', 'fault_2', 'fault_3', 'fault_4', 'fault_5', 'fault_6', 'fault_7']  # Multi-label targets

# Prepare the data
X = df[features]
y = df[target]

# Split the data into training and validation sets
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)

# Fill missing values
X_train.fillna(X_train.mean(), inplace=True)
X_valid.fillna(X_valid.mean(), inplace=True)

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_valid_scaled = scaler.transform(X_valid)

# Build the multi-label classification model
def create_model(input_dim):
    model = Sequential()
    model.add(Dense(units=128, activation='relu', input_dim=input_dim))
    model.add(Dropout(0.5))  # Dropout layer for regularization
    model.add(Dense(units=64, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(units=len(target), activation='sigmoid'))  # Sigmoid for multi-label classification
    return model

# Compile the model
model = create_model(X_train_scaled.shape[1])
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model with early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_data=(X_valid_scaled, y_valid), callbacks=[early_stopping])

# Prepare test data for predictions
X_test = test[features]
X_test.fillna(X_test.mean(), inplace=True)
X_test_scaled = scaler.transform(X_test)

# Make predictions
y_pred = model.predict(X_test_scaled)

# Convert predictions to DataFrame
predictions_df = pd.DataFrame(y_pred, columns=target)
predictions_df = (predictions_df > 0.5).astype(int)  # Convert probabilities to binary predictions

# Save predictions to CSV
submission_filename = f'submission.csv'
submission_df = pd.DataFrame({'patient_id': test.index, **predictions_df})
submission_df.to_csv(submission_filename, index=False)

print("Submission file created:", submission_filename)
```
------------------------------------- 26
```python
# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
import keras_tuner as kt

# Load the dataset
df = pd.read_csv("/kaggle/input/patient-survival-prediction-data/Dataset.csv")

# Display basic information about the dataset
print(df.head())
print(df.info())
print(df.describe())

# Drop columns with unique values that won't help in prediction
columns_to_drop = ['encounter_id', 'patient_id', 'hospital_id', 'hospital_admit_source', 
                   'icu_admit_source', 'icu_stay_type', 'icu_id', 'readmission_status']
df.drop(columns=columns_to_drop, inplace=True)

# Function to identify columns with more than 50% missing values
def missing_col(df):
    missing_df = pd.DataFrame(df.isnull().sum() / df.shape[0], columns=["Missing"])
    return missing_df[missing_df["Missing"] >= 0.50]

# Drop columns with more than 50% missing values
missing_val_col = list(missing_col(df).index)
df.drop(columns=missing_val_col, inplace=True)

# Drop rows with missing values in critical columns
df = df[df[['bmi', 'weight', 'height']].notnull().all(axis=1)]

# Impute remaining missing values with the most frequent value
imputer = SimpleImputer(strategy='most_frequent')
df.iloc[:, :] = imputer.fit_transform(df)

# One-hot encode categorical variables
cat_cols = df.select_dtypes(include=object).columns.tolist()
df_encoded = pd.get_dummies(df, columns=cat_cols, drop_first=False)

# Define features and target variable
X = df_encoded.drop("DiagPeriodL90D", axis=1)  # Assuming 'DiagPeriodL90D' is the target column
y = df_encoded['DiagPeriodL90D']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=45)

# Normalize the feature data
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Convert scaled data back to DataFrame
X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)

# Build the model
def build_model():
    model = Sequential()
    model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(16, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))  # Change to 'softmax' if multi-class classification
    return model

# Compile the model
model = build_model()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(X_train_scaled, y_train, validation_data=(X_test_scaled, y_test), epochs=25, batch_size=32)

# Plot training & validation accuracy and loss
def plot_history(history):
    plt.figure(figsize=(12, 4))
    
    # Plot accuracy
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Model Accuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend()
    
    # Plot loss
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Model Loss')
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend()
    
    plt.show()

# Call the plot function
plot_history(history)

# Hyperparameter tuning using Keras Tuner
def model_builder(hp):
    model = Sequential()
    model.add(Dense(hp.Int('units', min_value=32, max_value=512, step=32), activation='relu', input_shape=(X_train_scaled.shape[1],)))
    model.add(Dense(hp.Int('units', min_value=32, max_value=512, step=32), activation='relu'))
    model.add(Dense(1, activation='sigmoid'))  # Change to 'softmax' if multi-class classification
    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model

tuner = kt.RandomSearch(model_builder, objective='val_loss', max_trials=5)

# Search for the best hyperparameters
tuner.search(X_train_scaled, y_train, epochs=25, validation_data=(X_test_scaled, y_test))

# Get the optimal hyperparameters
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]
print(f"""
The hyperparameter search is complete. The optimal number of units in the first densely-connected
layer is {best_hps.get('units')} and the optimal learning rate for the optimizer
is {best_hps.get('learning_rate')}.
""")
```
------------------------------------- 27
```python
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout, Input
from tensorflow.keras.callbacks import EarlyStopping

# Load the dataset
df = pd.read_csv('path_to_your_patient_survival_data.csv')

# Display the first few rows of the dataset
print("First few rows of the dataset:")
print(df.head())

# Display basic statistics for numerical columns in the dataset
print("\nSummary statistics for numerical columns:")
print(df.describe())

# Check for null values
print('\nChecking for null values...')
null_values = df.isnull().sum()
print('Columns with null values:')
print(null_values[null_values > 0])

# Impute null values with the mean of the column
imputer = SimpleImputer(strategy='mean')
df[df.select_dtypes(include=['float64', 'int64']).columns] = imputer.fit_transform(df.select_dtypes(include=['float64', 'int64']))

# Check for null values again
print("\nNull values after imputation:")
print(df.isnull().sum())

# Encode categorical features
categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
label_encoder = LabelEncoder()
for col in categorical_cols:
    df[col] = label_encoder.fit_transform(df[col])

# Define features and target
X = df.drop('target_label', axis=1)  # Replace 'target_label' with your actual target column name
y = df['target_label']

# Split the dataset into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the numerical features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)

# Reshape the input data to include a time step dimension
num_features = X_train_scaled.shape[1]
X_train_reshaped = X_train_scaled.reshape(-1, 1, num_features)
X_val_reshaped = X_val_scaled.reshape(-1, 1, num_features)

# Build the bi-LSTM model
model = Sequential()
model.add(Input(shape=(1, num_features)))
model.add(Bidirectional(LSTM(units=64, activation='tanh')))
model.add(Dropout(0.2))
model.add(Dense(units=1, activation='sigmoid'))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model with early stopping
early_stopping = EarlyStopping(patience=3, monitor='val_loss')
model.fit(X_train_reshaped, y_train, validation_data=(X_val_reshaped, y_val), epochs=10, batch_size=32, callbacks=[early_stopping])

# Predict probabilities
y_pred_probs = model.predict(X_val_reshaped)

# Calculate ROC curve
fpr, tpr, thresholds = roc_curve(y_val, y_pred_probs)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Convert probabilities to class predictions
y_pred = (y_pred_probs > 0.5).astype(int)

# Generate confusion matrix
conf_matrix = confusion_matrix(y_val, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=True)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Calculate and print metrics
accuracy = accuracy_score(y_val, y_pred)
precision = precision_score(y_val, y_pred)
recall = recall_score(y_val, y_pred)
f1 = f1_score(y_val, y_pred)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)
```
------------------------------------- 28
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
from sklearn.metrics import mean_squared_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dropout, Dense
from tensorflow.keras.optimizers import Adam, RMSprop
from tensorflow.keras import backend as K
from scikeras.wrappers import KerasRegressor
from sklearn.model_selection import GridSearchCV
import os

# Load the dataset
train_path = r"/kaggle/input/predictiva-dl-time-series-forecasting/train.csv"
test_path  = r"/kaggle/input/predictiva-dl-time-series-forecasting/test.csv"
train_data = pd.read_csv(train_path)
original_test_data = pd.read_csv(test_path)

# Function to explore data
def explore_data(data):
    print("Data Overview:")
    print(data.head())
    print("\nData Info:")
    print(data.info())
    print("\nSummary Statistics:")
    print(data.describe())

# Function to clean the data
def clean_data(data):
    data.dropna(inplace=True)  # Handle missing values
    # Handle outliers (customize as needed)
    data = data[(data['num_sold'] > 0) & (data['num_sold'] < 200)]
    data['num_sold'] = np.log1p(data['num_sold'])  # Log transform
    return data

# Function to standardize data
def standardize_data(data, columns_to_standardize):
    scaler = StandardScaler()
    data[columns_to_standardize] = scaler.fit_transform(data[columns_to_standardize])
    return data

# Function to normalize data
def normalize_data(data, columns_to_normalize):
    scaler = MinMaxScaler()
    data[columns_to_normalize] = scaler.fit_transform(data[columns_to_normalize])
    return data

# Clean the data
cleaned_train_data = clean_data(train_data)

# Standardize and normalize data
columns_to_standardize = ['num_sold']
standardized_train_data = standardize_data(cleaned_train_data.copy(), columns_to_standardize)

# Prepare features and target variable
X = standardized_train_data.drop(columns=['num_sold', 'date', 'id'])
y = standardized_train_data['num_sold']

# Split the data into training, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.15, shuffle=False)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=1/3, shuffle=False)

# Scale features for LSTM
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

# Reshape data for LSTM
X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])
X_val_reshaped = X_val_scaled.reshape(X_val_scaled.shape[0], 1, X_val_scaled.shape[1])
X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])

# Define a function to create the LSTM model
def create_lstm_model():
    model = Sequential()
    model.add(LSTM(units=100, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))
    model.add(Dropout(0.2))
    model.add(Dense(units=1))
    
    # Compile the model with RMSprop optimizer and mean squared error loss function
    model.compile(optimizer=RMSprop(), loss='mean_squared_error')
    return model

# Create KerasRegressor for use in GridSearchCV
lstm_regressor = KerasRegressor(build_fn=create_lstm_model, verbose=0)

# Define hyperparameters grid including optimizers and loss functions
param_grid = {
    'batch_size': [16, 32],
    'epochs': [50, 100],
    'dropout_rate': [0.0, 0.2],
}

# Perform GridSearchCV
grid_search = GridSearchCV(estimator=lstm_regressor, param_grid=param_grid, cv=3)
grid_result = grid_search.fit(X_train_reshaped, y_train)

# Print best results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))

# Create the best LSTM model
best_lstm_model = create_lstm_model()

# Train the model
history = best_lstm_model.fit(X_train_reshaped, y_train, epochs=grid_result.best_params_['epochs'], 
                              batch_size=grid_result.best_params_['batch_size'], 
                              validation_data=(X_val_reshaped, y_val), 
                              verbose=1)

# Evaluate the model on test data
loss = best_lstm_model.evaluate(X_test_reshaped, y_test)
print("Test Loss (MSE):", loss)

# Make predictions on the test set
y_test_pred = best_lstm_model.predict(X_test_reshaped)

# Plot the predicted vs actual values
plt.figure(figsize=(12, 6))
plt.plot(y_test.values, label='Actual Data', marker='o')
plt.plot(y_test_pred, label='Predicted Data', marker='o')
plt.xlabel('Samples')
plt.ylabel('Number of Products Sold')
plt.title('LSTM Model - Predicted vs Actual on Test Data')
plt.legend()
plt.show()

# Prepare original test data for predictions
X_original_test = original_test_data.drop(columns=['date', 'id'])
X_original_test_scaled = scaler.transform(X_original_test)
X_original_test_reshaped = X_original_test_scaled.reshape(X_original_test_scaled.shape[0], 1, X_original_test_scaled.shape[1])

# Make predictions on the original test set
y_original_test_pred = best_lstm_model.predict(X_original_test_reshaped)

# Create submission DataFrame
submission = pd.DataFrame({
    'id': original_test_data['id'],
    'num_sold': np.exp(y_original_test_pred.flatten())  # Inverse log transform
})

# Save submission file
download_path = r'/kaggle/working/'
submission.to_csv(os.path.join(download_path, "submission_lstm.csv"), index=False)
```
------------------------------------- 29
```python
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Lambda
from tensorflow.keras.models import Sequential
from tensorflow.keras.losses import Huber
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import LearningRateScheduler
from tensorflow.keras.metrics import mean_absolute_error
from statsmodels.tsa.statespace.sarimax import SARIMAX

# Directory containing input files
DIR_IN = "/path/to/your/dataset/"
# Full path to the input file
FILE_IN = os.path.join(DIR_IN, "sales_data.csv")
# Date used to split the training and the test part
SPLIT_DATE = "2020-01-01"
# Size of the window applied to the time series
WINDOW_SIZE = 10
# Batch size for model training and prediction
BATCH_SIZE = 32
# Buffer size used to shuffle the training set
SHUFFLE_BUFFER = 3000

# Load the dataset
df = pd.read_csv(FILE_IN, sep=",")
df['Date'] = pd.to_datetime(df['Date'])
df.set_index('Date', inplace=True)

# Resample the data to daily frequency
df = df.resample('D').sum()
df.fillna(method='ffill', inplace=True)

# Split the dataset into training and testing sets
df_train = df[df.index < SPLIT_DATE]
df_test = df[df.index >= SPLIT_DATE]

# Prepare the training and testing data
X_train = df_train['Products_Sold'].values
X_test = df_test['Products_Sold'].values

def window_train(series, window_size, batch_size, shuffle_buffer):
    dataset = tf.data.Dataset.from_tensor_slices(series)
    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)
    dataset = dataset.flat_map(lambda w: w.batch(window_size + 1))
    dataset = dataset.map(lambda w: (w[:-1], w[-1]))
    dataset = dataset.shuffle(shuffle_buffer)
    dataset = dataset.batch(batch_size).prefetch(1)
    return dataset

def window_test(series, window_size, batch_size):
    dataset = tf.data.Dataset.from_tensor_slices(series)
    dataset = dataset.window(window_size, shift=1, drop_remainder=True)
    dataset = dataset.flat_map(lambda w: w.batch(window_size))
    dataset = dataset.batch(batch_size).prefetch(1)
    return dataset

# Create the train and test datasets
ds_train = window_train(X_train, WINDOW_SIZE, BATCH_SIZE, SHUFFLE_BUFFER)
ds_test = window_test(np.concatenate((X_train[-WINDOW_SIZE:], X_test[:-1])), WINDOW_SIZE, BATCH_SIZE)

# Build the LSTM model
tf.keras.backend.clear_session()
model = Sequential([
    Lambda(lambda x: tf.expand_dims(x, axis=-1), input_shape=[WINDOW_SIZE]),
    Bidirectional(LSTM(32, return_sequences=True)),
    Bidirectional(LSTM(32)),
    Dense(1)
])

# Compile the model
model.compile(loss=Huber(), optimizer=Adam(learning_rate=1e-4), metrics=['mae'])

# Train the model
hist = model.fit(ds_train, epochs=100)

# Make predictions with the LSTM model
forecasts_lstm = model.predict(ds_test).squeeze()

# SARIMAX model for comparison
sarimax_model = SARIMAX(df_train['Products_Sold'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))
sarimax_fit = sarimax_model.fit(disp=False)
forecasts_sarimax = sarimax_fit.forecast(steps=len(X_test))

# Plot the results
plt.figure(figsize=(14, 7))
plt.plot(df_test.index, X_test, label='Actual Sales', color='blue')
plt.plot(df_test.index, forecasts_lstm, label='LSTM Forecast', color='orange')
plt.plot(df_test.index, forecasts_sarimax, label='SARIMAX Forecast', color='green')
plt.title('Sales Forecasting: LSTM vs SARIMAX')
plt.xlabel('Date')
plt.ylabel('Number of Products Sold')
plt.legend()
plt.show()

# Calculate and print MAE for both models
mae_lstm = mean_absolute_error(X_test, forecasts_lstm)
mae_sarimax = mean_absolute_error(X_test, forecasts_sarimax)

print(f"MAE for LSTM: {mae_lstm:.2f}")
print(f"MAE for SARIMAX: {mae_sarimax:.2f}")
```
------------------------------------- 30
```python
import time
import os
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
from tensorflow.keras.losses import mean_squared_error
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras import Sequential
from sklearn.preprocessing import MinMaxScaler

# Load the dataset
data = pd.read_csv('path_to_your_dataset.csv')  # Update with your dataset path
data['Date'] = pd.to_datetime(data['Date'])
data = data[data['Commodity'] == 'Potato Red'].set_index('Date')

# Prepare the data
prices = data['Average'].values.reshape(-1, 1)
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_prices = scaler.fit_transform(prices)

# Function to create dataset for LSTM
def create_dataset(data, time_step=1):
    X, y = [], []
    for i in range(len(data) - time_step - 1):
        X.append(data[i:(i + time_step), 0])
        y.append(data[i + time_step, 0])
    return np.array(X), np.array(y)

# Define time step
time_step = 30
X, y = create_dataset(scaled_prices, time_step)

# Reshape input to be [samples, time steps, features]
X = X.reshape(X.shape[0], X.shape[1], 1)

# Split the dataset into training and testing sets
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = y[:train_size], y[train_size:]

# Build the LSTM model
def build_model(input_shape):
    model = Sequential()
    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))
    model.add(Dropout(0.2))
    model.add(LSTM(50, return_sequences=False))
    model.add(Dropout(0.2))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

# Create and train the model
model = build_model((X_train.shape[1], 1))
model.fit(X_train, y_train, epochs=100, batch_size=32)

# Make predictions
train_predict = model.predict(X_train)
test_predict = model.predict(X_test)

# Inverse transform the predictions
train_predict = scaler.inverse_transform(train_predict)
test_predict = scaler.inverse_transform(test_predict)

# Calculate RMSE
train_rmse = np.sqrt(mean_squared_error(prices[time_step:train_size + time_step], train_predict))
test_rmse = np.sqrt(mean_squared_error(prices[train_size + time_step:], test_predict))

print(f'Train RMSE: {train_rmse}')
print(f'Test RMSE: {test_rmse}')

# Plot the results
plt.figure(figsize=(14, 5))
plt.plot(data.index, prices, label='Real Prices', color='blue')
train_dates = data.index[time_step:train_size + time_step]
test_dates = data.index[train_size + time_step:]
plt.plot(train_dates, train_predict, label='Train Predictions', color='orange')
plt.plot(test_dates, test_predict, label='Test Predictions', color='red')
plt.xlabel('Date')
plt.ylabel('Price')
plt.title('Potato Red Price Prediction')
plt.legend()
plt.show()
```
------------------------------------- 31
```python
# Import necessary libraries
import os
import yfinance as yf
import pandas as pd
import numpy as np
import math
import datetime as dt
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, GRU
from itertools import cycle

# Function to fetch and preprocess stock data
def fetch_stock_data(ticker, start_date, end_date):
    df = yf.Ticker(ticker)
    df = df.history(start=start_date, end=end_date)
    df.reset_index(inplace=True)
    return df

# Function to scale data
def scale_data(data):
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = scaler.fit_transform(data)
    return scaled_data, scaler

# Function to create dataset matrix
def create_dataset(dataset, time_step=1):
    dataX, dataY = [], []
    for i in range(len(dataset) - time_step - 1):
        a = dataset[i:(i + time_step), 0]
        dataX.append(a)
        dataY.append(dataset[i + time_step, 0])
    return np.array(dataX), np.array(dataY)

# Function to build the GAN model
def build_gan_model(input_shape):
    model = Sequential()
    model.add(Bidirectional(LSTM(50, return_sequences=True), input_shape=input_shape))
    model.add(Dropout(0.2))
    model.add(Bidirectional(LSTM(50, return_sequences=False)))
    model.add(Dropout(0.2))
    model.add(Dense(25))
    model.add(Dropout(0.2))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

# Function to plot training history
def plot_training_history(history):
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    epochs = range(len(loss))
    
    plt.plot(epochs, loss, 'r', label='Training loss')
    plt.plot(epochs, val_loss, 'b', label='Validation loss')
    plt.title('Training and validation loss of GAN')
    plt.legend(loc=0)
    plt.figure()
    plt.show()

# Function to evaluate model performance
def evaluate_model(y_true, y_pred, scaler):
    y_true_inverse = scaler.inverse_transform(y_true.reshape(-1, 1))
    y_pred_inverse = scaler.inverse_transform(y_pred)
    
    rmse = math.sqrt(mean_squared_error(y_true_inverse, y_pred_inverse))
    mae = mean_absolute_error(y_true_inverse, y_pred_inverse)
    r2 = r2_score(y_true_inverse, y_pred_inverse)
    explained_var = explained_variance_score(y_true_inverse, y_pred_inverse)
    
    return rmse, mae, r2, explained_var

# Function to visualize predictions
def visualize_predictions(original, predicted, dates):
    plt.figure(figsize=(14, 5))
    plt.plot(dates, original, color='blue', label='Original Prices')
    plt.plot(dates, predicted, color='red', label='Predicted Prices')
    plt.title('Stock Price Prediction')
    plt.xlabel('Date')
    plt.ylabel('Price')
    plt.legend()
    plt.show()

# Main execution
if __name__ == "__main__":
    # Fetch stock data
    ticker = "ETH-USD"
    start_date = "2021-01-01"
    end_date = "2024-02-06"
    df = fetch_stock_data(ticker, start_date, end_date)

    # Prepare data
    close_stock = df['Close'].values.reshape(-1, 1)
    scaled_data, scaler = scale_data(close_stock)

    # Split data into training and testing sets
    training_size = int(len(scaled_data) * 0.80)
    train_data, test_data = scaled_data[0:training_size], scaled_data[training_size:]

    # Create datasets
    time_step = 60
    X_train, y_train = create_dataset(train_data, time_step)
    X_test, y_test = create_dataset(test_data, time_step)

    # Reshape input to be [samples, time steps, features]
    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

    # Build and train the GAN model
    model = build_gan_model((X_train.shape[1], 1))
    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=40, batch_size=32, verbose=1)

    # Plot training history
    plot_training_history(history)

    # Make predictions
    train_predict = model.predict(X_train)
    test_predict = model.predict(X_test)

    # Evaluate model performance
    rmse, mae, r2, explained_var = evaluate_model(y_test, test_predict, scaler)
    print(f"Test RMSE: {rmse}, MAE: {mae}, R2: {r2}, Explained Variance: {explained_var}")

    # Visualize predictions
    dates = df['Date'].values[training_size + time_step + 1:len(df) - 1]
    visualize_predictions(scaler.inverse_transform(y_test.reshape(-1, 1)), scaler.inverse_transform(test_predict), dates)
```
------------------------------------- 32
```python
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

# Load the dataset
def load_data(file_path):
    """
    Load historical Ethereum closing prices from a CSV file.
    """
    data = pd.read_csv(file_path)
    data['Date'] = pd.to_datetime(data['Date'])
    data.set_index('Date', inplace=True)
    return data

# Preprocess the data
def preprocess_data(data):
    """
    Preprocess the data by scaling the closing prices.
    """
    data = data[['Close']]
    scaler = StandardScaler()
    data['Close'] = scaler.fit_transform(data[['Close']])
    return data, scaler

# Create features and labels
def create_dataset(data, time_step=1):
    """
    Create a dataset with features and labels.
    """
    X, y = [], []
    for i in range(len(data) - time_step - 1):
        X.append(data[i:(i + time_step), 0])
        y.append(data[i + time_step, 0])
    return np.array(X), np.array(y)

# Build the model
def build_model(input_shape):
    """
    Build a Sequential Neural Network model.
    """
    model = Sequential()
    model.add(Dense(units=128, activation='relu', input_shape=input_shape))
    model.add(Dropout(0.2))
    model.add(Dense(units=64, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(units=32, activation='relu'))
    model.add(Dense(units=1))  # Output layer for regression
    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')
    return model

# Train the model
def train_model(model, X_train, y_train, epochs=100, batch_size=32):
    """
    Train the model with the training data.
    """
    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)
    return history

# Evaluate the model
def evaluate_model(model, X_test, y_test):
    """
    Evaluate the model performance on the test data.
    """
    predictions = model.predict(X_test)
    return predictions

# Plot training history
def plot_history(history):
    """
    Plot the training loss history.
    """
    plt.plot(history.history['loss'], label='train loss')
    plt.title('Model Loss')
    plt.ylabel('Loss')
    plt.xlabel('Epoch')
    plt.legend()
    plt.show()

# Main function to execute the workflow
def main():
    # Load and preprocess data
    data = load_data('ETH-USD.csv')  # Replace with your file path
    processed_data, scaler = preprocess_data(data)

    # Create dataset
    time_step = 10  # Number of previous days to consider for prediction
    X, y = create_dataset(processed_data.values, time_step)
    X = X.reshape(X.shape[0], X.shape[1], 1)  # Reshape for LSTM input

    # Split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Build and train the model
    model = build_model((X_train.shape[1], 1))
    history = train_model(model, X_train, y_train, epochs=100, batch_size=32)

    # Evaluate the model
    predictions = evaluate_model(model, X_test, y_test)

    # Inverse transform predictions
    predictions = scaler.inverse_transform(predictions)
    y_test = scaler.inverse_transform(y_test.reshape(-1, 1))

    # Plot training history
    plot_history(history)

    # Print predictions and actual values
    for i in range(len(predictions)):
        print(f"Predicted: {predictions[i][0]:.2f}, Actual: {y_test[i][0]:.2f}")

if __name__ == "__main__":
    main()
```

------------------------------------- 33
```python
import pandas as pd
import numpy as np
import re
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from keras.models import Sequential
from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional
from keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Load the Yelp reviews dataset
# Assuming the dataset is in a CSV file with 'text' and 'rating' columns
data = pd.read_csv('yelp_reviews.csv')  # Update with the correct path to your dataset

# Data Preprocessing
def clean_text(text):
    text = re.sub(r'@\w+', '', text)  # Remove Twitter handles
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # Remove non-alphabetic characters
    text = re.sub(r'\s+', ' ', text)  # Remove extra whitespace
    return text.lower()

# Clean the reviews
data['cleaned_text'] = data['text'].apply(clean_text)

# Prepare the data for training
X = data['cleaned_text']
y = data['rating'] - 1  # Convert ratings from 1-5 to 0-4 for classification

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Tokenization and Padding
max_words = 10000  # Maximum number of words to consider
max_len = 100  # Maximum length of each review

tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(X_train)
X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)
X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)

# Build the Bidirectional LSTM model
model = Sequential()
model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))
model.add(Bidirectional(LSTM(64, return_sequences=True)))
model.add(Dropout(0.5))
model.add(Bidirectional(LSTM(32)))
model.add(Dense(5, activation='softmax'))  # 5 classes for star ratings

# Compile the model
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Set up callbacks
checkpoint_cb = ModelCheckpoint("best_model.h5", save_best_only=True)
early_stopping_cb = EarlyStopping(patience=3, restore_best_weights=True)

# Train the model
history = model.fit(X_train_pad, y_train, epochs=10, batch_size=64, 
                    validation_split=0.1, 
                    callbacks=[checkpoint_cb, early_stopping_cb])

# Evaluate the model
loss, accuracy = model.evaluate(X_test_pad, y_test)
print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')

# Predictions
y_pred = model.predict(X_test_pad)
y_pred_classes = np.argmax(y_pred, axis=1)

# Classification report and confusion matrix
print(classification_report(y_test, y_pred_classes))
cm = confusion_matrix(y_test, y_pred_classes)

# Plot confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[1, 2, 3, 4, 5], yticklabels=[1, 2, 3, 4, 5])
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.title('Confusion Matrix')
plt.show()
```
------------------------------------- 34
```python
# Import necessary libraries
import tensorflow as tf
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Input, LSTM, Embedding, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.preprocessing import LabelEncoder
import pandas as pd
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from livelossplot import PlotLossesKeras
from tqdm import tqdm

# Load the dataset
data_train = pd.read_csv("path/to/train.csv")  # Update with your path
data_val = pd.read_csv("path/to/valid.csv")    # Update with your path

# Data preprocessing
def preprocess_data(data):
    data = data.drop_duplicates().reset_index(drop=True)
    return data

data_train = preprocess_data(data_train)
data_val = preprocess_data(data_val)

# Combine train and validation data for consistent preprocessing
overall_df = pd.concat([data_train, data_val]).reset_index(drop=True)

# Remove unwanted characters from essays
remove_characters = ['~', '\xa0', '\xad', '\u200b', '\u200c', '\u200d', '\u200e', '\u2060', '\ueb9a', '\uf03d', '\uf06e', '\ufeff', "\n"]
def clean_text(text):
    for char in remove_characters:
        text = text.replace(char, "")
    return text

overall_df['essays'] = overall_df['essays'].apply(clean_text)

# Tokenization
tokenizer = Tokenizer(num_words=20000, filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n', split=' ')
tokenizer.fit_on_texts(overall_df['essays'])

# Convert texts to sequences
train_sequences = tokenizer.texts_to_sequences(data_train['essays'])
val_sequences = tokenizer.texts_to_sequences(data_val['essays'])

# Pad sequences
max_length = 64
train_sequences = pad_sequences(train_sequences, maxlen=max_length, padding='post')
val_sequences = pad_sequences(val_sequences, maxlen=max_length, padding='post')

# Prepare labels
le = LabelEncoder()
train_labels = le.fit_transform(data_train['label'])
val_labels = le.transform(data_val['label'])

# Build the model
def build_model():
    latent_dim = 128
    encoder_inputs = Input(shape=(max_length,))
    enc_emb = Embedding(input_dim=20000, output_dim=latent_dim, trainable=True)(encoder_inputs)
    encoder_lstm = LSTM(latent_dim, return_sequences=False)(enc_emb)
    decoder_dense = Dense(1, activation='sigmoid')(encoder_lstm)  # Binary classification
    model = Model(inputs=encoder_inputs, outputs=decoder_dense)
    return model

model = build_model()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
plot_losses = PlotLossesKeras()

# Train the model
model.fit(train_sequences, train_labels, validation_data=(val_sequences, val_labels), 
          epochs=20, batch_size=32, callbacks=[early_stopping, plot_losses])

# Save the model
model.save("ai_text_detection_model.h5")

# Evaluate the model
val_predictions = (model.predict(val_sequences) > 0.5).astype("int32")

# Classification report
print(classification_report(val_labels, val_predictions))

# Confusion matrix
conf_matrix = confusion_matrix(val_labels, val_predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Student', 'AI'], yticklabels=['Student', 'AI'])
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.title('Confusion Matrix')
plt.show()
```
------------------------------------- 35
```python
import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional
from transformers import BertTokenizer, TFBertModel

# Load the dataset
data_path = 'path_to_your_malayalam_news_headlines_dataset.csv'  # Update with your dataset path
df = pd.read_csv(data_path)

# Display the first few rows of the dataset
print(df.head())

# Check for missing values
print(df.isnull().sum())

# Encode labels
label_encoder = LabelEncoder()
df['label'] = label_encoder.fit_transform(df['category'])  # Assuming 'category' is the label column

# Split the dataset into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(df['headline'], df['label'], test_size=0.2, random_state=42)

# Tokenization and padding
max_length = 100  # Maximum length of sequences
tokenizer = Tokenizer(num_words=10000, oov_token="<OOV>")
tokenizer.fit_on_texts(X_train)

X_train_seq = tokenizer.texts_to_sequences(X_train)
X_val_seq = tokenizer.texts_to_sequences(X_val)

X_train_padded = pad_sequences(X_train_seq, maxlen=max_length, padding='post')
X_val_padded = pad_sequences(X_val_seq, maxlen=max_length, padding='post')

# Define the LSTM model
def create_lstm_model(vocab_size, embedding_dim, max_length):
    model = Sequential()
    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))
    model.add(Bidirectional(LSTM(64, return_sequences=True)))
    model.add(Dropout(0.5))
    model.add(Bidirectional(LSTM(32)))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(len(label_encoder.classes_), activation='softmax'))  # Output layer for multi-class classification
    return model

# Create and compile the model
vocab_size = 10000
embedding_dim = 16
model = create_lstm_model(vocab_size, embedding_dim, max_length)
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Print model summary
model.summary()

# Train the model
history = model.fit(X_train_padded, y_train, 
                    validation_data=(X_val_padded, y_val), 
                    epochs=5, 
                    batch_size=32)

# Evaluate the model
loss, accuracy = model.evaluate(X_val_padded, y_val)
print(f"Validation Accuracy: {accuracy * 100:.2f}%")

# Function to predict categories for new headlines
def predict_headlines(headlines):
    sequences = tokenizer.texts_to_sequences(headlines)
    padded = pad_sequences(sequences, maxlen=max_length, padding='post')
    predictions = model.predict(padded)
    predicted_classes = np.argmax(predictions, axis=1)
    return label_encoder.inverse_transform(predicted_classes)

# Example usage
new_headlines = [
    "  ",
    "    "
]

predicted_categories = predict_headlines(new_headlines)
for headline, category in zip(new_headlines, predicted_categories):
    print(f"Headline: {headline}\nPredicted Category: {category}\n")
```
------------------------------------- 36
```python
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score
from transformers import BertTokenizer, TFBertForSequenceClassification

# Load the dataset
df = pd.read_csv('path/to/your/movie_reviews.csv')

# Check the first few rows of the dataframe
print(df.head())

# Preprocess the data
def preprocess_data(df):
    # Map labels to integers
    df['label'] = df['label'].map({'Fresh': 1, 'Rotten': 0})
    return df['review'].values, df['label'].values

reviews, labels = preprocess_data(df)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(reviews, labels, test_size=0.2, random_state=42)

# Load BERT tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Tokenize the input data
def tokenize_data(reviews):
    return tokenizer(reviews.tolist(), padding=True, truncation=True, max_length=512, return_tensors='tf')

train_encodings = tokenize_data(X_train)
test_encodings = tokenize_data(X_test)

# Create TensorFlow datasets
train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).shuffle(1000).batch(16)
test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(16)

# Load BERT model for sequence classification
model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

# Compile the model
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# Train the model
history = model.fit(train_dataset, epochs=3, validation_data=test_dataset)

# Evaluate the model
predictions = model.predict(test_dataset)
predicted_labels = np.argmax(predictions.logits, axis=1)

# Calculate metrics
accuracy = accuracy_score(y_test, predicted_labels)
precision = precision_score(y_test, predicted_labels)
recall = recall_score(y_test, predicted_labels)

print("Accuracy: {:.2f}%".format(accuracy * 100))
print("Precision: {:.2f}%".format(precision * 100))
print("Recall: {:.2f}%".format(recall * 100))

# Print classification report
print(classification_report(y_test, predicted_labels, target_names=['Rotten', 'Fresh']))
```
------------------------------------- 37
```python
import pandas as pd
import numpy as np
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Embedding, Dropout, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
import re
import ast
from tqdm import tqdm

# Load SQL queries dataset
def load_data(file_path):
    with open(file_path, 'r') as f:
        data = f.read()
    queries = re.findall(r'({.*?})', data)
    X, y = [], []
    for query in queries:
        try:
            query_dict = ast.literal_eval(query)
            X.append(query_dict['query'])  # Assuming the query is stored under 'query'
            y.append(query_dict['label'])    # Assuming the label is stored under 'label'
        except Exception as e:
            continue
    return X, y

# Preprocess the data
def preprocess_data(X, max_length=1000):
    tokenizer = Tokenizer(num_words=5000, lower=True)
    tokenizer.fit_on_texts(X)
    X_seq = tokenizer.texts_to_sequences(X)
    X_pad = pad_sequences(X_seq, maxlen=max_length)
    return X_pad, tokenizer

# Build the model
def build_model(input_length, num_tokens, embedding_dim=200):
    input_layer = Input(shape=(input_length,))
    embedding_layer = Embedding(num_tokens, embedding_dim)(input_layer)
    x = Bidirectional(LSTM(128, return_sequences=True))(embedding_layer)
    x = Bidirectional(LSTM(128, return_sequences=False))(x)
    x = Dense(64, activation="relu")(x)
    x = Dropout(0.25)(x)
    x = Dense(64, activation="relu")(x)
    x = Dropout(0.25)(x)
    output_layer = Dense(1, activation="sigmoid")(x)  # Binary classification
    model = Model(inputs=input_layer, outputs=output_layer)
    model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])
    return model

# Evaluate the model
def evaluate_model(model, X_test, y_test):
    y_pred = (model.predict(X_test) > 0.5).astype("int32")
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    return accuracy, precision, recall

# Main function to execute the workflow
def main():
    # Load and preprocess data
    file_path = 'path_to_your_sql_queries_dataset.json'  # Update with your dataset path
    X, y = load_data(file_path)
    
    # Convert labels to numpy array
    y = np.array(y)
    
    # Preprocess the SQL queries
    X_pad, tokenizer = preprocess_data(X)
    
    # Split the dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42)
    
    # Build the model
    model = build_model(input_length=X_pad.shape[1], num_tokens=len(tokenizer.word_index) + 1)
    
    # Set up model checkpointing
    checkpoint = ModelCheckpoint('best_sql_injection_model.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)
    
    # Train the model
    model.fit(X_train, y_train, batch_size=64, epochs=10, validation_split=0.1, callbacks=[checkpoint])
    
    # Evaluate the model
    accuracy, precision, recall = evaluate_model(model, X_test, y_test)
    print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}')

if __name__ == "__main__":
    main()
```
------------------------------------- 38
```python
import re
import nltk
import pandas as pd
import numpy as np
import tensorflow as tf
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Attention, Concatenate
import subprocess

# Download necessary NLTK resources
try:
    nltk.data.find('stopwords.zip')
    nltk.data.find('punkt.zip')
    nltk.data.find('wordnet.zip')
except:
    nltk.download('stopwords')
    nltk.download('punkt')
    nltk.download('wordnet')

# Load the dataset
data = pd.read_csv('/path/to/your/news_articles.csv')  # Update with your dataset path

# Preprocessing
data['text'] = data['text'].astype(str)
data['summary'] = data['summary'].astype(str)

# Split the data into training and testing sets
train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)

# Preprocessing function
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()
url_pattern = re.compile(r'https?://\S+')

def preprocess_text(text):
    text = text.lower()  # Convert to lowercase
    text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
    text = url_pattern.sub('', text)  # Remove URLs
    tokens = word_tokenize(text)  # Tokenization
    filtered_tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]
    return ' '.join(filtered_tokens)

# Apply preprocessing
train_data['preprocessed_text'] = train_data['text'].apply(preprocess_text)
train_data['preprocessed_summary'] = train_data['summary'].apply(preprocess_text)

# Tokenization
tokenizer = Tokenizer()
tokenizer.fit_on_texts(train_data['preprocessed_text'])
vocab_size = len(tokenizer.word_index) + 1

# Convert texts to sequences
train_sequences = tokenizer.texts_to_sequences(train_data['preprocessed_text'])
train_summary_sequences = tokenizer.texts_to_sequences(train_data['preprocessed_summary'])

# Padding sequences
max_length = max(len(seq) for seq in train_sequences)
train_sequences = pad_sequences(train_sequences, maxlen=max_length, padding='post')
train_summary_sequences = pad_sequences(train_summary_sequences, maxlen=max_length, padding='post')

# Define the model
def create_model(vocab_size, max_length):
    # Encoder
    encoder_inputs = Input(shape=(max_length,))
    encoder_embedding = Embedding(input_dim=vocab_size, output_dim=128)(encoder_inputs)
    encoder_lstm = LSTM(128, return_sequences=True)(encoder_embedding)

    # Decoder
    decoder_inputs = Input(shape=(max_length,))
    decoder_embedding = Embedding(input_dim=vocab_size, output_dim=128)(decoder_inputs)
    decoder_lstm = LSTM(128, return_sequences=True)(decoder_embedding)

    # Attention layer
    attention = Attention()([decoder_lstm, encoder_lstm])
    decoder_combined_context = Concatenate()([decoder_lstm, attention])

    # Output layer
    decoder_dense = Dense(vocab_size, activation='softmax')(decoder_combined_context)

    # Model
    model = Model([encoder_inputs, decoder_inputs], decoder_dense)
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

# Create and train the model
model = create_model(vocab_size, max_length)
model.summary()

# Prepare decoder input data
decoder_input_data = np.zeros((len(train_summary_sequences), max_length))
for i, seq in enumerate(train_summary_sequences):
    for t in range(1, len(seq)):
        decoder_input_data[i, t-1] = seq[t-1]

# Train the model
model.fit([train_sequences, decoder_input_data], np.expand_dims(train_summary_sequences, -1), 
          batch_size=64, epochs=10, validation_split=0.2)

# Save the model
model.save('text_summarization_model.h5')

# Function to summarize text
def summarize_text(text):
    preprocessed_text = preprocess_text(text)
    sequence = tokenizer.texts_to_sequences([preprocessed_text])
    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post')
    decoder_input = np.zeros((1, max_length))
    output = model.predict([padded_sequence, decoder_input])
    summary = tokenizer.sequences_to_texts(np.argmax(output, axis=-1))
    return summary[0]

# Example usage
example_text = "Your example news article text here."
summary = summarize_text(example_text)
print("Generated Summary:", summary)
```
------------------------------------- 39
```python
import numpy as np
import pandas as pd
import re
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, TimeDistributed
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping
import warnings
import pickle

# Suppress warnings
warnings.filterwarnings("ignore")

# Load the dataset
def load_data(file_path):
    encodings_to_try = ['utf-8', 'latin1', 'ISO-8859-1', 'utf-16']
    for encoding in encodings_to_try:
        try:
            df = pd.read_csv(file_path, encoding=encoding)
            print(f"Successfully read CSV file using encoding: {encoding}")
            return df
        except UnicodeDecodeError:
            print(f"Failed to read CSV file using encoding: {encoding}")
    return None

# Clean text function
def text_cleaner(column):
    for row in column:
        row = re.sub(r'\s+', ' ', str(row)).strip()  # Remove extra spaces
        yield row

# Preprocess the data
def preprocess_data(df):
    # Combine text and summary columns
    data = pd.DataFrame({
        'text': df['text'],
        'summary': df['summary']
    })

    # Clean text and summary
    cleaned_text = list(text_cleaner(data['text']))
    cleaned_summary = list(text_cleaner(data['summary']))

    # Add cleaned data back to DataFrame
    data['clean_text'] = cleaned_text
    data['clean_summary'] = cleaned_summary

    return data[['clean_text', 'clean_summary']]

# Tokenize and pad sequences
def tokenize_and_pad(data, max_text_len, max_summary_len):
    x_tokenizer = Tokenizer()
    x_tokenizer.fit_on_texts(data['clean_text'])
    x_train_seq = x_tokenizer.texts_to_sequences(data['clean_text'])
    x_train = pad_sequences(x_train_seq, maxlen=max_text_len, padding='post')

    y_tokenizer = Tokenizer()
    y_tokenizer.fit_on_texts(data['clean_summary'])
    y_train_seq = y_tokenizer.texts_to_sequences(data['clean_summary'])
    y_train = pad_sequences(y_train_seq, maxlen=max_summary_len, padding='post')

    return x_train, y_train, x_tokenizer, y_tokenizer

# Build the model
def build_model(x_voc, y_voc, max_text_len, max_summary_len):
    latent_dim = 256
    embedding_dim = 100

    # Encoder
    encoder_inputs = Input(shape=(max_text_len,))
    enc_emb = Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)
    encoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)
    encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)

    # Decoder
    decoder_inputs = Input(shape=(None,))
    dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)
    dec_emb = dec_emb_layer(decoder_inputs)
    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)
    decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])
    decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))
    decoder_outputs = decoder_dense(decoder_outputs)

    # Define the model
    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)
    return model

# Train the model
def train_model(model, x_train, y_train):
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')
    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)
    history = model.fit([x_train, y_train[:, :-1]], y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:, 1:], 
                        epochs=50, callbacks=[es], batch_size=128, validation_split=0.1)
    return history

# Save the model and tokenizers
def save_model_and_tokenizers(model, x_tokenizer, y_tokenizer):
    model.save('arabic_text_summarization_model.h5')
    with open('x_tokenizer.pkl', 'wb') as handle:
        pickle.dump(x_tokenizer, handle)
    with open('y_tokenizer.pkl', 'wb') as handle:
        pickle.dump(y_tokenizer, handle)

# Main function to run the entire process
def main(file_path):
    df = load_data(file_path)
    data = preprocess_data(df)
    
    max_text_len = 100
    max_summary_len = 15
    x_train, y_train, x_tokenizer, y_tokenizer = tokenize_and_pad(data, max_text_len, max_summary_len)

    x_voc = len(x_tokenizer.word_index) + 1
    y_voc = len(y_tokenizer.word_index) + 1

    model = build_model(x_voc, y_voc, max_text_len, max_summary_len)
    train_model(model, x_train, y_train)

    save_model_and_tokenizers(model, x_tokenizer, y_tokenizer)

# Example usage
file_path = 'path_to_your_arabic_dataset.csv'  # Update with your dataset path
main(file_path)
```
------------------------------------- 40
```python
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
import tensorflow as tf
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.layers import Dense, LSTM, Embedding, Input, TimeDistributed
from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint
from tensorflow.keras.models import Model
from sklearn.model_selection import train_test_split

# Suppress warnings
warnings.filterwarnings('ignore')

# Load the dataset
df1 = pd.read_csv('path_to_first_csv.csv')  # Update with your path
df2 = pd.read_csv('path_to_second_csv.csv')  # Update with your path
df = pd.concat([df1, df2], ignore_index=True)

# Preprocess the dataset
df = df[['text_column_name', 'summary_column_name']]  # Update with your column names
df.rename(columns={'text_column_name': 'text', 'summary_column_name': 'summary'}, inplace=True)
df.dropna(inplace=True)
df.drop_duplicates(inplace=True)

# Add start and end tokens to summaries
df['summary'] = df['summary'].apply(lambda x: '<start> ' + x + ' <end>')

# Tokenization
x_tokenizer = Tokenizer()
x_tokenizer.fit_on_texts(df.text)
text_sequences = x_tokenizer.texts_to_sequences(df.text)
text_pad_sequences = pad_sequences(text_sequences, padding='post')

y_tokenizer = Tokenizer()
y_tokenizer.fit_on_texts(df.summary)
summary_sequences = y_tokenizer.texts_to_sequences(df.summary)
summary_pad_sequences = pad_sequences(summary_sequences, padding='post')

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(text_pad_sequences, summary_pad_sequences, test_size=0.25, random_state=42)

# Define model parameters
max_text_len = X_train.shape[1]
max_summary_len = y_train.shape[1]
latent_dim = 256
embedding_dim = 100

# Encoder
encoder_inputs = Input(shape=(max_text_len,))
enc_emb = Embedding(input_dim=len(x_tokenizer.word_index) + 1, output_dim=embedding_dim)(encoder_inputs)
encoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)
encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)

# Decoder
decoder_inputs = Input(shape=(max_summary_len,))
dec_emb = Embedding(input_dim=len(y_tokenizer.word_index) + 1, output_dim=embedding_dim)(decoder_inputs)
decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)
decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])
decoder_dense = TimeDistributed(Dense(len(y_tokenizer.word_index) + 1, activation='softmax'))
decoder_outputs = decoder_dense(decoder_outputs)

# Define the model
model = Model([encoder_inputs, decoder_inputs], decoder_outputs)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Callbacks
es = EarlyStopping(monitor='val_loss', patience=5, verbose=1)
mc = ModelCheckpoint('text_summarization_model.h5', monitor='val_loss', save_best_only=True, verbose=1)

# Train the model
history = model.fit([X_train, y_train], 
                    y_train.reshape(y_train.shape[0], y_train.shape[1], 1), 
                    epochs=50, 
                    batch_size=64, 
                    validation_data=([X_test, y_test], y_test.reshape(y_test.shape[0], y_test.shape[1], 1)), 
                    callbacks=[es, mc])

# Plot training history
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.title('Loss Over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Function to decode the sequence
def decode_sequence(input_seq):
    e_out, e_h, e_c = encoder_model.predict(input_seq)
    target_seq = np.zeros((1, 1))
    target_seq[0, 0] = y_tokenizer.word_index['<start>']
    stop_condition = False
    decoded_sentence = ''
    
    while not stop_condition:
        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])
        sampled_token_index = np.argmax(output_tokens[0, -1, :])
        sampled_token = y_tokenizer.index_word[sampled_token_index]
        
        if sampled_token != '<end>':
            decoded_sentence += ' ' + sampled_token
            
        if (sampled_token == '<end>' or len(decoded_sentence.split()) >= (max_summary_len - 1)):
            stop_condition = True
            
        target_seq = np.zeros((1, 1))
        target_seq[0, 0] = sampled_token_index
        e_h, e_c = h, c
        
    return decoded_sentence.strip()

# Example of generating summaries
for i in range(10):
    print("Original Text:", df.text.iloc[i])
    print("Predicted Summary:", decode_sequence(X_test[i].reshape(1, max_text_len)))
    print("\n")
```
------------------------------------- 41
```python
import tensorflow as tf
import numpy as np

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, GRU, Attention
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.utils import pad_sequences

# Markers for start and end of sentences
mark_start = "START "
mark_end = " END"

data_src = []  # English sentences
data_dest = []  # French sentences

# Load and preprocess the dataset
for line in open('/path/to/french-english-dataset.txt', encoding='UTF-8'):
    en_text, fr_text = line.rstrip().split('\t')
    
    fr_text = mark_start + fr_text + mark_end
    
    data_src.append(en_text)
    data_dest.append(fr_text)

# Function to tokenize texts
def tokenize_texts(texts, num_words=None):
    tokenizer = Tokenizer(num_words=num_words)
    tokenizer.fit_on_texts(texts)
    return tokenizer

# Function to pad tokens
def pad_tokens(tokens, maxlen, padding, truncating):
    return pad_sequences(tokens, maxlen=maxlen, padding=padding, truncating=truncating)

# Function to preprocess and tokenize data
def tokenize_and_preprocess(texts, padding, reverse=False, num_words=None):
    tokenizer = tokenize_texts(texts, num_words=num_words)
    index_to_word = dict(zip(tokenizer.word_index.values(), tokenizer.word_index.keys()))
    
    tokens = tokenizer.texts_to_sequences(texts)
    if reverse:
        tokens = [list(reversed(x)) for x in tokens]
        truncating = "pre"
    else:
        truncating = "post"

    tokens_padded = pad_tokens(tokens, maxlen=None, padding=padding, truncating=truncating)

    return {
        'tokenizer': tokenizer,
        'index_to_word': index_to_word,
        'tokens': tokens,
        'tokens_padded': tokens_padded,
    }

# Tokenize and preprocess the source and destination texts
tokenizer_src = tokenize_and_preprocess(data_src, padding="pre", reverse=True)
tokenizer_dest = tokenize_and_preprocess(data_dest, padding="post")

tokens_src = tokenizer_src["tokens_padded"]
tokens_dest = tokenizer_dest["tokens_padded"]

# Prepare the data for training
encoder_input_data = tokens_src
decoder_input_data = tokens_dest[:, :-1]
decoder_output_data = tokens_dest[:, 1:]

num_encoder_words = len(tokenizer_src['tokenizer'].word_index) + 1
num_decoder_words = len(tokenizer_dest['tokenizer'].word_index) + 1

embedding_size = 100

# Create embedding matrices (optional: load pre-trained embeddings)
embedding_matrix = np.random.uniform(-1, 1, (num_encoder_words, embedding_size))

# Encoder
encoder_input = Input(shape=(None,), name='encoder_input')
encoder_embedding = Embedding(input_dim=num_encoder_words, output_dim=embedding_size, name='encoder_embedding')(encoder_input)
encoder_lstm = LSTM(256, return_sequences=True, return_state=True, name='encoder_lstm')
encoder_output, state_h, state_c = encoder_lstm(encoder_embedding)

# Decoder
decoder_input = Input(shape=(None,), name='decoder_input')
decoder_embedding = Embedding(input_dim=num_decoder_words, output_dim=embedding_size, name='decoder_embedding')(decoder_input)

# Attention mechanism
attention = Attention()([decoder_embedding, encoder_output])
decoder_lstm = LSTM(256, return_sequences=True, return_state=True, name='decoder_lstm')
decoder_output, _, _ = decoder_lstm(attention)

# Output layer
decoder_dense = Dense(num_decoder_words, activation='softmax', name='decoder_output')
decoder_output = decoder_dense(decoder_output)

# Define the model
model = Model(inputs=[encoder_input, decoder_input], outputs=decoder_output)

# Compile the model
optimizer = RMSprop(lr=0.001)
model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy')

# Model checkpoint
path_checkpoint = 'checkpoint.keras'
checkpoint = ModelCheckpoint(filepath=path_checkpoint, monitor='val_loss', verbose=1, save_best_only=True, mode='min', save_weights_only=True)

# Train the model
model.fit(x=[encoder_input_data, decoder_input_data], y=np.expand_dims(decoder_output_data, -1),
          batch_size=512, epochs=20, callbacks=[checkpoint])

# Save the model weights
model.save_weights("seq2seq_attention_weights.keras")

# Function to translate sentences
def translate(input_text):
    input_tokens = tokenizer_src['tokenizer'].texts_to_sequences([input_text])
    input_tokens = pad_tokens(input_tokens, maxlen=encoder_input_data.shape[1], padding='pre', truncating='pre')
    
    encoder_output = model.predict(input_tokens)
    
    # Initialize decoder input
    decoder_input_data = np.zeros((1, tokens_dest.shape[1] - 1))
    decoder_input_data[0, 0] = tokenizer_dest['tokenizer'].word_index[mark_start]
    
    translated_sentence = ''
    
    for i in range(tokens_dest.shape[1] - 1):
        output_tokens = model.predict([input_tokens, decoder_input_data])
        sampled_token_index = np.argmax(output_tokens[0, i, :])
        sampled_word = tokenizer_dest['index_to_word'].get(sampled_token_index, '')
        
        if sampled_word == mark_end.strip():
            break
        
        translated_sentence += ' ' + sampled_word
        
        # Update decoder input
        decoder_input_data[0, i + 1] = sampled_token_index
    
    print('Input text:', input_text)
    print('Translated text:', translated_sentence.strip())

# Example translation
translate("This is a test sentence.")
```
------------------------------------- 42
```python
import warnings
warnings.filterwarnings('ignore')

import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import seaborn as sns
from tqdm.auto import tqdm 

import re
from nltk.corpus import stopwords 
from collections import Counter 
from string import punctuation 

from sklearn.model_selection import train_test_split 

import tensorflow as tf 
from tensorflow import keras 
from tensorflow.keras.preprocessing.text import Tokenizer 
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Bidirectional, Dense, LSTM, Embedding, Concatenate, Dropout, TimeDistributed
from tensorflow.keras.losses import SparseCategoricalCrossentropy
from tensorflow.keras.optimizers import Adam

# Check for GPU availability
gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
    print("Name:", gpu.name, "  Type:", gpu.device_type)

tf.test.is_gpu_available()

# Load dataset
df = pd.read_csv('/path/to/turkish-english-dataset.csv')  # Update with your dataset path

def turkish_preprocessing(data, col): 
    data[col] = data[col].astype(str) 
    data[col] = data[col].apply(lambda x: x.lower())
    data[col] = data[col].apply(lambda x: re.sub("[^A-Za-z\s]", "", x)) 
    data[col] = data[col].apply(lambda x: re.sub("\s+", " ", x))
    return data 

def english_preprocessing(data, col): 
    data[col] = data[col].astype(str) 
    data[col] = data[col].apply(lambda x: x.lower()) 
    data[col] = data[col].apply(lambda x: re.sub("[^A-Za-z\s]", "", x))
    data[col] = data[col].apply(lambda x: re.sub("\s+", " ", x))
    return data

# Preprocess the dataset
df = turkish_preprocessing(df, 'turkish')
df = english_preprocessing(df, 'english')

# Filter sentences by length
df["turkish_len"] = [len(text.split()) for text in df.turkish]
df['english_len'] = [len(text.split()) for text in df.english]

df = df[~(df['turkish_len'] < 5) & ~(df['turkish_len'] > 20)]
df = df[~(df['english_len'] < 5) & ~(df['english_len'] > 20)]

# Vectorization function
def Vectorization(col, MAXLEN=20): 
    sents = df[col].tolist() 
    
    # Build vocabulary 
    corpus = [word for text in df[col] for word in text.split()] 
    vocab_size = len(Counter(corpus)) 
    
    tokenizer = Tokenizer(num_words=vocab_size, oov_token="<OOV>", 
                          filters='!#$%&()*+,-/:;<=>@""[\\]^_`{|}~\t\n')
    tokenizer.fit_on_texts(sents) 
    
    tokenizer.word_index['<pad>'] = 0 
    tokenizer.index_word[0] = '<pad>' 
    
    vocab_to_idx = tokenizer.word_index 
    idx_to_vocab = tokenizer.index_word 
    
    # Text Vectorization 
    seqs = tokenizer.texts_to_sequences(sents) 
    pad_seqs = pad_sequences(seqs, maxlen=MAXLEN, padding='post')
    
    return vocab_to_idx, idx_to_vocab, pad_seqs, tokenizer

# Vectorize Turkish and English sentences
turkish_vocab, turkish_inv_vocab, turkish_seqs, turkish_tokenizer = Vectorization('turkish')
english_vocab, english_inv_vocab, english_seqs, english_tokenizer = Vectorization('english')

# Split the dataset into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(english_seqs, turkish_seqs, train_size=0.80, random_state=42)

# Create TensorFlow datasets
BATCH_SIZE = 128
BUFFER_SIZE = 1000

train_set = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_set = train_set.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)

val_set = tf.data.Dataset.from_tensor_slices((x_val, y_val))
val_set = val_set.batch(BATCH_SIZE, drop_remainder=True)

# Define model parameters
EMBEDDING_DIM = 256
SRC_VOCAB_SIZE = len(english_vocab) + 1 
TRG_VOCAB_SIZE = len(turkish_vocab) + 1 
HIDDEN_DIM = 512
MAXLEN = 20
EPOCHS = 50
LR = 0.001

# Define Attention mechanism
class Attention(Model): 
    def __init__(self, hidden_dim): 
        super(Attention, self).__init__() 
        self.W1 = Dense(hidden_dim) 
        self.W2 = Dense(hidden_dim) 
        self.V = Dense(1)
        
    def call(self, s_hidden, h_hidden): 
        s_hidden = tf.expand_dims(s_hidden, axis=1) 
        score = tf.nn.tanh(self.W1(s_hidden) + self.W2(h_hidden))
        attention_weights = tf.nn.softmax(self.V(score), axis=1)
        context_vector = attention_weights * h_hidden 
        context_vector = tf.reduce_sum(context_vector, axis=1)
        context_vector = tf.expand_dims(context_vector, axis=1)
        return context_vector, attention_weights 

# Define Encoder
class Encoder(Model): 
    def __init__(self, vocab_size, embedding_dim, hidden_dim): 
        super(Encoder, self).__init__() 
        self.embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)
        self.lstm = Bidirectional(LSTM(hidden_dim // 2, return_sequences=True, return_state=True))
        
    def call(self, x): 
        embed = self.embedding(x) 
        enc_output, forward_h, forward_c, backward_h, backward_c = self.lstm(embed) 
        state_h = Concatenate()([forward_h, backward_h]) 
        state_c = Concatenate()([forward_c, backward_c])
        return enc_output, state_h, state_c

# Define Decoder
class Decoder(Model): 
    def __init__(self, vocab_size, embedding_dim, hidden_dim): 
        super(Decoder, self).__init__() 
        self.units = hidden_dim 
        self.embedding = Embedding(vocab_size, embedding_dim, mask_zero=True) 
        self.lstm = LSTM(hidden_dim, return_sequences=True, return_state=True) 
        self.attention = Attention(hidden_dim) 
        self.fc = TimeDistributed(Dense(vocab_size, activation='softmax'))
        
    def call(self, x, enc_output, state_h, state_c): 
        embed = self.embedding(x)
        context_vector, attention_weights = self.attention(state_h, enc_output) 
        context_vector = Concatenate(axis=-1)([context_vector, embed]) 
        dec_output, dec_h, dec_c = self.lstm(context_vector, initial_state=[state_h, state_c])
        output = self.fc(dec_output)
        return output, dec_h, dec_c, attention_weights

# Instantiate Encoder and Decoder
encoder = Encoder(SRC_VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM)
decoder = Decoder(TRG_VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM)

# Define loss and optimizer
optimizer = Adam(learning_rate=LR)
loss_object = SparseCategoricalCrossentropy()

def criterion(real, pred): 
    mask = tf.math.logical_not(tf.math.equal(real, 0)) 
    loss = loss_object(real, pred) 
    mask = tf.cast(mask, dtype=loss.dtype)
    loss *= mask 
    loss = tf.reduce_mean(loss)
    return loss

@tf.function 
def train_step(src, trg): 
    loss = 0 
    with tf.GradientTape() as tape: 
        enc_output, state_h, state_c = encoder(src)
        dec_input = tf.expand_dims(trg[:, 0], 1)
        
        for i in range(1, trg.shape[1]): 
            dec_output, state_h, state_c, _ = decoder(dec_input, enc_output, state_h, state_c)
            loss += criterion(trg[:, i], dec_output[:, 0, :]) 
            dec_input = tf.expand_dims(trg[:, i], 1)
            
    batch_loss = (loss / int(trg.shape[1])) 
    ModelWeights = encoder.trainable_variables + decoder.trainable_variables 
    gradients = tape.gradient(loss, ModelWeights)
    optimizer.apply_gradients(zip(gradients, ModelWeights))
    
    return batch_loss 

@tf.function 
def val_step(src, trg): 
    loss = 0 
    enc_output, state_h, state_c = encoder(src) 
    dec_input = tf.expand_dims(trg[:, 0], 1)
    
    for i in range(1, trg.shape[1]): 
        dec_output, state_h, state_c, _ = decoder(dec_input, enc_output, state_h, state_c)
        loss += criterion(trg[:, i], dec_output[:, 0, :])
        dec_input = tf.expand_dims(trg[:, i], 1)
        
    batch_loss = (loss / int(trg.shape[1]))
    return batch_loss

# Training loop
with tf.device("/GPU:0"): 
    training_losses = []
    val_losses = []
    for epoch in tqdm(range(EPOCHS)): 
        epoch_loss = [] 
        epoch_val_loss = [] 

        for x_train, y_train in train_set: 
            loss = train_step(x_train, y_train)
            epoch_loss.append(loss)

        for x_val, y_val in val_set: 
            val_loss = val_step(x_val, y_val) 
            epoch_val_loss.append(val_loss) 

        training_losses.append(np.mean(epoch_loss))
        val_losses.append(np.mean(epoch_val_loss))
        if (epoch + 1) % 10 == 0: 
            print(f"Epoch : {epoch+1} , Training Loss : {training_losses[-1]} , Validation Loss : {val_losses[-1]}\n")

# Plot training and validation losses
plt.plot(training_losses, label='train') 
plt.plot(val_losses, label='validation') 
plt.title('Training/Validation Loss over Epochs') 
plt.xlabel('epoch') 
plt.ylabel('Loss') 
plt.legend() 
plt.show()

# Save model weights
encoder.save_weights('turkish_english_encoder.h5') 
decoder.save_weights('turkish_english_decoder.h5')

# Load weights
encoder.load_weights('turkish_english_encoder.h5') 
decoder.load_weights('turkish_english_decoder.h5')

# Prediction function
def predict_sentence(en_input): 
    eng_seq = english_tokenizer.texts_to_sequences([en_input]) 
    en_input = pad_sequences(eng_seq, maxlen=MAXLEN, padding='post') 
    
    hidden_state, next_h, next_c = encoder(en_input) 
    attn_plot = [] 
    
    curr_token = np.zeros((1, 1)) 
    curr_token[0, 0] = turkish_tokenizer.word_index['<sos>'] 
    
    pred_sent = ''
    
    for i in range(MAXLEN): 
        output, next_h, next_c, attn_w = decoder(curr_token, hidden_state, next_h, next_c)
        attn_plot.append(attn_w.numpy().reshape(-1, )) 
        next_token = np.argmax(output[:, 0, :], axis=1)[0] 
        next_word = turkish_tokenizer.index_word[next_token] 
        
        if next_word == '<eos>':
            break
        else:
            pred_sent += ' ' + next_word
            curr_token[0, 0] = next_token
            
    return pred_sent.strip(), np.array(attn_plot)

# Test the model with sample sentences
test_sample = df.sample(1000)
x_test = test_sample['english'].tolist() 
y_test = test_sample['turkish'].tolist()

# Plot attention function
def plot_attention(attention, sent, pred_sent): 
    plt.figure(figsize=(9, 6))
    plt.rcParams['font.size'] = 7
    g = sns.heatmap(attention, annot=True, fmt='.2f')
    g.set_xticklabels(sent)
    g.set_yticklabels(pred_sent)
    plt.show()

# Generate predictions and plot attention
for en_sent in x_test[-10:]:
    result, attention_plot = predict_sentence(en_sent)
    print(f"English sentence: {en_sent}")
    print(f"Predicted translation: {result}")
    attention_plot = attention_plot[:len(result.split()), :len(en_sent.split())]
    plot_attention(attention_plot, en_sent.split(), result.split())
```
------------------------------------- 43
```python
# Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers import TextVectorization
from tensorflow.keras.callbacks import EarlyStopping
import json
import re

# Load the dataset
data_path = '/path/to/your/english_french_dataset.csv'  # Update with your dataset path
dataset = pd.read_csv(data_path)

# Preprocess the dataset
dataset['English'] = dataset['English'].str.lower()
dataset['French'] = "[start] " + dataset['French'] + " [end]"

# Split the dataset into training and testing
train_size = int(0.9 * len(dataset))
train_pairs = dataset[:train_size].values
test_pairs = dataset[train_size:].values

# Define parameters
vocab_size = 50000
sequence_length = 30
batch_size = 128

# Custom standardization function
def custom_standardization(input_string):
    lowercase = tf.strings.lower(input_string)
    return tf.strings.regex_replace(lowercase, "[%s]" % re.escape(string.punctuation), "")

# Text vectorization
eng_vectorization = TextVectorization(max_tokens=vocab_size, output_mode="int", output_sequence_length=sequence_length)
fr_vectorization = TextVectorization(max_tokens=vocab_size, output_mode="int", output_sequence_length=sequence_length + 1, standardize=custom_standardization)

# Adapt the vectorizers
eng_vectorization.adapt(train_pairs[:, 0])
fr_vectorization.adapt(train_pairs[:, 1])

# Create datasets
def format_dataset(eng, fr):
    eng = eng_vectorization(eng)
    fr = fr_vectorization(fr)
    return ({"encoder_inputs": eng, "decoder_inputs": fr[:, :-1]}, fr[:, 1:])

def make_dataset(pairs):
    eng_texts, fr_texts = zip(*pairs)
    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, fr_texts))
    dataset = dataset.batch(batch_size)
    dataset = dataset.map(format_dataset)
    return dataset.shuffle(2048).prefetch(16).cache()

train_ds = make_dataset(train_pairs)
test_ds = make_dataset(test_pairs)

# Define the Transformer model components
class PositionalEmbedding(layers.Layer):
    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):
        super().__init__(**kwargs)
        self.token_embeddings = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)
        self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=embed_dim)

    def call(self, inputs):
        positions = tf.range(start=0, limit=tf.shape(inputs)[-1], delta=1)
        embedded_tokens = self.token_embeddings(inputs)
        embedded_positions = self.position_embeddings(positions)
        return embedded_tokens + embedded_positions

class TransformerEncoder(layers.Layer):
    def __init__(self, embed_dim, num_heads, **kwargs):
        super().__init__(**kwargs)
        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.dense_proj = keras.Sequential([layers.Dense(embed_dim, activation="relu"), layers.Dense(embed_dim)])
        self.layernorm_1 = layers.LayerNormalization()
        self.layernorm_2 = layers.LayerNormalization()

    def call(self, inputs):
        attention_output = self.attention(query=inputs, value=inputs, key=inputs)
        proj_input = self.layernorm_1(inputs + attention_output)
        proj_output = self.dense_proj(proj_input)
        return self.layernorm_2(proj_input + proj_output)

class TransformerDecoder(layers.Layer):
    def __init__(self, embed_dim, num_heads, **kwargs):
        super().__init__(**kwargs)
        self.attention_1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.attention_2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.dense_proj = keras.Sequential([layers.Dense(embed_dim, activation="relu"), layers.Dense(embed_dim)])
        self.layernorm_1 = layers.LayerNormalization()
        self.layernorm_2 = layers.LayerNormalization()
        self.layernorm_3 = layers.LayerNormalization()

    def call(self, inputs, encoder_outputs):
        attention_output_1 = self.attention_1(query=inputs, value=inputs, key=inputs)
        out_1 = self.layernorm_1(inputs + attention_output_1)
        attention_output_2 = self.attention_2(query=out_1, value=encoder_outputs, key=encoder_outputs)
        out_2 = self.layernorm_2(out_1 + attention_output_2)
        proj_output = self.dense_proj(out_2)
        return self.layernorm_3(out_2 + proj_output)

# Build the Transformer model
embed_dim = 512
num_heads = 8

encoder_inputs = keras.Input(shape=(None,), dtype="int64", name="encoder_inputs")
x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)
encoder_outputs = TransformerEncoder(embed_dim, num_heads)(x)

decoder_inputs = keras.Input(shape=(None,), dtype="int64", name="decoder_inputs")
x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)
decoder_outputs = TransformerDecoder(embed_dim, num_heads)(x, encoder_outputs)

# Create the complete model
transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)

# Compile the model
transformer.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# Train the model
epochs = 30
history = transformer.fit(train_ds, epochs=epochs, validation_data=test_ds)

# Function to visualize attention scores
def plot_attention_weights(attention_weights, input_sentence, translated_sentence):
    fig = plt.figure(figsize=(10, 10))
    ax = fig.add_subplot(1, 1, 1)
    ax.matshow(attention_weights, cmap='viridis')
    plt.xticks(range(len(input_sentence.split())), input_sentence.split(), rotation=90)
    plt.yticks(range(len(translated_sentence.split())), translated_sentence.split())
    plt.xlabel('Input Sentence')
    plt.ylabel('Translated Sentence')
    plt.title('Attention Weights')
    plt.show()

# Example usage of the model to visualize attention
def decode_sequence(input_sentence):
    tokenized_input_sentence = eng_vectorization([input_sentence])
    decoded_sentence = "[start]"
    attention_weights_list = []
    
    for i in range(sequence_length):
        tokenized_target_sentence = fr_vectorization([decoded_sentence])[:, :-1]
        predictions, attention_weights = transformer([tokenized_input_sentence, tokenized_target_sentence], training=False)
        sampled_token_index = np.argmax(predictions[0, i, :])
        sampled_token = fr_vectorization.get_vocabulary()[sampled_token_index]
        decoded_sentence += " " + sampled_token
        
        # Store attention weights for visualization
        attention_weights_list.append(attention_weights)
        
        if sampled_token == "[end]":
            break
            
    return decoded_sentence, attention_weights_list

# Test the model and visualize attention
input_sentence = 'I love programming'
output_sentence, attention_weights = decode_sequence(input_sentence)
print("Translated Sentence:", output_sentence)

# Plot the attention weights for the first attention layer
plot_attention_weights(attention_weights[0][0], input_sentence, output_sentence)
```
------------------------------------- 44
```python
import warnings
warnings.filterwarnings('ignore')

import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import plotly.express as px
from tqdm.auto import tqdm 

import re
from nltk.corpus import stopwords 
from collections import Counter 
from string import punctuation 

from sklearn.model_selection import train_test_split 

import tensorflow as tf 
from tensorflow import keras 
from tensorflow.keras.preprocessing.text import Tokenizer 
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Bidirectional, Dense, LSTM, Embedding, Concatenate, Dropout, TimeDistributed
from tensorflow.keras.losses import SparseCategoricalCrossentropy
from tensorflow.keras.optimizers import Adam

# Check for GPU availability
gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
    print("Name:", gpu.name, "  Type:", gpu.device_type)

tf.test.is_gpu_available()

# Load the dataset
df = pd.read_csv('/path/to/your/english-tamil-dataset.csv')

def preprocess_data(data, col, lang):
    """Preprocess the text data by cleaning and normalizing."""
    data[col] = data[col].astype(str) 
    data[col] = data[col].apply(lambda x: x.lower())
    data[col] = data[col].apply(lambda x: re.sub("[^A-Za-z\s]","",x)) 
    data[col] = data[col].apply(lambda x: re.sub("\s+", " ", x))
    data[col] = data[col].apply(lambda x: x.strip())
    if lang == 'tamil':
        data[col] = "<sos> " + data[col] + " <eos>"
    return data 

# Preprocess English and Tamil sentences
df = preprocess_data(df, 'english', 'english')
df = preprocess_data(df, 'tamil', 'tamil')

# Filter sentences by length
df["en_len"] = [len(text.split()) for text in df.english]
df['ta_len'] = [len(text.split()) for text in df.tamil]
df = df[~(df['en_len'] < 5) & ~(df['en_len'] > 20)]
df = df[~(df['ta_len'] < 5) & ~(df['ta_len'] > 20)]

# Vectorization function
def vectorization(col, maxlen=20): 
    """Tokenize and pad the sequences."""
    sents = df[col].tolist() 
    tokenizer = Tokenizer(oov_token="<OOV>")
    tokenizer.fit_on_texts(sents) 
    seqs = tokenizer.texts_to_sequences(sents) 
    pad_seqs = pad_sequences(seqs, maxlen=maxlen, padding='post')
    return tokenizer.word_index, pad_seqs

# Vectorize English and Tamil sentences
en_vocab, en_seqs = vectorization('english')
ta_vocab, ta_seqs = vectorization('tamil')

# Split the dataset into training, validation, and test sets
x_train, x_test, y_train, y_test = train_test_split(ta_seqs, en_seqs, train_size=0.95, random_state=42)
x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size=0.75, random_state=42)

# Create TensorFlow datasets
BATCH_SIZE = 128
BUFFER_SIZE = 1000

train_set = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)
val_set = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(BATCH_SIZE, drop_remainder=True)
test_set = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE, drop_remainder=True)

# Define model parameters
EMBEDDING_DIM = 256
SRC_VOCAB_SIZE = len(ta_vocab) + 1
TRG_VOCAB_SIZE = len(en_vocab) + 1
HIDDEN_DIM = 512
EPOCHS = 100
LR = 0.001

class Attention(Model):
    """Attention mechanism for the decoder."""
    def __init__(self, hidden_dim):
        super(Attention, self).__init__()
        self.W1 = Dense(hidden_dim)
        self.W2 = Dense(hidden_dim)
        self.V = Dense(1)

    def call(self, s_hidden, h_hidden):
        s_hidden = tf.expand_dims(s_hidden, axis=1)
        score = tf.nn.tanh(self.W1(s_hidden) + self.W2(h_hidden))
        attention_weights = tf.nn.softmax(self.V(score), axis=1)
        context_vector = attention_weights * h_hidden
        context_vector = tf.reduce_sum(context_vector, axis=1)
        context_vector = tf.expand_dims(context_vector, axis=1)
        return context_vector, attention_weights

class Encoder(Model):
    """Encoder for the transformer model."""
    def __init__(self, vocab_size, embedding_dim, hidden_dim):
        super(Encoder, self).__init__()
        self.embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)
        self.lstm = Bidirectional(LSTM(hidden_dim // 2, return_sequences=True, return_state=True))

    def call(self, x):
        embed = self.embedding(x)
        enc_output, forward_h, forward_c, backward_h, backward_c = self.lstm(embed)
        state_h = Concatenate()([forward_h, backward_h])
        state_c = Concatenate()([forward_c, backward_c])
        return enc_output, state_h, state_c

class Decoder(Model):
    """Decoder for the transformer model."""
    def __init__(self, vocab_size, embedding_dim, hidden_dim):
        super(Decoder, self).__init__()
        self.units = hidden_dim
        self.embedding = Embedding(vocab_size, embedding_dim, mask_zero=True)
        self.lstm = LSTM(hidden_dim, return_sequences=True, return_state=True)
        self.attention = Attention(hidden_dim)
        self.fc = TimeDistributed(Dense(vocab_size, activation='softmax'))

    def call(self, x, enc_output, state_h, state_c):
        embed = self.embedding(x)
        context_vector, attention_weights = self.attention(state_h, enc_output)
        context_vector = Concatenate(axis=-1)([context_vector, embed])
        dec_output, dec_h, dec_c = self.lstm(context_vector, initial_state=[state_h, state_c])
        output = self.fc(dec_output)
        return output, dec_h, dec_c, attention_weights

# Instantiate encoder and decoder
encoder = Encoder(SRC_VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM)
decoder = Decoder(TRG_VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM)

# Define loss function and optimizer
optimizer = Adam(learning_rate=LR)
loss_object = SparseCategoricalCrossentropy()

def criterion(real, pred):
    mask = tf.math.logical_not(tf.math.equal(real, 0))
    loss = loss_object(real, pred)
    mask = tf.cast(mask, dtype=loss.dtype)
    loss *= mask
    return tf.reduce_mean(loss)

@tf.function
def train_step(src, trg):
    loss = 0
    with tf.GradientTape() as tape:
        enc_output, state_h, state_c = encoder(src)
        dec_input = tf.expand_dims(trg[:, 0], 1)
        for i in range(1, trg.shape[1]):
            dec_output, state_h, state_c, _ = decoder(dec_input, enc_output, state_h, state_c)
            loss += criterion(trg[:, i], dec_output[:, 0, :])
            dec_input = tf.expand_dims(trg[:, i], 1)
    batch_loss = (loss / int(trg.shape[1]))
    ModelWeights = encoder.trainable_variables + decoder.trainable_variables
    gradients = tape.gradient(loss, ModelWeights)
    optimizer.apply_gradients(zip(gradients, ModelWeights))
    return batch_loss

@tf.function
def val_step(src, trg):
    loss = 0
    enc_output, state_h, state_c = encoder(src)
    dec_input = tf.expand_dims(trg[:, 0], 1)
    for i in range(1, trg.shape[1]):
        dec_output, state_h, state_c, _ = decoder(dec_input, enc_output, state_h, state_c)
        loss += criterion(trg[:, i], dec_output[:, 0, :])
        dec_input = tf.expand_dims(trg[:, i], 1)
    return loss / int(trg.shape[1])

# Training loop
with tf.device("/GPU:0"):
    training_losses = []
    val_losses = []
    for epoch in tqdm(range(EPOCHS)):
        epoch_loss = []
        epoch_val_loss = []

        for x_train, y_train in train_set:
            loss = train_step(x_train, y_train)
            epoch_loss.append(loss)

        for x_val, y_val in val_set:
            val_loss = val_step(x_val, y_val)
            epoch_val_loss.append(val_loss)

        training_losses.append(np.mean(epoch_loss))
        val_losses.append(np.mean(epoch_val_loss))
        if (epoch + 1) % 10 == 0:
            print(f"Epoch : {epoch+1} , Training Loss : {training_losses[-1]} , Validation Loss : {val_losses[-1]}\n")

# Save the model
encoder.save('encoder_model.h5')
decoder.save('decoder_model.h5')
```
------------------------------------- 45
